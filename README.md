# Enhancing Text Summarization of Biomedical Journal Papers with Domain-Specific Knowledge Integration in State-of-the-Art NLP Models

### Nilay Bhatt, Tom Shin, Luning Yang

## Abstract
The exponential growth of biomedical literature over the past decade has not just created a need,2
but a pressing need for efficient summarization tools. These tools are crucial for researchers to stay3
informed about recent developments in their field. As the volume and complexity of scientific papers4
increase, automated summarization has become indispensable for researchers aiming to distill key5
information rapidly. Although modern Natural Language Processing (NLP) models like BERT and6
GPT have shown promising results in text summarization, they often need help to fully capture the7
nuances and domain-specific language inherent in biomedical texts. This results in summaries that8
lack accuracy or comprehensiveness, posing a significant challenge for researchers.9
To address these challenges, this project not only leverages state-of-the-art NLP models, including10
BART, T5, and LED, but also supplements them with domain-specific biomedical knowledge. This11
unique approach is designed to enhance the summarization quality of biomedical journal papers.12
By integrating specialized knowledge with these advanced models, we aim to not just improve the13
accuracy and conciseness of summaries, but also make them contextually relevant. This will enable14
researchers to navigate the rapidly expanding scientific literature more effectively. Our experimental15
design involves in-domain and cross-domain summarization tasks to rigorously assess and refine our16
models. Ultimately, our goal is to establish new benchmarks for summarization in this specialized17
field, a significant step towards advancing biomedical literature summarization.
