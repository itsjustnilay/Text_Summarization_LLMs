{"lay_summary": " the short - term periodicities of the daily sunspot area fluctuations from august 1923 to october 1933 are discussed . for these data \n the correlative analysis indicates negative correlation for the periodicity of about @xmath0 days , but the power spectrum analysis indicates a statistically significant peak in this time interval . \n a new method of the diagnosis of an echo - effect in spectrum is proposed and it is stated that the 155-day periodicity is a harmonic of the periodicities from the interval of @xmath1 $ ] days .    the autocorrelation functions for the daily sunspot area fluctuations and for the fluctuations of the one rotation time interval in the northern hemisphere , separately for the whole solar cycle 16 and for the maximum activity period of this cycle do not show differences , especially in the interval of @xmath2 $ ] days . \n it proves against the thesis of the existence of strong positive fluctuations of the about @xmath0-day interval in the maximum activity period of the solar cycle 16 in the northern hemisphere . \n however , a similar analysis for data from the southern hemisphere indicates that there is the periodicity of about @xmath0 days in sunspot area data in the maximum activity period of the cycle 16 only . ", "article": "for about 20 years the problem of properties of short - term changes of solar activity has been considered extensively .\nmany investigators studied the short - term periodicities of the various indices of solar activity .\nseveral periodicities were detected , but the periodicities about 155 days and from the interval of @xmath3 $ ] days ( @xmath4 $ ] years ) are mentioned most often .\nfirst of them was discovered by @xcite in the occurence rate of gamma - ray flares detected by the gamma - ray spectrometer aboard the _ solar maximum mission ( smm ) .\nthis periodicity was confirmed for other solar flares data and for the same time period @xcite .\nit was also found in proton flares during solar cycles 19 and 20 @xcite , but it was not found in the solar flares data during solar cycles 22 @xcite .\n_    several autors confirmed above results for the daily sunspot area data . @xcite studied the sunspot data from 18741984 .\nshe found the 155-day periodicity in data records from 31 years .\nthis periodicity is always characteristic for one of the solar hemispheres ( the southern hemisphere for cycles 1215 and the northern hemisphere for cycles 1621 ) .\nmoreover , it is only present during epochs of maximum activity ( in episodes of 13 years ) .\nsimilarinvestigationswerecarriedoutby + @xcite .\nthey applied the same power spectrum method as lean , but the daily sunspot area data ( cycles 1221 ) were divided into 10 shorter time series .\nthe periodicities were searched for the frequency interval 57115 nhz ( 100200 days ) and for each of 10 time series .\nthe authors showed that the periodicity between 150160 days is statistically significant during all cycles from 16 to 21 .\nthe considered peaks were remained unaltered after removing the 11-year cycle and applying the power spectrum analysis .\n@xcite used the wavelet technique for the daily sunspot areas between 1874 and 1993 .\nthey determined the epochs of appearance of this periodicity and concluded that it presents around the maximum activity period in cycles 16 to 21 .\nmoreover , the power of this periodicity started growing at cycle 19 , decreased in cycles 20 and 21 and disappered after cycle 21 .\nsimilaranalyseswerepresentedby + @xcite , but for sunspot number , solar wind plasma , interplanetary magnetic field and geomagnetic activity index @xmath5 .\nduring 1964 - 2000 the sunspot number wavelet power of periods less than one year shows a cyclic evolution with the phase of the solar cycle.the 154-day period is prominent and its strenth is stronger around the 1982 - 1984 interval in almost all solar wind parameters .\nthe existence of the 156-day periodicity in sunspot data were confirmed by @xcite .\nthey considered the possible relation between the 475-day ( 1.3-year ) and 156-day periodicities .\nthe 475-day ( 1.3-year ) periodicity was also detected in variations of the interplanetary magnetic field , geomagnetic activity helioseismic data and in the solar wind speed @xcite .\n@xcite concluded that the region of larger wavelet power shifts from 475-day ( 1.3-year ) period to 620-day ( 1.7-year ) period and then back to 475-day ( 1.3-year ) .\nthe periodicities from the interval @xmath6 $ ] days ( @xmath4 $ ] years ) have been considered from 1968 .\n@xcite mentioned a 16.3-month ( 490-day ) periodicity in the sunspot numbers and in the geomagnetic data .\n@xcite analysed the occurrence rate of major flares during solar cycles 19 .\nthey found a 18-month ( 540-day ) periodicity in flare rate of the norhern hemisphere .\n@xcite confirmed this result for the @xmath7 flare data for solar cycles 20 and 21 and found a peak in the power spectra near 510540 days .\n@xcite found a 17-month ( 510-day ) periodicity of sunspot groups and their areas from 1969 to 1986 .\nthese authors concluded that the length of this period is variable and the reason of this periodicity is still not understood .\n@xcite and + @xcite obtained statistically significant peaks of power at around 158 days for daily sunspot data from 1923 - 1933 ( cycle 16 ) . in this paper the problem of the existence of this periodicity for sunspot data from cycle 16 is considered .\nthe daily sunspot areas , the mean sunspot areas per carrington rotation , the monthly sunspot numbers and their fluctuations , which are obtained after removing the 11-year cycle are analysed . in section 2 the properties of the power spectrum methods are described . in section 3 a new approach to the problem of aliases in the power spectrum analysis\nis presented . in section 4 numerical results of the new method of the diagnosis of an echo - effect for sunspot area data are discussed . in section 5 the problem of the existence of the periodicity of about 155 days during the maximum activity period for sunspot data from the whole solar disk and from each solar hemisphere separately is considered .\nto find periodicities in a given time series the power spectrum analysis is applied . in this paper\ntwo methods are used : the fast fourier transformation algorithm with the hamming window function ( fft ) and the blackman - tukey ( bt ) power spectrum method @xcite .\nthe bt method is used for the diagnosis of the reasons of the existence of peaks , which are obtained by the fft method .\nthe bt method consists in the smoothing of a cosine transform of an autocorrelation function using a 3-point weighting average .\nsuch an estimator is consistent and unbiased .\nmoreover , the peaks are uncorrelated and their sum is a variance of a considered time series . the main disadvantage of this method is a weak resolution of the periodogram points , particularly for low frequences .\nfor example , if the autocorrelation function is evaluated for @xmath8 , then the distribution points in the time domain are : @xmath9 thus , it is obvious that this method should not be used for detecting low frequency periodicities with a fairly good resolution .\nhowever , because of an application of the autocorrelation function , the bt method can be used to verify a reality of peaks which are computed using a method giving the better resolution ( for example the fft method ) .\nit is valuable to remember that the power spectrum methods should be applied very carefully .\nthe difficulties in the interpretation of significant peaks could be caused by at least four effects : a sampling of a continuos function , an echo - effect , a contribution of long - term periodicities and a random noise .\nfirst effect exists because periodicities , which are shorter than the sampling interval , may mix with longer periodicities . in result , this effect can be reduced by an decrease of the sampling interval between observations .\nthe echo - effect occurs when there is a latent harmonic of frequency @xmath10 in the time series , giving a spectral peak at @xmath10 , and also periodic terms of frequency @xmath11 etc .\nthis may be detected by the autocorrelation function for time series with a large variance .\ntime series often contain long - term periodicities , that influence short - term peaks .\nthey could rise periodogram s peaks at lower frequencies .\nhowever , it is also easy to notice the influence of the long - term periodicities on short - term peaks in the graphs of the autocorrelation functions .\nthis effect is observed for the time series of solar activity indexes which are limited by the 11-year cycle .    to find statistically significant periodicities\nit is reasonable to use the autocorrelation function and the power spectrum method with a high resolution . in the case of a stationary time\nseries they give similar results .\nmoreover , for a stationary time series with the mean zero the fourier transform is equivalent to the cosine transform of an autocorrelation function @xcite .\nthus , after a comparison of a periodogram with an appropriate autocorrelation function one can detect peaks which are in the graph of the first function and do not exist in the graph of the second function .\nthe reasons of their existence could be explained by the long - term periodicities and the echo - effect .\nbelow method enables one to detect these effects .\n( solid line ) and the 95% confidence level basing on thered noise ( dotted line ) .\nthe periodogram values are presented on the left axis .\nthe lower curve illustrates the autocorrelation function of the same time series ( solid line ) .\nthe dotted lines represent two standard errors of the autocorrelation function .\nthe dashed horizontal line shows the zero level .\nthe autocorrelation values are shown in the right axis . ]     because the statistical tests indicate that the time series is a white noise the confidence level is not marked . ]    . ]\nthe method of the diagnosis of an echo - effect in the power spectrum ( de ) consists in an analysis of a periodogram of a given time series computed using the bt method .\nthe bt method bases on the cosine transform of the autocorrelation function which creates peaks which are in the periodogram , but not in the autocorrelation function .\nthe de method is used for peaks which are computed by the fft method ( with high resolution ) and are statistically significant .\nthe time series of sunspot activity indexes with the spacing interval one rotation or one month contain a markov - type persistence , which means a tendency for the successive values of the time series to remember their antecendent values .\nthus , i use a confidence level basing on the red noise of markov @xcite for the choice of the significant peaks of the periodogram computed by the fft method .\nwhen a time series does not contain the markov - type persistence i apply the fisher test and the kolmogorov - smirnov test at the significance level @xmath12 @xcite to verify a statistically significance of periodograms peaks . the fisher test checks the null hypothesis that the time series is white noise agains the alternative hypothesis that the time series contains an added deterministic periodic component of unspecified frequency . because the fisher test tends to be severe in rejecting peaks as insignificant the kolmogorov - smirnov test is also used .\nthe de method analyses raw estimators of the power spectrum .\nthey are given as follows    @xmath13    for @xmath14 + where @xmath15 for @xmath16 + @xmath17 is the length of the time series @xmath18 and @xmath19 is the mean value .\nthe first term of the estimator @xmath20 is constant .\nthe second term takes two values ( depending on odd or even @xmath21 ) which are not significant because @xmath22 for large m. thus , the third term of ( 1 ) should be analysed .\nlooking for intervals of @xmath23 for which @xmath24 has the same sign and different signs one can find such parts of the function @xmath25 which create the value @xmath20 .\nlet the set of values of the independent variable of the autocorrelation function be called @xmath26 and it can be divided into the sums of disjoint sets : @xmath27 where + @xmath28 + @xmath29 @xmath30 @xmath31 + @xmath32 + @xmath33 @xmath34 @xmath35 @xmath36 @xmath37 @xmath38\n@xmath39 @xmath40    well , the set @xmath41 contains all integer values of @xmath23 from the interval of @xmath42 for which the autocorrelation function and the cosinus function with the period @xmath43 $ ] are positive .\nthe index @xmath44 indicates successive parts of the cosinus function for which the cosinuses of successive values of @xmath23 have the same sign .\nhowever , sometimes the set @xmath41 can be empty .\nfor example , for @xmath45 and @xmath46 the set @xmath47 should contain all @xmath48 $ ] for which @xmath49 and @xmath50 , but for such values of @xmath23 the values of @xmath51 are negative .\nthus , the set @xmath47 is empty .    .\nthe periodogram values are presented on the left axis .\nthe lower curve illustrates the autocorrelation function of the same time series .\nthe autocorrelation values are shown in the right axis . ]\nlet us take into consideration all sets \\{@xmath52 } , \\{@xmath53 } and \\{@xmath41 } which are not empty . because numberings and power of these sets depend on the form of the autocorrelation function of the given time series , it is impossible to establish them arbitrary .\nthus , the sets of appropriate indexes of the sets \\{@xmath52 } , \\{@xmath53 } and \\{@xmath41 } are called @xmath54 , @xmath55 and @xmath56 respectively . for example\nthe set @xmath56 contains all @xmath44 from the set @xmath57 for which the sets @xmath41 are not empty .\nto separate quantitatively in the estimator @xmath20 the positive contributions which are originated by the cases described by the formula ( 5 ) from the cases which are described by the formula ( 3 ) the following indexes are introduced : @xmath58 @xmath59 @xmath60 @xmath61 where @xmath62 @xmath63 @xmath64 taking for the empty sets \\{@xmath53 } and \\{@xmath41 } the indices @xmath65 and @xmath66 equal zero .\nthe index @xmath65 describes a percentage of the contribution of the case when @xmath25 and @xmath51 are positive to the positive part of the third term of the sum ( 1 ) .\nthe index @xmath66 describes a similar contribution , but for the case when the both @xmath25 and @xmath51 are simultaneously negative .\nthanks to these one can decide which the positive or the negative values of the autocorrelation function have a larger contribution to the positive values of the estimator @xmath20 .\nwhen the difference @xmath67 is positive , the statement the @xmath21-th peak really exists can not be rejected .\nthus , the following formula should be satisfied : @xmath68    because the @xmath21-th peak could exist as a result of the echo - effect , it is necessary to verify the second condition :    @xmath69\\in c_m.\\ ] ]    .\nthe periodogram values are presented on the left axis .\nthe lower curve illustrates the autocorrelation function of the same time series ( solid line ) .\nthe dotted lines represent two standard errors of the autocorrelation function .\nthe dashed horizontal line shows the zero level .\nthe autocorrelation values are shown in the right axis . ]    to verify the implication ( 8) firstly it is necessary to evaluate the sets @xmath41 for @xmath70 of the values of @xmath23 for which the autocorrelation function and the cosine function with the period @xmath71 $ ] are positive and the sets @xmath72 of values of @xmath23 for which the autocorrelation function and the cosine function with the period @xmath43 $ ] are negative .\nsecondly , a percentage of the contribution of the sum of products of positive values of @xmath25 and @xmath51 to the sum of positive products of the values of @xmath25 and @xmath51 should be evaluated . as a result the indexes @xmath65 for each set\n@xmath41 where @xmath44 is the index from the set @xmath56 are obtained .\nthirdly , from all sets @xmath41 such that @xmath70 the set @xmath73 for which the index @xmath65 is the greatest should be chosen .    the implication ( 8) is true when the set @xmath73 includes the considered period @xmath43 $ ] .\nthis means that the greatest contribution of positive values of the autocorrelation function and positive cosines with the period @xmath43 $ ] to the periodogram value @xmath20 is caused by the sum of positive products of @xmath74 for each @xmath75-\\frac{m}{2k},[\\frac{2m}{k}]+\\frac{m}{2k})$ ] .    when the implication ( 8) is false , the peak @xmath20 is mainly created by the sum of positive products of @xmath74 for each @xmath76-\\frac{m}{2k},\\big [ \\frac{2m}{n}\\big ] + \\frac{m}{2k } \\big ) $ ] , where @xmath77 is a multiple or a divisor of @xmath21 .\nit is necessary to add , that the de method should be applied to the periodograms peaks , which probably exist because of the echo - effect .\nit enables one to find such parts of the autocorrelation function , which have the significant contribution to the considered peak .\nthe fact , that the conditions ( 7 ) and ( 8) are satisfied , can unambiguously decide about the existence of the considered periodicity in the given time series , but if at least one of them is not satisfied , one can doubt about the existence of the considered periodicity .\nthus , in such cases the sentence the peak can not be treated as true should be used .    using the de method\nit is necessary to remember about the power of the set @xmath78 .\nif @xmath79 is too large , errors of an autocorrelation function estimation appear .\nthey are caused by the finite length of the given time series and as a result additional peaks of the periodogram occur . if @xmath79 is too small , there are less peaks because of a low resolution of the periodogram . in applications\n@xmath80 is used . in order to evaluate the value\n@xmath79 the fft method is used .\nthe periodograms computed by the bt and the fft method are compared .\nthe conformity of them enables one to obtain the value @xmath79 .    .\nthe fft periodogram values are presented on the left axis .\nthe lower curve illustrates the bt periodogram of the same time series ( solid line and large black circles ) .\nthe bt periodogram values are shown in the right axis . ]\nin this paper the sunspot activity data ( august 1923 - october 1933 ) provided by the greenwich photoheliographic results ( gpr ) are analysed .\nfirstly , i consider the monthly sunspot number data . to eliminate the 11-year trend from these data ,\nthe consecutively smoothed monthly sunspot number @xmath81 is subtracted from the monthly sunspot number @xmath82 where the consecutive mean @xmath83 is given by @xmath84 the values @xmath83 for @xmath85 and @xmath86 are calculated using additional data from last six months of cycle 15 and first six months of cycle 17 .    because of the north - south asymmetry of various solar indices @xcite , the sunspot activity is considered for each solar hemisphere separately .\nanalogously to the monthly sunspot numbers , the time series of sunspot areas in the northern and southern hemispheres with the spacing interval @xmath87 rotation are denoted . in order to find periodicities ,\nthe following time series are used : + @xmath88  \n+ @xmath89\n   + @xmath90     + in the lower part of figure [ f1 ] the autocorrelation function of the time series for the northern hemisphere @xmath88 is shown .\nit is easy to notice that the prominent peak falls at 17 rotations interval ( 459 days ) and @xmath25 for @xmath91 $ ] rotations ( [ 81 , 162 ] days ) are significantly negative .\nthe periodogram of the time series @xmath88 ( see the upper curve in figures [ f1 ] ) does not show the significant peaks at @xmath92 rotations ( 135 , 162 days ) , but there is the significant peak at @xmath93 ( 243 days ) .\nthe peaks at @xmath94 are close to the peaks of the autocorrelation function .\nthus , the result obtained for the periodicity at about @xmath0 days are contradict to the results obtained for the time series of daily sunspot areas @xcite .    for the southern hemisphere ( the lower curve in figure [ f2 ] ) @xmath25 for @xmath95 $ ] rotations ( [ 54 , 189 ] days ) is not positive except @xmath96 ( 135 days ) for which @xmath97 is not statistically significant .\nthe upper curve in figures [ f2 ] presents the periodogram of the time series @xmath89 .\nthis time series does not contain a markov - type persistence .\nmoreover , the kolmogorov - smirnov test and the fisher test do not reject a null hypothesis that the time series is a white noise only .\nthis means that the time series do not contain an added deterministic periodic component of unspecified frequency .\nthe autocorrelation function of the time series @xmath90 ( the lower curve in figure [ f3 ] ) has only one statistically significant peak for @xmath98 months ( 480 days ) and negative values for @xmath99 $ ] months ( [ 90 , 390 ] days ) .\nhowever , the periodogram of this time series ( the upper curve in figure [ f3 ] ) has two significant peaks the first at 15.2 and the second at 5.3 months ( 456 , 159 days ) .\nthus , the periodogram contains the significant peak , although the autocorrelation function has the negative value at @xmath100 months .    to explain\nthese problems two following time series of daily sunspot areas are considered : + @xmath101  \n+ @xmath102     + where @xmath103    the values @xmath104 for @xmath105 and @xmath106 are calculated using additional daily data from the solar cycles 15 and 17 .     and the cosine function for @xmath45 ( the period at about 154 days ) .\nthe horizontal line ( dotted line ) shows the zero level .\nthe vertical dotted lines evaluate the intervals where the sets @xmath107 ( for @xmath108 ) are searched .\nthe percentage values show the index @xmath65 for each @xmath41 for the time series @xmath102 ( in parentheses for the time series @xmath101 ) . in the right bottom corner\nthe values of @xmath65 for the time series @xmath102 , for @xmath109 are written . ]\n( the 500-day period ) ]    the comparison of the functions @xmath25 of the time series @xmath101 ( the lower curve in figure [ f4 ] ) and @xmath102 ( the lower curve in figure [ f5 ] ) suggests that the positive values of the function @xmath110 of the time series @xmath101 in the interval of @xmath111 $ ] days could be caused by the 11-year cycle .\nthis effect is not visible in the case of periodograms of the both time series computed using the fft method ( see the upper curves in figures [ f4 ] and [ f5 ] ) or the bt method ( see the lower curve in figure [ f6 ] ) . moreover , the periodogram of the time series @xmath102 has the significant values at @xmath112 days , but the autocorrelation function is negative at these points .\n@xcite showed that the lomb - scargle periodograms for the both time series ( see @xcite , figures 7 a - c ) have a peak at 158.8 days which stands over the fap level by a significant amount . using the de method the above discrepancies are obvious . to establish the @xmath79 value the periodograms computed by the fft and\nthe bt methods are shown in figure [ f6 ] ( the upper and the lower curve respectively ) .\nfor @xmath46 and for periods less than 166 days there is a good comformity of the both periodograms ( but for periods greater than 166 days the points of the bt periodogram are not linked because the bt periodogram has much worse resolution than the fft periodogram ( no one know how to do it ) ) . for @xmath46 and @xmath113\nthe value of @xmath21 is 13 ( @xmath71=153 $ ] ) .\nthe inequality ( 7 ) is satisfied because @xmath114 .\nthis means that the value of @xmath115 is mainly created by positive values of the autocorrelation function .\nthe implication ( 8) needs an evaluation of the greatest value of the index @xmath65 where @xmath70 , but the solar data contain the most prominent period for @xmath116 days because of the solar rotation .\nthus , although @xmath117 for each @xmath118 , all sets @xmath41 ( see ( 5 ) and ( 6 ) ) without the set @xmath119 ( see ( 4 ) ) , which contains @xmath120 $ ] , are considered . this situation is presented in figure [ f7 ] . in this figure\ntwo curves @xmath121 and @xmath122 are plotted .\nthe vertical dotted lines evaluate the intervals where the sets @xmath107 ( for @xmath123 ) are searched . for such @xmath41 two numbers\nare written : in parentheses the value of @xmath65 for the time series @xmath101 and above it the value of @xmath65 for the time series @xmath102 . to make this figure clear the curves are plotted for the set @xmath124 only .\n( in the right bottom corner information about the values of @xmath65 for the time series @xmath102 , for @xmath109 are written . )\nthe implication ( 8) is not true , because @xmath125 for @xmath126 .\ntherefore , @xmath43=153\\notin c_6=[423,500]$ ] .\nmoreover , the autocorrelation function for @xmath127 $ ] is negative and the set @xmath128 is empty .\nthus , @xmath129 . on the basis of these information one can state , that the periodogram peak at @xmath130 days of the time series @xmath102 exists because of positive @xmath25 , but for @xmath23 from the intervals which do not contain this period .\nlooking at the values of @xmath65 of the time series @xmath101 , one can notice that they decrease when @xmath23 increases until @xmath131 .\nthis indicates , that when @xmath23 increases , the contribution of the 11-year cycle to the peaks of the periodogram decreases .\nan increase of the value of @xmath65 is for @xmath132 for the both time series , although the contribution of the 11-year cycle for the time series @xmath101 is insignificant .\nthus , this part of the autocorrelation function ( @xmath133 for the time series @xmath102 ) influences the @xmath21-th peak of the periodogram .\nthis suggests that the periodicity at about 155 days is a harmonic of the periodicity from the interval of @xmath1 $ ] days .\n( solid line ) and consecutively smoothed sunspot areas of the one rotation time interval @xmath134 ( dotted line ) .\nboth indexes are presented on the left axis .\nthe lower curve illustrates fluctuations of the sunspot areas @xmath135 .\nthe dotted and dashed horizontal lines represent levels zero and @xmath136 respectively .\nthe fluctuations are shown on the right axis . ]\nthe described reasoning can be carried out for other values of the periodogram .\nfor example , the condition ( 8) is not satisfied for @xmath137 ( 250 , 222 , 200 days ) .\nmoreover , the autocorrelation function at these points is negative .\nthese suggest that there are not a true periodicity in the interval of [ 200 , 250 ] days .\nit is difficult to decide about the existence of the periodicities for @xmath138 ( 333 days ) and @xmath139 ( 286 days ) on the basis of above analysis . the implication ( 8) is not satisfied for @xmath139 and the condition ( 7 ) is not satisfied for @xmath138 , although the function @xmath25 of the time series @xmath102 is significantly positive for @xmath140 .\nthe conditions ( 7 ) and ( 8) are satisfied for @xmath141 ( figure [ f8 ] ) and @xmath142 . therefore , it is possible to exist the periodicity from the interval of @xmath1 $ ] days .\nsimilar results were also obtained by @xcite for daily sunspot numbers and daily sunspot areas .\nshe considered the means of three periodograms of these indexes for data from @xmath143 years and found statistically significant peaks from the interval of @xmath1 $ ] ( see @xcite , figure 2 ) .\n@xcite studied sunspot areas from 1876 - 1999 and sunspot numbers from 1749 - 2001 with the help of the wavelet transform .\nthey pointed out that the 154 - 158-day period could be the third harmonic of the 1.3-year ( 475-day ) period .\nmoreover , the both periods fluctuate considerably with time , being stronger during stronger sunspot cycles .\ntherefore , the wavelet analysis suggests a common origin of the both periodicities . this conclusion confirms the de method result which indicates that the periodogram peak at @xmath144 days is an alias of the periodicity from the interval of @xmath1 $ ]\nin order to verify the existence of the periodicity at about 155 days i consider the following time series : + @xmath145     + @xmath146\n   + @xmath147  \n+ the value @xmath134 is calculated analogously to @xmath83 ( see sect .\nthe values @xmath148 and @xmath149 are evaluated from the formula ( 9 ) . in the upper part of figure [ f9 ] the time series of sunspot areas @xmath150 of the one rotation time interval from the whole solar disk and the time series of consecutively smoothed sunspot areas @xmath151\nare showed . in the lower part of figure [ f9 ]\nthe time series of sunspot area fluctuations @xmath145 is presented .\non the basis of these data the maximum activity period of cycle 16 is evaluated .\nit is an interval between two strongest fluctuations e.a .\n@xmath152 $ ] rotations .\nthe length of the time interval @xmath153 is 54 rotations .\nif the about @xmath0-day ( 6 solar rotations ) periodicity existed in this time interval and it was characteristic for strong fluctuations from this time interval , 10 local maxima in the set of @xmath154 would be seen .\nthen it should be necessary to find such a value of p for which @xmath155 for @xmath156 and the number of the local maxima of these values is 10 .\nas it can be seen in the lower part of figure [ f9 ] this is for the case of @xmath157 ( in this figure the dashed horizontal line is the level of @xmath158 ) .\nfigure [ f10 ] presents nine time distances among the successive fluctuation local maxima and the horizontal line represents the 6-rotation periodicity .\nit is immediately apparent that the dispersion of these points is 10 and it is difficult to find even few points which oscillate around the value of 6 .\nsuch an analysis was carried out for smaller and larger @xmath136 and the results were similar .\ntherefore , the fact , that the about @xmath0-day periodicity exists in the time series of sunspot area fluctuations during the maximum activity period is questionable .    .\nthe horizontal line represents the 6-rotation ( 162-day ) period . ]    ]    ]    to verify again the existence of the about @xmath0-day periodicity during the maximum activity period in each solar hemisphere separately , the time series @xmath88 and @xmath89 were also cut down to the maximum activity period ( january 1925december 1930 ) .\nthe comparison of the autocorrelation functions of these time series with the appriopriate autocorrelation functions of the time series @xmath88 and @xmath89 , which are computed for the whole 11-year cycle ( the lower curves of figures [ f1 ] and [ f2 ] ) , indicates that there are not significant differences between them especially for @xmath23=5 and 6 rotations ( 135 and 162 days ) ) .\nthis conclusion is confirmed by the analysis of the time series @xmath146 for the maximum activity period .\nthe autocorrelation function ( the lower curve of figure [ f11 ] ) is negative for the interval of [ 57 , 173 ] days , but the resolution of the periodogram is too low to find the significant peak at @xmath159 days .\nthe autocorrelation function gives the same result as for daily sunspot area fluctuations from the whole solar disk ( @xmath160 ) ( see also the lower curve of figures [ f5 ] ) . in the case of\nthe time series @xmath89 @xmath161 is zero for the fluctuations from the whole solar cycle and it is almost zero ( @xmath162 ) for the fluctuations from the maximum activity period .\nthe value @xmath163 is negative .\nsimilarly to the case of the northern hemisphere the autocorrelation function and the periodogram of southern hemisphere daily sunspot area fluctuations from the maximum activity period @xmath147 are computed ( see figure [ f12 ] ) .\nthe autocorrelation function has the statistically significant positive peak in the interval of [ 155 , 165 ] days , but the periodogram has too low resolution to decide about the possible periodicities .\nthe correlative analysis indicates that there are positive fluctuations with time distances about @xmath0 days in the maximum activity period .\nthe results of the analyses of the time series of sunspot area fluctuations from the maximum activity period are contradict with the conclusions of @xcite .\nshe uses the power spectrum analysis only .\nthe periodogram of daily sunspot fluctuations contains peaks , which could be harmonics or subharmonics of the true periodicities .\nthey could be treated as real periodicities .\nthis effect is not visible for sunspot data of the one rotation time interval , but averaging could lose true periodicities .\nthis is observed for data from the southern hemisphere .\nthere is the about @xmath0-day peak in the autocorrelation function of daily fluctuations , but the correlation for data of the one rotation interval is almost zero or negative at the points @xmath164 and 6 rotations .\nthus , it is reasonable to research both time series together using the correlative and the power spectrum analyses .\nthe following results are obtained :    1 .\na new method of the detection of statistically significant peaks of the periodograms enables one to identify aliases in the periodogram .\n2 .   two effects cause the existence of the peak of the periodogram of the time series of sunspot area fluctuations at about @xmath0 days : the first is caused by the 27-day periodicity , which probably creates the 162-day periodicity ( it is a subharmonic frequency of the 27-day periodicity ) and the second is caused by statistically significant positive values of the autocorrelation function from the intervals of @xmath165 $ ] and @xmath166 $ ] days .\nthe existence of the periodicity of about @xmath0 days of the time series of sunspot area fluctuations and sunspot area fluctuations from the northern hemisphere during the maximum activity period is questionable .\nthe autocorrelation analysis of the time series of sunspot area fluctuations from the southern hemisphere indicates that the periodicity of about 155 days exists during the maximum activity period .\ni appreciate valuable comments from professor j. jakimiec ."}
{"lay_summary": " we study the detectability of circular polarization in a stochastic gravitational wave background from various sources such as supermassive black hole binaries , cosmic strings , and inflation in the early universe with pulsar timing arrays . \n we calculate generalized overlap reduction functions for the circularly polarized stochastic gravitational wave background . \n we find that the circular polarization can not be detected for an isotropic background . however , there is a chance to observe the circular polarization for an anisotropic gravitational wave background . \n we also show how to separate polarized gravitational waves from unpolarized gravitational waves . ", "article": "it is believed that the direct detection of gravitational waves ( gws ) will bring the era of gravitational wave astronomy .\nthe interferometer detectors are now under operation and awaiting the first signal of gws  @xcite .\nit is also known that pulsar timing arrays ( ptas ) can be used as a detector for gws @xcite .\nthese detectors are used to search for very low frequency ( @xmath0 ) gravitational waves , where the lower limit of the observable frequencies is determined by the inverse of total observation time @xmath1 .\nindeed , the total observation time has a crucial role in ptas , because ptas are most sensitive near the lower edge of observable frequencies @xcite . taking into account its sensitivity ,\nthe first direct detection of the gravitational waves might be achieved by ptas .\nthe main target of ptas is the stochastic gravitational wave background ( sgwb ) generated by a large number of unresolved sources with the astrophysical origin or the cosmological origin in the early universe .\nthe promising sources are super massive black hole binaries  @xcite , cosmic ( super)string  @xcite , and inflation  @xcite .\nprevious studies have assumed that the sgwb is isotropic and unpolarized  @xcite .\nthese assumptions are reasonable for the primary detection of the sgwb , but the deviation from the isotropy and the polarizations should have rich information of sources of gravitational waves .\nrecently , the cross - correlation formalism has been generalized to deal with anisotropy in the sgwb @xcite .\nresult of this work enables us to consider arbitrary levels of anisotropy , and a bayesian approach was performed by using this formalism @xcite . on the other hand , for the anisotropy of the sgwb , the cross - correlation formalism has been also developed in the case of interferometer detectors  @xcite .\nas to the polarization , there are works including the ones motivated by the modified gravity  @xcite\n. we can envisage supermassive black hole binaries emit circularly polarized sgwb due to the chern - simons term  @xcite .\nthere may also exist cosmological sgwb with circular polarization in the presence of parity violating term in gravity sector  @xcite .    in this paper\n, we investigate the detectability of circular polarization in the sgwb by ptas .\nwe characterize sgwb by the so called stokes @xmath2 parameter  @xcite and calculate generalized overlap reduction functions ( orfs ) so that we can probe the circular polarization of the sgwb .\nwe also discuss a method to separate the intensity ( @xmath3 mode ) and circular polarization ( @xmath2 mode ) of the sgwb .\nthe paper is organized as follows . in section [ sec :\nstokes parameters for a plane gravitational wave ] , we introduce the stokes parameters for monochromatic plane gravitational waves , and clarify the physical meaning of the stokes parameters @xmath3 and @xmath2 . in section [ sec : formulation ] , we formulate the cross - correlation formalism for anisotropic circularly polarized sgwb with ptas .\nthe basic framework is essentially a combination of the formalism of @xcite , and the polarization decomposition formula of the sgwb derived in @xcite . in section [ sec : the generalized overlap reduction function for circular polarization ] , we calculate the generalized orfs for the @xmath2 mode .\nthe results for @xmath3 mode are consistent with the previous work  @xcite . in section [ sec : separation method ] , we give a method for separation between the @xmath3 mode and @xmath2 mode of the sgwb .\nthe final section is devoted to the conclusion . in appendixes , we present analytic results for the generalized overlap reduction functions . in this paper\n, we will use the gravitational units @xmath4 .\nlet us consider the stokes parameters for plane waves traveling in the direction @xmath5 , which can be described by @xmath6 \\\n, \\\\ & & h_{xy}(t , z)=h_{yx}(t , z)={\\rm re}[b_{\\times}\\mathrm{e}^{-iw(t - z ) } ] \\ .\\end{aligned}\\ ] ] for an idealized monochromatic plane wave , complex amplitudes @xmath7 and @xmath8 are constants .\npolarization of the plane gws is characterized by the tensor , ( see @xcite and also electromagnetic case @xcite ) @xmath9 where @xmath10 take @xmath11 .\nany @xmath12 hermitian matrix can be expanded by the pauli and the unit matrices with real coefficients .\nhence , the @xmath13 hermitian matrix @xmath14 can be written as @xmath15 where @xmath16 by analogy with electromagnetic cases , @xmath17 and @xmath2 are called stokes parameters . comparing with , we can read off the stokes parameters as @xmath18= b_{+}^{\\ast}b_{\\times}+ b_{\\times}^{\\ast}b_{+},\\\\ v&=&-2{\\rm i m } [ b_{+}^{\\ast}b_{\\times}]=i ( b_{+}^{\\ast}b_{\\times}- b_{\\times}^{\\ast}b_{+}).\\label{stv}\\end{aligned}\\ ] ] apparently , the real parameter @xmath3 is the intensity of gws . in order to reveal the physical meaning of the real parameter @xmath2 , we define the circular polarization bases @xcite @xmath19 from the relation @xmath20 we see @xmath21\nthus , we can rewrite the stokes parameters - as @xmath22 from the above expression , we see that the real parameter @xmath2 characterizes the asymmetry of circular polarization amplitudes .\nthe other parameters @xmath23 and @xmath24 have additional information about linear polarizations by analogy with the electromagnetic cases .\nalternatively , we can also define the tensor @xmath25 in circular polarization bases @xmath26 where @xmath27 .\nnote that the stokes parameters satisfy a relation @xmath28    next , we consider the transformation of the stokes parameters under rotations around the @xmath5 axis . the rotation around the @xmath5 axis is given by @xmath29 where @xmath30 is the angle of the rotation .\nthe gws traveling in the direction @xmath5 @xmath31 transform as @xmath32 where we took the transverse traceless gauge @xmath33 after a short calculation , we obtain @xmath34 using and , the four stokes parameters ( [ sti])-([stv ] ) transform as @xmath35 as you can see , the parameters @xmath23 and @xmath24 depend on the rotation angle @xmath30 .\nthis reflects the fact that @xmath23 and @xmath24 parameters characterize linear polarizations .\nnote that this transformation is similar to the transformation of electromagnetic case except for the angle @xmath36 and can be rewritten as @xmath37\nin this section , we study anisotropic distribution of sgwb and focus on the detectability of circular polarizations with pulsar timing arrays .\nwe combine the analysis of @xcite and that of @xcite . in sec.[subsec : the spectral ] , we derive the power spectral density for anisotropic circularly polarized sgwb @xmath38 .\nthen we also derive the dimensionless density parameter @xmath39 which is expressed by the frequency spectrum of intensity @xmath40  @xcite . in sec.[subsec : the signal ] , we extend the generalized orfs to cases with circular polarizations characterized by the parameter @xmath2 . for simplicity ,\nwe consider specific anisotropic patterns with @xmath41 expressed by the spherical harmonics @xmath42 .      in the transverse traceless gauge , metric perturbations @xmath43 with a given propagation direction @xmath44\ncan be expanded as @xcite @xmath45 where the fourier amplitude satisfies @xmath46 as a consequence of the reality of @xmath43 , @xmath47 , @xmath48 is the frequency of the gws , @xmath49 are spatial indices , @xmath50 label polarizations .\nnote that the fourier amplitude @xmath51 satisfies the relation @xmath52 where @xmath53 was defined by .\nthe polarized tensors @xmath54 are defined by @xmath55 where @xmath56 and @xmath57 are unit orthogonal vectors perpendicular to @xmath58 .\nthe polarization tensors satisfy @xmath59 with polar coordinates , the direction @xmath44 can be represented by @xmath60 and the polarization basis vectors read @xmath61    we assume the fourier amplitudes @xmath62 are random variables , which is stationary and gaussian .\nhowever , they are not isotropic and unpolarized .\nthe ensemble average of fourier amplitudes can be written as @xcite @xmath63 where @xmath64 here , the bracket @xmath65 represents an ensemble average , and @xmath66 is the dirac delta function on the two - sphere .\nthe gw power spectral density @xmath38 is a hermitian matrix , and satisfies @xmath67 because of the relation @xmath46 .\ntherefore , we have the relations @xmath68 note that the stokes parameters are not exactly the same as the expression of , but they have the relation and characterize the same polarization .\nwe further assume that the sgwbs satisfy @xmath69 we also assume the directional dependence of the sgwb is frequency independent @xcite .\nthis implies the gw power spectral density is factorized into two parts , one of which depends on the direction while the other depends on the frequency .\nbecause of the transformations - , the parameters @xmath3 and @xmath2 have spin 0 and the parameters @xmath70 have spin @xmath71  @xcite . to analyze the sgwb on the sky , it is convenient to expand the stokes parameters by spherical harmonics @xmath72\n. however , since @xmath70 parameters have spin @xmath71 , they have to be expanded by the spin - weighted harmonics @xmath73 @xcite .\nthus , we obtain @xmath74 in this paper , we study specific anisotropic patterns with @xmath41 for simplicity .\ntherefore , we can neglect @xmath23 and @xmath24 from now on .\nthus , the gw power spectral density becomes @xmath75 where @xmath76 so , we focus on the parameters @xmath3 and @xmath2 . in what follows , we will use the following shorthand notation @xmath77    next , we consider the dimensionless density parameter  @xcite @xmath78 where @xmath79 is the critical density , @xmath80 is the present value of the hubble parameter , @xmath81 is the energy density of gravitational waves , and @xmath82 is the energy density in the frequency range @xmath48 to @xmath83 .\nthe bracket @xmath65 represents the ensemble average .\nhowever , actually , we take a spatial average over the wave lengths @xmath84 of gws or a temporal average over the periods @xmath85 of gws . here\n, we assumed the ergodicity , namely , the ensemble average can be replaced by the temporal average .\nusing , , , as well as @xmath46 and @xmath86 , we get @xmath87 then we define @xmath88 hence , the dimensionless quantity @xmath39 in is given by @xmath89 where the spherical harmonics are orthogonal and normalized as @xmath90 using @xmath91 , we obtain @xmath92 without loss of generality , we normalize the monopole moment as @xmath93 so , becomes @xmath94      the time of arrival of radio pulses from the pulsar is affected by gws .\nconsider a pulsar with frequency @xmath95 located in the direction @xmath96 . to detect the sgwb ,\nlet us consider the redshift of the pulse from a pulsar @xcite @xmath97 where @xmath98 is a frequency detected at the earth and @xmath96 is the direction to the pulsar .\nthe unit vector @xmath44 represents the direction of propagation of gravitational plane waves .\nwe also defined the difference between the metric perturbations at the pulsar @xmath99 and at the earth @xmath100 as @xmath101 the gravitational plane waves at each point is defined as @xmath102 for the sgwb , the redshift have to be integrated over the direction of propagation of the gravitational waves @xmath44 : @xmath103 we choose a coordinate system @xmath104 and assume that the amplitudes of the metric perturbation at the pulsar and the earth are the same .\nthen becomes @xmath105 and therefore , reads @xmath106 where we have defined the pattern functions for pulsars @xmath107 note that our convention for the fourier transformation is @xmath108 therefore , the fourier transformation of can be written as @xmath109    in the actual signals from a pulsar , there exist noises .\nhence , we need to use the correlation analysis .\nwe consider the signals from two pulsars @xmath110 where @xmath111 labels the pulsar . here\n, @xmath112 denotes the signal from the pulsar and @xmath113 denotes the noise intrinsic to the measurement .\nwe assume the noises are stationary , gaussian and are not correlated between the two pulsars .\nto correlate the signals of two measurements , we define @xmath114 where @xmath1 is the total observation time and @xmath115 is a real filter function which should be optimal to maximize signal - to - noise ratio . in the case of interferometer\n, the optimal filter function falls to zero for large @xmath116 compered to the travel time of the light between the detecters .\nsince the signals of two detectors are expected to correlate due to the same effect of the gravitational waves , the optimal filter function should behave this way .\nthen , typically one of the detectors is very close to the other compared to the total observation time @xmath1 .\ntherefore , the total observation time @xmath1 can be extended to @xmath117 @xcite .\nin contrast , in the case of pta , it is invalid that @xmath1 is very large compered to the travel time of the light between the pulsars .\nnevertheless , we can assume that one of the two @xmath1 can be expanded to @xmath117 , because in situations @xmath118 and @xmath119 it is known that we can ignore the effect of the distance @xmath120 of pulsars .\nin this case , it is clear that any locations of the pulsars are optimal and optimal filter function should behave like as the interferometer case @xcite .    using these assumptions @xmath118 and @xmath119 , we can rewrite as @xmath121 where @xmath122 note that @xmath123 satisfies @xmath124 , because @xmath125 is real .\nmoreover , to deal with the unphysical region @xmath126 we require @xmath127 .\nthus , @xmath123 becomes real .\ntaking the ensemble average , using @xmath128 , @xmath118 , and assuming the noises in the two measurements are not correlated , we get @xmath129\\ , \\label{s2}\\end{aligned}\\ ] ] where we have defined @xmath130 the functions @xmath131 and @xmath132 are called the generalized orfs , which describe the angular sensitivity of the pulsars for the sgwb . note that , as we already mentioned , we consider the cases of @xmath41 for simplicity\n. then we have assumed @xmath118 and @xmath119 , this assumption implies that approximately becomes @xmath133 due to the rapid oscillation of the phase factor .\ntherefore , the distance @xmath120 of the pulsars does not appear in the generalized orfs , and hence the generalized orfs do not depend on the frequency .    as you can see from ,\nthe correlation of the two measurements involve both the total intensity and the circular polarization .\nhowever , the degeneracy can be disentangled by using separation method , which will be discussed in the section [ sec : separation method ] .\nin this section , we consider the generalized orfs for circular polarizations : @xmath134 where we defined @xmath135 in the above , we have used and the fact that the generalized orfs do not depend on frequency . for computation of the generalized orfs for circular polarizations ,\nit is convenient to use the computational frame @xcite defined by @xmath136 where @xmath137 is the angular separation between the two pulsars . using - , , and\n, one can easily show that @xmath138 we therefore get @xmath139 the explicit form of the spherical harmonics reads @xmath140 where @xmath141 is the normalization factor .\nthe associated legendre functions are given by @xmath142 and @xmath143 with the legendre functions @xmath144\\ .\\label{pl}\\end{aligned}\\ ] ] using the spherical harmonics , becomes @xmath145 where we have used the fact that the function of @xmath146 is odd parity in the case of @xmath147 and is even parity in the case of @xmath148 .\nnote that the generalized orfs for circular polarizations are real functions . in the case of @xmath149 and/or @xmath150 ,\nthe integrand in vanishes .\ntherefore , we can not detect circular polarizations for these cases .\nthis fact for @xmath151 implies that we do not need to consider auto - correlation for a single pulsar .\nthis is the reason why we neglected auto - correlation term in .    integrating ,\nwe get the following form for @xmath152 : @xmath153 for @xmath154 , we have obtained @xmath155 \\ , \\\\ \\gamma^{v}_{1 - 1}&=&\\gamma^{v}_{11 } \\ , \\end{aligned}\\ ] ] recall that @xmath156 .\nthe derivation of this formula for @xmath154 can be found in appendix [ sec : angular integral of the generalized overlap reduction function for dipole circular polarization ] .    for @xmath157 , we derived the following : @xmath158\\ , \\\\ \\gamma^{v}_{2 - 1}&=&\\gamma^{v}_{21}\\ , \\\\\n\\gamma^{v}_{22}&=&-\\frac{\\sqrt{30\\pi}}{6}(1-\\cos\\xi)\\left[2-\\cos\\xi+6\\left(\\frac{1-\\cos\\xi}{1+\\cos\\xi}\\right)\\log\\left(\\sin\\frac{\\xi}{2}\\right)\\right]\\ , \\\\ \\gamma^{v}_{2 - 2}&=&-\\gamma^{v}_{22}\\ , \\end{aligned}\\ ] ] for @xmath159 , the results are @xmath160\\ , \\\\ \\gamma^{v}_{3 - 1}&=&\\gamma^{v}_{31}\\ , \\\\ \\gamma^{v}_{32}&=&\\frac{\\sqrt{210\\pi}}{24}(1-\\cos\\xi)\\left[8 - 5\\cos\\xi-\\cos^2\\xi+24\\left(\\frac{1-\\cos\\xi}{1+\\cos\\xi}\\right)\\log\\left(\\sin\\frac{\\xi}{2}\\right)\\right]\\ , \\\\ \\gamma^{v}_{3 - 2}&=&-\\gamma^{v}_{3 - 2}\\ , \\\\ \\gamma^{v}_{33}&=&-\\frac{\\sqrt{35\\pi}}{16}\\sin\\xi\\left(\\frac{1-\\cos\\xi}{1+\\cos\\xi}\\right)\\left[11 - 6\\cos\\xi-\\cos^2\\xi+32\\left(\\frac{1-\\cos\\xi}{1+\\cos\\xi}\\right)\\log\\left(\\sin\\frac{\\xi}{2}\\right)\\right]\\ , \\\\ \\gamma^{v}_{3 - 3}&=&\\gamma^{v}_{33}\\ .\\end{aligned}\\ ] ] in fig .\n[ gv ] , we plotted these generalized orfs as a function of the angular separation between the two pulsars @xmath137 .\nit is apparent that considering the @xmath2 mode does not make sense when we only consider the isotropic ( @xmath152 ) orf . on the other hand ,\nwhen we consider anisotropic ( @xmath161 ) orfs , it is worth taking into account polarizations .\nthe polarizations of the sgwb would give us rich information both of super massive black hole binaries and of inflation in the early universe .\nas a function of the angular separation between the two pulsars @xmath137 . in fig .\n[ gv](a ) , we find the orf for the monopole ( l=0 ) is trivial . in fig .\n[ gv](b ) , the orfs for the dipole ( l=1 ) are shown . in fig .\n[ gv](c ) , the orfs for the quadrupole ( l=2 ) are depicted . in fig .\n[ gv](d ) , the orfs for the octupole ( l=3 ) are plotted .\nthe black solid curve , the blue dashed curve , the red dotted curve , the dark - red space - dotted curve , and the green long - dashed curve represent @xmath149 , @xmath162 , @xmath163 , @xmath164 , @xmath165 , respectively.,title=\"fig:\",width=340 ] ( a ) @xmath152     as a function of the angular separation between the two pulsars @xmath137 . in fig . [ gv](a ) , we find the orf for the monopole ( l=0 ) is trivial . in fig .\n[ gv](b ) , the orfs for the dipole ( l=1 ) are shown . in fig .\n[ gv](c ) , the orfs for the quadrupole ( l=2 ) are depicted . in fig .\n[ gv](d ) , the orfs for the octupole ( l=3 ) are plotted .\nthe black solid curve , the blue dashed curve , the red dotted curve , the dark - red space - dotted curve , and the green long - dashed curve represent @xmath149 , @xmath162 , @xmath163 , @xmath164 , @xmath165 , respectively.,title=\"fig:\",width=340 ] ( b ) @xmath154     as a function of the angular separation between the two pulsars @xmath137 . in fig . [ gv](a ) , we find the orf for the monopole ( l=0 ) is trivial . in fig .\n[ gv](b ) , the orfs for the dipole ( l=1 ) are shown . in fig .\n[ gv](c ) , the orfs for the quadrupole ( l=2 ) are depicted . in fig .\n[ gv](d ) , the orfs for the octupole ( l=3 ) are plotted .\nthe black solid curve , the blue dashed curve , the red dotted curve , the dark - red space - dotted curve , and the green long - dashed curve represent @xmath149 , @xmath162 , @xmath163 , @xmath164 , @xmath165 , respectively.,title=\"fig:\",width=340 ] ( c ) @xmath157     as a function of the angular separation between the two pulsars @xmath137 . in fig .\n[ gv](a ) , we find the orf for the monopole ( l=0 ) is trivial . in fig .\n[ gv](b ) , the orfs for the dipole ( l=1 ) are shown . in fig .\n[ gv](c ) , the orfs for the quadrupole ( l=2 ) are depicted . in fig .\n[ gv](d ) , the orfs for the octupole ( l=3 ) are plotted .\nthe black solid curve , the blue dashed curve , the red dotted curve , the dark - red space - dotted curve , and the green long - dashed curve represent @xmath149 , @xmath162 , @xmath163 , @xmath164 , @xmath165 , respectively.,title=\"fig:\",width=340 ] ( d ) @xmath159    using the same procedure described in the above to derive the generalized orfs for circular polarizations , we can also derive the generalized orfs for the intensity @xmath166 where @xmath167 the angular integral in this case was performed in @xcite .\nthe results are summarized in appendix [ sec : the generalized overlap reduction function for intensity ] .\nin this section , we separate the @xmath3 mode and @xmath2 mode of the sgwb with correlation analysis @xcite . to this aim ,\nwe use four pulsars ( actually we need at least three pulsars ) , and define correlations of @xmath168 @xmath169 where @xmath170 label the pulsars . comparing with , we obtain @xmath171 \\ ,\n\\label{1c12}\\\\ & & c_{34}(f)=\\sum_{lm}^{l=3}\\left[c_{lm}^{i}i(f)\\gamma_{lm,34}^{i}+c_{lm}^{v}v(f)\\gamma_{lm,34}^{v}\\right ] \\ .\\label{1c34}\\end{aligned}\\ ] ] if the @xmath3 mode and @xmath2 mode of the sgwb are dominated by a certain @xmath172 and @xmath173 , and become @xmath174 \\ , \\label{2c12 } \\\\ & & c_{34}(f)=\\left[c _ { l m}^{i}i(f)\\gamma _ { l m,34}^{i}+c _ { l ' m'}^{v}v(f)\\gamma _ { l ' m',34}^{v}\\right ] \\ .\\label{2c34}\\end{aligned}\\ ] ] to separate the intensity and the circular polarization , we take the following linear combinations @xmath175 where we defined coefficients @xmath176 as you can see , @xmath177 contains only @xmath40 , and @xmath178 contains only @xmath179 .\nfor the signal @xmath180 , the formulas corresponding to and are given by @xmath181 \\ , \\label{sp}\\end{aligned}\\ ] ] where @xmath182 denotes @xmath3 and @xmath2 .\nwe assume @xmath183 and that the noise in the four pulsars are not correlated .\nwe also assume that the ensemble average of fourier amplitudes of the noises @xmath184 is of the form @xmath185 where @xmath186 is the noise power spectral density .\nthe reality of @xmath187 gives rise to @xmath188 and therefore we obtain @xmath189 . without loss of generality\n, we can assume @xmath190 then we obtain corresponding noises @xmath191 : @xmath192\\ , \\label{np}\\end{aligned}\\ ] ] where @xmath193^{1/2 } \\label{sn12 } \\ , \\quad s_{n,34}(f ) \\equiv [ s_{n,3}(f)s_{n,4}(f)]^{1/2 } \\label{sn34 } \\ .\\end{aligned}\\ ] ] using the inner product @xmath194 \\ , \\end{aligned}\\ ] ] we can rewrite , as @xmath195 therefore , the optimal filter function can be chosen as @xmath196 using , we get optimal signal - to - noise ratio @xmath197^{1/2}\\ .\\label{snr}\\end{aligned}\\ ] ] plugging , , and into , we obtain @xmath198^{1/2}\\ , \\\\\n{ \\rm snr}_{v}&=&\\left[t\\int_{-\\infty}^{\\infty}df\\,\\,\\frac{\\left(c^{v}_{{l}'{m}'}\\right)^{2}v^{2}(f)\\left(\\gamma_{{l}'{m}',34}^{v}\\gamma^{i}_{{l}{m},12}-\\gamma_{{l}'{m}',12}^{v}\\gamma^{i}_{{l}{m},34}\\right)^2}{\\left(\\gamma^{i}_{{l}{m},12}\\right)^2s^{2}_{n,34}(f)+\\left(\\gamma^{i}_{{l}{m},34}\\right)^2s^{2}_{n,12}(f)}\\right]^{1/2}\\ .\\end{aligned}\\ ] ] if we assume all of the noise power spectral densities are the same , becomes @xmath199 thus , the compiled orfs can be defined as @xmath200^{1/2}}\\ , \\\\ \\gamma_{12:34}^{v}&\\equiv&\\frac{\\gamma_{{l}'{m}',34}^{v}\\gamma^{i}_{{l}{m},12}-\\gamma_{{l}'{m}',12}^{v}\\gamma^{i}_{{l}{m},34}}{\\left[\\left(\\gamma^{i}_{{l}{m},12}\\right)^2+\\left(\\gamma^{i}_{{l}{m},34}\\right)^2\\right]^{1/2}}\\ .\\end{aligned}\\ ] ] this compiled orfs @xmath201 and @xmath202 describe the angular sensitivity of the four pulsars for the pure @xmath3 and @xmath2 mode of the sgwb , respectively .\nnote that , to do this separation , we must know a priori the coefficients @xmath203 and @xmath204 .\nif we do not assume , the generalized orfs depend on the frequency . in this case\n, it seems difficult to calculate these coefficients .\nwe next consider the case that @xmath3 mode and/or @xmath2 mode dominant in two or more @xmath205 . in this case , if we have a priori knowledge of the values of @xmath206 in each of @xmath205 for coefficients\n@xmath203 and @xmath204 , we can separate @xmath3 mode and @xmath2 mode . for example , assume that @xmath3 mode is dominated by @xmath207 , while @xmath2 mode is dominated by @xmath208 , then and become @xmath209\\ , \\label{3c12}\\\\ & & c_{34}(f)=\\left[c^{i}_{00}i(f)\\left(\\gamma_{00,34}^{i}+\\frac{c^{i}_{11}}{c^{i}_{00}}\\gamma_{11,34}^{i}\\right)+c_{11}^{v}v(f)\\gamma_{11,34}^{v}\\right]\\ .\\label{3c34}\\end{aligned}\\ ] ] thus , we can separate @xmath3 mode and @xmath2 mode by using linear combinations @xmath210\\ , \\\\\nd_{v}&\\equiv&a_{v}c_{34}(f)+b_{v}c_{12}(f ) \\nonumber\\\\ & = & c_{11}^{v}v(f)\\left[\\gamma_{11,34}^{v}\\left(\\gamma_{00,12}^{i}+\\frac{c^{i}_{11}}{c^{i}_{00}}\\gamma_{11,12}^{i}\\right)-\\gamma_{11,12}^{v}\\left(\\gamma_{00,34}^{i}+\\frac{c^{i}_{11}}{c^{i}_{00}}\\gamma_{11,34}^{i}\\right)\\right]\\ , \\end{aligned}\\ ] ] where @xmath211 as in the previous calculations , we can get the compiled orfs @xmath212^{1/2}}\\ , \\label{gi1234}\\\\ \\gamma_{12:34}^{v}&\\equiv&\\frac{\\gamma_{11,34}^{v}\\left(\\gamma_{00,12}^{i}+\\displaystyle\\frac{c^{i}_{11}}{c^{i}_{00}}\\gamma_{11,12}^{i}\\right)-\\gamma_{11,12}^{v}\\left(\\gamma_{00,34}^{i}+\\displaystyle\\frac{c^{i}_{11}}{c^{i}_{00}}\\gamma_{11,34}^{i}\\right)}{\\left[\\left(\\gamma_{00,12}^{i}+\\displaystyle\\frac{c^{i}_{11}}{c^{i}_{00}}\\gamma_{11,12}^{i}\\right)^2+\\left(\\gamma_{00,34}^{i}+\\displaystyle\\frac{c^{i}_{11}}{c^{i}_{00}}\\gamma_{11,34}^{i}\\right)^2\\right]^{1/2}}\\ .\\label{gv1234}\\end{aligned}\\ ] ]    [ cols=\"^,^ \" , ]     in fig .\n[ cg ] we show some compiled orfs @xmath213 ( left panels ) and @xmath214 ( right panels ) as a function of the two angular separations @xmath137 and @xmath215 for two pulsar pairs , respectively .\nwe used the expressions of @xmath2 mode and @xmath3 mode ( see appendix [ sec : the generalized overlap reduction function for intensity ] ) , and we assumed @xmath216 for simplicity . in fig .\n[ cg](a ) and [ cg](b ) , the @xmath3 mode is dominated by @xmath217 and @xmath2 mode is dominated by @xmath218 . in fig .\n[ cg](c ) and [ cg](d ) , the @xmath3 mode is dominated by @xmath219 and @xmath2 mode is dominated by @xmath218 . in fig .\n[ cg](e ) and [ cg](f ) , the @xmath3 mode is dominated by @xmath207 and @xmath2 mode is dominated by @xmath218 . in fig .\n[ cg](e ) and [ cg](f ) , the @xmath3 mode is dominated by @xmath220 and @xmath2 mode is dominated by @xmath218 . by definition , in the case of @xmath221 ,\nthe compiled orfs are zero .\nwe have studied the detectability of the stochastic gravitational waves with ptas . in most of the previous works ,\nthe isotropy of sgwb has been assumed for the analysis .\nrecently , however , a stochastic gravitational wave background with anisotropy have been considered .\nthe information of the anisotropic pattern of the distribution should contain important information of the sources such as supermassive black hole binaries and the sources in the early universe .\nit is also intriguing to take into account the polarization of sgwb in the pta analysis .\ntherefore , we extended the correlation analysis to circularly polarized sgwb and calculated generalized overlap reduction functions for them .\nit turned out that the circular polarization can not be detected for an isotropic background .\nhowever , when the distribution has anisotropy , we have shown that there is a chance to observe circular polarizations in the sgwb .\nwe also discussed how to separate polarized modes from unpolarized modes of gravitational waves .\nif we have a priori knowledge of the abundance ratio for each mode in each of @xmath205 , we can separate @xmath3 mode and @xmath2 mode in general .\nthis would be possible if we start from fundamental theory and calculate the spectrum of sgwb .\nin particular , in the case that the signal of lowest @xmath222 is dominant , we performed the separation of @xmath3 mode and @xmath2 mode explicitly .\nthis work was supported by grants - in - aid for scientific research ( c ) no.25400251 and \" mext grant - in - aid for scientific research on innovative areas no.26104708 and `` cosmic acceleration''(no.15h05895 ) .\nin this appendix , we perform angular integration of the generalized orf for dipole ( @xmath154 ) circular polarization ( see @xcite ) : @xmath223 where we have defined @xmath224 .\nit is obvious that in the case of @xmath225 , integrand of the generalized orf is zero , because of @xmath226 , then we obtain @xmath227 then , using - , we calculate @xmath228 and we find @xmath229    therefore we only have to consider the dipole generalized orf in the case of @xmath154 , @xmath230 : @xmath231 where @xmath232 first , to calculate @xmath233 , we use contour integral in the complex plane . defining @xmath234 and substituting @xmath235 into , we can rewrite @xmath233 as @xmath236 } \\ , \\end{aligned}\\ ] ] where @xmath237 denotes a unit circle .\nwe can factorize the denominator of the integrand and get @xmath238 where @xmath239 hereafter , the upper sign applies when @xmath240 and the lower one applies when @xmath241 .\nnote that we only consider the region @xmath242 , so we have used the relation @xmath243 in above expression . in the region\n@xmath244 , @xmath245 is inside the unit circle @xmath237 except for @xmath246 and @xmath247 is outside the unit circle @xmath237 .\nnow , we can perform the integral using the residue theorem @xmath248 where @xmath249 the residues inside the unit circle @xmath237 can be evaluated as @xmath250\\right\\ }             = \\frac{i(z_{+}+z_{-})}{2\\sqrt{1-x^2}\\sin\\xi } \\ , \\end{aligned}\\ ] ] @xmath251 thus , we obtain @xmath252 next , we consider @xmath253 defined in\n. using , we can calculate @xmath253 as @xmath254    similarly , we can evaluate @xmath255 given in . to calculate @xmath255 in the complex plane , we again substitute into and obtain @xmath256 we use the residue theorem @xmath257 where @xmath258 the residues inside the unit circle @xmath237 can be calculated as @xmath259\\right\\ }        = \\frac{i(z_{+}^2+z_{-}^2)}{4\\sqrt{1-x^2}\\sin\\xi } \\ , \\end{aligned}\\ ] ] @xmath260 therefore , @xmath255 becomes @xmath261 substituting to , we can calculate @xmath262 : @xmath263    finally , substituting and into , we get the generalized orf for @xmath264 @xmath265\\ .\\end{aligned}\\ ] ]     as a function of the angular separation between the two pulsars @xmath137 .\n[ gi](a ) shows monopole ( l=0 ) , fig .\n[ gi](b ) shows dipole ( l=1 ) , fig .\n[ gi](c ) shows quadrupole ( l=2 ) and fig .\n[ gi](d ) shows octupole ( l=3 ) .\nthe black solid curve , the blue dashed curve , the dark - blue dash - dotted curve , the red dotted curve , the green long - dashed curve , the dark - green space - dashed curve represent @xmath149 , @xmath266 , @xmath267 , @xmath268 , @xmath269 , @xmath270 , respectively.,title=\"fig:\",width=340 ] ( a ) @xmath152     as a function of the angular separation between the two pulsars @xmath137 .\n[ gi](a ) shows monopole ( l=0 ) , fig .\n[ gi](b ) shows dipole ( l=1 ) , fig .\n[ gi](c ) shows quadrupole ( l=2 ) and fig .\n[ gi](d ) shows octupole ( l=3 ) .\nthe black solid curve , the blue dashed curve , the dark - blue dash - dotted curve , the red dotted curve , the green long - dashed curve , the dark - green space - dashed curve represent @xmath149 , @xmath266 , @xmath267 , @xmath268 , @xmath269 , @xmath270 , respectively.,title=\"fig:\",width=340 ] ( b ) @xmath154     as a function of the angular separation between the two pulsars @xmath137 . fig . [ gi](a ) shows monopole ( l=0 ) , fig .\n[ gi](b ) shows dipole ( l=1 ) , fig .\n[ gi](c ) shows quadrupole ( l=2 ) and fig .\n[ gi](d ) shows octupole ( l=3 ) .\nthe black solid curve , the blue dashed curve , the dark - blue dash - dotted curve , the red dotted curve , the green long - dashed curve , the dark - green space - dashed curve represent @xmath149 , @xmath266 , @xmath267 , @xmath268 , @xmath269 , @xmath270 , respectively.,title=\"fig:\",width=340 ] ( c ) @xmath157     as a function of the angular separation between the two pulsars @xmath137 .\n[ gi](a ) shows monopole ( l=0 ) , fig .\n[ gi](b ) shows dipole ( l=1 ) , fig .\n[ gi](c ) shows quadrupole ( l=2 ) and fig .\n[ gi](d ) shows octupole ( l=3 ) . the black solid curve , the blue dashed curve , the dark - blue dash - dotted curve , the red dotted curve , the green long - dashed curve , the dark - green space - dashed curve represent @xmath149 , @xmath266 , @xmath267 , @xmath268 , @xmath269 , @xmath270 , respectively.,title=\"fig:\",width=340 ] ( d ) @xmath159\nin this appendix , we show orfs for the intensity @xcite .\nthe following form for @xmath152 was derived in @xcite , and our expressions are identical to their expressions : @xmath271\\ , \\end{aligned}\\ ] ] for , @xmath154 , we calculated as @xmath272\\ , \\\\ \\gamma^{i}_{11}&=&\\frac{\\sqrt{6\\pi}}{12}\\sin\\xi\\left[1 + 3(1-\\cos\\xi)\\left\\{1+\\frac{4}{1+\\cos\\xi}\\log\\left(\\sin\\frac{\\xi}{2}\\right)\\right\\}\\right]\\ , \\\\ \\gamma^{i}_{1 - 1}&=&-\\gamma^{i}_{11}\\ , \\end{aligned}\\ ] ] for @xmath157 , we obtain @xmath273\\ , \\\\ \\gamma^{i}_{21}&=&-\\frac{\\sqrt{30\\pi}}{60}\\sin\\xi\\left[21 - 15\\cos\\xi-5\\cos^2\\xi+60\\left(\\frac{1-\\cos\\xi}{1+\\cos\\xi}\\right)\\log\\left(\\sin\\frac{\\xi}{2}\\right)\\right]\\ , \\\\ \\gamma^{i}_{2 - 1}&=&-\\gamma^{i}_{2 - 1}\\ , \\\\ \\gamma^{i}_{22}&=&\\frac{\\sqrt{30\\pi}}{24}(1-\\cos\\xi)\\left[9 - 4\\cos\\xi-\\cos^2\\xi+24\\left(\\frac{1-\\cos\\xi}{1+\\cos\\xi}\\right)\\log\\left(\\sin\\frac{\\xi}{2}\\right)\\right]\\ , \\\\ \\gamma^{i}_{2 - 2}&=&\\gamma^{i}_{22}\\ ,\n\\end{aligned}\\ ] ] for @xmath159 , it is straightforward to reach the following @xmath274\\ , \\\\ \\gamma^{i}_{31}&=&\\frac{\\sqrt{21\\pi}}{48}\\sin\\xi(1-\\cos\\xi)\\left[34 + 15\\cos\\xi+5\\cos^2\\xi+\\frac{96}{1+\\cos\\xi}\\log\\left(\\sin\\frac{\\xi}{2}\\right)\\right]\\ , \\\\ \\gamma^{i}_{3 - 1}&=&-\\gamma^{i}_{31}\\ , \\\\ \\gamma^{i}_{32}&=&-\\frac{\\sqrt{210\\pi}}{48}(1-\\cos\\xi)\\left[17 - 9\\cos\\xi-3\\cos^2\\xi-\\cos^3\\xi+48\\left(\\frac{1-\\cos\\xi}{1+\\cos\\xi}\\right)\\log\\left(\\sin\\frac{\\xi}{2}\\right)\\right]\\ , \\\\ \\gamma^{i}_{3 - 2}&=&\\gamma^{i}_{32}\\ , \\\\ \\gamma^{i}_{33}&=&\\frac{\\sqrt{35\\pi}}{48}\\frac{(1-\\cos\\xi)^2}{\\sin\\xi}\\left[34 - 17\\cos\\xi-4\\cos^2\\xi-\\cos^3\\xi+96\\left(\\frac{1-\\cos\\xi}{1+\\cos\\xi}\\right)\\log\\left(\\sin\\frac{\\xi}{2}\\right)\\right]\\ , \\\\ \\gamma^{i}_{3 - 3}&=&-\\gamma^{i}_{33}\\ .\\end{aligned}\\ ] ] these are plotted in fig .\nthe generalized orfs of total intensity are different from that of circular polarization in that the value for @xmath149 is non - trivial .\nthen the @xmath3 mode orfs for @xmath275 have value even in the case of @xmath151 .\nthis implies that we can consider auto - correlation for a single pulsar .\n99 j.  aasi _ et al .\n_ [ ligo scientific collaboration ] , class .\ngrav .   * 32 * , 074001 ( 2015 ) doi:10.1088/0264 - 9381/32/7/074001 [ arxiv:1411.4547 [ gr - qc ] ] .\nf.  acernese _ et al . _\n[ virgo collaboration ] , class .\ngrav .   * 32 * , no . 2 , 024001 ( 2015 ) doi:10.1088/0264 - 9381/32/2/024001 [ arxiv:1408.3978 [ gr - qc ] ] . k.  somiya [ kagra collaboration ] , class .\n* 29 * , 124007 ( 2012 ) doi:10.1088/0264 - 9381/29/12/124007 [ arxiv:1111.7185 [ gr - qc ] ] .\ns.  l.  detweiler , astrophys .\nj.   * 234 * , 1100 ( 1979 ) .\ndoi:10.1086/157593 romani , r. w. ( 1989 ) .\ntiming a millisecond pulsar array . timing neutron stars , 113 - 117 .\nl.  lentati _ et al .\n_ , mon .  not .\nsoc .   * 453 * , 2576 ( 2015 ) [ arxiv:1504.03692 [ astro-ph.co ] ] .\nz.  arzoumanian _ et al .\n_ [ nanograv collaboration ] , arxiv:1508.03024 [ astro-ph.ga ] . e.  s.  phinney , astro - ph/0108028 . a.  vilenkin , phys .\nrept .   * 121 * , 263 ( 1985 ) .\ns.  kuroyanagi , k.  miyamoto , t.  sekiguchi , k.  takahashi and j.  silk , phys .\nd * 87 * , no . 2 , 023522 ( 2013 ) [ phys .\nd * 87 * , no .\n6 , 069903 ( 2013 ) ] [ arxiv:1210.2829 [ astro-ph.co ] ] .\nm.  maggiore , gr - qc/0008027 .\nl.  p.  grishchuk , phys .\n* 48 * , 1235 ( 2005 ) doi:10.1070/pu2005v048n12abeh005795 [ gr - qc/0504018 ] .\nb.  allen and j.  d.  romano , phys .\nd * 59 * , 102001 ( 1999 ) [ gr - qc/9710117 ] .\nc.  m.  f.  mingarelli , t.  sidery , i.  mandel and a.  vecchio , phys .\nd * 88 * , no . 6 , 062005 ( 2013 ) [ arxiv:1306.5394 [ astro-ph.he ] ] .\ns.  r.  taylor and j.  r.  gair , phys .\nd * 88 * , 084001 ( 2013 ) [ arxiv:1306.5395 [ gr - qc ] ] .\nn.  seto and a.  taruya , phys .\nlett .   * 99 * , 121101 ( 2007 ) doi:10.1103/physrevlett.99.121101 [ arxiv:0707.0535 [ astro - ph ] ] . n.  seto and a.  taruya , phys .  rev .\nd * 77 * , 103001 ( 2008 ) [ arxiv:0801.4185 [ astro - ph ] ] . s.  j.  chamberlin and x.  siemens , phys .\nd * 85 * , 082001 ( 2012 ) doi:10.1103/physrevd.85.082001 [ arxiv:1111.5661 [ astro-ph.he ] ] . j.  r.  gair , j.  d.  romano and s.  r.  taylor , phys .  rev .\nd * 92 * , no .\n10 , 102003 ( 2015 ) doi:10.1103/physrevd.92.102003 [ arxiv:1506.08668 [ gr - qc ] ] .\nr.  jackiw and s.  y.  pi , phys .\nd * 68 * , 104012 ( 2003 ) doi:10.1103/physrevd.68.104012 [ gr - qc/0308071 ] . m.  satoh , s.  kanno and j.  soda , phys .\nd * 77 * , 023526 ( 2008 ) doi:10.1103/physrevd.77.023526 [ arxiv:0706.3585 [ astro - ph ] ] . c.  r.  contaldi , j.  magueijo and l.  smolin , phys .\n* 101 * ( 2008 ) 141101 doi:10.1103/physrevlett.101.141101 [ arxiv:0806.3082 [ astro - ph ] ] .\nt.  takahashi and j.  soda , phys .\nlett .   * 102 * , 231301 ( 2009 ) doi:10.1103/physrevlett.102.231301 [ arxiv:0904.0554 [ hep - th ] ] .\nj.  l.  cook and l.  sorbo , phys .\nd * 85 * , 023534 ( 2012 ) [ phys .\nd * 86 * , 069901 ( 2012 ) ] doi:10.1103/physrevd.86.069901 , 10.1103/physrevd.85.023534 [ arxiv:1109.0022 [ astro-ph.co ] ] .\ni.  obata , t.  miura and j.  soda , phys .\nd * 92 * , no .\n6 , 063516 ( 2015 ) doi:10.1103/physrevd.92.063516 [ arxiv:1412.7620 [ hep - ph ] ] .\na. p. lightman , w. h. press , r. h. price , and s. a. teukolski , problem book in relativity and gravitation , 2nd ed .\n( princeton university press , 1979 ) .\nm. maggiore , gravitational waves , vol . 1 : theory and experiments ( oxford university press , 2008 )\n. g. b. rybicki , a. p. lightman , radiative processes in astrophysics ( wiley - interscience , 1979 ) .\nl. d. landau and e. m. lifshitz , the classical theory ( pergamon press , 1975 ) . c. misner , k. thorne and j. wheeler , gravitation , ( freeman 1973 ) .\nb.  allen and a.  c.  ottewill , phys .\nd * 56 * , 545 ( 1997 ) doi:10.1103/physrevd.56.545 [ gr - qc/9607068 ] .\nu.  seljak and m.  zaldarriaga , phys .\nlett .   * 78 * , 2054 ( 1997 ) doi:10.1103/physrevlett.78.2054 [ astro - ph/9609169 ] .\nj. n. goldberg et al .\n, journal of mathematical physics * 8 * , 2155 , 1967 . m.  anholm , s.  ballmer , j.  d.  e.  creighton , l.  r.  price and x.  siemens , phys .\nd * 79 * , 084030 ( 2009 ) doi:10.1103/physrevd.79.084030 [ arxiv:0809.0701 [ gr - qc ] ] . l.  g.  book and e.  e.  flanagan , phys .\nd * 83 * , 024024 ( 2011 ) doi:10.1103/physrevd.83.024024 [ arxiv:1009.4192 [ astro-ph.co ] ] . f.  a.  jenet and j.  d.  romano , am .\nj.  phys .\n* 83 * , 635 ( 2015 ) doi:10.1119/1.4916358 [ arxiv:1412.1142 [ gr - qc ] ] .\nr.  w.  hellings and g.  s.  downs , astrophys .\nj.   * 265 * , l39 ( 1983 ) . doi:10.1086/183954"}
{"lay_summary": " starting from the wkb approximation , a new barrier penetration formula is proposed for potential barriers containing a long - range coulomb interaction . \n this formula is especially proper for the barrier penetration with penetration energy much lower than the coulomb barrier . \n the penetrabilities calculated from the new formula agree well with the results from the wkb method . as a first attempt , \n this new formula is used to evaluate @xmath0 decay half - lives of atomic nuclei and a good agreement with the experiment is obtained . ", "article": "as a common quantum phenomenon , the tunneling through a potential barrier plays a very important role in the microscopic world and has been studied extensively since the birth of quantum mechanics .\none of the earliest applications of quantum tunneling is the explanation of @xmath0 decays in atomic nuclei .\nthe quantum tunneling effect governs also many other nuclear processes such as fission and fusion .\nin particular , a lot of new features are revealed in sub - barrier fusion reactions which are closely connected with the tunneling phenomena  @xcite .    for most of the potential barriers , the penetrability can not be calculated analytically  @xcite . among those potentials for which analytical solutions can be obtained ,\nthe parabolic potential  @xcite is the mostly used in the study of nuclear fusion . by approximating the coulomb barrier to a parabola\n, wong derived an analytic expression for the fusion cross section  @xcite which is widely adopted today in the study of heavy ion reactions ( see , e.g. , recent refs .\nthe parabolic approximation works remarkably well both for the penetrability and for the fusion cross section at energies around or above the coulomb barrier  @xcite .\napparently the parabolic approximation breaks down at energies much smaller than the barrier height due to the long - range coulomb interaction .\none may calculate the penetration probability numerically by using the path integral method or the wkb approximation .\nhowever , it is highly desirable to have an analytical expression for the barrier penetrability when one introduces an energy - dependent one - dimensional potential barrier  @xcite or barrier distribution functions  @xcite .    in the present work\n, we derived a new barrier penetration formula based on the wkb approximation .\nthe influence of the long coulomb tail in the barrier potential is taken into accout properly .\ntherefore this formula is especially applicable to the barrier penetration with penetration energy much lower than the coulomb barrier .    as a first attempt and a test study\n, we apply this new formula to evaluate @xmath0 decay half - lives of atomic nuclei . for the @xmath0 decay ,\nthe penetrability is usually calculated with the wkb approach  @xcite , in other words , integrating numerically the wave number within two turning points at which the interaction potential is equal to the @xmath1-value of the @xmath0 decay .\nwe will show that the present analytical formula reproduces the experimental results very well , especially for spherical nuclei .\nthe paper is organized as follows . in sec .\n[ sec : formalism ] we present the new barrier penetration formula .\nthe validity of the new formula is investigated and its application to @xmath0 decays are given in sec .\n[ sec : results ] . finally in sec .\n[ sec : summary ] we summarize our work . in the appendix ,\nthe detailed derivation of the new penetration formula is given .\nwhen the penetration energy is well below the coulomb barrier , the barrier penetrability formula derived from the wkb approximation reads , @xmath2 ,   \\label{eq : wkb}\\ ] ] where the potential usually consists of three parts , the nuclear , the coulomb , and the centrifugal potentials , @xmath3 @xmath4 and @xmath5 are the inner and outer turning points determined by the relation @xmath6 .    by approximating @xmath7 to a parabola with the height @xmath8 and the width @xmath9 , eq .\n( [ eq : wkb ] ) is reduced as @xmath10 ,   \\label{eq : hw}\\ ] ] which has been widely used in the study of heavy ion reactions .    because of the long - range coulomb interaction , the coulomb barrier given in eq .\n( [ eq : potential ] ) has a long tail and is asymmetric .\nthus for the penetration well below the barrier , the parabolic approximation is not valid .\nwe may divide the potential barrier into two parts at the barrier position @xmath11 .\nthe first part of @xmath7 with @xmath12 could still be approximated by half of a parabola and we need to evaluate the integration in eq .\n( [ eq : wkb ] ) in the range @xmath13 only . for s wave , the integral in eq .\n( [ eq : wkb ] ) is evaluated as , @xmath14 ,   \\label{eq : x1x2}\\ ] ] with @xmath15 under the parabolic approximation and @xmath16   \\nonumber \\\\   &    & \\mbox { }   +   \\frac { k a } { \\sqrt { \\tau - 1 } } \\frac{v_0}{e }   \\ln [ 1 + e^ { ( r_0 - r_b ) / a } ]   \\label{eq : new }   , \\end{aligned}\\ ] ] where @xmath17 and @xmath18 .\nthe details of the derivation of eq .\n( [ eq : new ] ) are given in the appendix .\nit should be mentioned that in the derivation of eq .\n( [ eq : new ] ) , a woods - saxon form is used for @xmath19 .\nin this section , we use the new formula to study the typical barrier penetration problem , @xmath0 decays of atomic nuclei .\nthe @xmath0 decay half - life is related to the decay width @xmath20 by @xcite @xmath21 the decay width @xmath20 is calculated as  @xcite @xmath22 where @xmath23 is the assaults frequency of @xmath0 particle on the barrier , @xmath24 the spectroscopic or preformation factor and @xmath25 the penetrability with @xmath1 the @xmath0 decay q - value . for spherical nuclei ,\n@xmath26 is parametrized as  @xcite @xmath27 and the penetrability will be calculated with eqs .\n( [ eq : x1x2 ] ) , ( [ eq : left ] ) , and ( [ eq : new ] ) .\n( color online ) the barrier potential between the @xmath0 and the daughter nucleus for @xmath28po and @xmath29nd .\nthe solid curve shows the exact potential @xmath7 and the dashed curve stands for the effective potential given in eq .\n( [ eq : veff ] ) associated with the parabolic approximation eq .\n( [ eq : left ] ) and the new barrier penetration formula eq .\n( [ eq : new ] ) .\nnote that the two curves are almost identical to each other . , title=\"fig:\",scaledwidth=45.0% ]   ( color online ) the barrier potential between the @xmath0 and the daughter nucleus for @xmath28po and @xmath29nd .\nthe solid curve shows the exact potential @xmath7 and the dashed curve stands for the effective potential given in eq .\n( [ eq : veff ] ) associated with the parabolic approximation eq .\n( [ eq : left ] ) and the new barrier penetration formula eq .\n( [ eq : new ] ) .\nnote that the two curves are almost identical to each other .\n, title=\"fig:\",scaledwidth=45.0% ]    for the @xmath0-nuclear interaction , we adopt the coulomb and the woods - saxon potentials and parameters proposed in ref .\n@xcite , @xmath30 , & r \\le r_m ,   \\end{cases }   \\label{eq : coulomb}\\ ] ] and @xmath31 }   , \\end{aligned}\\ ] ] with @xmath32 and @xmath33 the mass and charge numbers of the daughter nucleus and @xmath1 the @xmath0 decay energy . the parameters in these potentials and given in eq .\n( [ eq : prefomation ] ) were obtained by fitting @xmath0 decay half lives and cross section data for several fusion reactions .\nit can be easily verified that the position of the coulomb barrier @xmath11 is larger than @xmath34 thus the use of the coulomb force given in eq .\n( [ eq : coul ] ) is valid .\nbefore the new formula is used to study alpha decays , we investigate in details its validity .\nfirst we examine how the effective potential connected with the new formula eq .\n( [ eq : new ] ) is close to the exact one .\ntwo extreme examples are chosen for this purpose , @xmath28po which has a very short half - life @xmath35 s and @xmath29nd which has a quite long half - life @xmath36 s  @xcite .\nthe barrier potential @xmath7 is shown in fig .\n[ fig : potential ] for these two systems .\nthe effective potential ,    @xmath37    is also shown for comparison .\n@xmath38 fm is the radial position outside of which the nuclear part of the @xmath0-nucleus potential could be neglected ( see the appendix for more details ) . in our calculations , the width of the parabolic potential is obtained by fitting the barrier potential from the inner turning point @xmath39 to the position of the barrier @xmath11 . unlike the full parabolic approximation ,\nthe effective potential is asymmetric and coincides with the exact potential very well , especially the outer side of the barrier which critically influences @xmath0 decays .\n.[tab : deviation ] comparison of the results for the barrier penetration probability for @xmath0 decays in po isotopes ( charge and mass numbers of the @xmath0 emitter are listed in the first and the second entries ) .\nthe meaning of @xmath40 is given in eq .\n( [ eq : x1x2 ] ) .\nthe superscript `` wkb '' means the penetrability calculated from the wkb approach , `` para '' from the parabolic approximation in eq .\n( [ eq : left ] ) , and `` new '' from the new formulas eq .\n( [ eq : new ] ) . [ cols=\"^,^,^,^,^,^,^\",options=\"header \" , ]     the deformation influences the @xmath0 decay life time both on the preformation mechanism and on the penetration process  @xcite . in the present work , we have assumed the barrier potential to be spherical . in 68 of these 344 nuclei\n, the spherical potential assumption is met well ( with @xmath41 for the daughter nucleus  @xcite ) . in table\n[ tab : spherical ] the calculated and experimental values of the @xmath0 decay half lives for these nuclei are given . the statistical summary is also shown in the last line of table  [ tab : stati ] .\nit is found that the new formula gives very good results for these spherical nuclei . in most cases , the differences between the calculated and the experimental values of @xmath42 are smaller than 0.5 .\nthe root mean square deviation between @xmath43 $ ] and @xmath44 $ ] is 0.34 .\nin the study of barrier penetration in nuclear physics , the parabolic approximation is usually adopted because an analytical solution exists for the penetrability of a parabola barrier potential .\nthe parabola approximation works indeed well both for the penetrability and for the fusion cross section at energies around or above the coulomb barrier .\nbut it fails at energies much smaller than the barrier height due to the long - range coulomb interaction .    in the present work\n, we derived a new barrier penetration formula , eq .\n( [ eq : new ] ) , based on the wkb approximation .\nwe took into account the influence of the long coulomb tail in the barrier potential properly .\ntherefore this formula is especially applicable to the barrier penetration with penetration energy much lower than the coulomb barrier .\nwe have shown that the present analytical formula reproduces the wkb results very well .\nthis new penetration formula is used to calculate @xmath0 decay half - lives of 344 nuclei with the @xmath0-nucleus potential given in ref .\nsatisfactory agreement between the present calculation and the experiment is achieved . for spherical and even - even nuclei ,\nthe results are particularly good .\ntherefore , the new formula could be used in the study of barrier penetration at energies much smaller than the barrier height .\nfurthermore , we expect that the new formula will facilitate the study of the barrier penetrability where one has to introduce an energy - dependent one - dimensional potential barrier or a barrier distribution function .\nthis work was partly supported by the national natural science foundation ( 10575036 , 10705014 , and 10875157 ) , the major state basic research development program of china ( 2007cb815000 ) , the knowledge innovation project of cas ( kjcx3-syw - n02 and kjcx2-sw - n17 ) , and deutsche forschungsgemeinschaft .\nthe computation of this work was supported by supercomputing center , cnic , cas .\nin order to evaluate the integration @xmath45 in eq .\n( [ eq : x1x2 ] ) , we divide the potential between the position of the barrier @xmath11 and the outer turning point @xmath5 into two parts , @xmath46 and @xmath47 .\n@xmath48 should be large enough so that the nuclear potential vanishes for @xmath49 . for s\nwave , @xmath50 it has been verified that when @xmath48 is not very close to @xmath5 , @xmath51 , therefore , @xmath52\\ dr   \\nonumber \\\\   &    & \\mbox { } +   2 \\int^{r _ \\mathrm{out } } _ { r_\\mathrm{v } }      \\sqrt { \\frac{2\\mu } { \\hbar^2 } \\left ( v_\\mathrm{c}(r ) - e \\right ) } \\ dr   \\nonumber   \\end{aligned}\\ ] ] @xmath53 since the coulomb potential outside the barrier ( @xmath54 ) is well described by [ c.f .\n( [ eq : coulomb ] ] , @xmath55 the first term in the above equation can be evaluated easily as , @xmath56   , \\end{aligned}\\ ] ] with @xmath17 and @xmath18 . for the evaluation of the second term in eq .\n( [ eq : x1x2_approx ] ) , we adopt a woods - saxon form for the nuclear part of the barrier potential , @xmath57 }   , \\end{aligned}\\ ] ] and replace @xmath58 in the denominator by @xmath59 , @xmath60   \\right\\ } \\right|_{r_b}^ { r _ { \\mathrm{v } } }   \\nonumber \\\\   & \\approx &   \\frac { k } { \\sqrt { \\tau - 1 } } \\frac{v_0}{e }   \\ {   r_0- r_b + a \\ln [ 1 + e^ { ( r_b - r_0 ) / a } ]   \\ }   \\nonumber \\\\   & = &   \\frac { k a } { \\sqrt { \\tau - 1 } } \\frac{v_0}{e }   \\ln [ 1 + e^ { ( r_0 - r_b ) / a } ]   .\\end{aligned}\\ ] ] in the above derivation , we have used the fact that @xmath61 \\gg 1 $ ] for @xmath0 decay and penetration well below the coulomb barrier .\nfinally , we have an analytical expression for @xmath45 , @xmath62   \\nonumber \\\\   &    & \\mbox { }   +   \\frac { k a } { \\sqrt { \\tau - 1 } } \\frac{v_0}{e }   \\ln [ 1 + e^ { ( r_0 - r_b ) / a } ]   .\\end{aligned}\\ ] ]"}
{"lay_summary": " we study a novel class of numerical integrators , the adapted nested force - gradient schemes , used within the molecular dynamics step of the hybrid monte carlo ( hmc ) algorithm . \n we test these methods in the schwinger model on the lattice , a well known benchmark problem . \n we derive the analytical basis of nested force - gradient type methods and demonstrate the advantage of the proposed approach , namely reduced computational costs compared with other numerical integration schemes in hmc . ", "article": "for the hybrid monte carlo algorithm ( hmc)@xcite , often used to study quantum chromodynamics ( qcd ) on the lattice , one is interested in efficient numerical time integration schemes which are optimal in terms of computational costs per trajectory for a given acceptance rate . high order\nnumerical methods allow the use of larger step sizes , but demand a larger computational effort per step ; low order schemes do not require such large computational costs per step , but need more steps per trajectory .\nso there is a need to balance these opposing effects .\nomelyan integration schemes @xcite of a force - gradient type have proved to be an efficient choice , since it is easy to obtain higher order schemes that demand a small additional computational effort .\nthese schemes use higher - order information from force - gradient terms to both increase the convergence of the method and decrease the size of the leading error coefficient . other ideas to achieve better efficiency for numerical time integrators are given by multirate or nested approaches .\nthese schemes do not increase the order but reduce the computational costs per path by recognizing the different dynamical time - scales generated by different parts of the action .\nslow forces , which are usually expensive to evaluate , need only to be sampled at low frequency while fast forces which are usually cheap to evaluate need to be sampled at a high frequency . a natural way to inherit the advantages from both force - gradient type schemes and multirate approaches would be to combine these two ideas .    previously , we studied the behavior of the adapted nested force - gradient scheme for the example of the @xmath0-body problem @xcite and would like to learn more about their usefulness for lattice field theory calculations . due to the huge computational effort required for qcd simulations ,\nit is natural to attempt an intermediate step first .\nwe chose the model problem of quantum electrodynamics ( qed ) in two dimensions , the schwinger model @xcite , since it is well - suited as a test case for new concepts and ideas which can be subsequently applied to more computationally demanding problems @xcite .\nas a lattice quantum field theory , it has many of the properties of more sophisticated models such as qcd , for example the numerical cost is still dominated by the fermion part of the action . the fact that this model , with far fewer degrees of freedom , does not require such large computational effort makes it the perfect choice for testing purposes .\nwe compare the behavior of numerical time integration schemes currently used for hmc @xcite with the nested force - gradient integrator @xcite and the adapted version introduced in @xcite .\nwe investigate the computational costs needed to perform numerical calculations , as well as the effort required to achieve a satisfactory acceptance rate during the hmc evolution .\nour goal is to find a numerical scheme for the hmc algorithm which would provide a sufficiently high acceptance rate while not drastically increasing the simulation time .\nthe paper is organized as follows . in section 2\nwe give a short overview of the hmc algorithm and numerical schemes for time integration , which are used in hmc . in section 3\nwe present the 2-dimensional schwinger model and introduce the idea of the force - gradient approach and the resulting novel class of numerical schemes .\nsection 4 is devoted to the results of a comparison between widely used algorithms and the new approach and section 5 draws our conclusion .\nin this section we provide a general overview of the hmc algorithm @xcite to introduce our novel integrator .\nwe also present some standard numerical time integrating methods used in hmc , as well state - of - the - art numerical schemes , which we later compare by applying them to the two - dimensional schwinger model .      in the hybrid monte carlo algorithm ,\nthe quantum lattice field theory is embedded in a higher - dimensional classical system through the introduction of a fictitious ( simulation ) time @xcite .\nthe gauge field @xmath1 is associated with its ( fictitious ) conjugate momenta @xmath2 , and the classical system is described by the hamiltonian , @xmath3 + { \\mathcal{b}}[u],\\ ] ] where @xmath4 $ ] and @xmath5 $ ] represent the kinetic and potential energy respectively .    for a given configuration @xmath1 ,\na new configuration @xmath6 is generated by performing an hmc update @xmath7 , which consists of two steps :    * * molecular dynamics trajectory : * evolve the gauge fields @xmath1 , elements of a lie group , and the momenta @xmath2 , elements of the corresponding lie algebra , in a fictitious computer time @xmath8 according to hamilton s equations of motions @xmath9 since analytical solutions are not available in general , numerical methods must be used to solve the system of eqn .  .\nthe discrete updates of @xmath1 and @xmath2 with an integration step @xmath10 are @xmath11 leading to a first - order approximation at time @xmath12 .\nsince the momenta @xmath2 are elements of lie algebra , we have an additive update of @xmath2 .\non the other hand , the links @xmath1 must be elements of the lie group , therefore an exponential update is used for @xmath1 to preserve the underlying group structure . * * metropolis step : * accept or reject the new configuration @xmath13 with probability @xmath14 where @xmath15 .      in this paper\nwe are concerned with numerical time integration schemes , which preserve the fundamental properties of geometric integration , time - reversibility and volume - preservation .\nall numerical schemes presented below possess these necessary properties .\n* basic schemes : * well - known , commonly used integration schemes in molecular dynamics are given by    * the leap - frog method , a 3-stage composition scheme of the discrete updates defined above : @xmath16 * and a 5-stage extension widely used in qcd computations : @xmath17    * force gradient schemes : * force - gradient schemes increase accuracy by using additional information from the force gradient term @xmath18 , with @xmath19 defining lie brackets . the 5-stage force - gradient scheme proposed by omelyan et\nal @xcite is the simplest ; @xmath20 here we also test the modification of the force - gradient method proposed in @xcite , where the force - gradient term @xmath21 is approximated via a taylor expansion .\nan extension is given by the 11-stage decomposition @xcite , recently implemented as the integrator in the open source code openqcd as one of the standard options @xcite\n@xmath22where @xmath23 , @xmath24 , @xmath25 and @xmath26 are parameters from equation ( 71 ) in ref .\n@xcite .    *\nnested schemes : * qed and qcd problems usually lead to hamiltonians with the following fine structure @xmath27 + { \\mathcal{b}}_{1}[u]+ { \\mathcal{b}}_{2}[u],\\ ] ] where the action of the system can be split into two parts : a fast action @xmath28 such as the gauge action , and a slow part @xmath29 , for example , the fermion action .\nthis allows us to apply the idea of multirate schemes ( an idea known as nested integration in physics literature)@xcite in order to reduce the computational effort . at\nfirst we consider the nested version of the leap - frog method @xmath30 where the inner cheaper system @xmath31+{\\mathcal{b}}_{1}[u]$ ] is solved by @xmath32 with @xmath33 being a number of iterations for the fast part of the action .\nour main goal is to compare the above - mentioned methods with more elaborated nested schemes : in @xcite , a similar 5-stage decomposition scheme has been recently introduced : @xmath34    a nested version of , which has been used in  @xcite reads @xmath35 where @xmath36 with @xmath37 and @xmath38 . in the limit @xmath39\nwe have @xmath40 .\nnote that this approach uses force - gradient information at all levels , i.e. , the high computational cost of high order schemes appears at all levels .\none may overcome this problem by using schemes of different order at the different levels without losing the effective high order of the overall multirate scheme .\nfor the latter , we include appropriate force gradient information as we explain in the following for the case of two time levels , where the gauge action plays the role of the fast and cheap part , and the fermionic action plays the role of the slow and expensive part .\nthe reasoning is as follows : if one uses the 5-stage sexton - weingarten integrator of second order for the slow action , and approximates the fast action by @xmath41 leap - frog steps of step size @xmath42 , the error of the overall multirate scheme will be of order @xmath43 . with the use of force gradient information only at the slowest level it is possible to cancel the leading error term of order @xmath44 .\nas @xmath45 usually holds in the multirate setting , the overall order is then given by the leading error term of order @xmath46 , i.e. , the scheme has an effective order of four .\none example for such a scheme for problems of type is given by the 5-stage nested force - gradient scheme introduced in @xcite @xmath47 to summarize , the adapted scheme   differs from the original one   in two perspectives :    * the force gradient scheme for the fast action is replaced by a leap - frog scheme . *\nonly the part @xmath48 of the full force gradient @xmath49 is needed to gain the effective order of four .\nthe numerical schemes - and - are second order convergent schemes . methods - and - have the fourth order of convergence .\nwe do not consider integrators of higher order than four since the computational costs are too high .\nthe schemes of the same convergence order differ from each other by the number of stages ( updates of momenta and links per time step ) .\nusually methods with more stages have smaller leading error coefficients and therefore have better accuracy , but higher computational costs .\nwe would like to determine which integrator would represent the best compromise between high accuracy and computational efficiency\n.    we will apply all these numerical integration schemes  to the two - dimensional schwinger model .\nthe most challenging task from the theoretical point of view is to derive the force - gradient term @xmath21 . in the next section\nwe introduce the schwinger model and explain how to obtain the force - gradient term .\nthe 2 dimensional schwinger model is defined by the following hamiltonian function @xmath50 = \\frac{1}{2}\\sum_{n=1,\\mu=1}^{v,2 } p_{n,\\mu}^2 + s_g[u ] + s_f[u].}\\ ] ] with @xmath51 the volume of the lattice . unlike qcd , where @xmath52 and @xmath53 , for this qed problem , the links @xmath1 are the elements of the lie group @xmath54 and the momenta @xmath55 belong to @xmath56 , which represents the lie algebra of the group @xmath54 .\nthis makes this test example very cheap in terms of the computational time .\nthis together with the fact that the schwinger model also shares many of the features of qcd simulations , makes the schwinger model an excellent test example when considering numerical integrators : a fast dynamics given by the computationally cheap gauge part @xmath57 $ ] of the action demanding small step sizes , and a slow dynamics given by the computationally expensive fermion part @xmath58 $ ] allowing large step sizes .\nthe pure gauge part of the action @xmath59 sums up over all plaquettes @xmath60 in the two - dimensional lattice with @xmath61 and is given by @xmath62 the links @xmath1 can be written in the form @xmath63 and connect the sites @xmath0 and @xmath64 on the lattice ; @xmath65 $ ] , @xmath66 , @xmath67 @xmath68 are respectively space and time directions and @xmath69 is a coupling constant .\nnote that from now on we will set the lattice spacing @xmath70 .\nthe fermion part of the action @xmath71 is given by @xmath72 where @xmath26 is a complex pseudofermion field . here , @xmath73 denotes the wilson  dirac operator given by @xmath74 where @xmath75 are the pauli matrices @xmath76 @xmath77 is the mass parameter and the kronecker delta @xmath78 acts on the pseudofermion field by @xmath79 with @xmath80 the pseudofermion field , a vector in the two - dimensional spinor space taking values at each lattice point @xmath0 . in order to proceed with the numerical integration we need to obtain the force @xmath81 and the force gradient term @xmath21 .\nthe force term @xmath82 with respect to the link @xmath83 is given by the first derivative of the action @xmath84 and can be written as @xmath85 since the numerical schemes  use the multi - rate approach , the shifts in the momenta updates are split on @xmath86 and @xmath87 and we can consider them separately .\nthe force terms @xmath86 and @xmath87 are obtained by differentiation over @xmath54 group elements , which for the schwinger model is the standard differentiation .    the force associated with link @xmath88 from the gauge action\nis given by @xmath89 the force term of the fermion part is given by @xmath90 \\,\\ ] ] where vectors @xmath91 and @xmath92 are given @xmath93    for the numerical methods and we need to find the force gradient term @xmath94 with respect to the link @xmath83 . in case of the schwinger model this term reads @xmath95    for simplicity we decompose the force gradient term in four parts @xmath96 this decomposition is also useful since the numerical integrator only uses the term @xmath97 by construction .\nas shown in @xcite , to obtain the fourth order convergent scheme from the second order convergent method we must eliminate the leading error term , which is exactly represented by @xmath97 . for completeness we discuss all 4 parts below .\nthe @xmath98 part of the force - gradient term is @xmath99 \\end{aligned}\\ ] ] with the set of plaquettes @xmath100 then by using the vectors @xmath101 defined in we obtain the @xmath102 piece of the force - gradient term given by @xmath103 . }\n\\end{aligned}\\ ] ] the second derivative of the fermion action is @xmath104 \\xi + } \\nonumber \\\\ & & { 2 \\operatorname{re } \\chi^\\dagger \\frac{\\partial d}{\\partial q_\\mu(n ) } ( d^\\dagger d)^{-1 } \\frac{\\partial d^\\dagger}{\\partial q_\\nu(m ) } \\chi \\ , , } \\nonumber \\\\ & & { = 2 \\operatorname{re } \\left [ z_{1,m,\\nu}^\\dagger \\frac{\\partial d}{\\partial q_{\\mu}(n ) } \\xi +   \\chi^\\dagger\n\\frac{\\partial d}{\\partial q_{\\mu}(n ) } d^{-1 } w_{2,m,\\nu } -   \\chi^\\dagger   \\frac{\\partial^2 d}{\\partial q_{\\nu}(m ) \\partial q_{\\mu}(n ) } \\xi +   \\chi^\\dagger\n\\frac{\\partial d}{\\partial q_{\\mu}(n ) } d^{-1 } z_{1,m,\\nu}\\right ] } \\nonumber \\\\ & & { = 2 \\textrm{re } \\left [ z_{1,m,\\nu}^\\dagger w_{2,n,\\mu } +   w_{1,n,\\mu}^\\dagger z_{2,m,\\nu } -   \\chi^\\dagger   \\frac{\\partial^2 d}{\\partial q_{\\nu}(m ) \\partial q_{\\mu}(n ) } \\xi \\right ] } \\end{aligned}\\ ] ] in terms of the vectors @xmath105 and @xmath92 defined in .\nnow the fields @xmath106 and @xmath107 are given by @xmath108 with @xmath109    in order to calculate @xmath110 and @xmath111 it is possible to perform the summation of @xmath112 before the inversions of @xmath73 and @xmath113 to get @xmath114 and @xmath115 which save @xmath116 additional inversions for the force gradient terms .\nit follows for the force gradient term @xmath111 @xmath117\\ ] ] with @xmath118 + z_1 \\right ) \\ , .\n\\end{aligned}\\ ] ] the expression for @xmath110 can be obtained from the one for @xmath111 by replacing in and the vector @xmath119 with @xmath120 defined in .\nit is important to mention that the computationally most demanding part of the numerical integration of the schwinger model and quantum field theory in general is the inverse of the dirac operator @xmath121 .\nevery momenta update , which includes fermion action requires 2 inversions of the dirac operator , the addition of the force - gradient term @xmath21 requires 4 more inversions .\ntherefore leap - frog based methods and need 4 computations of @xmath121 per time step ; schemes and 6 times ; force - gradient based methods 8 for and , 10 for and the 11 stage method has 12 inversions of the dirac operator . since we use the multi - rate approach for schemes , and , which leads generally to fewer macro time steps needed than for the standard schemes we expect the integrator will be the most efficient choice among the methods considered . in the next section we present numerical tests of this prediction .\nin this section we apply the numerical integrators  to compute the molecular dynamics step for the schwinger model when studied with the hmc algorithm .\nwe consider a @xmath122 by @xmath122 lattice with a coupling constant @xmath123 and mass @xmath124 .\nthe parameters were taken from @xcite and correspond to the scaling variable @xmath125 defined in @xcite.we have chosen them to simulate close to the scaling limit with light fermions and also to increase the impact of the fermion part of the action .\nwe use one thermalised gauge configuration . for each integrator and value of the step - size\nwe generate @xmath126 independent sets of momenta and integrate the equations of motion on a trajectory of length @xmath127 .\nwe compute the absolute error @xmath128 and estimate its statistical error from the standard deviation .\nalso the parameter @xmath33 is chosen in such a way to make micro step size to be @xmath129 times smaller than the macro step size @xmath10 .\nfigure [ fig:1 ] presents the comparison between the numerical integrators  .\nit shows the absolute error @xmath128 versus the step - size of the numerical scheme . here\nthe multi - rate schemes , , and outperform their standard versions as expected .\nalso it is easy to see that the scheme has the best accuracy and the nested force - gradient method just slightly edges the adapted nested force - gradient scheme .\nfigure [ fig:2 ] presents the cpu time , required for the proposed integrators \n, versus the achieved accuracy .\nwe can observe that the nested force - gradient method and adapted nested force- gradient method show much better results in terms of a computational efficiency than the integrators and ; and even compared to the 11 stage scheme .\nhere we can see that the modification of proposed in @xcite also performs better than its original version .\nit shows almost similar computational costs as nested versions of the force - gradient approach - , since it has the same number of @xmath121  ( see table [ tab:1 ] ) .\nbut it is less efficient because the proposed nested approach is more precise .\n.step - sizes and number of inversions of @xmath73 per step and per trajectory for acceptance rate of 90% [ cols=\"^,^,^,^,^\",options=\"header \" , ]     table [ tab:1 ] shows the number of inversions of the dirac operator @xmath73 , which is needed to reach 90% acceptance rate of the hmc . since @xmath121 is the most computationally demanding part it is important to see how many of these inversions are required per each trajectory . from table\n[ tab:1 ] it easy to see that the adapted nested force - gradient method and nested force - gradient method need the least number of @xmath121 per trajectory to reach the chosen acceptance rate @xmath130 .\nwe can also claim that methods and have a potential to perform even better with respect to the computational effort in the case of lattice qcd problems , since the impact of the fermion action and the computational time to obtain the inversion of the dirac operator @xmath73 is much more significant .\nwe presented the nested force - gradient approach and its adapted version applied to a model problem in quantum field theory , the two - dimensional schwinger model .\nthe derivation of the force - gradient terms was given and the schwinger model was introduced .\nnested force - gradient schemes seem to be an optimal choice with relatively high convergence order and low computational effort .\nalso it would be possible to improve the algorithm by measuring the poisson brackets of the shadow hamiltonian of the proposed integrator and then tuning the set of optimal parameters , e.  g. micro and macro step sizes .\n+ in future work we will apply this approach to the hmc algorithm for numerical integration in lattice qcd . here\nwe expect the adapted nested - force gradient scheme to outperform the original one , if we further partition the action into more than two parts , by using techniques to factorize the fermion determinant : less force - gradient information is needed for the most expensive action , and only leap - frog steps are needed for the high frequency parts of the action .\nthis work is part of project b5 within the sfb / transregio 55 _ hadronenphysik mit gitter - qcd _ funded by dfg ( deutsche forschungsgemeinschaft ) .\ns.  duane , a.d .\nkennedy , b.j .\npendleton , d.  roweth , hybrid monte carlo , phys .\nb195 ( 1987 ) , pp .\ne.  hairer , c.  lubich , g.  wanner , geometric numerical integration : structure - preserving algorithms for ordinary differential equations , springer , berlin , 2002 .\nomelyan , i.m .\nmryglod , r.  folk , symplectic analytically integrable decomposition algorithms : classification , derivation , and application to molecular dynamics , quantum and celestial mechanics , comput .\n151 ( 2003 ) , pp ."}
{"lay_summary": " new methods for obtaining functional equations for feynman integrals are presented . \n application of these methods for finding functional equations for various one- and two- loop integrals described in detail . \n it is shown that with the aid of functional equations feynman integrals in general kinematics can be expressed in terms of simpler integrals .    \n pacs numbers : 02.30.gp , 02.30.ks , 12.20.ds , 12.38.bx + keywords : feynman integrals , functional equations     +    derivation of functional equations for feynman integrals + from algebraic relations   +    * o.v .  \n tarasov * +   ii . \n institut fr theoretische physik , universitt hamburg , + luruper chaussee 149 , 22761 hamburg , germany + and + joint institute for nuclear research , + 141980 dubna , russian federation + : otarasov@jinr.ru + ", "article": "recently it was discovered that feynman integrals obey functional equations @xcite , @xcite .\ndifferent examples of functional equations were presented in refs .\n@xcite , @xcite,@xcite . in these articles\nonly one - loop integrals were considered .    in the present paper\nwe propose essentially new methods for deriving functional equations .\nthese methods are based on algebraic relations between propagators and they are suitable for deriving functional equations for multi - loop integrals . also these methods can be used to derive functional equations for integrals with some propagators raised to non - integer powers .\nour paper is organized as follows . in sec .\n2 . the method proposed in ref .  @xcite is shortly reviewed .    in sec .\n3 . a method for finding algebraic relations between products of propagators is formulated .\nwe describe in detail derivation of explicit relations for products of two , three and four propagators .\nalso algebraic relation for products of arbitrary number of proparators is given .\nthese relations are used in sec.4 . to obtain functional equations for some one- , as well as two- loop integrals .\nin particular functional equation for the massless one - loop vertex type integral is presented . also functional equation for the two - loop vertex type integral with arbitrary masses\nis given .    in sec .\nanother method for obtaining functional equations is proposed .\nthe method is based on finding algebraic relations for ` deformed propagators ' and further conversion of integrals with ` deformed propagators ' to usual feynman integrals by imposing conditions on deformation parameters . to perform such a conversion the @xmath0- parametric representation for both types of integrals\nis exploited .\nthe method was used to derive functional equation for the two - loop vacuum type integral with arbitrary masses . as a by product , from this functional equation we obtained new hypergeometric representation for the one - loop massless vertex integral .    in conclusion\nwe formulate our vision of the future applications and developments of the proposed methods .\nthe method for deriving functional equations proposed in ref .\n@xcite is based on the use different kind of recurrence relations . in particular in refs .\n@xcite , @xcite , @xcite , generalized recurrence relations @xcite were utilized to obtain functional equations for one - loop feynman integrals . in general such recurrence relations\nconnect a combination of some number of integrals @xmath1 corresponding to diagrams , say , with @xmath2 lines and integrals corresponding to diagrams with fewer number of lines . diagrams with fewer number of lines can be obtained by contracting some lines in integrals with @xmath2 lines .\nintegrals corresponding to such diagrams depend on fewer number of kinematical variables and masses compared to integrals with @xmath2 lines .\nsuch recurrence relations can be written in the following form : @xmath3 where @xmath4 and @xmath5 are ratios of polynomials depending on masses @xmath6 , scalar products @xmath7 of external momenta , powers of propagators @xmath8 and parameter of the space time dimension @xmath9 . at the left hand - side of eq .\n( [ nconnectr ] ) we combined integrals with @xmath2 lines and on the right hand - side integrals with fewer number of lines .    in accordance with the method of ref .\n@xcite , to obtain functional equation from eq .\n( [ nconnectr ] ) one should eliminate terms on the left hand - side by defining some kinematical variables from the set of equations : @xmath10 if there is a nontrivial solution of this system and for this solution some @xmath11 are different from zero then the right - hand side of eq .\n( [ nconnectr ] ) will represent functional equation .\nfor the one - loop integrals with @xmath2 propagators @xmath12 where @xmath13 different types of recurrence relations were given in refs .\n@xcite , @xcite .\ndiagram corresponding to this integral is given in figure 1 .\nexternal legs ]    in refs .\n@xcite , @xcite the following relation was derived : @xmath14 where the operators @xmath15 shift index of propagators by one unit @xmath16 , @xmath17\n@xmath18 @xmath19 here @xmath20 are external momenta going through lines @xmath21 respectively , and @xmath22 is mass attributed to @xmath23-th line .\ngram determinant @xmath24 and modified cayley determinant @xmath25 are polynomials depending on scalar products and masses .\nit is assumed that these scalar products are made of @xmath9 dimensional vectors and @xmath24 and @xmath25 are not subject to any restriction or condition specific to some integer values of @xmath9 .\n( [ reducedtod ] ) is written in the form corresponding to eq .\n( [ nconnectr ] ) . to eliminate integrals with @xmath2 lines on the left hand - side of eq .\n( [ reducedtod ] ) the following conditions to be hold : @xmath26    eq .\n( [ reducedtod ] ) is valid for arbitrary kinematical variables and masses .\nsolution of eqs .\n( [ sharik ] ) can be easily done with respect to two kinematical variables or masses .\nstarting from @xmath27 substitution of such solutions into eq .\n( [ reducedtod ] ) gives nontrivial functional equations .\nthe method for obtaining functional equations by eliminating complicated integrals from recurrence relations is quite general one .\nhowever for multi loop integrals , depending on several kinematical variables , derivation of equations like eq .\n( [ reducedtod ] ) is computationally challenging . in the next sections we will describe easier and more powerful methods that can be used for deriving functional equations for multi - loop integrals .\nsetting @xmath28 in eq .\n( [ reducedtod ] ) and imposing conditions ( [ sharik ] ) leads to the following equation : @xmath29 in eq .\n( [ fe_n_points ] ) integrands of @xmath30 are products of @xmath31 propagators depending on different external momenta , i.e. each term in this relation corresponds to the same function but with different arguments .\nin fact functional equations considered in refs .\n@xcite are of the same form as eq .\n( [ fe_n_points ] ) .\nthe question naturally arises : this relationship holds for integrals or it can be obtained as the consequence of a relationship between integrands ?    by inspecting eq .\n( [ fe_n_points ] ) , one can suggest the following form of the relation between products of propagators of integrands : @xmath32 where @xmath33 in what follows we will omit @xmath34 term assuming that all masses have such a correction .\nadditionally we assume that vectors @xmath35 are linearly dependent , i.e. the gram determinant for the set of vectors @xmath36 is equal to zero .\nsuch a condition is valid for all examples considered in refs .\n@xcite , @xcite .\nnow let s consider in detail implementation of our prescription for products of 2,3 and 4 propagators . at @xmath37 relation ( [ usual_props ] )\nreads : @xmath38 where @xmath39 according to our assumption three vectors @xmath40,@xmath41,@xmath42 are linearly dependent . without loss of generality we may assume that @xmath43 furthermore , we assume that @xmath44 will be integration momentum and scalar quantities @xmath45,@xmath46 , @xmath47 , @xmath47 do not depend on @xmath44 .\nputting all terms in eq .\n( [ 2prop_relation ] ) over a common denominator and then equating to zero the coefficients in front of various products of @xmath48 , @xmath49,@xmath50 yields the following system of equations : @xmath51 solution of this system of equations is : @xmath52 where @xmath53 is a root of the equation @xmath54 with @xmath55 this solution can be rewritten in an explicit form : @xmath56 where @xmath57    now let s find algebraic relation for the products of three propagators . at @xmath27 eq .\n( [ usual_props ] ) reads : @xmath58 where @xmath59 , @xmath60 , @xmath61 are defined in eq.([p1p2p3 ] ) and @xmath62 in complete analogy with the previous case we can represent one momentum as a combination of other ones . without loss of generality we may write @xmath63 where @xmath64 for the time being are arbitrary coefficients . putting all terms in eq .\n( [ 3prop_relation ] ) over a common denominator and then equating to zero the coefficients in front of various products of @xmath65 , @xmath66 , @xmath67 , @xmath68 yields the following system of equations : @xmath69 solving these equations for @xmath45 , @xmath46 , @xmath70 , @xmath71 , @xmath72 we have @xmath73 where @xmath74 is solution of the equation @xmath75 here @xmath76    let us now turn to the derivation of algebraic relation for the product of four propagators . at @xmath77\n( [ usual_props ] ) reads : @xmath78 where @xmath59 , @xmath60 , @xmath61,@xmath79 are defined in eqs .\n( [ p1p2p3 ] ) , ( [ d4 ] ) , @xmath80 and @xmath81 is a linear combination of vectors @xmath40,  ,@xmath82 , @xmath83 putting all terms in eq .\n( [ 4prop_relation ] ) over a common denominator and then equating to zero the coefficients in front of different products of @xmath48 , @xmath84 yields system of equations : @xmath85 solving this system for @xmath45 , @xmath46 , @xmath70,@xmath86 , @xmath87 , @xmath88 we have @xmath89 where @xmath90 is a solution of the equation @xmath91 with @xmath92    eqs .\n( [ 3prop_relation ] ) , ( [ 3prop_relation ] ) and ( [ 4prop_relation ] ) will be used in the next sections to derive functional equations for the propagator , vertex and box type of integrals .\nrelations between products of five and more propagators can be easily derived in the same way as as it was done for products of two- , three- and four- propagators . from eq .\n( [ usual_props ] ) one can derive system of equations and find its solution for arbitrary @xmath2 .\nmultiplying both sides of eq .\n( [ usual_props ] ) by the product of @xmath93 propagators @xmath94 yields @xmath95 or @xmath96 since we assume linear dependence of vectors @xmath97 , without loss of generality we may write : @xmath98 substituting ( [ pnp1 ] ) into eq.([ini_equ ] ) , collecting terms in front of @xmath48 , @xmath84 and terms without @xmath44 , equating them to zero after some simplifications yields the following system of @xmath99 equations : @xmath100 solving eq .\n( [ sumy ] ) for one of the @xmath64 an substituting this solution into eq .\n( [ kwadraticy ] ) gives quadratic equation for the remaining @xmath64 .\nthis quadratic equation can be solved with respect to one of the parameters @xmath64 .\nthus the solution of the system of equations ( [ xequs ] ) , ( [ sumy ] ) , ( [ kwadraticy ] ) will depend on @xmath101 arbitrary parameters @xmath64 and one arbitrary mass @xmath102 .\nit is interesting to note that for any @xmath2 , functional equations for integrals with all masses equal to zero and functional equations for integrals with all masses equal are the same . in case of equal masses , two mass dependent terms in eq .\n( [ kwadraticy ] ) cancel each other due to eq .\n( [ sumy ] ) . in both cases systems of equations for @xmath103 ,\n@xmath104 are the same and therefore arguments of integrals are the same .\n( [ 2prop_relation ] ) is analogous to the equation for splitting propagators presented in ref .\n( [ 3prop_relation ] ) is a generalization of eq .\n( [ 2prop_relation ] ) . indeed , setting @xmath105 , canceling common factor @xmath61 on both sides of eq .\n( [ 3prop_relation ] ) yields relation similar to ( [ 2prop_relation ] ) . in turn\n( [ 4prop_relation ] ) is a generalization of ( [ 3prop_relation ] ) .\nmultiplying algebraic relations ( [ 2prop_relation]),([3prop_relation ] ) , ( [ 4prop_relation ] ) by products of any number of propagators raised to arbitrary powers @xmath106 @xmath107^{\\nu_j}}\\ ] ] and integrating with respect to @xmath44 we get a functional equation for one - loop integrals .\n( [ 2prop_relation ] ) , ( [ 3prop_relation ] ) , ( [ 4prop_relation ] ) also can be used to derive functional equations for integrals with any number of loops .\nmultiplying algebraic relations for propagators by function corresponding to feynman integral depending on momentum @xmath44 and any number of external momenta and then integrating with respect to @xmath44 will produce functional equations .\njust for demonstrational purposes we present graphically in figure 2 functional equation based on @xmath2 propagator relation .\n- propagator functional equation ]    the blob on this picture correspond to either product of propagators raised to arbitrary powers or to an integral with any number of loops and external legs .\none of the external momenta of this multi loop integral should be @xmath44 .\nin this section several particular examples of functional equations resulting from algebraic relations for products of propagators will be considered .\nfirst , we consider the simplest case , namely , functional equation for the integral @xmath108 : @xmath109           [ ( k_1-p_k)^2-m_k^2]}.\\ ] ] integrating both sides of eq .\n( [ 2prop_relation ] ) with respect to @xmath44 , we get : @xmath110 the arguments @xmath111 , @xmath112 of integrals on the right hand - side depend on @xmath113 , @xmath47 @xmath114 substituting solution for @xmath64 from eq .\n( [ y_for_2prop ] ) into eq .\n( [ p13_p23 ] ) yields : @xmath115 in this equation @xmath116 is an arbitrary parameter and can be taken at will . functional equation ( [ prop_fe ] )\nis in agreement with the result presented in refs .\n@xcite,@xcite .\nfunctional equations for the vertex type integral @xmath117           [ ( k_1-p_2)^2-m_2 ^ 2 ]       [ ( k_1-p_3)^2-m_3 ^ 2 ]       } , \\label{i3definition }      \\end{aligned}\\ ] ] can be obtained from eq .\n( [ 2prop_relation ] ) as well as from eq .\n( [ 3prop_relation ] ) .\nmultiplying eq .\n( [ 2prop_relation ] ) with the factor @xmath118 where @xmath119 and integrating over @xmath44 leads to the equation : @xmath120 this equation in terms of integrals @xmath121 reads @xmath122 two more functional equations can be obtained from eq .\n( [ fe_for_vertex ] ) by symmetric permutations @xmath123 and @xmath124 .\nanother functional equation for the vertex type integral can be obtained by integrating eq .\n( [ 3prop_relation ] ) with respect to @xmath44 : @xmath125 where @xmath126 there is an essential difference between functional equation eq .\n( [ fei3massiv ] ) obtained from eq .\n( [ 2prop_relation ] ) and functional equation ( [ fei3massive ] ) derived from eq .\n( [ 3prop_relation ] ) .\nfor example , at @xmath127 , eq .  ( [ fei3massiv ] ) becomes trivial while from eq .\n( [ fei3massive ] ) for the integral @xmath128 we obtain nontrivial functional equation : @xmath129 where @xmath74 is a root of the quadratic equation @xmath130    if one argument of @xmath131 is zero then by applying functional equation ( [ fe_triangle ] ) such an integral can be expressed in terms of integrals @xmath121 with two arguments equal to zero .\nfor example , at @xmath132 and @xmath133 the relation ( [ fe_triangle ] ) becomes : @xmath134 this is a typical example how functional equations can be used to simplify evaluation of an integral by reducing it to a combination of integrals with fewer number of arguments .    at @xmath135 , similar to the previous case , eq.([fei3massiv ] ) degenerate while from eq.([fei3massive ] ) for the integral @xmath136 we obtain nontrivial functional equation : @xmath137 where @xmath74 is a root of the quadratic equation @xmath138 eqs .\n( [ fe_triangle_eqm ] ) , ( [ l3_eqm ] ) are identical to eqs .\n( [ fe_triangle]),([lambda3_zero_masses ] ) respectively and therefore functional equation for the integral with massless propagators and functional equation for the integral with all masses equal are the same .\n( [ fe_triangle_eqm ] ) at @xmath132 and @xmath133 leads to the relation similar to ( [ 1zero_2zeros ] ) : @xmath139 this is not surprising because coefficients of the eq .\n( [ fe_triangle_eqm ] ) are mass independent and in the integrand @xmath140 and @xmath34 appear in the covariant combination @xmath141 .\nfor this reason the similarity of functional equations for massless integrals and integrals with all masses equal take place for integrals with more external legs and more loops .\nfunctional equations for the box type integrals can be obtained by multiplying relation ( [ 2prop_relation ] ) by two propagators , or by multiplying relation ( [ 3prop_relation ] ) by one propagator and then integrating over momentum @xmath44 . yet\nanother relation can be obtained just by integrating eq .\n( [ 4prop_relation ] ) over momentum @xmath44 : @xmath142 here @xmath90 is defined in eq .\n( [ lambda4 ] ) and @xmath143,@xmath144 , @xmath145 are arbitrary parameters and @xmath146 arbitrary parameters in this functional equation can be chosen from the requirement of simplicity of evaluation of integrals on the right hand - side of eq .\n( [ box_func_equ ] ) or from some other requirements .\nfor example , one can choose these parameters by transforming arguments to a certain kinematical region needed for analytic continuation of the original integral .      the method described in the previous section can be applied to multi loop integrals .\nconsider , for example , integral corresponding to the diagram given in figure 3 .\n]    if we multiply eq .\n( [ 2prop_relation ] ) by the one - loop integral depending on @xmath44 @xmath147 [ ( k_1-k_2)^2-m_5 ^ 2]}\\ ] ] and integrate with respect to momentum @xmath44\nthen we obtain functional equation @xmath148 where @xmath149[(k_2-q_2)^2-m_2 ^ 2 ] [ k_1 ^ 2-m_3 ^ 2][(k_1-k_2)^2-m_4 ^ 2 ] } , \\label{rdefinition}\\end{aligned}\\ ] ] @xmath150 integrals of this type arise , for example , in calculations of two - loop radiative corrections in the electroweak theory . instead of the integral @xmath151 one can consider derivative of @xmath152 with respect to @xmath116 which is uv finite : @xmath153[(k_2-q_2)^2-m_2 ^ 2 ] [ k_1 ^ 2-m_3 ^\n2]^2[(k_1-k_2)^2-m_4 ^ 2]}. \\label{r3definition}\\end{aligned}\\ ] ] integral @xmath154 satisfy the following functional equations : @xmath155 this relation can be used for computing basis integral arising in calculation of two - loop radiative correction to the ortho -positronium lifetime . in particular one of these basis integrals corresponds to kinematics @xmath135 , @xmath156 , @xmath157 . in this case relation ( [ fe3 ] ) reads @xmath158 integral on the right hand - side is in fact propagator type integral with one massless line . applying recurrence relations given in ref .\n@xcite this integral can be reduced to simpler integral : @xmath159 ^ 2[(k_1+q_1)^2-m^2 ] } \\nonumber \\\\ & & = \\frac{2}{3(d-3 ) } j_{111}^{(d-2)}(m^2),\\end{aligned}\\ ] ] where @xmath160 [ ( k_2-q)^2-m^2]}.\\ ] ] at @xmath161 , the result for @xmath162 is known @xcite : @xmath163 } } + ( d-3){\\,{}_3f_2}{{\\!\\!\\left[\\begin{array}{c}1,\\frac{4-d}{2},\\frac{d-1}{2}\\,;\\\\#2\\,;\\end{array}1\\right]}},\\end{aligned}\\ ] ] and it can be used for the @xmath164 expansion of @xmath152 and @xmath154 . as was already mentioned at @xmath156 , @xmath157 integrals on the right hand - side of eq.([fe_for_r ] ) correspond to propagator type integrals .\nanalytic result for @xmath152 reads @xmath165,\\end{aligned}\\ ] ] where @xmath166 we checked that several first terms in the @xmath167 expansion of @xmath152 and @xmath154 are in agreement with results of @xcite .\nthe main profit from functional equations for @xmath152 and @xmath154 comes from the fact that vertex integrals were expressed in terms of simpler , propagator type integrals .\nthe method described in the previous section does not work for deriving functional equations for all kinds of feynman integrals .\nfor example , we did not found functional equation for the two - loop vacuum type integral given in figure 4 .        in this section\nwe shall describe another method that extends the class of integrals for which we can obtain functional equations .\nthe method is based on transformation of functional equations for some auxiliary integrals depending on arbitrary parameters into functional equations for integrals of interest .\nsuch functional equations will be derived from algebraic relations for ` deformed propagators ' which will be defined in the next section .\nthese auxiliary integrals will be transformed into @xmath0 parametric representation . in general characteristic polynomials of these integrals in @xmath0 parametric representation\ndiffer from those for the investigated integral . functional equation for the integral of interest\ncan be obtained in case when it will be possible to map characteristic polynomials of auxiliary integrals with ` deformed propagators ' to characteristic polynomials of this integral .\nsuch a mapping will be performed by rescaling @xmath0 parameters and appropriate choice of arbitrary ` deforming parameters ' .      in the previous section to derive functional equation we added to our consideration a propagator with combination of external momenta taken with arbitrary scalar coefficient .\nnow we consider generalization of this method .    to find functional equation for @xmath168-loop feynman integral depending on @xmath169- external momenta we start from the relation of the form @xmath170 where @xmath171 is defined as : @xmath172 with @xmath173 and @xmath174 , @xmath175 for the time being are arbitrary scalar parameters .\nsome of these parameters as well as @xmath176 will be fixed from the equation ( [ x_parameters ] ) .\nanother part of these parameters will be fixed from the requirement that the product of propagators in ( [ x_parameters ] ) should correspond to the integrand of the integral with the considered topology .\nwe would like to remark that instead of deformation of propagators proposed in eqs .\n( [ deformed_prop]),([deformed_momentum ] ) one can use other deformations .\nfor example , all terms in denominators of propagators can be taken with arbitrary scalar coefficients : @xmath177    to establish algebraic relation ( [ x_parameters ] ) we put all terms over a common denominator and then equate coefficients in front scalar products depending on integration momenta .\nsolving obtained system of equations gives some restrictions on the scalar parameters .\nin general integrals obtained by integrating products of ` deformed propagators ' will not correspond to usual feynman integrals .\nfurther restrictions on parameters should be imposed in order to obtain relations between integrals corresponding to feynman integrals coming from a realistic quantum field theory models .\nas an example , let us consider derivation of functional equation for the two - loop vacuum type integral given in figure 4 : @xmath178 analytic expression for this integral was presented in ref @xcite . instead of this integral\nwe will first consider an auxiliary integral with integrand made from ` deformed propagators ' defined in eqs.([deformed_prop ] ) , ( [ deformed_momentum ] ) : @xmath179 where @xmath180 for the product of three deformed propagators one can try to find an algebraic relation of the form : @xmath181 where @xmath182 , @xmath183,@xmath184 are defined in eq.([d123_for2loop_bubble ] ) and @xmath185 here @xmath186 are arbitrary masses , @xmath187 , @xmath188 , @xmath189 , @xmath190 , @xmath191 are undetermined parameters and @xmath44 , @xmath192 will be integration momenta\n.      we would like to notice that eq .\n( [ equ_with_redefined_masses2 ] ) is valid for integrals but not for their integrands .\nthis is due to the fact that the factor in front of integral that comes from the scaling of @xmath0 parameters in parametric integral is not fully compensated by scaling momenta given in eq .\n( [ scaling_momenta ] ) .    at @xmath246\nthe dependence on all parameters @xmath247,@xmath248,@xmath249 in eqs .\n( [ equ_with_redefined_masses_mm4nz ] ) , ( [ equ_with_redefined_masses2 ] ) drops out and the integral @xmath250 reduces to a comination of simpler integrals : @xmath251    analytic expression for the integral @xmath201 with one mass equal to zero is known @xcite . under assumption that @xmath252 it reads @xmath253}}. \\label{j0_hgf}\\ ] ] from functional equation ( [ j0_mm4_zero ] ) as a by - product\none can get a new hypergeometric representation for the one - loop massless vertex type integral . in ref .\n@xcite an interesting relation between the dimensionally regularized one - loop vertex type integral @xmath254 and the two - dimensional integral @xmath255 was discovered @xmath256 functional equation ( [ j0_mm4_zero ] ) with @xmath257 defined in eq .\n( [ j0_hgf ] ) provide us a new hypergeometric representation for the integral @xmath121 with massless propagators .\nformula for the one - loop massless vertex integral in terms of other gauss hypergeometric functions is given in ref .\nfinally , we summarize what we have accomplished in this paper .\nfirst of all , we formulated new methods for deriving functional equations for feynman integrals .\nthese methods are rather simple and do not use any kind of integration by parts techniques .\nsecond , it was shown that integrals with many kinematic arguments can be reduced to a combination of simpler integrals with fewer arguments . in our future publications\nwe are going to demonstrate that in some cases applying functional equations one can reduce , the so - called , master integrals to a combination of simpler integrals from , what we would like to call , a ` universal ' basis of integrals .\nthe method based on algebraic relations for ` deformed propagators ' can be used not only for vacuum type of integrals but also for integrals depending on external momenta . in the present paper we considered rather particular cases of functional equations .\nthe systematic investigation and classification of the proposed functional equations requires application of the methods of algebraic geometry and group theory .    at the present moment\nit is not quite clear whether functional equations derivable from recurrence relations can be reproduced by the methods of algebraic relations between products of propagators described in section 3 and section 5 .\na detailed consideration of our functional equations and their application to the one - loop integrals with four , five and six external legs as well as to some two- and three- loop feynman integrals will be presented in future publications .\nthis work was supported by the german science foundation ( dfg ) within the collaborative research center 676 _ particle , strings and the early universe : the structure of matter and space - time_. i am thankful to o.l .\nveretin for providing results for integrals contributing to ortho - positronium lifetime described in ref.@xcite ."}
{"lay_summary": " in the hierarchical search for periodic sources of gravitational waves , the candidate selection , in the incoherent step , can be performed with hough transform procedures . in this paper \n we analyze the problem of sensitivity loss due to discretization of the parameters space vs computing cost , comparing the properties of the sky hough procedure with those of a new frequency hough , which is based on a transformation from the _ time - observed frequency _ plane to the _ source frequency - spin down _ plane . \n results on simulated peakmaps suggest various advantages in favor of the use of the frequency hough . the ones which show up to really make the difference are 1 ) the possibility to enhance the frequency resolution without relevantly affecting the computing cost . \n this reduces the digitization effects ; 2 ) the excess of candidates due to local disturbances in some places of the sky map . \n they do not affect the new analysis because each map is constructed for only one position in the sky . \n + pacs . \n numbers : 04.80nn,07.05kf,97.60jd ", "article": "one of the main goals of the search for periodic isolated sources of gravitational waves ( g.w . ) is to perform all sky surveys , based on `` blind searches '' , where the source parameters are unknown . in this case\nhierarchical procedures are applied , based on a sequence of increasing resolution steps . in this paper\nwe study in details the problem of sensitivity loss due to discretization of parameters and to the needs to limit the computing cost , with hough procedures .\nin particular , we propose and study the characteristics of a frequency hough procedure , designed mainly to reduce the discretization problem , and we compare it with the sky hough procedure , which is actually used in the virgo collaboration .\n+ the paper is organized as follows : in sect .\n2 we present the basic scheme of the rome hierarchical procedure , based on the main idea of coincidences among subsets of data ; in sect .\n3 we discuss the limits due to digitization of the sky hough procedure ; in sects . 4 , 5 we present the new frequency hough procedure , discussing details its implementation and its basic characteristics ; in sect .\n6 we present the study of amplitude losses due to digitization , and thus efficiencies , for both the procedures .\nconclusions and comments are given in sect .\nhierarchical procedures , based on hough transform algorithms , are applied by various groups in the g.w . community .\nsee , for example , references @xcite .\nthere are various ways of implementing the hierarchical procedure and the hough transform .\nthe hough transform is a linear transform that is used to recognize the parameters of the analytical description of a curve from the position of some points on it .\nit operates on an `` image '' of points , in our case the peakmap in the time - frequency plane . for each peak of this map\nwe increase a set of bins of a multi - dimensional histogram ( in our case a two - dimensional histogram ) defined on the parameters space , called the hough map . in the old procedure ,\nthe parameter space was the position of the source , i.e. the celestial sphere , and we fixed the spin down value for each hough map . in the new one ,\nthe parameter space is the plane @xmath0 , and for each hough map , we fix the position of the source . the mapping ( i.e. which points of the hough map must be increased for a certain point in the peakmap ) can be done in different ways : we use always what we call the `` biunivocal mapping '' , i.e. a mapping in which every point in the hough map derive from a single point of the peakmap at a given time .\nit is easy to demonstrate that in this case the mapping is also uniform , i.e. in the case of uniformly distributed random dots in the peakmap , the expected value of the hough map @xmath1 is a constant ( for all parameter value ) .\nthis value , depending on the number n of the spectra of the peakmap and on the mapping , defines the `` noise '' of the map .\nit is binomially distributed with parameters n and @xmath2 .\nwe will refer here to the rome scheme , presently used in virgo data .\n[ fig : schema ] shows the basic scheme of the rome hierarchical procedure .\ndetails on the main aspects of the procedure are given in references @xcite .\nafter data cleaning ( short time domain disturbances removal ) and `` short ffts data base '' ( sfdb ) creation , peakmaps are computed , using a very refined auto - regressive algorithm to equalize the spectral data by an appropriate follow - up of the noise .\npeakmaps are frequency vs time maps , obtained from equalized spectra by selecting all the local maxima above a chosen threshold .\nan accurate cleaning of peakmaps , by removing known noise lines and the more persistent lines , is needed and its implementation is critical for the next step analysis . on the cleaned peakmaps ,\nmethods of peaks detection are applied .\nthat is , transformation from the input plane to the hough plane , thresholding and first order candidates selection .\ncandidate parameters are defined by source frequency , celestial coordinates , first spin - down parameter .\nthe need for coincidences among candidates obtained in different subsets of data ( two in the scheme of fig .\n[ fig : schema ] ) has been discussed in references @xcite .\nthis method is very efficient to reduce the number of spurious candidates at a fixed threshold .\nthus , for a given false alarm probability , we can lower the threshold -with respect to the choice of not doing coincidences- gaining in detection efficiency .\nthe method has a better efficiency when the data sets have similar sensitivities .\nafter the coincidence , the survived candidates are analyzed coherently with longer ffts on corrected data .\nthen the spectral filtering is used to take into account the spread of the power in five bands , as explained in reference @xcite .\nfinally , second order candidates are produced .\nas stated before , the sky hough method shows amplitude losses , and thus loss of sensitivity , which are due to digitization of parameters .\nthis effect shows up mainly for the complexity of the transform together with the need of reducing the computing cost :    * the method is based on a transform between the time - frequency peakmap and the celestial sphere .\nit is not simple for the non linearity of the mapping ; * to reduce the computational effort , we need to use `` look - up tables '' which introduce further digitization errors ; * to reduce the computational effort , fast algorithms have been developed , which require the use of a rectangular grid to map the sky . compared to the `` optimal '' ( see later ) grid , the rectangular one has over - resolution in some regions of the sky .\nthis leads also to a higher number of candidates .\n* the use of the celestial map as the space to spot the candidates is very prone to artifacts , see @xcite : some regions are always `` privileged '' , that is they have a higher candidates number with respect to the expectation . the problem arises because each hough map is constructed over the whole sky .    hence , it seemed important the study of alternative procedures .\ngiven the observation that most of the problems are related to the complexity of the transformation , we exploit the possibility of the use of a different but simpler transformation . a part the simplicity of the transformation we obviously need to study a procedure which is less , or equivalently , computationally expensive .\ntherefore we studied a procedure which has a better , or equivalent , sensitivity , at the same computational cost of the sky hough .\nthe transformation we propose transforms the * time - observed frequency * plane into the * source frequency - spin down * plane . let\ns go into details . if @xmath3 is the frequency ( doppler corrected for a given sky direction ) , @xmath4 the source intrinsic frequency , @xmath5 the first spin - down parameter , @xmath6 the time at the detector and @xmath7 a reference time , we have that @xmath8 a straight line in the hough plane .\nwe then get the following : @xmath9 each point in the input plane @xmath10 , that is a peak in the doppler shifted peakmap , is transformed into a straight line in the hough @xmath11 plane , with slope @xmath12 .\nthe slope depends on the choice of the reference time .\nif we choose @xmath7 equal to the beginning time of the data we analyze , then the slope is always negative and inversely proportional to the time gap .\n+ this is the choice we have done here . in addition , considering the width @xmath13 of the frequency bins in the input plane we notice that each peak is transformed into a stripe among two parallel straight lines    @xmath14    it is a linear transformation .\nnow the input plane is obtained from the original peakmap by correcting it for the doppler shift due to the earth revolution and rotation , for each point in the sky grid we need to analyze .\nthus `` time '' is the time at the detector and `` frequency '' the observed frequency , after the doppler correction .\nbut , as each sfdb is short enough to not be affected by a time - varying doppler shift , then the doppler effect removal from the original peakmap , obtained from the collection of all the sfdb data , reduces to a very simple `` shifting '' procedure of the peakmap bins . in the analysis scheme , this bins shift is part of the hough procedure . + in the following , we give details on the construction of the map .\nthe frequency hough map is constructed using the `` direct differential method '' , as is done with the sky hough . with this method , instead of building directly the hough map , one builds a map that , if `` integrated '' ( i.e. summed over bins from left to right ) , gives the hough map .\nthis is important to minimize the number of floating point operations .\nas already explained , for each sky position , the input peakmap is got from the original one by shifting bins to correct for the doppler effect .\nthe sky is sampled with a non uniform covering grid , which will be later discussed . here\nwe explain in detail the technique , by giving the sequence of operations :    * for each point in the sky grid , for each coordinate in the input plane @xmath10 and for each spin - down value @xmath15 ,    the map is incremented by 1 in the point @xmath16 and decremented by 1 in the point @xmath17 .    hence ,\nfor each sky position , a differential map is constructed .\nthe sum of the bins along the frequency direction is then performed to construct the final integral map .\nthis two dimensional histogram is the frequency hough map . in the algorithm implementation\nwe plan to divide the input peakmap into 10 hz bands , thus constructing , for each position in the sky , a different hough map every 10 hz .\n+ in case there is the need to exploit higher order one spin down parameters , one ( or more ) loop(s ) has ( have ) to be added to the sequence of operations , to scan the discrete set of values of the new parameter(s ) .\nthis clearly influences the computing cost , but does not change the basics of the method .\nlet s first discuss two peculiar aspects of this new method , which are the basis of its appeal .      from the given analysis scheme , it is easy to see that the frequency resolution for the estimation of the source frequency @xmath4 can be enhanced , with respect to the binning frequency @xmath13 , without relevantly affecting the computational effort .\nin fact , the use of a resolution @xmath18 with @xmath19 , affects only the size of the hough map .\nthis has a computational cost only when summing over the bins to construct the integral map from the differential one .\nbut we notice that the total cost of the construction of the hough map is due to the construction of the differential map , dominated by the number of peaks in the peakmap and to the construction of the integral map , dominated by the number of bins .\nthe former , in all practical cases , is the one which dominates .\n+ the possibility to enhance the frequency resolution results to be , as will be shown in the next sections , a very important peculiarity of the new method .\nit which enhances considerably the efficiency , by reducing the digitalization effect .\nthe same in the sky hough procedure would have a relevant computational cost .\nregarding the increasing of the spin down resolution , it would cost for both the procedures : the better the resolution in the spin down estimation the higher is the number of loops of the procedures .      here\nwe describe how we construct the grid on the sky .\nsuppose two sources , at the same frequency @xmath4 and same latitude @xmath20 .\ntheir angular delay @xmath21 with respect to the detector rotation produces a time delay @xmath22 .\nthe two sources will then have the same frequency variation at the detector , which is the classical equation due to the doppler effect , @xmath23 but with time delay @xmath24 .\nthe observed frequency difference has thus a maximum value which is given by @xmath25 thus the angular resolution is , in radians : @xmath26 where @xmath27 is the number of points in the doppler band for a signal of max frequency @xmath4 : @xmath28 and @xmath29 .\n+ we now repeat the same reasoning , supposing the two sources , at the same frequency @xmath4 and same longitude @xmath30 .\nthe two sources will have the same frequency variation at the detector , now given by @xmath31 , but with an angular delay @xmath32 .\nthe observed frequency difference has a maximum value which is : @xmath33 we obtain for the angular resolution , in radians : @xmath34 using eqs .\n[ gammalong ] and [ gammalat ] we get : @xmath35 @xmath36 using these equations we construct the grid on the sky , which we call the `` optimal '' grid .\nthe points of the grid are not uniformly distributed . with a simulation\n, we have estimated the the number of points in the grid @xmath37 , which is , in the high frequency limit : @xmath38 @xmath39 is an extra resolution factor , which can be greater than 1 , to enhance the efficiency , but even less than 1 , to save computing cost , obviously worsening the efficiency .\nfig.[fig : gridsim1 ] shows the optimal sky grid , for @xmath40 ( which corresponds to a source frequency @xmath41 hz ) .\nas already said , the grid used in the sky hough method , is not optimal , but rectangular , to use fastest computing algorithms .\nthe number of points in this rectangular grid is : @xmath42 which is , asymptotically , a factor @xmath43 higher then the number of points of the optimal grid . in fact\nthis grid has to be over resolved to maintain the same sensitivity of the corresponding optimal grid .\nfurther , we note that this over resolution produces a higher number of candidates from certain sky positions .    ,\nx - axis : ecliptical longitude , degrees , from 0 to 400 ; y - axis : ecliptical latitude , degrees , from -100 to 100 ; the number of points in the map is @xmath37=2902.,width=453 ]          the sensitivity of the sky hough procedure is affected by artifacts , i.e. an excess of candidates in some places of the sky map , which are due to local spectral disturbances . the effect ca nt be eliminated because each map is constructed over the whole sky , and hence the threshold for candidate selection has to be the same for the whole sky . using the frequency hough procedure\nthis effect disappears because each map is constructed for only one position in the sky .\nso , because of the adaptivity of the threshold , if a sky region gives an excess of candidates , the threshold is raised and then there is a loss in sensitivity only for that sky region .\nwe are now ready to enter into details by studying the efficiency of both the methods , by the use of simulations .\nfigure [ fig : gridsim2 ] is an example of how a frequency hough map looks like , having injected into white noise three signals , at different frequencies and spin - down .      to study the efficiency of the methods , as a function of the frequency over resolution factor\n, we have simulated a signal in the absence of noise .\nthe reason for this is that we were interested in studying only the losses due to the discretization errors .\nthe parameters chosen for the simulation are similar to actual situations ( detector parameters , source expected parameters ) .\nthe parameters of the simulation are shown in table [ tab : par ] .\n[ fig : freqloss ] shows the amplitude loss versus the frequency over resolution factor @xmath45 .\nthe loss was calculated as the average value of all the peaks found in the 500 spectra ( it is important to remember that our procedure considers peaks only the maxima above threshold ) .\nthe result is clear : using @xmath46 the amplitude loss is 3.6 @xmath47 ( the efficiency @xmath48 ) , while with @xmath49 , which is the only practically possible choice of the sky hough , the amplitude loss is 11.6 @xmath47 ( the efficiency @xmath50 ) . from the figure ,\nwe notice that there is no further gain of increasing the over resolution factor over 10 .\nthus , we fixed to 10 the over resolution factor for the frequency hough .\nin next simulations , results with @xmath46 are thus for the frequency hough , results with @xmath49 are for the sky hough .\nonce we have fixed the frequency over resolution factor we wanted to quantify how the increasing of the spin down resolution from the nominal one would affect the sensitivity .\nthe results are in fig .\n[ fig : freqloss1 ] , which shows the loss in amplitude vs the spin down over resolution factor , for both the cases @xmath49 , sky hough , and @xmath46,frequency hough .\nit can be noticed that , in the case of the frequency hough , even for the worst analyzed situation , which corresponds to the nominal spin down step @xmath51 the loss is quite small .\nis is 3.6 @xmath47 ( the efficiency @xmath48 ) .\nthe situation is worst for the sky hough , where the loss in amplitude at the nominal spin down step is 11.6 @xmath47 ( the efficiency @xmath50 ) .\nthe improvement obtained by a better spin down resolution is not so important , as can be seen from the figure .\nit seems reasonable , given the observation that increasing the spin down resolution has a computational cost for both the methods , to use the nominal @xmath52 resolution ( x - axis equal to 1 in the figure ) .      to study the loss due to the sky grid resolution\n, we have simulated 50 signals , randomly distributed over the sky .\nwe have then looked for results using the optimal grid , again registering the average value of all the detected peaks . in what follows ,\nwe suppose to use the optimal grid for both the procedures , sky and frequency hough .\nfig.[fig : loss_spinres ] shows the amplitude losses , as a function of the over resolution sky map factor @xmath39 , in the two cases of @xmath46 ( left ) , frequency hough , and @xmath49 ( right ) , sky hough .\nthe amplitude loss , for @xmath44 , is @xmath53 for the frequency hough , and @xmath54 , for the sky hough .\nagain , a better efficiency for the new procedure .\nwe notice that the use of an over resolution for the sky map , would have an impact on the computing cost , with both the procedures .    .\nthe figures compare the loss when @xmath46 ( left ) , frequency hough , and when @xmath55 ( right ) , sky hough.,title=\"fig:\",width=302 ] .\nthe figures compare the loss when @xmath46 ( left ) , frequency hough , and when @xmath55 ( right ) , sky hough.,title=\"fig:\",width=302 ]        + we see that the ratio of the amplitude efficiencies is @xmath57 which in power is 1.317 . from this\n, we can compute the gain in computing cost for the same sensitivity .\nlet us firstly recall that the @xmath58 sensitivity in the hierarchical search is proportional to @xmath59 , and the computing cost to @xmath60 .\nthus , the `` equivalent fft '' length factor is @xmath61=1.734 and the gain in computing cost is @xmath62=5.2 ( that is , the ratio of computing costs needed to have the same @xmath58 sensitivity ) .      * the * adaptivity * , that is the weight of peaks to consider the noise level and the gain due to the antenna pattern toward a direction , is , with this approach , immediate and very simple , as each hough map is done for a single sky position .\nit has been shown , with the sky hough , that the adaptivity of the procedure is a very important task for the analysis ; * this new procedure is appropriate also for all those situations in which the * source position * is known and we should estimate only source frequency and spin down ; * with a proper choice of parameters , it is also possible to detect and hence remove * spurious signals * , with a constant or linearly varying frequency .    on the latter point , we are now working to study the efficiency of this method in terms of rejection of spurious lines in the peakmap . we know that this is a very critical task for the analysis , since the presence of spurious lines highly affects the sensitivity of the search .\nwe expect this new method to be much more insensitive to the presence of spurious lines , since in the chosen hough plane spurious lines and g.w .\nsignals should have a very different and well separable behavior .\nb. krisnan , a. sintes , m. a. papa , b .\nf. schutz , s. frasca , c. palomba , _\nphys.rev.d70:082001_ , 2004 .\n`` the hough transform search for continuous gravitational waves '' a. sintes , b. krisnan , _\nphys.conf.ser.32:206-211_ , 2006 .\n`` improved hough search for gravitational wave pulsars ''\np. astone , s. frasca , c. palomba,_cqg 22:s1197-s1210_,2005 `` the short fft database and the peakmap for the hierarchical search of periodic sources '' s. frasca , p. astone , c. palomba,_cqg 22:s1013-s1019 _ , 2005 `` evaluation of sensitivity and computing power for the virgo hierarchical search for periodic sources '' c. palomba , p. astone , s. frasca , _\ncqg 22:s1255-s1264_,2005 `` adaptive hough transform for the search of periodic sources '' f. acernese et al ( virgo coll . ) _ cqg 24:s491-s499 _ , 2007 `` coincidence analysis between periodic source candidates in c6 and c7 virgo data '' f. acernese et al ( virgo coll . ) _ proceedings of the eleventh marcel grossmann meeting on general relativity ( berlin , 2006 ) edited by h. kleinert , r.t .\njantzen and r. ruffini , world scientific , singapore _ , 2008 `` first coincidence search among periodic gravitational wave source candidates using virgo data '' p. astone , s. frasca , c. palomba_proceedings of the eleventh marcel grossmann meeting on general relativity ( berlin 2006 ) edited by h. kleinert , r.t . jantzen and r. ruffini , world scientific , singapore _ , 2008 `` incoherent strategies for the network detection of periodic gravitational waves '' c. palomba , s. frasca , _\ncqg 21:s1645-s1654 _ , 2004 `` spectral filtering for hierarchical search of periodic sources ''"}
{"lay_summary": " i summarize what we have learned about the nature of stars that ultimately explode as core - collapse supernovae from the examination of images taken prior to the explosion . by registering pre - supernova and post - supernova images , usually taken at high resolution using either space - based optical detectors , or ground - based infrared detectors equipped with laser guide star adaptive optics systems , nearly three dozen core - collapse supernovae \n have now had the properties of their progenitor stars either directly measured or ( more commonly ) constrained by establishing upper limits on their luminosities . \n these studies enable direct comparison with stellar evolution models that , in turn , permit estimates of the progenitor stars physical characteristics to be made . \n i review progenitor characteristics ( or constraints ) inferred from this work for each of the major core - collapse supernova types ( ii - plateau , ii - linear , iib , iin , ib / c ) , with a particular focus on the analytical techniques used and the processes through which conclusions have been drawn . \n brief discussion of a few individual events is also provided , including sn 2005gl , a type iin supernova that is shown to have had an extremely luminous  and thus very massive  progenitor that exploded shortly after a violent , luminous blue variable - like eruption phase , contrary to standard theoretical predictions . ", "article": "this review focuses specifically on what we have learned about the progenitors of core - collapse supernovae ( cc  sne ) by examining images of the supernova ( sn ) sites taken prior to the explosion . by registering pre - sn and post - sn images , usually taken at high resolution using either space - based optical detectors , or ground - based infrared detectors equipped with laser guide star adaptive optics systems ( lgs - ao ) , about one dozen cc sn progenitors have now been directly detected ( i.e. , shown to be spatially coincident with the sn ) in pre - sn images , with roughly two dozen upper limits derived from non - detections @xcite .\nthis field has come a long way in the last decade , and promises to advance rapidly as more and more nearby galaxies  hosts of future cc sne  have high - resolution images added to the archive .\nthis review is organized as follows . following a brief summary of sn classification and stellar evolution theory (   2 ) , one example from each of the following three categories of progenitor studies\nis provided (   3 ; ordered from most - to - least common ) : ( 1 ) no progenitor star detected in pre - sn image(s ) ; ( 2 ) likely progenitor star identified via spatial coincidence in pre - sn and post - sn images ; ( 3 ) progenitor star detected in pre - sn image(s ) and subsequently confirmed by demonstrating its absence in images taken after the sn has faded beyond detection . a summary of overall results to date for each sn type\nis then given (   4 ) , followed by a brief discussion of outstanding questions and areas in which future progress is likely (   5 ) .\nnote that discussion is limited to what the examination of images of sn sites taken prior to the explosion has taught us , and necessarily excludes ( or relegates to very brief comment ) such related investigations as sn environments ( e.g. , @xcite ; see also the article by elias rosa in this volume ) and sn progenitor `` forensics '' ( e.g. , @xcite ; see also the article by modjaz in this volume ) . for a comprehensive discussion of all such related areas ,\nsee the recent review by @xcite .\nit is typical to subdivide cc  sne into at least five major categories ( see @xcite for a thorough review ) : ii - plateau ( ii - p ; hydrogen in spectrum and plateau in optical light curve ) , ii - linear ( ii - l ; hydrogen in spectrum , no plateau in optical light curve ) , iin ( hydrogen in spectrum and spectral and photometric evidence for interaction between sn ejecta and a dense circumstellar medium [ csm ] ) , iib ( hydrogen in spectrum initially , but transforms into a hydrogen - deficient spectrum at later times ) , and ib / c ( no evidence for hydrogen in spectrum at any time ) , where the ordering is a roughly increasing one in terms of inferred degree of envelope stripping prior to explosion ( i.e. , ii - p are the least stripped at the time of explosion , and ib / c are the most stripped ) .\nwhile most of this review focuses on the observational advances that have been made , theoretical input is critical to translate observed progenitor luminosity ( or limits ) into zero - age - main - sequence masses ( @xmath0 ) and stellar evolutionary states . among the most complete ( and accessiblestars . ] ) stellar evolution models at present are the metallicity - dependent models produced with the cambridge stellar evolution code , stars , the descendant of the code developed originally by @xcite and updated most recently by @xcite ( 2004 ; see also @xcite , and references therein ) , since they follow stellar evolution up to the initiation of core neon burning , which is likely to give an accurate indication of the pre - sn luminosity .\nthe hertzsprung - russell diagram ( hrd ) of the stars evolutionary tracks are shown in figure  1 for stars ranging in initial mass from @xmath1 .\ncomparison with other contemporary model grids ( e.g. , @xcite ; @xcite ) show that the endpoints for stars in the @xmath2 range differ by at most @xmath3 dex in luminosity among the codes @xcite , which gives some assurance that systematic uncertainties are not great , at least at the low - mass end for red supergiant ( rsg ) stars .\ntwo areas of uncertainty in need of better quantification ( or , at least , agreement within the community ) include the effects that stellar rotation and mass - loss might have on the observable characteristics of stars prior to core collapse .\nnot surprisingly , when no progenitor star is actually detected at the sn location in pre - sn images , only an upper limit to the progenitor s luminosity and , hence , mass , can be derived . to illustrate the analysis process in such a situation , i consider sn  2006my , an sn\nii - p that exploded in a galaxy @xmath4 mpc away ( nearly all sne with progenitor studies are within @xmath5 mpc , since source confusion becomes an increasing problem with distance ) .\ndetails for this particular event are provided by @xcite ; here i briefly outline the steps my colleagues and i took to derive an upper mass limit on its progenitor .    the _ hubble space telescope _ ( _ hst _ ) imaged the site of sn  2006my using the wide - field and planetary camera 2 ( wfpc2 ) in 1994 ( pre - sn ) and again in 2007 ( shortly after explosion ) .\nwe registered the two images and pinpointed the sn location to better than 30 milli - arcsec in the pre - sn frame ( figure 2a , b ) .\nsuch fine registration allowed us to rule out a nearby point source ( source ` 1 ' in figure 2a ) as the progenitor star with greater than @xmath6 confidence .\n( note that this source had been previously identified by @xcite as the likely progenitor based on registration with lower - resolution ground - based optical post - sn images . )\nwe next set an @xmath7-band detection limit in the pre - sn frame by placing artificial stars of progressively fainter magnitude at the sn location and letting the photometry software ( in this case , hstphot , see @xcite ) attempt to detect them .\nthe point at which the software no longer detected a point source then serves as the limiting upper magnitude for the progenitor star .    to translate this single - filter detection limit into a luminosity , we assumed that the progenitor was a rsg ( given other sn  ii - p progenitor detections this seems a reasonable assumption ; see  3.2 and  4 ) , and then determined the greatest bolometric magnitude it could have had while still remaining below our detection threshold .\nthis is accomplished through :    @xmath8    where @xmath9 is the distance modulus of the host galaxy ( ngc 4651 ) , @xmath10 the extinction to sn  2006my , @xmath7 the @xmath7-band detection threshold , @xmath11 the color range of rsg stars ( i.e. , spectral types @xmath12 ) , and @xmath13 the bolometric correction corresponding to each @xmath14 . upon adopting the most conservative values for each of the parameters ( i.e. , the ones that produce the least restrictive @xmath15 for the progenitor s upper luminosity limit ) , and allowing for a maximum systematic uncertainty of 0.2 dex in the theoretical stellar model endpoints ( see   2 ) , the limiting bolometric magnitude above which any rsg would have been detected in our pre - sn image , @xmath15 , is derived .\nwe then compared this with the final luminosity of stars with @xmath16 predicted by the stars stellar evolution models ( figure 2c ) to derive an upper bound on the progenitor mass of @xmath17 . from this analysis , then , we conclude that any rsg progenitor with an initial mass greater than @xmath18 would have been detected using our analysis procedure .    analyses similar to that described here for sn  2006my have been carried out on each of 22 non - detections in pre - sn images @xcite . as we shall see (   4 ) , it is the sheer number of such progenitor non - detections that permits rather strong conclusions to be drawn about cc sn progenitors from this category of progenitor studies .\nnext , we consider the individually more revealing situation where an object coincident with the transformed sn location is actually detected in the pre - sn image(s ) , a situation that exists now for 11 cc sne @xcite . as an outstanding example of the analytic power provided by having multi - filter pre - sn images available ( especially in the near infrared for rsg progenitors ) , we consider the recent work of @xcite on sn  2008bk , a very nearby ( @xmath19 mpc ) sn  ii - p . in this case ,\npre - sn ground - based images in @xmath20 were registered with post - sn lgs - ao @xmath21-band images to yield solid progenitor star detections in @xmath22 , and upper luminosity limits in @xmath23 and @xmath24 . when compared with the known spectral energy distribution ( sed ) of rsg , a good match for the progenitor of sn  2008bk\nis found with a progenitor of spectral type m4i ( figure  3 ) . from comparison with the stars stellar evolutionary models an initial progenitor mass of @xmath25\nis derived for this sn .\nsimilar studies on seven other detected sn  ii - p progenitors have found stars consistent with rsg in all cases , providing nice agreement between theory and observation . as we shall see in   4 , however , the _ range _ of masses inferred for these rsg progenitors is somewhat unexpected .\nfinally , we consider the most satisfying situation where images taken before , during , and long after the sn explosion exist that clearly show the progenitor star , the sn , and the absence of the progenitor star , respectively .\nsuch a sequence provides nearly conclusive proof of the progenitor star s identity .\ncurrently , such a time series exists for only two objects : sn  1987a ( e.g. , * ? ? ?\n* ) and sn  2005gl @xcite .\nbecause the case of sn  1987a is well - known , i present sn  2005gl as the example of this situation ; it also clearly demonstrates the investigative power provided by having a third observation , long after the sn has dropped below detection .\nas shown by @xcite , early spectra of sn  2005gl exhibited the classic features of a type iin event , showing narrow but resolved lines of hydrogen superposed on an intermediate - width component on an otherwise featureless continuum .\nanalysis of the spectral features indicate ejecta interacting with a dense csm , whose properties suggest that the progenitor star exploded shortly after an lbv - like mass - loss episode . comparison of a pre - sn _ hst _ image with a post - sn image obtained from the ground using the lgs - ao at the keck ii telescope established a spatial coincidence between the sn and a very bright source possessing an estimated luminosity of over @xmath26 ( @xcite ; see figures  4a and 4b ) .\nthe only single stars known to possess such an extraordinary luminosity are very massive ( @xmath27 ; see figure  1 ) , which conventional theory predicts should explode only after the lbv phase has ended @xcite .\ninitially , strong claims for the unexpectedly luminous progenitor / sn  2005gl association had to be tempered by consideration of the distance of sn  2005gl s host galaxy . at over 60 mpc away , the @xmath28 resolution of the pre - sn _ hst _ image corresponds to @xmath5 pc , which raises suspicion that the object could be , e.g. , an unresolved stellar cluster or association of several massive stars , with only part of the light coming from the actual progenitor of sn  2005gl @xcite .\nadditional observations , therefore , were clearly needed to settle the case , and two years later , an additional _ hst _ observation was made .\nthis observation demonstrates that the luminous source in the pre - sn image has , indeed , disappeared ( figure  4c ) , which implies that the progenitor of sn  2005gl was a single , extremely luminous , star that exploded while in the lbv phase @xcite .\nsuch a luminosity is indicative of having had an initial mass of @xmath29 , which likely left behind a stellar mass black hole ( e.g. , * ? ? ?\nin addition to exploding during an unexpected evolutionary phase , the very fact _ that _ such a massive star is demonstrated to have exploded at all  as opposed to directly collapsing to a black hole with no sn explosion  is important , since the optical signature produced at the time of stellar collapse to a black hole is , at present , virtually unconstrained by either observation or theory ( see , e.g. , * ? ? ? * and references therein ) .\nthe three examples discussed in   3 serve to illustrate how the science of seeking progenitors in pre - sn images is carried out , and what conclusions can typically be drawn .\ni now briefly summarize results to date arising from direct progenitor searches in pre - sn images ; for a more comprehensive review , see @xcite .\n* type ii - plateau : * sne  ii - p are by far the most well - defined category of cc sne in terms of direct observational progenitor constraints , having had eight putative progenitor detections made and 12 upper luminosity limits established .\nall of the available evidence suggests that rsg are the immediate progenitors of sne  ii - p . by employing a uniform reduction and analysis procedure ,\n@xcite has produced the cumulative frequency distribution shown in figure  5 for sne  ii - p , from which an intriguing result is immediately evident : all but one of the sne  ii - p have initial masses constrained to be @xmath30 , with the most massive _ detected _ progenitor of an sn  ii - p having a mass of only @xmath31 .\nthis is surprising , since rsg up to @xmath32 are clearly observed in the local group ( * ? ? ?\n* and references therein ) , and would have easily been detected in the pre - sn images .\nthis lack of massive rsg progenitors for sne ii - p lead @xcite to speculate that these massive rsg progenitors may be forming black holes heralded by faint , or non - existent , sn explosions ( see also * ? ? ?\n* type ii - linear : * a rare type of cc sn , it is perhaps not surprising that only one sn  ii - l ( sn  1980k ) has a pre - sn image , the analysis of which rules out massive rsg greater than about @xmath33 @xcite .\nanalysis of the stellar population of the type ii - l sn  1979c by @xcite determines a mass range of @xmath34 for its progenitor . at this point ,\nfirm conclusions about the progenitors of sne  ii - l can not be made , although early indications are that at least some do not arise from extremely massive stars .\n* type iin : * sn  2005gl , described earlier in this review (   3.3 ) as having a very massive ( @xmath27 ) progenitor that exploded while in the lbv phase , is the only example of an sn  iin for which a progenitor has been detected in pre - sn images .\nwhether such a massive progenitor is indicative of the class as a whole is not known .\n* type iib : * pre - sn images exist for two events .\nfirst , sn  1993j in m81 , where extensive analyses of pre - sn and post - sn images ( and spectra ) lead to the conclusion that a @xmath35 star exploded in a binary system , with a slightly less massive secondary surviving the explosion ( * ? ? ?\n* and references therein ) .\nvery recently , the type iib sn  2008ax has provided a great opportunity to further investigate this rare class of cc sne since pre - sn _\nhst_/wfpc2 images exist in @xmath36 .\na study by @xcite finds a curiously flat sed for the progenitor star , which is impossible to reconcile with a single rsg , but may be consistent with an early - type w - r ( wn class ) progenitor , suggesting a progenitor star with a large ( @xmath37 ) initial mass .\n* type ib / c : * a well - studied class , with ten upper limits but no detections from analysis of pre - sn images .\nthe lack of detections is surprising , since it is commonly thought that at least some of the progenitors of sne  ib / c should be luminous , single w - r stars , in addition to others perhaps arising from lower mass stars in binary systems . while none of the non - detections definitively rule out a w - r progenitor\n, @xcite demonstrates that it is quite unlikely at this point that all sne  ib / c come from them .\na summary of the current state of affairs of cc sn progenitor research via studies of pre - sn images is provided by figure  6 .\nthe science of seeking sn progenitors has made tremendous strides in just the last ten years . for the future ,\ni look with particular interest at the extremes as areas ripe for breakthrough discoveries , since it is there that many of our most fundamental questions lie . on the low - mass end , how will the lack of massive rsg progenitors for sne  ii - p be resolved ?\nare we seeing the first glimpse of the mass cutoff for direct collapse to black holes ?\nif so , then how will this be reconciled with the _ very _ massive stars ( i.e. , the other mass extreme ) that apparently do explode as sne  iin or possibly iib ? and finally , how does binarity influence all of these conclusions ?\nclearly , we are just at the beginning stages of this exciting field of research , and great advances will no doubt be made in the coming decade .\ni thank the scientific organizing committee of the `` hot and cool : bridging gaps in massive star evolution '' conference for inviting me to provide this review .\ni thank seppo mattila for permitting reproduction of a figure from a recent paper , and stephen smartt for allowing the use of figures in advance of publication of his annual reviews article on the topic ."}
{"lay_summary": " we present a phenomenological study of the single - transverse spin asymmetry in azimuthal correlations of two jets produced nearly `` back - to - back '' in @xmath0 collisions at rhic . \n we properly take into account the initial- and final - state interactions of partons that can generate this asymmetry in qcd hard - scattering . using distribution functions fitted to the existing single - spin data , we make predictions for various weighted single - spin asymmetries in dijet correlations that are now readily testable at rhic . ", "article": "single - transverse spin asymmetries ( ssas ) play a fundamental role for our understanding of qcd in high - energy hadronic scattering .\nthey may be obtained for reactions in , for example , lepton - proton or proton - proton scattering with one transversely polarized initial proton , by dividing the difference of the cross sections for the two settings of the transverse polarization by their sum .\nthere have been extensive experimental investigations of such asymmetries  @xcite .\nthese have initiated much theoretical progress , in particular within the last few years .\na particular focus has been on a class of single - spin observables that are characterized by a large momentum scale @xmath1 ( for example , the virtuality of the photon in deeply - inelastic scattering ( dis ) ) and by a much smaller , but also measured , transverse momentum @xmath2 .\nin such a `` two - scale '' situation , single - spin asymmetries may arise at leading power , that is , not suppressed by an inverse power of @xmath1 . for some of these cases ,\nfactorization theorems have been established  @xcite that allow to write the spin - dependent cross sections in terms of parton distribution functions and/or fragmentation functions , perturbative hard - scattering functions , and so - called soft factors .\na crucial feature is that the distribution functions and the soft factor in this factorization are not integrated over the transverse momenta of partons , because these in fact generate the observed transverse momentum @xmath2 . among other things\n, the observables may therefore provide valuable insights into the dependence of parton distributions in nucleons on transverse momentum .\nthis becomes particularly interesting when the nucleon is transversely polarized , because there may be correlations between the nucleon spin vector , its momentum , and the parton s transverse momentum .\none particular correlation , known as the `` sivers effect '' and described by so - called `` sivers functions ''  @xcite , is now widely believed to be involved in a variety of observed hadronic single - spin phenomena .\ncloser theoretical studies have revealed that the sivers effect plays an important role in qcd , beyond giving rise to phenomenological functions to be used in the description of single - spin asymmetries .\na particularly interesting feature is that the sivers effect is not universal in the usual sense , that is , it is not represented by universal probability functions convoluted with partonic hard - scattering cross sections .\nthis might at first sight appear to make the study of these functions less interesting .\nhowever , the non - universality has in fact a clear physical origin , and its closer investigation has turned out to be an extremely important and productive development in qcd . in a nutshell , in order not to be forced to vanish because of the time - reversal symmetry of qcd , single - spin asymmetries require the presence of a strong - interaction phase . for the sivers functions this phase originates from the `` gauge links '' in their definition  @xcite , which are path - ordered exponentials of the gluon field that make the functions gauge - invariant . in dis\n, the gauge link may be viewed as a rescattering of the parton in the color field of the nucleon remnant . that such a final - state rescattering may generate the phase required for a nonzero ssa in semi - inclusive hadron production in dis ( sidis ) was first discovered within a model calculation  @xcite .\ndepending on the hard - scattering process , the `` rescattering '' will however manifest itself in different ways .\nfor example , for drell - yan lepton pair production in hadronic scattering , _ initial - state _ , rather than final - state , interactions are relevant . as a result , the phase provided by the gauge links is opposite , and the sivers functions for the drell - yan process have opposite sign  @xcite . in more general terms ,\nthe nontrivial  universality \" property of the sivers functions is the direct consequence of gauge interactions in quantum chromodynamics  @xcite , and of the qcd factorization theorems applying to the relevant hard processes  @xcite .\nit is a remarkable and fundamental qcd prediction that really tests all concepts we know of for analyzing hard - scattering reactions in strong interactions , and it awaits experimental verification .    while measurements of ssas in sidis are now maturing and have established the presence of sivers - type contributions  @xcite , it will still be a while until precise single - spin measurements in the relatively rare drell - yan process will become feasible at rhic  @xcite or elsewhere  @xcite . however , there are of course other hard - scattering reactions in hadronic collisions for which single - transverse spin asymmetries may be defined , and that may potentially be used in lieu of the drell - yan process for testing the nontrivial\n universality \" properties of the sivers functions . in @xcite , it was proposed to use the ssa in azimuthal correlations of two jets produced in @xmath0 collisions at rhic to learn about the sivers functions . to a first approximation ,\nsuch dijets are produced by @xmath3 partonic qcd hard - scattering .\nwith collinear kinematics , the jets are exactly `` back - to - back '' in the plane perpendicular to the initial beam directions and thus separated by @xmath4 in azimuthal angle in this plane .\npartonic transverse momenta will generate deviations from this topology , because they will lead on average to a non - vanishing net transverse momentum @xmath2 of the jet pair , much smaller than each of the jet transverse momenta @xmath5 individually .\nthe observable is therefore of the `` two - scale '' type described above , and as was shown in @xcite , if one proton is polarized , a single - spin asymmetry may be defined that is in principle sensitive to the sivers functions . as\na caveat , factorization of the spin - dependent cross section for this observable in terms of transverse - momentum - dependent ( tmd ) functions still remains to be established .    unlike the relatively simple cases of sidis and the drell - yan process , where either final - state or initial - state interactions contribute to the sivers asymmetry , both are present for dijet production @xcite\nthis complicates the analysis of the process - dependence of the sivers functions considerably , but at the same time it also makes it much more interesting from a theoretical point of view , because the interactions in this case are `` truly qcd '' , that is , they involve the detailed gauge structure of the theory , including for example its non - abelian nature . at the time of @xcite ,\nthe process - dependence had not yet been worked out for the case of the ssa in dijet production , so that phenomenological predictions had to remain qualitative , at best . over the last year\n, however , there has been extensive work on deriving and clarifying the structure of the gauge links for this and related processes in @xmath0 collisions @xcite .\nindeed , the resulting structure is far more complicated than that in sidis or the drell - yan process .\nhowever , it turns out that if one takes a certain weighted integral ( `` moment '' ) of the asymmetry , remarkable simplifications occur .\nthis moment is defined by integrating the spin - dependent cross section with a factor @xmath6 , where @xmath7 is the azimuthal imbalance between the two jets ( @xmath8 if the jets are exactly back - to - back in azimuth ) . for each of the various contributing @xmath3 partonic channels ,\nthe gauge link then essentially collapses into a set of simple color factors that multiply contributions from color - gauge invariant subamplitudes to the given partonic process .\none may , in fact , for convenience choose to absorb these factors into the hard - scattering functions , and _ define _ the sivers functions as the functions measured in the ssa in sidis . in this way , the net effect of the gauge links on the @xmath6-moment of the spin - dependent cross section is to generate new partonic hard - scattering functions that are different from the usual spin - independent ones , but that are actually similarly simple in structure .    at the same time , taking the moment of the factorized spin - dependent cross section leads to a new expression that involves only a certain moment of the sivers functions in partonic transverse momentum @xmath9 , rather than the fully transverse - momentum dependent functions themselves . as was shown in  @xcite , these @xmath9-moments of the sivers functions are directly related to twist - three quark - gluon correlation functions first introduced in  @xcite to describe the ssa for single - inclusive hadron production in hadronic scattering . by now , quite some knowledge about these correlation functions has been gathered from phenomenological studies  @xcite of the corresponding data .\nthe upshot of all this is that it has now become possible for the first time to make predictions for the @xmath6-moment of the single - transverse spin asymmetry in dijet production at rhic that correctly take into account the process - dependence of the sivers functions and incorporate phenomenological information on some properties of the functions that is available from other measurements .\nthis is the goal of this note .\nwe study azimuthal correlations of two jets produced nearly `` back - to - back '' in a hadronic collision .\nmore specifically , we are interested in situations in which the sum of the two jet transverse momenta , @xmath10 ( or a component or projection thereof ) , is measured and small , while both individual jet transverse momenta are large and similar .\nwe will therefore approximate @xmath11 wherever possible .\nfor the lengths of these momentum vectors we will simply write @xmath12 and @xmath13 . the differential cross section for the process with one transversely polarized hadron contains terms of the form @xmath14 where @xmath15 is a unit vector in the direction of the polarized proton\n, @xmath16 is the transverse spin vector of the polarized proton , and @xmath17 and @xmath18 are the pseudo - rapidities of the two jets .\nthe first term in eq .\n( [ sigma ] ) represents the unpolarized ( or spin - averaged ) cross section , while the second term is the single - transverse - spin dependent one .\nwe note that the angular dependence of the spin - dependent term is @xmath19 , where @xmath20 is the so - called bisector - angle of the two jets , which ( approximately ) corresponds to the direction of @xmath21 . for this reason one may also choose to integrate the six - fold differential cross section in eq .\n( [ sigma ] ) over @xmath22 , keeping @xmath21 fixed .    as a generalization of the sidis and drell - yan cases @xcite , we can write down a factorization formula for the differential cross section at small imbalance ( @xmath23 ) of the jets , in terms of tmd parton distributions , soft factors , and hard - scattering functions  @xcite .\nwe remind the reader that such a factorization still remains to be proven . in this paper\n, we will not discuss the details of factorization issues related to the dijet correlations . as we mentioned above\n, significant simplifications occur when the imbalance of the two jets is integrated out by taking certain moments .\nfor example , integrating the spin - independent differential cross section over all @xmath21 , its expression reverts to the standard collinear factorization formula for dijet production , @xmath24 where the @xmath25 denote the usual collinear ( light - cone ) parton distribution functions for parton type @xmath26 .\nwe have assumed here that these are recovered by integration of the corresponding tmd distribution functions over all partonic transverse momentum , and we disregard the renormalization properties of the operators defining these distributions and the scale dependence introduced by renormalization .\nhowever , all these effects can be systematically included accordingly .\nthe factors @xmath27 in eq .\n( [ jeteq ] ) are the customary hard - scattering cross sections @xmath28 for the partonic processes @xmath29 ( for a compilation , see , for example , ref .\nthey are functions of the partonic mandelstam variables , @xmath30 , @xmath31 , @xmath32 , with obvious notation of the parton momenta . in terms of the hadronic center - of - mass energy @xmath33 and the jet transverse momenta and pseudo - rapidities\n, one has @xmath34 , @xmath35 , @xmath36 , where the partonic momentum fractions are fixed by @xmath37 , @xmath38 .\nnext we turn to the single - transverse - spin dependent differential cross section @xmath39 in eq .\n( [ sigma ] ) , which can be further simplified by taking a moment in @xmath40 where @xmath41 measures how far the two jets are away from the back - to - back configuration . within our approximations\n, the weight @xmath42 corresponds to a weight in @xmath2 .\none finds  @xcite : @xmath43 & = & \\vert \\vec s_\\perp\\vert   \\sum_{ab } x_a\\,\\frac{-1}{m_p}\\,gt_{f\\,a}(x_a)\\,x_bf_b(x_b ) \\,h_{ab\\to cd}^{\\rm sivers}(\\hat{s},\\hat{t},\\hat{u})\\ , \\end{aligned}\\ ] ] where @xmath44 is the proton mass , @xmath45 is the strong coupling constant and the @xmath46 are the qiu - sterman matrix elements or quark - gluon correlation functions @xcite , defined as @xmath47 with the quark fields @xmath48 ( for flavor @xmath49 ) and the gluon field strength tensor @xmath50 .\nthe @xmath46 matrix elements enter because they are related to the @xmath9-moment of the ( sidis ) sivers function for quark flavor @xmath49 @xcite , that is , @xmath51 .\nwe note that there could also be contributions by purely gluonic `` @xmath52 '' correlation functions .\nthese will be ignored for now , so that the label @xmath49 in eq .\n( [ qtmp ] ) runs only over quarks and anti - quarks .\nfurthermore , there is actually a second contribution to the single - transverse - spin dependent cross section , which involves the scattering of transversely polarized quarks from both the polarized proton ( transversity distribution , @xmath53 or @xmath54 ) and from the unpolarized proton ( boer - mulders function @xmath55  @xcite ) .\nthe latter functions are also effects of initial- and final - state interactions and appear in a matrix element for unpolarized protons similar to eq .  .\nlike the sivers - type `` @xmath52 '' correlation functions , we will also ignore the contributions associated with the boer - mulders functions in the present study , even though a future more detailed analysis of forthcoming experimental data may well require to take all of these into account .\nwe now use the above formulas to obtain some predictions for the ssa in dijet - production at rhic .\na ssa for our @xmath59-moment ( i.e. @xmath60-moment ) can be defined as ( from now on we choose @xmath61 ) @xmath62 the quark - gluon correlation functions @xmath63 have recently been fitted  @xcite to data  @xcite for the ssa in single - inclusive hadron production in hadronic collisions .\ntwo sets of @xmath63 were presented in  @xcite . for definiteness ,\nwe choose set  i , which is a two - flavor fit with valence @xmath64 and @xmath65-quark @xmath66 distributions only .\nfor these the following parameterizations were obtained in  @xcite : @xmath67 where the @xmath68 are the corresponding unpolarized valence quark distributions . for the latter , as for all other unpolarized parton distributions we need ,\nwe choose the cteq5l parameterizations @xcite .\nwe plot the resulting weighted asymmetry in fig .\nthe kinematics are chosen to correspond to current measurements at star : both jets have transverse momenta @xmath69 and pseudo - rapidities @xmath70 .\nthe asymmetry is plotted as a function of the sum of the two jet pseudo - rapidities .\nwe have chosen the hard scale @xmath71 in the strong coupling constant and the unpolarized parton distributions .    for comparison , we also show in fig .\n[ fig1 ] the asymmetries that one would have expected if the sivers functions relevant for dijet production were identical to the ones in sidis or the drell - yan process . in the framework of our present calculation ,\nthe corresponding partonic hard - scattering functions would in this case be identical to the spin - averaged functions @xmath72 , or to their negatives .\nthe dotted - dashed lines in the right panel of fig .  [ fig1 ] represent these cases .\nthey essentially correspond to the earlier predictions of  @xcite and  @xcite that were made when the process - dependence of the sivers functions had not yet been worked out for the dijet case .\none can see that when the correct process - dependence is incorporated , the asymmetry overall becomes smaller by about a factor two , which can be traced back to the color factors for the dominant subprocess @xmath73 .\nthe sign is identical to the case when the sivers functions for dijet production are assumed to be `` dis - like '' , implying that in a sense final - state interactions dominate over initial - state ones .    in principle\n, one might verify experimentally the process - dependence of the sivers functions by discriminating between the various curves in fig .\n[ fig1 ] and confirming the qcd - predicted result shown by the solid line . in practice\n, this may require good knowledge of the @xmath66 distributions , and an understanding of issues like scale evolution and higher - order corrections .\na closer analysis reveals that the asymmetry in fig .\n[ fig1 ] is the result of rather significant cancellations between contributions of opposite signs by @xmath64 and @xmath65 quarks . to show this\n, we display their individual contributions separately in the left panel of fig .\n[ fig1 ] .    -0.4\ncm    we finally also briefly discuss a related type of ssa in dijet production at rhic . in @xcite ,\na differently weighted ssa was considered , defined in the following way : @xmath74 where @xmath75 is the sign function .\nthis asymmetry has the property that the weight only depends on the azimuthal separation of the two jets , but not on their transverse momenta .\nthis may be an advantage for experimental measurements when the jet energy scale is not precisely known . when applied to the tmd factorized expression for the spin - dependent cross section , the moment defined in eq .\n( [ sign ] ) leads to an expression different from  ( [ qtmp ] ) .\none finds in fact that in general the transverse - momentum dependences of the various functions do not completely decouple anymore , so that the final result can in general no longer be expressed in terms of only functions of light - cone momentum fractions .\nif one assumes for simplicity  @xcite , however , that the only relevant dependence on transverse momentum resides in the sivers functions , the resulting expression again resembles a collinearly - factorized one : @xmath76 where the @xmath77 are the so - called `` @xmath78-moments '' of the sivers functions for sidis and are defined as @xmath79 in the above equations , we have used the notation `` @xmath80 '' for the sivers function for quark flavor @xmath49 ; its definition is identical to that in @xcite : @xmath81 . in  @xcite\n, the hard - scattering functions were chosen to be the same as the spin - averaged ones , with opposite sign . in light of the above discussions ,\none now would like to update the predictions for the asymmetry in  ( [ eqan ] ) .\nwe will use the @xmath56 given in eqs .\n( [ hsivers ] ) .\nwe note that it remains to be established that the same @xmath56 do contribute in this case .\nthis is not a priori clear , because the general gauge link structure is very complex in the general tmd case , and it has so far only been demonstrated that the @xmath56 apply when the @xmath6 moment is taken . for\nnow , we just conjecture that use of the @xmath56 of  @xcite is justified in this case ; a closer discussion of this issue is left for future work  @xcite .\nthe 1/2-moments of the quark sivers functions were determined in  @xcite by a fit to the hermes data  @xcite for the sivers - type single - spin asymmetry : @xmath82 these results correspond to set  ii presented in  @xcite . in fig .\n[ fig2 ] , we show predictions for the asymmetry for the dijet - correlation defined in  ( [ eqan ] ) at rhic , based on this parameterization . we find that the asymmetry shares many features with the one shown for the @xmath59-moment in fig .\nwe note that first preliminary experimental data for this asymmetry have now been presented by star  @xcite , which are so far consistent with a vanishing asymmetry .    -0.4\nin summary , we have studied single - transverse spin asymmetries in dijet - correlations at rhic , making use of the recently derived partonic hard - scattering cross sections that properly incorporate the initial- and final - state interactions , and of distribution functions fitted to existing data for single - spin asymmetries .\nwe have found that the initial- and final - state interactions tend to decrease the magnitude of the asymmetry at rhic with respect to earlier estimates that assumed the sivers functions for this observable to be identical to the sivers functions in sidis or the drell - yan process .\noverall , the resulting asymmetries turn out to be more dominated by the final - state interactions , and hence more `` dis - like '' .    with experimental data on dijet single - spin asymmetries now forthcoming , it will be interesting to perform detailed comparisons with the theoretical expectations .\nother observables , such as the ssas in dihadron production @xmath83 or in photon - plus - jet production @xmath84 , will also be extremely interesting\n. it will be important to further develop the theoretical framework for all these observables , by addressing issues like tmd factorization , higher orders , soft factors , and sudakov suppression , in particular .\n* acknowledgments . *\nwe thank jan balewski and steve vigdor for valuable communications about the recent star measurements and the future prospects .\nwe are also grateful to daniel boer and jianwei qiu for discussions .\nare grateful to riken , brookhaven national laboratory and the u.s .\ndepartment of energy ( contract number de - ac02 - 98ch10886 ) for providing the facilities essential for the completion of their work .\nthis work has benefited from the research program of the eu integrated infrastructure initiative hadron physics ( rii3-ct-2004 - 506078 ) .\nthe work of c.b . is supported by the foundation for fundamental research of matter ( fom ) and the national organization for scientific research ( nwo ) .    for fixed - target ssa data ,\nsee for example : d.  l.  adams _ et al .\n_ [ e581 and e704 collaborations ] , phys\n.  lett .\nb * 261 * , 201 ( 1991 ) ; d.  l.  adams _ et al . _\n[ fnal - e704 collaboration ] , phys .\nb * 264 * , 462 ( 1991 ) ; k.  krueger _\net al . _ , phys .\nb * 459 * , 412 ( 1999 ) .\nj.  adams _ et al . _ [ star collaboration ] , phys .  rev .\nlett .   *\n92 * , 171801 ( 2004 ) ; l.  nogach , talk presented at the `` 17th international spin physics symposium ( spin 2006 ) '' , kyoto , japan , october 2 - 7 , 2006 , arxiv : hep - ex/0612030 .\nj.  balewski , talk presented at the `` 17th international spin physics symposium ( spin 2006 ) '' , kyoto , japan , october 2 - 7 , 2006 , arxiv : hep - ex/0612036 ; s. vigdor , talk presented at the annual meeting of the division of nuclear physics of the american physical society , nashville , tennessee , october 25 - 28 , 2006 .\ns.  s.  adler [ phenix collaboration ] , phys .\nlett .   *\n95 * , 202001 ( 2005 ) ; m.  chiu , talk presented at the `` 17th international spin physics symposium ( spin 2006 ) '' , kyoto , japan , october 2 - 7 , 2006 , arxiv : nucl - ex/0701031 ; c.  a.  aidala , ph.d . thesis , columbia u. , arxiv : hep - ex/0601009 .\nf.  videbaek [ brahms collaboration ] , aip conf .\n* 792 * , 993 ( 2005 ) ; j.  h.  lee [ brahms collaboration ] , talk presented at the `` 17th international spin physics symposium ( spin 2006 ) '' , kyoto , japan , october 2 - 7 , 2006 .\na.  airapetian _ et al . _\n[ hermes collaboration ] , phys .\nlett .   * 84 * , 4047 ( 2000 ) ; phys .\n* 94 * , 012002 ( 2005 ) ; m. diefenthaler [ hermes collaboration ] , talk presented at the `` 17th international spin physics symposium ( spin 2006 ) '' , kyoto , japan , october 2 - 7 , 2006 , arxiv : hep - ex/0612010 .\na.  bravar [ spin muon collaboration ] , nucl .\na * 666 * , 314 ( 2000 ) ; h.  avakian [ clas collaboration ] , talk presented at the rbrc workshop `` single - spin asymmetries '' , brookhaven national laboratory , upton , new york , june 1 - 3 , 2005 , rbrc proceedings volume 75 ( bnl-74717 - 2005 ) ; v.  y.  alexakhin _ et al . _\n[ compass collaboration ] , phys .\nlett .   * 94 * , 202002 ( 2005 ) ; e.  s.  ageev _ et al .\n_ [ compass collaboration ] , arxiv : hep - ex/0610068 ; f.  bradamante [ compass collaboration ] , talk presented at the `` 17th international spin physics symposium ( spin 2006 ) '' , kyoto , japan , october 2 - 7 , 2006 .\nx.  ji and f.  yuan , phys .\nb * 543 * , 66 ( 2002 ) ; a.  v.  belitsky , x.  ji and f.  yuan , nucl .\nb * 656 * , 165 ( 2003 ) .\nd.  boer , p.  j.  mulders and f.  pijlman , nucl .\nb * 667 * , 201 ( 2003 ) .\ns.  j.  brodsky , d.  s.  hwang and i.  schmidt , phys .\nb * 530 * , 99 ( 2002 ) ; nucl .\nb * 642 * , 344 ( 2002 ) . c. aidala\n_ et al . _ , http://spin.riken.bnl.gov/rsc/report/masterspin.pdf , _ research plan for spin physics at rhic_.    gsi - pax collab\n, p.  lenisa and f.  rathmann ( spokespersons ) _ et al .\n_ , technical proposal , arxiv : hep - ex/0505054 ; y.  goto , talk presented at the `` workshop on hadron structure at j - parc '' , tsukuba , ibaraki , japan , nov .\n30 - dec . 2 , 2005 ;\ny.  shatunov , talk presented at the `` 17th international spin physics symposium ( spin 2006 ) '' , kyoto , japan , october 2 - 7 , 2006 . plans for drell - yan measurements in pion - nucleon scattering also exist for the compass experiment .\nd.  boer and w.  vogelsang , phys .\nd * 69 * , 094025 ( 2004 ) .\nsee , for example , n.  kidonakis , g.  oderda and g.  sterman , nucl .\nb * 525 * , 299 ( 1998 ) ; nucl .\nb * 531 * , 365 ( 1998 ) . c.  j.  bomhof , p.  j.  mulders and f.  pijlman , phys .\nb * 596 * , 277 ( 2004 ) ; eur .\nj.  c * 47 * , 147 ( 2006 ) .\na.  bacchetta , c.  j.  bomhof , p.  j.  mulders and f.  pijlman , phys\n.  rev .\nd * 72 * , 034030 ( 2005 ) ; the @xmath85 dependence in this paper must be replaced by a @xmath86 dependence everywhere .\na.  v.  efremov and o.  v.  teryaev , sov .\nj.  nucl .\nphys .   * 36 * , 140 ( 1982 ) [ yad .  fiz .\n* 36 * , 242 ( 1982 ) ] ; a.  v.  efremov and o.  v.  teryaev , phys .\nb * 150 * , 383 ( 1985 ) .\nj.  qiu and g.  sterman , phys .\n* 67 * , 2264 ( 1991 ) ; nucl\n.  phys .\nb * 378 * , 52 ( 1992 ) ; phys .\nd * 59 * , 014004 ( 1999 ) .    c.  kouvaris , j.  w.  qiu , w.  vogelsang and f.  yuan , phys .\nd * 74 * , 114013 ( 2006 ) .\nw.  vogelsang and f.  yuan , phys .\nd * 72 * , 054028 ( 2005 ) ; f.  yuan , aip conf .\n842 , 383 ( 2006 ) .\nd.  boer and p.  j.  mulders , phys .\nd * 57 * , 5780 ( 1998 ) .\nj.  w.  qiu , w.  vogelsang and f.  yuan , in preparation ."}
{"lay_summary": " kingman s coalescent is a random tree that arises from classical population genetic models such as the moran model . \n the individuals alive in these models correspond to the leaves in the tree and the following two laws of large numbers concerning the structure of the tree - top are well - known : ( i ) the ( shortest ) distance , denoted by @xmath0 , from the tree - top to the level when there are @xmath1 lines in the tree satisfies @xmath2 almost surely ; ( ii ) at time @xmath0 , the population is naturally partitioned in exactly @xmath1 families where individuals belong to the same family if they have a common ancestor at time @xmath0 in the past . if @xmath3 denotes the size of the @xmath4th family , then @xmath5 almost surely . for both laws of large numbers \n we prove corresponding large deviations results . for ( i ) , the rate of the large deviations is @xmath1 and we can give the rate function explicitly . for ( ii ) , the rate is @xmath1 for downwards deviations and @xmath6 for upwards deviations . for both cases \n we give the exact rate function .    \n =     =    =     = ", "article": "kingman s coalescent is a random tree introduced by @xcite as the genealogy arising in large population genetic models .\nit has infinitely many leaves and is usually constructed from leaves to the root as follows : given that there are @xmath7 lines in the tree , after some exponential time with rate @xmath8 , two lines are chosen uniformly and merged to one line , leaving the tree with @xmath9 lines . due to the quadratic rate @xmath10 the tree immediately comes down from infinitely to finitely many leaves @xcite . since the seminal paper by @xcite this random tree has been generalized to other infinite trees arising in population genetics models .    for the kingman\ncoalescent some laws of large numbers and central limit theorems have been proved .\nthey are nicely summarized in @xcite , chapter  4.2 ; see also proposition  [ p:11 ] below . for @xmath11\nlet @xmath12 denote the number of lines time @xmath13 in the past .\nthen , since the kingman coalescent immediately comes down from infinity , @xmath12 is finite .\nfurthermore it is approximately @xmath14 .\nequivalently , the time @xmath0 it takes the coalescent to go from infinitely many lines to @xmath1 lines is approximately @xmath15 for large @xmath1 .\ngoing to the fine structure , at time @xmath0 the infinite population is decomposed in @xmath1 families ( whose joint distribution is exchangeable ) and every leaf in the tree belongs to exactly one of the @xmath1 families whose frequencies are denoted by @xmath16 .\nit is known that for large @xmath1 a randomly chosen @xmath3 is approximately exponentially distributed with mean @xmath17 .\nthis translates into several laws of large numbers ; see e.g.  ( 35 ) in @xcite .\nin particular the probability of picking ( from the initial infinite population ) two leaves that belong to the same family , given by @xmath18 , is approximately @xmath15 .    the main goal of the present paper is to study the corresponding large deviations results . to the best of our knowledge , except for @xcite , cf .\nremark  [ rem : angel ] , results in this direction are not present in the literature .\nwe formulate our results in the next section .\ntheorem  [ t1 ] gives a full large deviation principle for the distributions of @xmath19 .\nthe proof , given in section  [ sec : proofs1 ] , is an application of the grtner - ellis theorem . as a byproduct\n, we derive a large deviation principle for the distributions of @xmath20 in corollary  [ cor : tnt ] .\nlarge deviations of @xmath21 are considered in theorem  [ t2 ] and exact rate functions for downwards and upwards deviations are given . the proof is given in section  [ sec : proof - theorem - reft2 ] . for the upward deviations we use a variant of cramr s theorem for heavy - tailed random variables\n; see e.g.  @xcite . for the downward deviations we use a connection to self - normalized large deviations ; see @xcite .\nthis connection was pointed out to us by alain rouault and nina gantert .\nsince the rate function for downward deviations is hard to treat analytically we provide in theorem  [ t3 ] a simple lower bound .\nthe proof of that bound is given in section  [ sec : proof - theorem3 ] .\nthe kingman coalescent can be seen as a discrete graph , more precisely a discrete tree with infinitely many leaves .\nlet @xmath22 be independent exponentially distributed variables with mean @xmath23 .\nthen the kingman coalescent tree can be constructed from the root to the leaves as follows .    1 .\nstart the tree with two lines from the root .\n2 .   for @xmath24\nthe tree stays with @xmath7 lines for the amount of time @xmath25 .\nafter that time one of the @xmath7 lines is randomly chosen .\nthis line splits in two so that the number of lines jumps from @xmath7 to @xmath26 .\n3 .   stop upon reaching infinitely many lines , which happens after ( the almost surely finite ) time @xmath27 .\nthe random variable @xmath28 is the total tree height .\nalternatively , @xmath28 is the time to the most recent common ancestor ( mrca ) of the infinite population ( of leaves ) . counted from the top of the tree at time @xmath29 a random number @xmath12 of active lines in the kingman tree is present , i.e.@xmath30 at time @xmath0 every leaf belongs to one of @xmath1 disjoint families and all members of each such family stem from the same line at time @xmath0 .\nlet us denote the frequencies of these families ( which exist due to exchangeability by definetti s theorem ) by @xmath16 .\nthe following results are well known ( see @xcite for   and and @xcite for ; proofs can also be found in @xcite . )     + let [ p:11 ] @xmath31 , @xmath32 and @xmath33 be as above .\nthen @xmath34    we [ rem : interllnfe ] note that the left hand side of has the interpretation of a _\nhomozygosity by descent _ in the following sense : when picking two leaves from the tree at time @xmath35 , the probability that both share a common ancestor at time @xmath0 is @xmath36 .\nthen , the law of large number states that the homozygosity by descent at time @xmath0 is approximately @xmath15 for large @xmath1 .    in the present paper\nwe are interested in large deviations results corresponding to the statements of proposition  [ p:11 ] .\nwe start with large deviations connected with .\nfirst we introduce some notation . for @xmath37 let @xmath38 denote the distribution of @xmath19 ,\ni.e.  @xmath39 .\nfurthermore we denote by @xmath40 the borel @xmath41-algebra on @xmath42 and for @xmath43 we denote by @xmath44 the _ interior _ and by @xmath45 the _ closure _ of @xmath46 . for @xmath47 ,\nlet @xmath48 be the unique solution of the equation @xmath49 , where the continuous and increasing function @xmath50 is defined by ( see figure  [ fig : t1 ] for a plot ) @xmath51      2 & : \\ ; t=0 , \\\\[2ex ]      \\displaystyle\\frac{2}{\\sqrt{|t|}}\\arctan\\sqrt{|t| } & : \\ ; t < 0 .\n\\end{cases}\\end{aligned}\\ ] ] the proof of the following theorem is given in section  [ sec : proof - theorem - reft1 ] .    the sequence [ t1 ] @xmath52 satisfies a large deviation principle with scale @xmath1 and good rate function @xmath53 given by @xmath54        \\infty & : \\\n; x\\leq 0 .\n\\end{cases }    \\end{aligned}\\ ] ] in other words , for any @xmath55 we have @xmath56     and @xmath53 from and , respectively.,title=\"fig:\",width=226 ]   and @xmath53 from and , respectively.,title=\"fig:\",width=226 ]    both , the function @xmath57 from and @xmath53 from are plotted in figure  [ fig : t1 ] .\nthe minimum of the rate function is attained at @xmath58 .\nthis fact is clear from the law of large numbers , .\nin addition , @xmath59 for @xmath60 because @xmath61 almost surely .\nlet us now have a closer look at the behaviour of @xmath62 for @xmath63 near @xmath35 and for large @xmath63 .\nsince @xmath64 , we have that @xmath65 , and hence , @xmath66 . in this case , @xmath67 where the last equality follows from @xmath68 .\nto understand the behaviour for large @xmath63 , note that since @xmath69 for @xmath70 we have @xmath71 and in particular @xmath72 .\nit follows @xmath73    note that and are equivalent .\nindeed , @xmath74 ( this also holds with @xmath75 replaced by @xmath76 ) by construction , and @xmath77 as @xmath78 and @xmath79 as @xmath80 .\nhence , theorem  [ t1 ] translates into a large deviation principle for @xmath20 . in the following\nwe denote by @xmath81 the distribution of @xmath82 , i.e.  @xmath83 .\nthe proof of the next result is given in section  [ sec : proof - coroll - refc ] ; see figure  [ fig : cor1 ] for a plot of the rate function @xmath84 .    for @xmath85\nthe family @xmath86 [ cor : tnt ] satisfies a large deviation principle with scale @xmath87 and good rate function @xmath84 given by @xmath88 \\displaystyle        \\frac{\\pi^2}{2 } & : \\ ,   x=0 , \\\\[1.5ex ]        \\infty & : \\ , x<0 ,      \\end{cases }    \\end{aligned}\\ ] ] with @xmath53 from  .\nin particular , for @xmath89 we have @xmath90     from corollary  [ cor : tnt ] .\nthe figure on the right is a comparison of @xmath84 with the lower bound obtained from @xcite.,title=\"fig:\",width=226 ]   from corollary  [ cor : tnt ] .\nthe figure on the right is a comparison of @xmath84 with the lower bound obtained from @xcite.,title=\"fig:\",width=226 ]    the distributions @xmath91 ( as well as @xmath92 ) have been described explicitely in the literature .\n@xcite , section 6 , gives @xmath93 in principle , this formula must also give the large deviations for the measures @xmath81 , but this does not seem straight - forward .    although [ rem : angel ] the main goal of  @xcite was the analysis of spatial @xmath94-coalescents , they also provide some large deviations bounds on kingman s coalescent .\nthese bounds are mainly based on markov inequality .\nprecisely , in lemma 2.2 in @xcite it is shown that for @xmath95 @xmath96 and therefore @xmath97 in the neighbourhood of @xmath98 the last inequality translates easily into a bound for the rate function @xmath84 from ; see figure  [ fig : cor1 ] .\nnamely , for @xmath99 we have @xmath100    next , we state some large deviations results connected to  . for @xmath101 we know from   that @xmath102 holds almost surely .\nthe proof of this result is based on the well - known fact ( see e.g.  section  5 in @xcite ) that the distribution of @xmath103 can be derived using uniform order statistics : let @xmath104 be independent and uniformly distributed on @xmath105 $ ] , and @xmath106 be their order statistics .\nadditionally , let @xmath107 be independent exponentially distributed random variables with mean @xmath23 . then , @xmath108 here the second equality in distribution is one of the well known representations of uniform spacings ; see e.g.  section  4.1 in @xcite .\nit follows @xmath109 we will use this representation to obtain large deviations results for @xmath103 . in particular\nwe show that upwards large deviations of @xmath103 are on the scale @xmath6 while downwards large deviations are on the scale @xmath1 . the proof is given in section  [ sec : proof - theorem - reft2 ] .    for [ t2 ]\neach @xmath110 , we have @xmath111 furthermore @xmath112 and for each @xmath113 , we have @xmath114 the function @xmath115 is positive for @xmath116 and is given by @xmath117 here @xmath118 is a function of the form @xmath119 with @xmath120 where @xmath121 denotes the distribution function of the one dimensional standard gaussian distribution .\nthough the rate function in   is exact it is hard to treat analytically . for this reason we provide in theorem  [ t3 ] a much simpler lower bound for downwards large deviations of @xmath103 . for the proof we use the following lemma which provides another representation of @xmath103 in terms of exponential random variables ( see section  [ sec : proofs2 ] for proofs ) .\nlet [ l : wn ] @xmath122 be independent exponentially distributed random variables with mean @xmath23 .\nthen , @xmath123    for [ t3 ] @xmath124 we have @xmath125    the main point in the proof of lemma  [ l : wn ] is that @xmath103 does not depend on the order of the @xmath126 and hence we can as well order them according to their size .\nlet us briefly explain how we will use in the proof of in . since @xmath103 is minimal if @xmath127 ( whence @xmath128 ) , we have to look for possibilities that all @xmath126 s are of about the same size in order to obtain a large deviations result for @xmath103 .\nlet @xmath129 denote the above exponential random variables ordered in increasing order , i.e.  @xmath130 is the @xmath4th smallest value .\nusing `` competing exponential clocks '' arguments ( see also the proof of the lemma ) one can see that @xmath131 is exponentially distributed with mean @xmath132 . hence , one way of obtaining similar values for all @xmath126 s arises if @xmath133 is particularly large , which then leads to a large deviations result for @xmath103 .     from in theorem  [ t2 ] and the lower bound from in theorem  [ t3].,width=226 ]    \\1 .\nlet us give some heuristics about the rates arising in theorem  [ t2 ] . for , we have to ask ourselves about the easiest way @xmath103\nbecomes too large . from\n, we see that this is the case if one of the @xmath126 s is too large , making this kind of deviations a local property in the sense that only a single of the @xmath126 s has to show some untypical behavior .\nthis is different when looking at , i.e.  too small values of @xmath103 .\nfirst , observe that @xmath103 is small only if all ( or many ) families have about equal sizes ( extreme case @xmath134 gives the minimal value @xmath128 ) .\nhence , such downward deviations require to study a global property of the random variable @xmath103 , which is significantly harder .\nfor the proof of we will interpret @xmath103 as a self - normalised sum and use from @xcite a result on large deviations result for such sums .    \\2 . from\n, we see that in fact @xmath103 is a function of uniform order statistics , which , for instance , have been studied in detail ( although no large deviations results were given ) in @xcite .\nhence , theorem  [ t2 ] may as well be interpreted as a large deviations result for uniform order statistics .    \\3 .\nas stated in remark  [ rem : interllnfe ] , @xmath135 can be interpreted as homozygosity at time @xmath0 . using a poisson process along the tree with intensity @xmath136 , we can ask for the probability of picking two leaves from the tree which are not separated by a poisson mark , denoted by _ homozygosity in state _ , abbreviated by @xmath137 . this quantity is closely related to the poisson - dirichlet distribution and some large deviations ( in the limit of large @xmath138 )\nwere derived in @xcite .\nit is shown there in theorem  5.1 that @xmath139 and that @xmath140 for @xmath141 . however , a large deviation principle for the quantity @xmath142 ( noting that @xmath143 ) , which corresponds to the results from theorem  [ t2 ] , could not be obtained by @xcite . at least , it was shown that its scale can not be larger than @xmath144 .\nthe proof of theorem  [ t1 ] is an application of the grtner - ellis theorem ; see for instance section  2.3 in @xcite .\nlet @xmath145 $ ] and @xmath146 . to show that the sequence @xmath147 satisfies a large deviation principle with scale @xmath1 and a good rate function we need to check the following three conditions .    1\n.   @xmath148 exists for all @xmath149 as a limit in @xmath150 .\nfurthermore @xmath151 is lower - semicontinuous , @xmath152 , where @xmath153 .\n@xmath94 is differentiable on @xmath154 .\n3 .   @xmath94 is _ steep _ , i.e.  @xmath155 whenever @xmath156 and @xmath157 .    then the good rate function is given by @xmath158    we proceed in three steps .\nfirst , we compute @xmath159 .\nsecond , we check the further assumptions of the grtner - ellis theorem and obtain @xmath53 as the fenchel - legendre transform of @xmath94 . in the third step , for the rate function @xmath53 from\nwe obtain its simplified form given in theorem  [ t1 ] .\nthe limit of @xmath160 : * we will show that @xmath161 for this , recall from that @xmath162 where @xmath163 is exponentially distributed with rate @xmath164 as well as independent of @xmath165 for all @xmath166 .\nfurthermore recall that the moment generating function of an exponentially distributed random variable @xmath167 with rate @xmath168 is given by @xmath169 =    \\begin{cases }      \\frac{\\lambda}{\\lambda - t } , & \\text{if $ t<\\lambda$},\\\\ \\infty ,      & \\text{if $ t\\geq \\lambda$. }    \\end{cases}\\end{aligned}\\ ] ] hence , for each @xmath170 and @xmath171 we obtain by the monotone convergence theorem @xmath172    = \\mathbf{e}\\left[e^{t n^2 \\sum_{k = n+1}^\\infty s_k/\\binom k2}\\right ]    = \\prod_{k = n+1}^\\infty \\mathbf{e}\\left[e^{tn^2 s_k/\\binom k 2}\\right].\\ ] ] we have to consider two cases @xmath173 and @xmath174 separately .\nfirst suppose that @xmath175 . then there exists @xmath176 so that for all @xmath177 we have @xmath178 consequently , using , we obtain @xmath179 = \\infty$ ] for each @xmath177 .\nhence , @xmath180 and @xmath181 for @xmath1 large enough .\nthus , we have @xmath182 now suppose that @xmath183 . for @xmath184 and @xmath185\nwe have @xmath186 . furthermore using and\nwe can write @xmath187 using this we can rewrite @xmath188 for @xmath189 as @xmath190 and by the dominated convergence theorem we obtain @xmath191 hence , ge1 is shown with @xmath94 as in .\nmoreover , we have @xmath192 $ ] , @xmath193 and @xmath94 is lower - semi - continuous .    * step 2 .\nfurther assumptions of the grtner - ellis theorem : * we proceed by checking the assumptions ge2 and ge3 . for differentiability of @xmath94 for @xmath194\nconsider for @xmath195 the function @xmath196 we have @xmath197 for @xmath198 and the derivative @xmath199 exists for each @xmath200 and is continuous in @xmath149 .\nhence , we can interchange differentiation and integration and obtain @xmath201 furthermore , for a sequence @xmath202 with @xmath203 we obtain @xmath204 i.e.  condition ge3 is also satisfied .    * step 3 .\nproperties of @xmath205 : * applying the grtner - ellis theorem reveals that the sequence of distributions of @xmath206 satisfies a large deviation principle with good rate function @xmath207= \\sup_{t \\leq      1 } \\left [ \\frac t2 x + \\int_1^\\infty      \\log\\left(1-\\frac{t}{y^2}\\right ) \\,\\emph dy \\right].\\end{aligned}\\ ] ] in order to compute that supremum , we write for @xmath208 @xmath209 & = x -    2\\int_1^\\infty \\frac{1}{y^2 - t}dy \\\\ & = x +    \\frac{1}{\\sqrt{t}}\\int_1^\\infty \\frac{1}{y+\\sqrt{t } } -    \\frac{1}{y-\\sqrt{t } } dy \\\\ & = x - \\frac{1}{\\sqrt{t } } \\log    \\frac{1+\\sqrt{t}}{1-\\sqrt{t}}\\end{aligned}\\ ] ] while for @xmath210 @xmath209 & = x -    2\\int_1^\\infty \\frac{1}{y^2 + |t|}dy \\\\ & = x -    \\frac{2}{\\sqrt{|t|}}\\arctan\\sqrt{|t|}.\\end{aligned}\\ ] ] it is easy to see that the second derivative is negative throughout , such that the supremum is attained at @xmath211 given by the solution of @xmath212 for @xmath57 as in  .\nfinally we note that for @xmath213 the range of @xmath214 is @xmath215 and for @xmath216 $ ] the range of @xmath217 is @xmath218 $ ] .\nhence , the scale function @xmath53 is of the form given in  .      the proof is based on the fact that @xmath219 .\nthus , for @xmath220 we have @xmath221 and for @xmath222 @xmath223 the value @xmath224 follows from  . since the rate function @xmath53 attains its minimum at @xmath58 , is decreasing below and increasing above @xmath98 , the result follows .\nwhen looking at , note that @xmath103 does not depend on the order of the @xmath126 s .\ntherefore , it is possible to order them according to their size . precisely , let @xmath225 be their order statistics .\nthen it is well - known that @xmath226 indeed , the smallest of @xmath1 independent exponentially distributed mean @xmath23 random variables is exponentially distributed with mean @xmath227 ( as does @xmath228 ) , and the second smallest then has the same distribution as @xmath229 etc .\nnow , we obtain as follows @xmath230      we start by proving  .\nlet @xmath110 and let @xmath231 be independent exponential random variables with mean @xmath23 . in what follows we set @xmath232 according to , it suffices to show that @xmath233 to this end we will show that for all @xmath234 , @xmath235 as well as @xmath236 and obtain by letting @xmath237 .\nfor   we have @xmath238 we consider the two terms on the right hand side of the last display separately and start with the first one .\nobserve that @xmath239 = \\infty$ ] for @xmath168 , @xmath240 = 2 $ ] and @xmath241 for @xmath242 .\nwe use a variant of cramr s theorem for heavy - tailed random variables from @xcite .\nin particular , we refer to the statement around equation ( 1.2 ) there ( the assumption there is fulfilled with @xmath243 replaced by @xmath244 and @xmath245 , @xmath246 and @xmath247 ) .\nwe obtain @xmath248 for the second term on the right hand side of by the ( classical ) cramr theorem we obtain @xmath249 where @xmath250 is the fenchel - legendre transform of the function @xmath251 $ ] . now , using , and we obtain @xmath252 which shows . for the proof of\nwe write @xmath253 again we consider both terms in the last line separately . for the first term , as in\nwe obtain @xmath254 for the second term , we use the same argument as for and get @xmath255 combining   and   with   now gives   which proves  .    since the minimum of @xmath103 is @xmath23 ( when @xmath256 for all @xmath7 ) the assertion @xmath257 is clear .\nit remains to prove , show that the rate function is of the form   and justify the positivity of @xmath115 for @xmath258 .    for @xmath259\nusing we obtain @xmath260 furthermore , for @xmath258 we have @xmath261/\\sqrt{\\mathbf e[r_1 ^ 2]}$ ] .\nthus , we can use theorem  1.1 from @xcite and obtain @xmath262.\\end{aligned}\\ ] ] now we have @xmath263 & = \\int_0^\\infty \\exp\\bigl(-y + t(c    y - \\frac1{2\\sqrt x}(y^2+c^2))\\bigr ) \\ , dy \\\\ \\intertext{and elementary integration yields } & = \\frac{\\sqrt{2\\pi}x^{1/4}}{\\sqrt{t } }      \\exp\\left(\\frac{(tc-1)^2x - t^2c^2}{2t\\sqrt{x}}\\right )      \\phi\\left(\\frac{(tc-1)x^{1/4}}{\\sqrt t}\\right),\\end{aligned}\\ ] ] where @xmath121 denotes the distribution function of the one dimensional standard gaussian distribution . taking @xmath264 of the last term we obtain .\nnow we fix @xmath258 and show that @xmath115 is positive . in the sequel we write\n@xmath265 we have @xmath266 \\\\ & \\ge   \\mathbf    e\\left [ \\inf_{t \\ge 0}\\exp\\bigl(t h(r_1,c ) \\bigr)\\right ] \\\\    & = \\mathbf e\\left[\\mathbbm 1_{\\{h(r_1,c ) < 0\\ } } \\inf_{t \\ge        0}\\exp\\bigl(t h(r_1,c ) \\bigr)\\right ] +    \\mathbf e\\left [ \\mathbbm 1_{\\{h(r_1,c ) \\ge 0\\ } }   \\inf_{t \\ge        0}\\exp\\bigl(t h(r_1,c ) \\bigr)\\right ] \\\\    & = \\mathbf p \\bigl(h(r_1,c ) \\ge 0\\bigr).\\end{aligned}\\ ] ] the function @xmath267 is non - negative on the interval @xmath268 $ ] where @xmath269 are the zeros of the function .\nit follows @xmath270 =    \\mathbf p \\left ( r_1 \\le r_1 \\le r_2 \\right ) =    e^{-c(\\sqrt{x}-\\sqrt{x-1 } ) } - e^{-c(\\sqrt{x}+\\sqrt{x-1})}.\\end{aligned}\\ ] ] finally , by elementary calculation we obtain @xmath271 this expression ( and therefore also @xmath115 ) is positive for @xmath258 .\nthus , the proof of theorem  [ t2 ] is concluded .\nwe prove the inequality using lemma  [ l : wn ] .\nlet @xmath272 and set @xmath273 . for @xmath11\nwe have @xmath274 now @xmath275 , and conditioning in the second factor in the curly braces can be removed by using the fact that conditioned on @xmath276 the exponential random variable @xmath277 has the same distribution as @xmath278 .\nafter some elementary calculations we see that the last line of the above display equals @xmath279 from the strong law of large numbers and with lemma  [ l : wn ] we know that @xmath280{n\\to\\infty } 2 \\quad \\text{almost surely.}\\end{aligned}\\ ] ] it follows that almost surely @xmath281{n\\to\\infty } \\frac{2 + 2y+y^2}{1 + 2y+y^2 } = x.\\end{aligned}\\ ] ] thus , @xmath282 the rest follows by letting @xmath283 .\nwe thank shui feng for pointing out connections to @xcite and nina gantert and alain rouault for pointing out the reference @xcite and fruitful email discussion that led to the exact rate function in .\nthis research was supported by the dfg through grants pf-672/6 - 1 to ad and pp .\nevans , s. ( 2000 ) .\nkingman s coalescent as a random metric space . in _\nstochastic models : proceedings of the international conference on stochastic models in honour of professor donald a. dawson , ottawa , canada , june 10 - 13 , 1998 ( l.g gorostiza and b.g .\nivanoff eds . )\n_ , canad ."}
{"lay_summary": " we discuss several novel types of multi - component ( temporal and spatial ) envelope solitary waves that appear in fiber and waveguide nonlinear optics . \n in particular , we describe multi - channel solitary waves in bit - parallel - wavelength fiber transmission systems for high performance computer networks , multi - colour parametric spatial solitary waves due to cascaded nonlinearities of quadratic materials , and quasiperiodic envelope solitons due to quasi - phase - matching in fibonacci optical superlattices .    2 ", "article": "rapid progress in the design and manufacture of optical fiber systems is a result of worldwide demand for ultra - high bit - rate optical communications .\nthis explains the growing interest of the soliton community in soliton - based optical fiber communication systems .\nthis area of research was considerably advanced in recent years  @xcite .\nthe most remarkable results include the application of the concept of the dispersion management to _ temporal optical solitons _ and soliton - based optical transmission systems , and the discovery of the so - called _ dispersion managed soliton_. high - speed optical communications require effective components such as high - performance broadband computer networks that can be developed by employing the concept of the bit - parallel - wavelength ( bpw ) pulse transmission that offers many of the advantages of both parallel fiber ribbon cable and conventional wavelength - division - multiplexing ( wdm ) systems  @xcite .\nexpanding development in the study of the soliton fiber systems has been observed in parallel with impressive research on their spatial counterparts , optical self - trapped beams or _\nspatial optical solitons_. one of the key concepts in this field came from the theory of multi - frequency wave mixing and cascaded nonlinearities where a nonlinear phase shift is produced as a result of the parametric wave interaction  @xcite .\nin all such systems , the nonlinear interaction between the waves of two ( or more ) frequencies is the major physical effect that can support coupled - mode multi - frequency solitary waves .\nthe examples of temporal and spatial solitons mentioned above have one common feature : they involve the study of solitary waves in multi - component nonlinear models .\nthe main purpose of this paper is to overview several different physical examples of multi - mode and/or multi - frequency solitary waves that occur for the pulse or beam propagation in nonlinear optical fibers and waveguides . for these purposes , we select three different cases : multi - wavelength solitary waves in bit - parallel - wavelength optical fiber links , multi - colour spatial solitons due to multistep cascading in optical waveguides with quadratic nonlinearities , and quasiperiodic solitons in the fibonacci superlattices .\nwe believe these examples display both the diversity and richness of the multi - mode soliton systems , and they will allow further progress to be made in the study of nonlinear waves in multi - component nonintegrable physical models .\nbecause the phenomenon of the long - distance propagation of _ temporal optical solitons _ in optical fibers  @xcite is known to a much broader community of researchers in optics and nonlinear physics , first we emphasize _ the difference between temporal and spatial solitary waves_. indeed , for a long time stationary beam propagation in planar waveguides has been considered somewhat similar to the pulse propagation in fibers .\nthis approach is based on the so - called _ spatio - temporal analogy _ in wave propagation , meaning that the propagation coordinate @xmath0 is treated as the evolution variable and the spatial beam profile along the transverse direction in waveguides , is similar to the temporal pulse profile in fibers .\nthis analogy is based on a simple notion that both beam evolution and pulse propagation can be described by the cubic nonlinear schrdinger ( nls ) equation .\nhowever , contrary to the widely accepted opinion , there is a crucial difference between temporal and spatial solitons . indeed , in the case of the nonstationary pulse propagation in fibers , the operation wavelength is usually selected near the zero point of the group - velocity dispersion .\nthis means that the absolute value of the fiber dispersion is small enough to be compensated by a weak nonlinearity such as that produced by the ( very weak ) kerr effect in optical fibers which leads to a relative nonlinearity - induced change in the refractive index .\ntherefore , nonlinearity in such systems is always weak and it should be well modeled by a cubic nls equation which is known to be integrable by means of the inverse - scattering technique . however , for very short ( e.g. , fs ) pulses the cubic nls equation describing the long - distance propagation of pulses should be corrected to include additional terms that would account for such effects as higher - order dispersion , raman scattering , etc .\nall such corrections can be taken into account with the help of the perturbation theory  @xcite .\nthus , in fibers nonlinear effects are weak and they become important only when dispersion is small ( near the zero - dispersion point ) affecting the pulse propagation over large distances ( of order of hundreds of meters or even kilometers ) .\nthe situation changes dramatically when we consider the propagation of multi - wavelength pulses with almost equal group velocities .\nthe corresponding model is described by a nonintegrable and rather complicated system of coupled nls equations , which we briefly discuss below .    in contrary to the pulse propagation in optical fibers ,\nthe physics underlying the stationary beam propagation in planar waveguides and bulk media is different . in this case\nan optical beam is generated by a continuous wave ( cw ) source and it is time independent .\nhowever , when the beam evolves with the propagation distance @xmath0 , it diffracts in the transverse spatial directions .\nthen , a nonlinear change in the refractive index should compensate for the beam spreading caused by diffraction _ which is not a small effect_. that is why to observe spatial solitons as self - trapped optical beams , much larger nonlinearities are usually required , and very often such nonlinearities are not of the kerr type ( e.g. they saturate at higher intensities ) .\nthis leads to the models of generalized nonlinearities with the properties of solitary waves different from those described by the integrable cubic nls equation .\npropagation distances involved in the phenomenon of the beam self - focusing and spatial soliton propagation are of the order of millimeters or centimeters .\nto achieve such large nonlinearities , one needs to use the optical materials with large nonlinearity - induced refractive index .\none of the possible way to overcome this difficulty is to use the so - called _ cascaded nonlinearities _ of noncentrosymmetric optical materials where nonlinear effects are accumulated due to parametric wave interaction under the condition of the wave phase matching .\nsuch parametric wave - mixing effects generate novel classes of spatial optical solitons where resonant parametric coupling between the envelopes of two ( or more ) beams of different frequencies supports stable spatially localised waves even in a bulk medium ( see details in ref .\nit is this kind of multi - component solitary waves that we discuss below .\na growing demand for high - speed computer communications requires an effective and inexpensive computer interconnection .\none attractive alternative to the conventional wdm systems is bpw single - mode fiber optics links for very high bandwidth computer communications  @xcite .\nthey differ from the wdm schemes in that no parallel to serial conversion is necessary , and parallel pulses are launched simultaneously on different wavelengths .\nwhen the pulses of different wavelengths are transmitted simultaneously , the cross - phase modulation can produce an interesting _ pulse shepherding effect _\n@xcite , when a strong ( `` shepherd '' ) pulse enables the manipulation and control of pulses co - propagating on different wavelengths in a multi - channel optical fiber link .    to describe the simultaneous transmission of @xmath1 different wavelengths in a nonlinear optical fiber , we follow the standard derivation  @xcite and obtain a system of @xmath1 coupled nonlinear schrdinger ( nls ) equations @xmath2 ) : @xmath3 { \\displaystyle \\qquad      + \\chi_j \\left ( |a_j|^2 + 2 \\sum_{m \\neq j } |a_m|^2\n\\right ) a_j      = 0 ,    } \\end{array}\\ ] ] where , for the @xmath4th wave , @xmath5 is the slowly varying envelope , @xmath6 and @xmath7 are the group velocity and group - velocity dispersion , respectively , and the nonlinear coefficients @xmath8 characterize the kerr effect\n. equations  ( [ eq : nls_dim ] ) do not include the fiber loss , since the fiber lengths involved in bit - parallel links are only a small fraction of the attenuation length .\nwe measure the variables in the units of the central wavelength channel ( say , @xmath9 ) , and obtain the following normalized system of the @xmath1 coupled nls equations , @xmath10 { \\displaystyle \\qquad      + \\gamma_j \\left(|u_j|^2 + 2 \\sum_{m\\neq j } |u_m|^2\\right ) u_j      = 0 ,    } \\end{array}\\ ] ] where @xmath11 , @xmath12 is the incident optical power in the central channel , @xmath13 , @xmath14 , so that @xmath15 . for the operating wavelengths spaced @xmath16 nm apart within the band @xmath17 nm , the coefficients @xmath18 and @xmath19 are different but close to @xmath20 . initially , in eq .\n( [ eq : nls ] ) , we omit the mode walk - off effect described by the parameters @xmath21 ( so that @xmath22 ) .\nthis effect will be analysed later in this section .    to analyze the nonlinear modes , i.e. localized states of the bpw model ( [ eq : nls ] )\n, we look for stationary solutions in the form , @xmath23 and therefore obtain the system of equations for the normalized mode amplitudes , @xmath24 { \\displaystyle     \\frac{1}{2 } \\alpha_n \\frac{d^2u_n}{dt^2 }      + \\gamma_n \\left ( |u_n|^2      + 2\\sum_{m \\neq n } |u_m|^2 \\right ) u_n      = \\lambda_n u_n ,   } \\end{array}\\ ] ] where @xmath25 , the amplitudes and time are measured in the units of @xmath26 and @xmath27 , respectively , and @xmath28 .    system ( [ eq : nls_nn ] ) has _ exact analytical solutions _ for @xmath1 coupled components , the so - called _\nbpw solitons_. indeed , looking for solutions in the form @xmath29 , @xmath30 , we obtain the constraint @xmath31 , and a system of @xmath1 coupled algebraic equations for the wave amplitudes , @xmath32 in a special symmetric case , we take @xmath33 , and the solution of those equations is simple  @xcite : + @xmath34^{-1/2}$ ] .\nanalytical solutions can also be obtained in the _ linear limit _\n, when the central frequency pulse ( at @xmath35 ) is large . then , linearizing eqs .\n( [ eq : nls_nn ] ) for small @xmath36 , we obtain a decoupled nonlinear equation for @xmath37 and @xmath38 decoupled linear equations for @xmath39 . each of the latter possess a localized solution provided @xmath40 , where @xmath41 ^ 2 $ ] . in this limit\nthe central soliton pulse @xmath37 ( `` shepherd pulse '' ) can be considered as inducing an effective waveguide that supports a fundamental mode @xmath39 with the corresponding cutoff @xmath42 .\nsince , by definition , the parameters @xmath43 and @xmath44 are close to @xmath20 , we can verify that the soliton - induced waveguide supports maximum of two modes ( fundamental and the first excited one ) .\nthis is an important physical result that explains the effective robustness of the pulse guidance by the shepherding pulse .    to demonstrate a number of unique properties of the multi - channel bpw solitons , we consider the case @xmath45 in more details .\na comprehensive discussion of the case @xmath46 can be found in the preprint  @xcite .\nwe select the following set of the normalized parameters : @xmath47 , @xmath48 , and @xmath49 .\nsolitary waves of this four - wavelength bpw system can be found numerically as localized solutions of eqs .\n( [ eq : nls_nn ] ) . figure  [ fig : bpw1 ] presents the lowest - order families of such localized solutions . in general\n, they are characterized by @xmath38 parameters , but we can capture the characteristic features by presenting power dependencies along the line @xmath50 in the parameter space @xmath51 .\nthe power of the central - wavelength component ( @xmath35 ) does not depend on @xmath52 ( straight line @xmath53 ) .\nthin dashed , dotted , and dash - dotted curves correspond to the three separate single - mode solitons of the multi - channel bpw system , ( 1 ) , ( 2 ) , and ( 3 ) , respectively , shown with the corresponding branches of ( 0 + 1 ) , ( 0 + 2 ) , and ( 0 + 3 ) two - mode solitons .\nthe latter curves start off from the bifurcation points on the @xmath37 branch at @xmath54 , @xmath55 , and @xmath56 , respectively .\nclose separation of those curves is the result of closeness of the parameters @xmath43 and @xmath44 for @xmath57 .\nthick solid curves in fig .\n[ fig : bpw1 ] correspond to the two- ( 1 + 2 ) and three - mode ( 0 + 1 + 2 ) localized solutions .\nthe latter solutions bifurcate and give birth to four - wavelength solitons ( 0 + 1 + 2 + 3 ) ( branch a - b ) .\ntwo examples of such four - wave composite solitons are shown in fig .\n[ fig : bpw1 ] ( bottom row ) .\nthe solution b is close to an exact sech - type solution at @xmath58 ( described above ) for @xmath45 , whereas the solution a is close to that approximately described in the linear limit in the vicinity of a bifurcation point .\nimportantly , for different values of the parameters @xmath59 , the uppermost bifurcation point for this branch ( open circle in fig . [\nfig : bpw1 ] ) is not predicted by a simple linear theory and , due to the nonlinear mode coupling , it gets shifted from the branch of the central - wavelength soliton ( straight line ) to a two - mode branch ( 0 + 1 + 2 ) ( thick solid curve ) .    as a result , if we start on the right end of the horizontal branch and follow the lowest branches of the total power @xmath60 in fig .\n[ fig : bpw1 ] , we pass the following sequence of the soliton families and bifurcation points : @xmath61 . if the modal parameters are selected closer to each other , the first two links of _ the bifurcation cascade _ disappear ( i.e. the corresponding bifurcation points merge ) , and the four - mode soliton bifurcates directly from the central - wavelength pulse , as predicted by the linear theory .\nnote however that the sequence and location of the bifurcation points is a function of the cross - section of the parameter space @xmath51 , and the results presented above correspond to the choice @xmath62 .    the qualitative picture of the cascading bifurcations preserves for other values of @xmath1 .\nin particular , near the bifurcation point a mixed - mode soliton corresponds to the localized modes guided by the central - wavelength soliton ( shepherd ) pulse .\nthe existence of such soliton solutions is a key concept of bpw transmission when the data are launched in parallel carrying a desirable set of bits of information , all guided by the shepherd pulse at a selected wavelength .\neffects of the walk - off on the multi - channel bpw solitons seems to be most dangerous for the pulse alignment in the parallel links . for nearly equal soliton components ,\nit was shown long time ago @xcite that nonlinearity can provide an effective trapping mechanism to keep the pulses together . for the shepherding effect , the corresponding numerical simulations are presented in figs .\n[ fig : bpw2](a - d ) for the four - channel bpw system .\ninitially , we launch a composite four - mode soliton as an unperturbed solution a [ see fig .  [\nfig : bpw1 ] ] of eqs .\n( [ eq : nls ] ) , without walk - off and centered at @xmath63 .\nwhen this solution evolves along the propagation direction @xmath0 in the presence of small to moderate relative walk - off ( @xmath64 for @xmath65 ) , its components remain strongly localized and mutually trapped [ fig .\n[ fig : bpw2](a , b ) ] , whereas it loses some energy into radiation for much larger values of the relative mode walk - off [ fig .\n[ fig : bpw2](c , d ) ] .\nrecent progress in the study of cascading effects in optical materials with quadratic ( second - order or @xmath66 ) nonlinear response has offered new opportunities for all - optical processing , optical communications , and optical solitons  @xcite .\nmost of the studies of cascading effects employ parametric wave mixing processes with a single phase - matching and , as a result , two - step cascading  @xcite .\nfor example , the two - step cascading associated with type i second - harmonic generation ( shg ) includes the generation of the second harmonic ( @xmath67 ) followed by reconstruction of the fundamental wave through the down - conversion frequency mixing ( dfm ) process ( @xmath68 ) .\nthese two processes are governed by one phase - matched interaction and they differ only in the direction of power conversion .    the idea to explore more than one simultaneous nearly phase - matched process , or _\ndouble - phase - matched ( dpm ) wave interaction _ , became attractive only recently  @xcite , for the purposes of all - optical transistors , enhanced nonlinearity - induced phase shifts , and polarization switching .\nin particular , it was shown  @xcite that multistep cascading can be achieved by two second - order nonlinear cascading processes , shg and sum - frequency mixing ( sfm ) , and these two processes can also support a novel class of multi - colour parametric solitons  @xcite , briefly discussed below .      to introduce the simplest model of multistep cascading ,\nwe consider the fundamental beam with frequency @xmath69 entering a noncentrosymmetric nonlinear medium with a quadratic response . as a first step ,\nthe second - harmonic wave with frequency @xmath70 is generated via the shg process .\nas a second step , we expect the generation of higher order harmonics due to sfm , for example , a third harmonic ( @xmath71 ) or even fourth harmonic ( @xmath72 )  @xcite .\nwhen both such processes are nearly phase matched , they can lead , via down - conversion , to a large nonlinear phase shift of the fundamental wave  @xcite .\nadditionally , the multistep cascading can support _ a novel type of three - wave spatial solitary waves _ in a diffractive @xmath66 nonlinear medium , _ multistep cascading solitons_.    we start our analysis with the reduced amplitude equations derived in the slowly varying envelope approximation with the assumption of zero absorption of all interacting waves ( see , e.g. , ref .\n@xcite ) . introducing the effect of diffraction in a slab waveguide geometry\n, we obtain @xmath73 { \\displaystyle   \\qquad\\qquad\\qquad\\qquad      + \\chi_{2}a_{2 } a_{1}^{\\ast}e^{-i\\delta k_{2}z } = 0 ,     } \\\\*[9pt ] { \\displaystyle       4\ni k_{1 } \\frac{\\partial a_{2}}{\\partial z }       + \\frac{\\partial^{2 } a_{2}}{\\partial x^{2 } }       + \\chi_{4 } a_{3 } a_{1}^{\\ast } e^{-i\\delta k_{3}z }     } \\\\*[9pt ] { \\displaystyle   \\qquad\\qquad\\qquad\\qquad      + \\chi_{5 } a_{1}^{2 } e^{i\\delta k_{2}z }       = 0 ,     } \\\\*[9pt ] { \\displaystyle       6 i k_{1}\\frac{\\partial a_{3}}{\\partial z }       + \\frac{\\partial^{2 } a_{3}}{\\partial x^{2 } }       + \\chi_{3}a_{2}a_{1}e^{i\\delta k_{3}z }       = 0 ,     } \\end{array}\\ ] ] where @xmath74 , @xmath75 , and @xmath76 , and the nonlinear coupling coefficients @xmath77 are proportional to the elements of the second - order susceptibility tensor which we assume to satisfy the following relations ( no dispersion ) , @xmath78 , @xmath79 , and @xmath80 .    in eqs .\n( [ physeqns ] ) , @xmath81,@xmath82 and @xmath83 are the complex electric field envelopes of the fundamental harmonic ( fh ) , second harmonic ( sh ) , and third harmonic ( th ) , respectively , @xmath84 is the wavevector mismatch for the shg process , and @xmath85 is the wavevector mismatch for the sfm process .\nthe subscripts ` 1 ' denote the fh wave , the subscripts ` 2 ' denote the sh wave , and the subscripts ` 3 ' , the th wave .\nfollowing the technique earlier employed in refs .\n@xcite , we look for stationary solutions of eq .\n( [ physeqns ] ) and introduce the normalised envelope @xmath86 , @xmath87 , and @xmath88 according to the relations , @xmath89 { \\displaystyle       a_{2 } = \\frac{2 \\beta k_{1}}{\\chi_{2}}e^{2i\\beta z + i\\delta k_{2 } z } v ,     } \\\\*[9pt ] { \\displaystyle       a_{3 } = \\frac{\\sqrt{2\\chi_{2}}\\beta      k_{1}}{\\chi_{1}\\sqrt{\\chi_{5}}}e^{3i\\beta z + i\\delta k z } u ,    } \\end{array}\\ ] ] where @xmath90 . renormalising the variables as @xmath91 and @xmath92 , we finally obtain a system of coupled equations , @xmath93 { \\displaystyle 2i \\frac{\\partial v}{\\partial z } + \\frac{\\partial^{2 } v}{\\partial x^{2 } } - \\alpha v + \\frac{1}{2 } w^{2 } + w^{\\ast}u = 0 , } \\\\*[9pt ] { \\displaystyle 3i\\frac{\\partial u}{\\partial z } + \\frac{\\partial^{2 } u}{\\partial x^{2 } } - \\alpha_{1}u + \\chi vw = 0 , } \\\\*[9pt ] \\end{array}\\ ] ] where @xmath94 and @xmath95 are two dimensionless parameters that characterise the nonlinear phase matching between the parametrically interacting waves .\ndimensionless material parameter @xmath96 depends on the type of phase matching , and it can take different values of order of one .\nfor example , when both shg and sfm are due to quasi - phase matching ( qpm ) , we have @xmath97 $ ] , where @xmath98 .\nthen , for the first - order @xmath99 qpm processes ( see , e.g. , ref .\n@xcite ) , we have @xmath100 , and therefore @xmath101 . when sfm is due to the third - order qpm process ( see , e.g. , ref .\n@xcite ) , we should take @xmath102 , and therefore @xmath103 . at\nlast , when sfm is the fifth - order qpm process , we have @xmath104 and @xmath105 .\ndimensionless equations ( [ normal ] ) present a fundamental model for three - wave multistep cascading solitons in the absence of walk - off . additionally to the type\ni shg solitons ( see , e.g. , refs  @xcite ) , the multistep cascading solitons involve the phase - matched sfm interaction ( @xmath106 ) that generates a third harmonic wave .\ntwo - parameter family of localised solutions consists of three mutually coupled waves .\nit is interesting to note that , similar to the case of nondegenerate three - wave mixing  @xcite , eqs .\n( [ normal ] ) possess an exact solution . to find it , we make a substitution @xmath107 , @xmath108 and @xmath109 , and obtain unknown parameters from the following algebraic equations @xmath110 valid for @xmath111 and @xmath112 .\nequations ( [ exactsol ] ) have two solutions corresponding to _ positive _ and _ negative _ values of the amplitude ( @xmath113 ) .\nthis indicates a possibility of multi - valued solutions , even within the class of exact solutions .    in general , three - wave solitons of eqs .\n( [ normal ] ) can be found only numerically .\nfigures [ fig : tr1](a ) and [ fig : tr1](b ) present two examples of solitary waves for different sets of the mismatch parameters @xmath114 and @xmath115 .\nwhen @xmath116 [ see fig .\n[ fig : tr1](a ) ] , which corresponds to an unmatched sfm process , the amplitude of the third harmonic is small , and it vanishes for @xmath117 .    to summarise different types of three - wave solitary waves , in fig .\n[ fig : tr2 ] we plot the dependence of the total soliton power defined as @xmath118 .\nit is clearly seen that for some values of @xmath119 ( including the exact solution at @xmath120 shown by two filled circles ) , there exist _ two different branches _ of three - wave solitary waves , and only one of those branches approaches , for large values of @xmath119 , a family of two - wave solitons of the cascading limit ( fig .  [ fig : tr2 ] , dashed ) . the slope of the branches changes from negative ( for small @xmath119 ) to positive ( for large @xmath119 ) , indicating a possible change of the soliton stability .\nhowever , the detailed analysis of the soliton stability is beyond the scope of this paper ( see , e.g. , refs .\n@xcite ) .\nanother type of multistep cascading parametric processes which involve only two frequencies , i.e. _ two - colour multistep cascading _\n, can occur due to the vectorial interaction of waves with different polarization .\nwe denote two orthogonal polarization components of the fundamental harmonic ( fh ) wave ( @xmath121 ) as a and b , and two orthogonal polarizations of the second harmonic ( sh ) wave ( @xmath122 ) , as s and t. then , a simple multistep cascading process consists of the following steps .\nfirst , the fh wave a generates the sh wave s via type i shg process .\nthen , by down - conversion\nsa - b , the orthogonal fh wave b is generated .\nat last , the initial fh wave a is reconstructed by the processes sb - a or ab - s , sa - a .\ntwo principal second - order processes aa - s and ab - s correspond to _ two different components _ of the @xmath66 susceptibility tensor , thus introducing additional degrees of freedom into the parametric interaction .\ndifferent cases of such type of multistep cascading processes are summarized in table  [ tab : dpm ] .    to demonstrate some of the unique properties of the multistep cascading\n, we discuss here how it can be employed for soliton - induced waveguiding effects in quadratic media . for this purpose\n, we consider a model of two - frequency multistep cascading described by the principal dpm process ( c ) ( see table  [ tab : dpm ] above ) in the planar slab - waveguide geometry .\nusing the slowly varying envelope approximation with the assumption of zero absorption of all interacting waves , we obtain @xmath123 { \\displaystyle       2 i k_{1}\\frac{\\partial b}{\\partial z } + \\frac{\\partial^{2 } b }       { \\partial x^{2 } } + \\chi_2 s b^{\\ast}e^{-i\\delta k_2 z } = 0 ,    } \\\\*[9pt ] { \\displaystyle       4 i k_{1 } \\frac{\\partial s}{\\partial z }       + \\frac{\\partial^{2 } s}{\\partial x^{2 } }       + 2 \\chi_1 a^2 e^{i\\delta k_1 z }       + 2 \\chi_2 b^2 e^{i\\delta k_2 z }       = 0 ,    } \\end{array}\\end{aligned}\\ ] ] where @xmath74 , the nonlinear coupling coefficients @xmath77 are proportional to the elements of the second - order susceptibility tensor , and @xmath124 and @xmath125 are the corresponding wave - vector mismatch parameters .    to simplify the system ( [ eq_1 ] ) , we look for its stationary solutions and introduce the normalized envelopes @xmath126 , @xmath127 , and @xmath128 according to the following relations , @xmath129 , @xmath130 , and @xmath131 , where @xmath132 , @xmath133 , and @xmath134 , and the longitudinal and transverse coordinates are measured in the units of @xmath135 and @xmath136 , respectively .\nthen , we obtain a system of normalized equations , @xmath137    { \\displaystyle      i \\frac{\\partial v}{\\partial z } +       \\frac{\\partial^{2 } v}{\\partial x^{2 } } - \\alpha_1 v + \\chi v^{\\ast}w= 0 , }                        \\\\*[9pt ]    { \\displaystyle      2i \\frac{\\partial w}{\\partial z } +       \\frac{\\partial^{2}w}{\\partial x^{2 } } - \\alpha w+\\frac{1}{2}(u^2+v^2)= 0 , }    \\end{array}\\ ] ] where @xmath138 , @xmath139 , and @xmath140 .\nfirst of all , we notice that for @xmath141 ( or , similarly , @xmath142 ) , the dimensionless eqs .\n( [ eq_n ] ) reduce to the corresponding model for the two - step cascading due to type i shg discussed earlier @xcite , and its stationary solutions are defined by the equations for real @xmath126 and @xmath128 , @xmath143    { \\displaystyle     \\frac{d^2 w}{d x^{2 } } - \\alpha w + \\frac{1}{2 } u^2 = 0 , }    \\end{array}\\ ] ] that possess a one - parameter family of two - wave localized solutions @xmath144 found earlier numerically for any @xmath145 , and also known analytically for @xmath146 , @xmath147 ( see ref .\n@xcite ) .\nthen , in the small - amplitude approximation , the equation for real orthogonally polarized fh wave @xmath127 can be treated as an eigenvalue problem for an effective waveguide created by the sh field @xmath148 , @xmath149 v = 0.\\ ] ] therefore , an additional parametric process allows to propagate a probe beam of one polarization in _ an effective waveguide _ created by a two - wave spatial soliton in a quadratic medium with fh component of another polarization .\nhowever , this type of waveguide is different from what has been studied for kerr - like solitons because it is _ coupled parametrically _ to the guided modes and , as a result , the physical picture of the guided modes is valid , rigorously speaking , only in the case of stationary phase - matched beams . as a result , the stability of the corresponding waveguide and localized modes of the orthogonal polarization it guides is a key issue . in particular , the waveguide itself ( i.e. _ two - wave parametric soliton _ ) becomes unstable for @xmath150  @xcite .    in order to find the guided modes of the parametric waveguide created by a two - wave quadratic soliton\n, we have to solve eq .\n( [ eq_eigen ] ) where the exact solution @xmath148 is to be found numerically .\nthen , to address this problem analytically , approximate solutions can be used , such as those found with the help of the variational method  @xcite .\nhowever , the different types of the variational ansatz used do not provide a very good approximation for the soliton profile at all @xmath114 .\nfor our eigenvalue problem ( [ eq_eigen ] ) , the function @xmath148 defines parameters of the guided modes and , in order to obtain accurate results , it should be calculated as close as possible to the exact solutions found numerically . to resolve this difficulty , below we suggest a novel `` almost exact '' solution that _ would allow to solve analytically many of the problems involving quadratic solitons _\n, including the eigenvalue problem  ( [ eq_eigen ] ) .\nfirst , we notice that from the exact solution at @xmath146 and the asymptotic result for large @xmath114 , @xmath151 , it follows that the sh component @xmath148 of eqs .\n( [ eq_2 ] ) remains almost self - similar for @xmath152 .\nthus , we look for the sh field in the form @xmath153 , where @xmath154 and @xmath155 are to be defined .\nthe solution for @xmath156 should be consistent with this choice of the shape for sh , and it is defined by the first ( linear for @xmath126 ) equation of the system ( [ eq_2 ] ) .\ntherefore , we can take @xmath126 in the form of the lowest guided mode , @xmath157 , that corresponds to an effective waveguide @xmath148 . by matching the asymptotics of these trial functions with those defined directly from eqs .\n( [ eq_2 ] ) at small and large @xmath158 , we obtain the following solution , @xmath159 @xmath160 here , the third relation allows us to find @xmath154 for arbitrary @xmath114 as a solution of a cubic equation , and then to find all other parameters as functions of @xmath114 . for mismatches in the interval @xmath161\n, the parameter values change monotonically in the regions : @xmath162 , @xmath163 , and @xmath164 .\nit is really amazing that the analytical solution  ( [ eq_s]),([eq_p ] ) provides _ an excellent approximation _ for the profiles of the two - wave parametric solitons found numerically , with the relative errors not exceeding 1%3% for stable solitons\n( e.g. when @xmath165 ) . as a matter of fact\n, we can treat eqs .\n( [ eq_s ] ) and  ( [ eq_p ] ) as an _\napproximate scaling transformation _ of the family of two - wave bright solitons .\nmoreover , this solution allows us to capture some remarkable internal similarities and distinctions between the solitons existing in different types of nonlinear media .\nin particular , as follows from eqs .\n( [ eq_s ] ) and  ( [ eq_p ] ) , the fh component and the self - consistent effective waveguide ( created by the sh field ) have approximately the same stationary transverse profiles as for one - component solitons in a kerr - like medium with power - law nonlinear response  @xcite . for @xmath166 ( @xmath167 ) and @xmath168 ( @xmath169 )\nour general expressions reduce to the known analytical solutions , and the fh profile is exactly the same as that for solitons in quadratic and cubic kerr media , respectively .\non the other hand , the strength of self - action for quadratic solitons depends on the normalized phase mismatch @xmath114 and , in general , the beam dynamics for parametric wave mixing can be very different from that observed in kerr - type media .\nnow , the eigenvalue problem ( [ eq_eigen ] ) can be readily solved analytically .\nthe eigenmode cutoff values are defined by the parameter @xmath119 that takes one of the discrete values , @xmath170 , where @xmath171^{1/2}$ ] .\nnumber @xmath172 stands for the mode order @xmath173 , and the localized solutions are possible provided @xmath174 .\nthe profiles of the corresponding guided modes are @xmath175 where @xmath176 , @xmath177 is the hypergeometric function , and @xmath178 is the mode s amplitude which can not be determined within the framework of the linear analysis .    according to these results , a two - wave parametric soliton creates , a multi - mode waveguide and larger number of the guided modes can be observed for smaller @xmath114 .\nfigures  [ fig : al1](a , b ) show the dependence of the mode cutoff values @xmath179 for a fixed @xmath180 , and @xmath181 for a fixed @xmath114 , respectively . for the case\n@xmath103 , the dependence has a simple form : @xmath182 ^ 2 $ ] .\nbecause a two - wave soliton creates an induced waveguide parametrically coupled to its guided modes of the orthogonal polarization , the dynamics of the guided modes _ may differ drastically _ from that of conventional waveguides based on the kerr - type nonlinearities .\nfigures   show two examples of the evolution of guided modes . in the first example\n[ see fig .\n[ fig : wave_w](a - c ) ] , a weak fundamental mode is amplified via parametric interaction with a soliton waveguide , and the mode experiences a strong power exchange with the orthogonally polarized fh component through the sh field .\nthis process is accompanied by only a weak deformation of the induced waveguide [ see fig .  [\nfig : wave_w](a )  dotted curve ] .\nthe resulting effect can be interpreted as a power exchange between two guided modes of orthogonal polarizations in a waveguide created by the sh field . in the second example , the propagation is stable [ see fig .  [\nfig : wave_w](d ) ] .    when all the fields in eq .\n( [ eq_n ] ) are not small , i.e. the small - amplitude approximation is no longer valid , the profiles of the three - component solitons should be found numerically . however , some of the lowest - order states can be calculated approximately using the approach of the `` almost exact '' solution ( [ eq_s]),([eq_p ] ) described above , which is presented in detail elsewhere  @xcite .\nmoreover , a number of the solutions and their families can be obtained in _\nan explicit analytical form_. for example , for @xmath183 , there exist two _ families of three - component solitary waves _ for any @xmath152 , that describe soliton branches starting at the bifurcation points @xmath184 at : ( i )  the soliton with a zero - order guided mode for @xmath185 : @xmath186 , @xmath187 , @xmath188 , and ( ii )  the soliton with a first - order guided mode for @xmath103 : @xmath189 , @xmath190 , @xmath188 , where @xmath191 and @xmath192 .    for a practical realization of\nthe dpm processes and the soliton waveguiding effects described above , we can suggest two general methods .\nthe first method is based on the use of _ two commensurable periods _ of the quasi - phase - matched ( qpm ) periodic grating . indeed , to achieve dpm\n, we can employ the first - order qpm for one parametric process , and the third - order qpm , for the other parametric process .\ntaking , as an example , the parameters for linbo@xmath193 and aa - s @xmath194 and bb - s @xmath195 processes @xcite , we find two points for dpm at about 0.89 @xmath196 m and 1.25 @xmath196 m .\nthis means that a single qpm grating can provide simultaneous phase - matching for two parametric processes .\nfor such a configuration , we obtain @xmath197 or , interchanging the polarization components , @xmath198 . the second method to achieve the conditions of dpm processes\nis based on the idea of _ quasi - periodic qpm grating _\nspecifically , fibonacci optical superlattices provide an effective way to achieve phase - matching at _ several incommensurable periods _ allowing multi - frequency harmonic generation in a single structure .\nwe describe the properties of such structures in the next section .\nfor many years , solitary waves have been considered as _ coherent localized modes _ of nonlinear systems , with particle - like dynamics quite dissimilar to the irregular and stochastic behavior observed for chaotic systems  @xcite . however , about 20 years ago akira hasegawa , while developing a statistical description of the dynamics of an ensemble of plane waves in nonlinear strongly dispersive plasmas , suggested the concept of a localized envelope of random phase waves  @xcite . because of the relatively high powers required for generating self - localized random waves , this notion remained a theoretical curiosity until recently , when the possibility to generate spatial optical solitons by a partially incoherent source was discovered in a photorefractive medium  @xcite .\nthe concept of incoherent solitons can be compared with a different problem : the propagation of a soliton through a spatially disordered medium . indeed , due to random scattering on defects , the phases of the individual components forming a soliton experience random fluctuations , and the soliton itself becomes _ partially incoherent _ in space and time . for a low - amplitude wave ( linear regime )\nspatial incoherence is known to lead to a fast decay . as a result\n, the transmission coefficient vanishes exponentially with the length of the system , the phenomenon known as anderson localization  @xcite .\nhowever , for large amplitudes ( nonlinear regime ) , when the nonlinearity length is much smaller than the anderson localization length , a soliton can propagate almost unchanged through a disordered medium as predicted theoretically in 1990 @xcite and recently verified experimentally  @xcite .    these two important physical concepts , spatial self - trapping of light generated by an incoherent source in a homogeneous medium , and suppression of anderson localization for large - amplitude waves in spatially disordered media , both result from the effect of strong nonlinearity .\nwhen the nonlinearity is sufficiently strong it acts as _ an effective phase - locking mechanism _ by producing a large frequency shift of the different random - phase components , and thereby introducing _ an effective order _ into an incoherent wave packet , thus enabling the formation of localized structures . in other words ,\nboth phenomena correspond to the limit when the ratio of the nonlinearity length to the characteristic length of ( spatial or temporal ) fluctuations is small . in the opposite limit , when this ratio is large , the wave propagation is practically linear .    below we show that , at least for aperiodic inhomogeneous structures , solitary waves can exist in the intermediate regime in the form of _ quasiperiodic nonlinear localized modes_. as an example , we consider shg and nonlinear beam propagation in _ fibonacci optical superlattices _ , and demonstrate numerically the possibility of spatial self - trapping of quasiperiodic waves whose envelope amplitude varies quasiperiodically , while still maintaining a stable , well - defined spatially localized structure , _ a quasiperiodic envelope soliton_.      we consider the interaction of a fundamental wave with the frequency @xmath69 ( fh ) and its sh in a slab waveguide with quadratic ( or @xmath66 ) nonlinearity . assuming the @xmath66 susceptibility to be modulated and the nonlinearity to be of the same order as diffraction , we write the dynamical equations in the form @xmath199     { \\displaystyle i\\frac{\\partial w}{\\partial z } + \\frac{1}{4 }     \\frac{\\partial^2 w}{\\partial x^2 } + d(z ) u^2 e^{i\\beta z } =   0 , }    \\end{array}\\ ] ] where @xmath200 and @xmath201 are the slowly varying envelopes of the fh and sh , respectively .\nthe parameter @xmath202 is proportional to the phase mismatch @xmath203 , @xmath204 and @xmath205 being the wave numbers at the two frequencies .\nthe transverse coordinate @xmath158 is measured in units of the input beam width @xmath206 , and the propagation distance @xmath0 in units of the diffraction length @xmath207 .\nthe spatial modulation of the @xmath66 susceptibility is described by the quasi - phase - matching ( qpm ) grating function @xmath208 . in the context of shg\n, the qpm technique is an effective way to achieve phase matching , and it has been studied intensively  @xcite .    here\nwe consider a qpm grating produced by a quasiperiodic nonlinear optical superlattice .\nquasiperiodic optical superlattices , one - dimensional analogs of quasicrystals  @xcite , are usually designed to study the effect of anderson localization in the linear regime of light propagation .\nfor example , gellermann _ et al .\n_ measured the optical transmission properties of quasiperiodic dielectric multilayer stacks of sio@xmath209 and tio@xmath209 thin films and observed a strong suppression of the transmission  @xcite . for qpm gratings , a nonlinear quasiperiodic superlattice of litao@xmath193 , in which two antiparallel ferro - electric domains are arranged in a fibonacci sequence ,\nwas recently fabricated by zhu _\net al . _\n@xcite , who measured multi - colour shg with energy conversion efficiencies of @xmath210 .\nthis quasiperiodic optical superlattice in litao@xmath193 can also be used for efficient direct third harmonic generation @xcite .\nthe quasiperiodic qpm gratings have two building blocks a and b of the length @xmath211 and @xmath212 , respectively , which are ordered in a fibonacci sequence [ fig .\n[ fig : d_z](a ) ] .\neach block has a domain of length @xmath213=l ( @xmath214=l ) with @xmath215=@xmath216 ( shaded ) and a domain of length @xmath217=@xmath218 [ @xmath219=@xmath220 with @xmath215=@xmath221 ( white ) . in the case of @xmath66\nnonlinear qpm superlattices this corresponds to positive and negative ferro - electric domains , respectively .\nthe specific details of this type of fibonacci optical superlattices can be found elsewhere  @xcite . for our simulations presented below\nwe have chosen @xmath222= @xmath223= 0.34 , where @xmath224= @xmath225 is the so - called _\ngolden ratio_. this means that the ratio of length scales is also the golden ratio , @xmath226= @xmath224 .\nfurthermore , we have chosen @xmath227=0.1 .\nthe grating function @xmath208 , which varies between @xmath216 and @xmath221 according to the fibonacci sequence , can be expanded in a fourier series @xmath228 where @xmath229=@xmath230=0.52 for the chosen parameter values .\nhence the spectrum is composed of sums and differences of the basic wavenumbers @xmath231=@xmath232 and @xmath233=@xmath234 .\nthese components fill the whole fourier space densely , since @xmath231 and @xmath233 are incommensurate .\nfigure  [ fig : d_z](b ) shows the numerically calculated fourier spectrum @xmath235 .\nthe lowest - order `` fibonacci modes '' are clearly the most intense .      to analyze the beam propagation and shg in a quasiperiodic qpm grating one\ncould simply average eqs .\n( [ dynam ] ) .\nto lowest order this approach always yields a system of equations with constant mean - value coefficients , which does not allow to describe oscillations of the beam amplitude and phase .\nhowever , here we wish to go beyond the averaged equations and consider the rapid large - amplitude variations of the envelope functions .\nthis can be done analytically for periodic qpm gratings  @xcite . however , for the quasiperiodic gratings we have to resolve to numerical simulations .\nthus we have solved eqs .\n( [ dynam ] ) numerically with a second - order split - step routine . at the input of the crystal\nwe excite the fundamental beam ( corresponding to unseeded shg ) with a gaussian profile , @xmath236 we consider the quasiperiodic qpm grating with matching to the peak at @xmath237 , i.e. , @xmath238=@xmath237=82.25 .\nfirst , we study the small - amplitude limit when a weak fh is injected with a low amplitude .\nfigures  [ fig : soliton](a , b ) show an example of the evolution of fh and sh in this effectively linear regime . as is clearly seem from fig .\n[ fig : soliton](b ) the sh wave is excited , but both beams eventually diffract .\nwhen the amplitude of the input beam exceeds a certain threshold , self - focusing and localization should be observed for both harmonics .\nfigures  [ fig : soliton](c , d ) show an example of the evolution of a strong input fh beam , and its corresponding sh . again\nthe sh is generated , but now the nonlinearity is so strong that it leads to self - focusing and mutual self - trapping of the two fields , resulting in a spatially localized two - component soliton , despite the continuous scattering of the quasiperiodic qpm grating .\nit is important to notice that the two - component localized beam created due to the self - trapping effect is quasiperiodic by itself . as a matter of fact , after an initial transient its amplitude oscillates in phase with the quasiperiodic qpm modulation @xmath208 .\nthis is illustrated in fig .\n[ fig : oscillations ] , where we show in more detail the peak intensities in the asymptotic regime of the evolution . the oscillations shown in fig .  [\nfig : oscillations ] are in phase with the oscillations of the qpm grating @xmath208 , and we indeed found that their spectra are similar .\nour numerical results show that the quasiperiodic envelope solitons can be generated for a broad range of the phase - mismatch @xmath238 .\nthe amplitude and width of the solitons depend on the effective mismatch , which is the separation between @xmath238 and the nearest strong peak @xmath235 in the fibonacci qpm grating spectrum [ see fig .  [\nfig : d_z](b ) ] .\nthus , low - amplitude broad solitons are excited for @xmath238-values in between peaks , whereas high - amplitude narrow solitons are excited when @xmath238 is close to a strong peak , as shown in fig .\n[ fig : soliton](c , d ) .\nto analyse in more detail the transition between the linear ( diffraction ) and nonlinear ( self - trapping ) regimes , we have made a series of careful numerical simulations  @xcite . in fig .\n[ fig : transmission ] we show the transmission coefficients and the beam widths at the output of the crystal versus the intensity of the fh input beam , for a variety of @xmath238-values .\nthese dependencies clearly illustrate the universality of the generation of localised modes for varying strength of nonlinearity , i.e. a quasiperiodic soliton is generated only for sufficiently high amplitudes .\nthis is of course a general phenomenon also observed in many nonlinear isotropic media .\nhowever , here the self - trapping occurs for quasiperiodic waves , with the quasiperiodicity being preserved in the variation of the amplitude of both components of the soliton .\nwe have overviewed several important physical examples of the multi - component solitary waves which appear due to multi - mode and/or multi - frequency coupling in nonlinear optical fibers and waveguides .\nwe have described several types of such multi - component solitary waves , including : ( i )  multi - wavelength solitary waves in multi - channel bit - parallel - wavelength fiber transmission systems , ( ii )  multi - colour parametric spatial solitary waves due to multistep cascading in quadratic materials , and ( iii )  quasiperiodic envelope solitons in fibonacci optical superlattices .\nthese examples reveal some general features and properties of multi - component solitary waves in nonintegrable nonlinear models , also serving as a stepping stone for approaching other problems of the multi - mode soliton coupling and interaction .\nthe work was supported by the australian photonics cooperative research centre and by a collaborative australia - denmark grant of the department of industry , science , and tourism ( australia ) .          for an overview of quadratic spatial solitons ,\nsee l.  torner , in : _\nbeam shaping and control with nonlinear optics _ , f. kajzer and r. reinisch , eds .\n( plenum , new york , 1998 ) , p. 229 ; yu .  s.  kivshar , in : _ advanced photonics with second - order optically nonlinear processes _ , a.  d. boardman , l. pavlov , and s. tanev , eds .\n( kluwer , dordretch , 1998 ) , p. 451"}
{"lay_summary": " strong subadditivity inequality for a three - particle composite system is an important inequality in quantum information theory which can be studied via a four - particle entangled state . \n we use two three - level atoms in @xmath0 configuration interacting with a two - mode cavity and the raman adiabatic passage technique for the production of the four - particle entangled state . using this four - particle entanglement \n , we study for the first time various aspects of the strong subadditivity inequality . ", "article": "entanglement @xcite in a composite system refers to certain implicit correlation between the subsystems arising from their interaction .\nit is the key resource of quantum computation and quantum information processing @xcite .\ndue to recent advances in this field , entanglement has generated renewed interest .\nthere have been different approaches to understand and to quantify entanglement @xcite .\nbut so far the entanglement , only in a bipartite pure state has been investigated very extensively .\nthe von neumann entropy @xcite of either of the subsystems provides a good measure of entanglement in this case @xcite .\nthis is the quantum partner of the shannon s entropy @xcite in classical information theory and is defined as @xcite @xmath1 where @xmath2 . here , @xmath3 is the reduced density operator of the subsystem @xmath4 and is given by @xmath5 where @xmath6 is the density operator of the composite system under consideration and @xmath7 , @xmath8 .\nin general , the quantities @xmath9 satisfy the following inequality ( due to araki and lieb ) @xcite : @xmath10 where @xmath11 is the joint entropy of the composite system comprising @xmath12 and @xmath13 .\nthe second part of the above inequality is known as subadditivity inequality @xcite . for a pure state , @xmath14 and thus @xmath15 .\nthe equality sign in the above relation holds good if and only if the composite density matrix @xmath6 can be written as a tensor product of its two reduced density matrices @xmath16 and @xmath17 , i.e. , for a disentangled state .\none can define the index of correlation @xmath18 given by the expression @xmath19 @xcite , which can also be interpreted as information entropy in quantum information point of view .\nwe note that kim _\net al . _ have calculated the entropies of different kinds of pure states including two - mode fock states and squeezed states @xcite .\nfurther , the above relation for entropy has been studied in the context of entangled gaussian states @xcite .\nso far we have discussed about the measurement of entanglement in a bipartite pure state .\nif the composite system is in a mixed state ( defined by the density operator @xmath20 ) , the entanglement of formation @xmath21 can be defined in terms of the average von neumann entropies of the pure states of the decompositions @xcite .\nwootters has shown the quantity @xmath21 to be an explicit function of @xmath20 @xcite .\nhe has introduced the notion of concurrence in this context .\nwe further notice that from the schmidt decomposition of a pure bipartite state , one can properly identify the entanglement present in the state @xcite .\nthis is also very useful to study bipartite continuous systems @xcite . on the other hand , for a mixed state @xmath20 , the separability criterion has been proposed @xcite to study entanglement .\nthis is based on positive partial transpose mapping of @xmath20 .\nthus the negativity ( entanglement monotone ) of the eigenvalues of the partial transpose of @xmath20 could be a measure of entanglement in a mixed bipartite system @xcite .\nthe concept of negativity as an entanglement measure has been used in context of interaction of atoms with thermal field @xcite .\nthe separability criterion has been extended to continuous systems @xcite also .    despite many approaches to define entanglement for a bipartite system ,\nthere have been only a few approaches to quantify entanglement in the composite systems of three or more particles @xcite .\nwe note that a generalization of schmidt decomposition in multipartite systems in pure states has been introduced @xcite .\n@xcite proposed a measurement of entanglement in a tripartite system in terms of concurrences of the pairs of subsystems .\nthis measure is invariant under permutations of the subsystems .\nan average entanglement in a four - partite entangled state has been defined in terms of von neumann entropies of the pairs of subsystems @xcite .\nvery recently , yukalov has addressed the question more generally and quantified multipartite entanglement @xcite in terms of the ratio of norms of an entangling operator and of a disentangling operator in the relevant disentangled hilbert space .    in this paper\n, we put forward a possible measurement of entanglement of a four - particle system by studying the entropy of the reduced three - particle system .\nas mentioned above , the von neumann entropy is a good measure for entanglement in a bipartite system . for a tripartite composite state ,\nthis entropy satisfies a strong subadditivity inequality ( ssi ) @xcite , which has many important implications in the subject of quantum information theory . in this paper\n, we study the properties of a four - particle entangled state through the three - particle entropy and the ssi .\nthe structure of the paper is as follows . in sec .\nii , we provide a brief discussion on strong subadditivity inequality from the quantum information point of view . in sec .\niii , we describe a physical model and show the preparation of a four - particle entangled state . in sec .\niv , we study the validity of the ssi in the present context and provide a physical explanation of the results .\nwe conclude this paper by proposing a measurement of the corresponding four - particle entanglement .\nwe have already mentioned that for a bipartite composite system of two particles @xmath12 and @xmath13 , the joint entropy @xmath11 satisfies the subadditivity inequality ( [ ineq ] ) . for a composite system of three particles a , b , and c , this inequality can be extended to the following form @xcite : @xmath22 this inequality is known as strong subadditivity inequality . the most obvious situation that the equality sign holds in ( [ lieb ] ) is when\nthe composite density matrix @xmath23 can be written as the tensor product of its three reduced density matrices as @xmath24 , i.e. , when the system is in a disentangled state .\nhowever , the more stringent condition for this reads as @xcite @xmath25    there have been numerous implications of the above inequality ( [ lieb ] ) in quantum information theory @xcite .\nfirstly , it refers to the fact that the conditioning on the subsystem always reduces the entropy , i.e. , @xmath26 , where , @xmath27 is the entropy of a conditional on knowing the state of b. secondly , the above inequality implies that discarding a quantum system never increases mutual information , i.e. , @xmath28 , where , @xmath29 is the mutual information of the subsystems a and b. thirdly , quantum operations never increase mutual information of two subsystems .\nthis means that if the mutual information of the two subsystems a and b becomes @xmath30 after trace - preserving operation on b , then @xmath31 .\nfurther , this inequality ( [ lieb ] ) implies that the conditional entropy of the subsystems a , b , and c is also subadditive , i.e. , @xmath32 .    to verify ssi\n, one needs to calculate the entropies like @xmath33 which clearly requires a three - particle mixed state which we can produce using a pure four - particle entangled state @xcite . in the next section ,\nwe discuss how one can prepare a pure four - particle entangled state so that we can study ssi for the first time for a system realizable using cavity qed methods .\nwe consider two three - level atoms ( a and b ) with relevant energy levels in @xmath0-configuration ( see fig .  [ fig1 ] ) interacting with a two - mode high quality optical cavity .\nthe specified annihilation operators for the cavity modes are @xmath34 and @xmath35 .\nthe atoms are interacting with the cavity mode @xmath34 in @xmath36 transition and with the mode @xmath35 in @xmath37 transition .\nthe hamiltonian for the system under rotating wave approximation can be written as    @xmath38\\;,\\ ] ]    where , @xmath39 is the atomic transition frequency between the levels @xmath40 and @xmath41 , @xmath42 @xmath43 is the respective frequency of the cavity modes @xmath34 and @xmath35 , @xmath44 @xmath43 provides the atom - cavity coupling .\nwe assume @xmath44 s to be real and function of time .\nwe start with the initial state @xmath45 , where @xmath46 and @xmath47 are the initial numbers of photons in the cavity modes @xmath34 and @xmath35 , respectively and the two atoms are in @xmath48 state .\nthe state of the system can be expanded in terms of the relevant basis states in the following way : @xmath49 from the schrdinger equation we find the following equations of the corresponding probability amplitudes : @xmath50\\;,\\\\ \\dot{d}_6&=&-i(\\sqrt{\\mu + 2}g_{2a}d_4+\\sqrt{\\mu + 2}g_{2b}d_7)\\;,\\nonumber\\\\ \\dot{d}_7&=&-i(\\sqrt{\\mu + 1}g_{2a}d_5+\\sqrt{\\mu + 2}g_{2b}d_6+\\delta d_7+\\sqrt{n-1}g_{1b}d _ 8)\\;,\\nonumber\\\\ \\dot{d}_8&=&-i(\\sqrt{n-1}g_{1b}d_7+\\sqrt{\\mu + 1}g_{2a}d_9)\\;,\\nonumber\\\\ \\dot{d}_9&=&-i(\\sqrt{n}g_{1a}d_1+\\sqrt{n-1}g_{1b}d_5+\\sqrt{\\mu + 1}g_{2a}d_8+\\delta d_9)\\;,\\nonumber\\end{aligned}\\ ] ] where , we have used the following transformations : @xmath51 where , @xmath52 , @xmath53 is the one - photon detuning of the cavity modes for the @xmath54-th atom .\nhere we have assumed that the cavity modes are in two - photon resonance and @xmath55 .    writing these equations ( [ doteq ] ) in the matrix form @xmath56=-i[m][d_i]$ ] , we find that one of the eigenvalues of the matrix @xmath57 $ ] is zero .\nthe corresponding eigenstate is @xmath58\\ ; , \\label{dark}\\ ] ]    where @xmath59 clearly , this state is an entangled state of four particles , namely , the atoms a and b , and the two modes @xmath34 and @xmath35 . using appropriate time - dependence of the pulses ,\nthe four - particle system can be prepared in this state , as discussed in the next section .\nrecently , there have a few experimental demonstrations of preparation of four - particle entangled state @xcite and performance of a c - not gate @xcite .\ninterestingly , the state @xmath60 is a two - atom two - mode multipartite coherent population trapping ( cpt ) state which is a counterpart of the well - known cpt state for a single atom interacting with two coherent fields @xcite .\nwe next discuss how the state @xmath60 can be prepared by using raman adiabatic passage technique .\nwe assume that both the atoms are initially in @xmath48 state .\nwe further assume the time - dependence of the rabi frequencies @xmath44 of the two modes as @xmath61 here , @xmath62 ( @xmath63 ) is the amplitude of the respective pulse , @xmath64 and @xmath65 are the width and time - separation respectively , of the two pulses .\nnote that the pulses are applied in counterintuitive sequence . under this condition\n, the atom - cavity system follows the evolution of the state @xmath60 adiabatically .\nthis state is a zero eigenvalue eigenstate ( adiabatic state ) of the hamiltonian ( [ hamil1 ] ) . during this process , known as stimulated raman adiabatic technique ( stirap ) @xcite ,\nthe atom - cavity system remains in this state for all times . in the present case , at the end of the evolution ,\nthe population of both the atoms are simultaneously transferred to the state @xmath66 . however , if the atoms are not in one - photon resonance , i.e. , if @xmath67\n, then this transfer process is not complete .\nthis happens because the system does not remain confined in the null adiabatic state @xmath60 for @xmath67 @xcite .\nwe now investigate the validity of ssi for any trio of quantum systems in the present process .\nwe can express this inequality for any three particles , namely , atom a , atom b , and cavity mode @xmath34 with number @xmath46 of photons out of the four - particle system under consideration as @xmath68 here , @xmath69 defines the joint von neumann entropy of the relevant subsystems [ see eq .\n( [ entropy ] ) ] . this can be calculated from the state ( [ wavefunc ] ) by tracing over the other subsystems , e.g. , @xmath70 where , @xmath6 is the reduced density matrix of the atoms a and b and is given by @xmath71 we show the time variation of @xmath72 in fig .\nclearly , @xmath73 never becomes negative during the evolution and thus the ssi ( [ ssi ] ) holds for all times .    from fig .\n[ fig2 ] , one clearly sees that for @xmath74 , in long time limit , @xmath72 becomes zero .\nthis means that the subsystems ( a , b , and the mode @xmath34 with photon number @xmath46 ) become disentangled .\nthis happens because of complete adiabatic transfer of population to the level @xmath66 of both the atoms at long time limit .\nthe entire process can be written as @xmath75 we have shown the time - variation of the coefficients @xmath76 , @xmath77 , @xmath78 , and @xmath79 [ see eq .  ( [ norm ] ) ] in fig .  [ fig3 ] .\nthis figure reveals the above evolution according to the state @xmath60 under the action of the pulses ( [ pulse ] ) .\nbut for @xmath80 , since complete population transfer does not occur , the system remains entangled in the state @xmath81 at long time limit .\nthis is clear from the dashed curve of fig .\n[ fig2 ] , as the equality @xmath82 no longer holds at this time limit .\nthus we can recognize the expression @xmath72 [ see eq .\n( [ ssi ] ) ] as a measure of four - particle entanglement in the present process .\nprecisely , @xmath83 , where the equality sign holds good for the disentangled states .\nan increase in value of @xmath72 refers to increase in entanglement .\nthus , during the evolution , the system gets more entangled for @xmath74 than for @xmath80 .\nhowever , at the end of the evolution , the entanglement persists for nonzero @xmath84 .\nwe must emphasize here that , the present definition of entanglement measurement satisfies all the relevant criteria , namely , ( a ) it is semipositive , i.e. , @xmath83 , ( b ) @xmath82 for an disentangled state , and ( c ) the function @xmath73 is continuous in time domain .\nusing our four - particle entanglement , we can also study the inequality ( [ ineq ] ) involving the entropies of two particles , say , atoms a and b. they remain strongly correlated during the evolution , as @xmath18 remains much larger than zero . at the end of the evolution , @xmath18 becomes zero for @xmath85 which means that the subsystems become uncorrelated .\nin other words , the entanglement between them vanishes .\nwe note in passing that for a four - particle ghz state defined by @xmath86 of four qubits a , b , c , and d , one is led to a three - particle mixed state @xmath23 defined by @xmath87 in this case , @xmath88 .\ntherefore , the parameter @xmath72 in this case becomes zero , as from eq .\n( [ ssi ] ) .\nso we have a counter - example , in which the equality sign in ( [ lieb ] ) holds for an entangled state , too .\nhowever , we note that the above state ( [ mix ] ) satisfies the condition ( [ must ] ) and thus the said equality .\nin conclusion , we have shown for the first time the role of strong subadditivity inequality for entropies in a four - particle composite system .\nthe stimulated raman adiabatic technique has been used to prepare the four - particle entangled state using two three - level atoms initially in their ground states in a two - mode cavity .\nwe further show that the parameter @xmath72 could serve as a possible measurement of entanglement in the four - particle entangled state under consideration .              c. h. bennett , g. brassard , s. popescu , b. schumacher , j. a. smolin , and w. k. wootters , phys .\nlett . * 76 * , 722 ( 1996 ) ; c. h. bennett , d. p. divincenzo , j. smolin , and w. k. wootters , phys . rev .\na * 54 * , 3824 ( 1996 ) .\na. peres , phys .\nlett . * 77 * , 1413 ( 1996 ) ; m. horodecki , p. horodecki , and r. horodecki , phys .\na * 223 * , 1 ( 1996 ) ; p. horodecki , _ ibid . _ * 232 * , 333 ( 1997 ) ; v. giovannetti , s. mancini , d. vitali , and p. tombesi , phys . rev .\na * 67 * , 022320 - 1 ( 2003 ) .                          c. a. sackett , d. kielpinski , b. e. king , c. langer , v. meyer , c. j. myatt , m. rowe , q. a. turchette , w. m. itano , d. j. wineland , and c. monroe , nature ( london ) * 404 * , 256 ( 2000 ) ; m. eibl , s. gaertner , m. bourennane , c. kurtsiefer , m. ukowski , and h. weinfurter , phys .\nlett . * 90 * , 200403 ( 2003 ) ."}
{"lay_summary": " evolutionary tracks and pulsational analysis of models with masses of 13 - 18 @xmath0 are presented . \n we address two important questions . the first one deals with one of the most unresolved problems in astrophysics , i.e. , the existence of a blue loop after core helium ignition ; the so called `` to loop or not to loop '' problem . \n we show that inward overshooting from the outer convective zone in the red giant phase is prerequisite for the development of the blue loop . \n our second question concerns pulsational instability of models in the core helium burning phase . \n we present for the first time that models on the blue loop can have unstable modes driven by the @xmath1 mechanism operating in the @xmath2bump . \n contrary to post - main sequence models in the shell hydrogen burning phases , pulsational instability of the blue loop models depends mainly on effective temperature and metallicity is of secondary importance . \n finally , we try to interpret the oscillation spectrum of the blue supergiant hd 163899 , the only member of the spbsg class , and to get some clue on the evolutionary status of the star .    \n [ firstpage ]    stars : early - type  stars : supergiants  stars : oscillations ", "article": "slowly pulsating b - type supergiants ( spbsg ) have emerged as a new class of pulsating variables after saio et al .\n( 2006 ) have detected pulsational frequencies in the most satellite data of the blue supergiant hd 163899 ( b2 ib / ii , klare & neckel 1977 , schmidt & carruthers 1996 ) .\nsaio et al .\n( 2006 ) identified 48 frequency peaks in the most light curve and attributed them to g- and p - mode pulsations . because so far only one object of this type is found , the spbsg class is not yet well defined as for the range of effective temperature and luminosity .\nalso the evolutionary status of these pulsators remains unrevealed ; they may be either in the shell hydrogen burning phase as well as after core helium ignition .\nthe finding of saio et al .\n( 2006 ) has prompted a few groups ( godart et al .\n2009 , daszyska - daszkiewicz , ostrowski , pamyatnykh . 2013 ; hereafter d2013 ) to reanalyse pulsation stability in models of b - type stars after the terminal age main sequence ( tams ) and to further studies of spbsg variables .\nthe presence of g - mode pulsations in b - type post - main sequence stars has been explained by a partial reflection of some modes at an intermediate convective zone ( icz ) related to the hydrogen - burning shell or at a chemical gradient zone surrounding the radiative core .\nhowever , all studies of these objects published so far are based on the assumption that hd 163899 has not reached the phase of core helium ignition , i.e. , it is in the phase of shell hydrogen burning .\nthis assumption might not necessary be fulfilled , because the blue loop can reach temperatures of early b spectral types . in this paper\nwe calculate models which undergo core helium burning on the blue loop and compare them with models in the hydrogen shell burning phase .\nthe structure of the paper is as follows . in section\n[ domains ] , we present the new instability domains which include pulsational instability on the blue loops .\nthe effects of opacity , metallicity , overshooting , element diffusion and mass loss on the pulsational instability areas are studied .\npropagation diagrams and properties of instability parameter and kinetic energy of modes for representative models are described in section [ models ] . in section [ identification ]\nwe construct photometric diagnostic diagrams for the b - type supergiant models and discuss a prospect for mode identification . an attempt to interpret the oscillation spectrum of hd 163899\nis presented in section [ hd163899 ] .\nthe last section contains conclusions .\nthe evolutionary models were calculated with mesa evolution code ( modules for experiments in stellar astrophysics , paxton et al .\n2011 , paxton et al . 2013 ) .\nmesa allows to follow the evolution of massive stars to the pre - supernova phase . our previous calculations ( d2013 )\nwere limited to the phase before core helium ignition due to the lack of helium burning in warsaw - new jersey evolution code we used .\nwe considered the mass range of 13@xmath318 @xmath0 .\nall computed models have an initial hydrogen abundance of @xmath4 and agss09 metal mixture ( asplund et al .\nthe initial metal abundance varies from @xmath5 to @xmath6 .\nopal ( iglesias & rogers 1996 ) and op opacity tables ( seaton 2005 ) were used .\nall effects of rotation were neglected .\nnon - adiabatic pulsation analysis was performed using the code of dziembowski ( 1977 ) . in fig.[fig1 ] we present evolutionary tracks including various effects : opacity , metallicity , overshooting , mass loss and element diffusion .\nthey will be discussed in detail in the following subsections .\nthe convective zones are determined by the ledoux criterion .\nit seems to be more justified than the schwarzschild criterion because of a direct sensitivity of the chemical gradient to evolution .\nlebreton et al .\n( 2009 ) argued that the use of the ledoux criterion leads to a narrower icz and hence to the smaller number of unstable modes . in case of our models\n, mesa produces the wide icz with both criterions and this effect is not significant . for the envelope , we adopted the parameter of the mixing length theory ( mlt ) of @xmath7 which is the higher value than usually used for massive stars . during the main sequence ( ms ) and\nhydrogen - shell burning phases , the value of @xmath8 has a negligible effect on structure of massive stars but on the red giant branch ( rgb ) a higher efficiency of convection is needed and hence we opted for the higher value of @xmath8 .\nwe took into account convective overshooting from the hydrogen and helium core and inward overshooting from non - burning convective zones , using the exponential formula ( herwig 2000 ) : @xmath9 where @xmath10 is the diffusion coefficient derived from mlt at a user - defined location near the boundary of a convective zone , @xmath11 is the pressure scale height at that location , @xmath12 is the distance in the radiative layer away from that location , and @xmath13 is an adjustable parameter , which we set to @xmath14 for most of calculated models .\nthis value of @xmath13 mimics the behaviour of step overshooting with @xmath15 .    in our models\nthe core helium ignition commences on the way towards the rgb but at this stage the energy produced from the helium burning is much lower than the energy produced from the hydrogen shell burning .\nthe shell dominates the evolution up to the tip of rgb . at this point\nthe energy produced in a helium core becomes comparable to the energy from the shell and the luminosity of a star drops .\na star might eventually move towards higher effective temperatures and form a blue loop .\nthe behaviour of the blue loops is still very poorly known and it is difficult to predict the effect of different parameters on their properties .\nwe found that the convective overshooting has the most visible effect on their emergence , especially the inward overshooting from the non - burning zone . without that overshooting it is impossible to obtain blue loops in our models independently of metallicity , opacity , diffusion , etc .\nthis effect is shown in fig.[fig2 ] , where we depicted two evolutionary tracks for the mass of 15 @xmath0 calculated with and without inward overshooting from the non - burning zone .\nthe blue loop emerges if the @xmath16-gradient left by the evolution during ms is erased by the outer convective zone on the rgb .\nthe range of this convective zone is increased by the inward overshooting . on the other hand\n, the overshooting from the hydrogen core generally acts against emerging of the blue loops .\nwe show the effect of different values of the overshooting parameter on the evolutionary tracks in the central - left panel ( @xmath17 ) and in the bottom - left panel ( @xmath18 ) of fig.[fig1 ] . in both cases\nthe blue loops are present but for the lower value of @xmath13 they have a larger extension .\nif we increase the overshooting only from the hydrogen core to @xmath18 and we leave @xmath17 for the helium core overshooting and the inward overshooting from non - burning zone , the blue loops still emerge but their extension is lower .\nthis is caused mainly by the reduced overshooting from the helium core which decreases the amount of helium available to burn and hence leads to smaller extension of the blue loop .     with ( solid line ) and without ( dashed line )\ninward overshooting from the non - burning convective zone .\nopal opacity tables and metallicity @xmath19 were used.,width=325 ]    the presented examples show that properties of mixing , especially the convective overshooting , have a huge impact on the behaviour of the blue loops .\nit is difficult to discriminate between different effects but generally it seems that the inward overshooting from the outer convective zone on the rgb is indispensable to obtain blue loops for the models in the studied range of masses .\nthe overshooting from the hydrogen core suspends the emerging of the blue loops and the overshooting from the helium core has a slight effect on their extension .      for the models considered in section2.1\n, we computed pulsational instability for modes with the degrees @xmath20 .\nthey are shown as thick lines in in fig.[fig1 ] .\nthe top panels show models calculated with @xmath21 and opal ( the top - left panel ) and op opacity tables ( the top - right panel ) .\nthe central panels depicts models calculated for @xmath22 and opal tables without and with mass loss ( the central - left and central - right panels , respectively ) .\nthe bottom - left panel shows the models calculated with @xmath22 , opal tables and convective overshooting parameter @xmath18 .\nthe bottom - right panel depicts models calculated with element diffusion .\ndetails of the used mass - loss models and implementation of diffusion are described later in this section . similarly to our previous results ( d2013 ) there is the p- and g - mode instability beyond tams for the models that undergo hydrogen shell burning .\nmost of the unstable modes are non - radial , but the radial fundamental mode is also unstable in hotter models beyond main sequence .\nthe main difference between our current and all previous calculations is the presence of unstable non - radial modes on the blue loops for more massive models ( @xmath23 and @xmath24 ) .\nthe radial modes are stable in this evolutionary stage in all calculated models .\nthe existence of pulsation instability on the blue loop , as well as the blue loops themselves , depend critically on the metallicity , @xmath25 . with lowering the metallicity\nthe blue loops reach the higher effective temperatures which has a huge impact on pulsation instability . in models with the lower value of @xmath26\nthe driving layer related to the metal opacity bump is located too deep in the star to be effective . on the other hand , the lower value of metallicity the lower the @xmath25 opacity bump .\nthis crucially weakens instability for the ms and h - shell burning models but it seems to have a negligible effect on the instability on the blue loops , especially when compared to the effect of the effective temperature . in models with @xmath27 the instability in the phase before core helium ignition is entirely quenched whereas there are still a lot of unstable modes in the models with very well developed blue loop .\nthe pulsational instability on the blue loops vanishes at @xmath28 .\nthe reason for that is a difference in the internal structure resulting from a presence of an inward overshooting from the nonburning zone in the blue - loop models .\nthe main effect of this overshooting is visible during the evolution on the rgb , but there is also a thin zone of overshooting below the icz .\nthat leads to enrichment of hydrogen in layers just below the icz , which causes a steep increase of the @xmath16-gradient in a thin zone . as a consequence the brunt - visl frequency , @xmath29 , increases as well , what makes trapping of pulsation modes more effective and some of them can be driven by the @xmath1-mechanism operating in the z - bump despite low metallicity .\nthe opposite situation occurs for models with higher metallicities .\nfor example with @xmath6 there is a large instability area beyond ms but there are no unstable modes in the blue loop models , because of too low temperature the blue loops reach .\nthe exceptions are the highest considered masses - @xmath30 for opal opacities and @xmath31 for op opacity tables . for those masses\nthere are a few models on the hottest part of the blue loops that have unstable modes .    for every calculated mass and independently of metallicity or opacity tables we obtained unstable radial modes in the cooler models on the red giant branch or its vicinity .\nthis result is similar to the one from saio et al .\n( 2013 ) and it was expected because in this area of hr diagram a classical instability strip is located .\nthose models are high - mass classical cepheids , in which the pulsations are driven in a region of the second ionization of helium .\nit is important to note that there are two effects that make the pulsational code we use unsuitable for such stars : the linear approximation and the lack of convection - pulsation interaction .\nwe use the convective flux freezing approximation which is not adequate in large outer convective zones . we do not study properties of these stars to any further extent in this paper .\n( solid lines ) and and the lamb frequencies , @xmath32 , for @xmath33 ( dashed lines ) and @xmath34 ( dotted lines ) , as a function of @xmath35 , for model1 ( top panel ) and model2 ( bottom panel ) .\nthe scales of @xmath26 are different to represent the actual temperature profiles of the models.,title=\"fig:\",width=332 ]   ( solid lines ) and and the lamb frequencies , @xmath32 , for @xmath33 ( dashed lines ) and @xmath34 ( dotted lines ) , as a function of @xmath35 , for model1 ( top panel ) and model2 ( bottom panel ) .\nthe scales of @xmath26 are different to represent the actual temperature profiles of the models.,title=\"fig:\",width=332 ]    as depicted in fig.[fig1 ] , for @xmath21 and @xmath36 there is a large instability strip that covers models both before and after core helium ignition .\na comparison of the top- and central - left panels gives the effect of metallicity .\nfor @xmath21 ( top - left panel ) , the range of effective temperatures that covers unstable models on the blue loop is a little wider than for @xmath22 ( central - left panel ) .\nthis is a consequence of a larger extension of the loops towards the higher effective temperatures for lower metallicieties .\nas expected , an increase in @xmath25 results in wider instability area on ms and beyond tams .\nthe upper panels show an effect of opacity tables on instability domains for @xmath21 , but the main conclusions are the same for every tested metallicity .\nthere are significant differences on the ms phase , due to a long - known fact that for op tables instability starts earlier than for opal tables . during the hydrogen shell burning phase and on the blue loop\nthe differences are very subtle .\nthe loops and instability areas have slightly different shapes but generally they are similar for both sources of the opacity data .    in the central panels we compare instability domains for models with @xmath22 calculated without ( the central - left panel ) and with mass loss ( the central - right panel ) .\nfor @xmath37 we used the wind s scheme of vink et al .\n( 2001 ) whereas for @xmath38 a recipe of de jager et al .\n( 1988 ) was adopted .\nwe do not study very massive models and hence the amount of mass which is lost during the evolution is rather modest .\nfor instance , a star with initial mass of @xmath39 loses only about @xmath40 during the evolution from zams to the point when helium is depleted in its core .\nthe maximum value of the mass - loss rate is reached on the tip of the red giant branch and for the @xmath39 star it has the value of @xmath41 .\nmass loss seems to have a negligible effect on instability of models immediately beyond tams , whereas this effect on the instability on the blue loops is much more pronounced . with the reduced mass a star reaches lower luminosity during helium burning phase and\nalso a blue loop reaches lower effective temperature than for models calculated without mass loss .\nboth of these effects lead to smaller instability range during this phase of evolution . the description of wind which we used for lower effective temperatures ( de jager et al .\n( 1988 ) ) gives relatively low values of mass loss when compared to other models we checked ( nieuwenhuijzen & de jager 1990 , van loon et al .\n2005 , reimers 1975 ) .\nit means that the instability areas on the blue loops calculated with other mass - loss models would be even smaller or entirely vanished .\nalso with sufficiently high mass loss the blue loops do not emerge at all .\nwe will not discuss effects of mass loss anymore in this paper because they do not change any qualitative results presented here . despite this\nit has to be remembered that it is a common phenomenon and it should be enabled during construction of detailed asteroseismic models .\nthe bottom - left panel depicts the instability areas calculated for higher value of convective overshooting , @xmath18 .\nthe most important difference when compared to models with @xmath17 ( central - left panel ) is smaller extension of the blue loops and hence there are no unstable models present during this evolutionary phase .    in the bottom - right panel of fig.[fig1 ] we present models calculated with @xmath22 , opal opacity tables and element diffusion .\nmesa calculates element diffusion by solving burgler s equations using the method and diffusion coefficients of thoul et al .\nthe effect of diffusion on the shape of evolution tracks and instability areas is negligible , both for models before and after core helium ignition .\nthe small changes of abundances of chemical elements in the central regions of the star do not modify significantly a behaviour of pulsation modes .\nthe minor differences of frequencies might be important during a comparison to the observations but they do not influence the qualitative results presented here .\nhere , we compare pulsation properties of two representative models with similar positions in the h - r diagram but in two different evolutionary stages , one during the shell hydrogen burning phase ( @xmath39 , @xmath42 , @xmath43 , hereafter model1 ) and the second during core helium burning ( @xmath44 , @xmath45 , @xmath46 , hereafter model2 ) . they are calculated with opal opacity tables , agss09 metal mixture and @xmath19 .\npropagation of pulsational modes in the radial direction is confined to the regions determined by the two characteristic frequencies ( e.g. , unno et al .\n1989 ) , i.e. , the lamb ( acoustic ) frequency ( @xmath47 ) and brunt - visl ( buoyancy ) frequency ( @xmath48 ) .\nthe values of @xmath47 depend mostly on the mode degree , @xmath49 , whereas the brunt - visl frequency is very sensitive to the structure of a star ( e.g. , a presence of convective zones or chemical gradients ) .    in fig.[fig3 ]\n, we present propagation diagrams , i.e. , @xmath50 , @xmath51 , for models 1 and 2 ( the top and bottom panels , respectively ) . the main difference between these models is the presence of a convective core ( @xmath52 ) in the model on the blue loop , whereas the model that undergoes shell hydrogen burning has a radiative core . beyond the core ,\nthe propagation diagrams of these two models are qualitatively similar ; in particular , both have a fully developed intermediate convective zone .\nthe two spikes in the run of brunt - visl frequency that occur in the vicinity of convective zones in model2 have different origin .\nthe one at the border of the convective core is both a consequence of the very steep @xmath16-gradient in this region of star ( the main reason ) and also a numerical effect related to the extreme difficulties with precise determination of the border of helium core by evolution codes . due to a very high sensitivity of triple - alpha process to a change of temperature , the location of border changes slightly with every step of evolution .\nthat results in an artificial increase of the @xmath16-gradient , which is clearly visible in behaviour of @xmath29 .\nthe second spike , at the innermost border of icz is related to the presence of inward overshooting from this convective zone .\nthat leads to a steep change of @xmath16 and a peak in the propagation diagram .    in fig.[fig4 ] , we present the instability parameter , @xmath53 , for modes with the harmonic spherical degrees @xmath54 , as a function of frequency for models 1 and 2 ( the top and bottom panels respectively ) .\ninstability parameter measures the net energy gained by a mode during one pulsational cycle and is defined as ( stellingwerf 1978 ) :    @xmath55    where @xmath56 is the global work integral .\nthis definition gives normalization @xmath57 $ ] . if @xmath58 a pulsation mode is unstable and if @xmath59 it is stable .\nthere are two global maxima of @xmath53 in model1 , which is similar to the behaviour during the ms evolution ( d2013 ) . the first one , at low frequencies ,\nis related to the very high - order g - modes , while the second one , at higher frequencies , is related to the low - order p- and g - modes . all non - radial modes in the second group are mixed modes and they behave like p - modes only in the outer envelope of the star . in the frequency range presented in fig.[fig4 ] ,\ni.e. , from 0.04 to 3.5 d@xmath60 , the values of the radial order , @xmath61 , are in ranges of about @xmath62 for the @xmath33 modes and @xmath63 for the @xmath34 modes . in model1 the fundamental radial mode and the first overtone are unstable with the ratio of periods @xmath64 .\nthe most interesting behaviour of @xmath53 is visible in the vicinity of the first maximum .\nthere is a clearly visible pattern of consecutive local minima and maxima , which does not occur in ms models .\nthis phenomenon is related to the partial trapping of pulsation modes in the radiative core and the envelope .\nthe detailed description of this phenomenon can be found in our previous paper ( d2013 ) .    in model2 , which burns helium in its core\n, a situation is different .\nthere are only a few very high - order low - frequency g - modes which are unstable .\nthese maximum values of @xmath53 are shifted towards lower frequencies when compared to model1 .\nthere is no pattern of local minima and maxima and the calculated frequency spectrum is much sparser than for model1 .\nthis is typical for every blue - loop that a number of unstable modes is very low .\nmodel2 has one unstable dipole mode with frequencies of @xmath65 c / d and two unstable quadruple modes with frequencies @xmath66 c / d .\nradial modes are always stable in models during core helium burning phase , regardless of metallicity , opacity tables , etc .\nhowever , the ratio of periods between the first overtone and the fundamental mode is visibly lower than in model1 and has a value @xmath67 . in model2 ,\nthe radial orders of pulsation modes are much larger , in particular for the quadruple mode .\nfor the considered range of @xmath68 , cf .\nfig.[fig4 ] , the values of @xmath61 are : @xmath69 for @xmath33 and @xmath70 for @xmath34 .    in fig.[fig5 ]\n, we compare the kinetic energy densities , @xmath71 ( top panels ) , and differential work integrals , @xmath72 ( bottom panels ) , for unstable and stable modes of the degree @xmath34 with very close frequencies . the left group of panels is for model1 ( before core helium ignition ) and the left group of panels for model2 ( after core helium ignition ) .\nthe behaviour of presented modes is typical and representative for all unstable and stable modes during shell hydrogen burning and on the blue loops .\nthe properties of pulsational modes in the shell hydrogen burning model have been already presented in d2013 but for comparative purposes we repeat them here .    in model1 , both unstable ( @xmath73 c / d , @xmath74 ) and stable ( @xmath75 , @xmath76 ) modes exhibit a very strong damping in the radiative helium core , which is visible in the behaviour of @xmath72 in the bottom panels of the left group .\nas shown in the upper panels of this group , most of the kinetic energy of the modes is confined in the central region .\nthe most notable difference between the presented modes is that the unstable one has some energy deposited also in the radiative envelope , whereas the stable one has almost no energy in this region .\nthis is due to the fact that the unstable mode has been partially reflected at the icz and is trapped in two cavities : the core and the outer layers .\nthat energy , although its amount is small when compared to the amount trapped in the core , is sufficient for the @xmath1 mechanism , operating in the @xmath2bump , to efficiently drive the pulsations .\nthis is visible in the behaviour of differential work integral - there is a maximum around @xmath77 and it dominates over the damping in the core . on the contrary ,\nthe stable mode has not been reflected at icz because it does not have a node of eigenfunction there .\nthat means that it penetrates the core with high amplitude and is effectively damped there .\nthe above behaviour of @xmath71 explains the pattern of local maxima and minima of @xmath53 described earlier on .    for model2\nwe also compare two very close modes : the unstable one with @xmath78 c / d and @xmath79 and the stable one with @xmath80 c / d and @xmath81 . their kinetic energy densities and differential work integrals are shown in the right group of panels in fig.[fig5 ] .\nthe behavior of @xmath71 is different for these modes than for the modes from the model1 .\nthe entire energy of the stable mode is confined to the radiative zone in - between the convective core and the icz ( there is strong damping in this region of the star ) , whereas the unstable mode has almost all of its energy trapped in the outer radiative zone .\nthat means that the unstable modes of the blue loop models have to be almost entirely reflected at the icz .\nthis fact might be the explanation why we do have far fewer unstable modes from models burning helium in its core than from models before core helium ignition and also the lack of the structure of @xmath53 observed in model1 .\nthe behaviour of kinetic energy density depicted in fig.[fig5 ] is typical for all unstable and stable modes both during hydrogen shell burning and on the blue loops .\nin our previous paper ( d2013 ) , we have shown that one should not expect regular patterns in the oscillation spectra of blue supergiants which the asymptotic theory predicts for g - mode pulsations . however , it turned out that there is a prospect for identification of the degree , @xmath49 , for modes excited in the blue supergiant models before core helium ignition from photometric diagnostic diagrams ( d2013 ) . here\n, we will check whether the photometric amplitudes and phases of pulsations in models after core helium ignition have similar properties .\nthe expression for the complex amplitudes of the light variations in a given passband within the linear and zero - rotation approximation can be found , e.g. , in daszyska - daszkiewicz et al .\n( 2002 ) , and need not be repeated here . to compute the values of these observables\n, we used the nonadiabatic pulsational code of dziembowski ( 1977 ) and tables of the fluxes in photometric passbands and nonlinear limb - darkening coefficients computed by daszyska - daszkiewicz & szewczuk ( 2011 ) on the basis of the nlte atmosphere models of lanz & hubeny ( 2007 ) .    in fig.[fig6 ] , we show positions of unstable modes with the degree @xmath82 excited in the supergiant models in the photometric diagnostic diagrams employing the @xmath83 and @xmath84 johnson filters .\nthese passbands are similar to those used on the bright - star target explorer constellation ( brite ) which is already operating .\nwe used the opal data for the agss09 mixture and @xmath22 . in the left panel we marked positions of all unstable modes in models with masses @xmath85 whereas in the right panel we chose modes excited in models with @xmath86 and @xmath87 .\nthese temperature range is a typical maximum error and larger than the error for hd 163899 ( saio et al .\n2006 ) . with different symbols we discriminate between different values of @xmath49 and evolutionary stages .\ntheir meanings are described in the legend of the plots .    in the diagram for\nall studied masses , there is a perfect separation between radial and non - radial modes and fairly good separation between dipoles and quadruples .\na discrimination between models undergoing shell hydrogen burning and models on the blue loops is not obvious .\nmodes excited in models on these evolution stages tend to group in slightly different locations but in a plot including such a range of masses their distinction would be uncertain given observational errors in the photometric amplitudes and phases .\nthe situation improves slightly when we are able to constrain the mass and effective temperature . after fixing the range of @xmath26 in the right panel of fig.[fig6 ] ,\nthe separation between phases before and after core helium ignition can be noticeable .\nfig.[fig7 ] presents how the photometric observables depend on the mode frequency considering again the br johnson passbands and the same models as in the right panel of fig.[fig6 ] . from this plot\nwe can conclude that much better separation between modes of different values of @xmath49 , from both the amplitude ratios and phase differences , occurs for higher frequency modes which are unstable only in model1 .\nand @xmath88 , respectively .\nthe models have been calculated with @xmath21 and opal opacity tables .\nthe grey area depicts the error of @xmath26 for hd 163899 ( saio et al .\n2006).,width=332 ]    the greatest uncertainty concerning spbsg stars is their evolutionary status .\nalthough the basic parameters ( @xmath26 , @xmath89 , @xmath25 , @xmath90 , etc . ) of hd 163899 are very poorly determined or unknown , our calculations still can give some insights about the star . in fig.[fig8\n] , we present a comparison of evolution times in the pulsational unstable region of hr diagram during shell hydrogen burning phase and on the blue loop , for models with masses @xmath91 and @xmath92 , respectively , and @xmath21 .\nthe star spends only a very short time ( about 8 000 years ) in the instability strip during the shell - hydrogen burning phase compared to the time spent on the unstable region of the blue loop ( about 800 000 years ) .\nthere should be much more stars in the region of hr diagram occupied by blue supergiants that undergo core helium burning than stars that moves towards red giant branch ( rgb ) .\non the one hand , this is the main and only argument why spbsg stars should be on the blue loop . on the other hand , hd 163899\nis the only know star of this type and we might be very lucky to catch it during the very short phase of pulsational instability before core helium ignition\n. other arguments also prefer this evolutionary stage .\nthe instability area during a crossing towards rgb is wider in @xmath93 than on the blue loop .\nthis is especially important when we take into account the effect of mass loss which is ubiquitous effect for massive stars . in such a case\nthe instability area on the blue loops become very small .\nthe most important argument is a number of excited modes ; there is much more unstable modes in models during the shell - hydrogen burning phase than in models on the blue loop .\nthe last argument against the evolution on the blue loop is a complete lack of unstable high - frequency modes in this phase .\nsuch modes are present in the spectrum of hd 163899 and they are present in our models before core helium ignition .    in fig.[fig9 ] , we compare the oscillation spectrum of hd 163899 ( top panel ) and the theoretical one computed for a model in the shell - hydrogen burning phase ( @xmath53 vs. @xmath68 , bottom panel ) .\npulsational modes with the degree up to @xmath94 were considered .\nthis is one of models in which the larger number of pulsation modes are excited .\nthe observed spectrum consists of 48 frequencies between @xmath95 to @xmath96 c / d ( c.f .\ntable 1 in saio et al .\nthis range covers both g - modes ( high - order ) and p - modes in post - ms models .\nthere are also frequencies between those two groups which do not occur in pulsation calculations .\nwe do not know @xmath90 for the star and hence we do not include rotation in our calculations .\nthis is left for the future work .\nthe estimated critical velocity for model1 , which has the stellar radius @xmath97 , is @xmath98 km / s which corresponds to the critical rotation frequency of about @xmath99 c / d .\nit is very unlikely that a supergiant would rotate at such a high rate , but even with lower rotation rate the very low dominant frequency , @xmath100 c / d , could be explained by retrograde modes .\nthe rotational splitting could also solve the biggest problem of our pulsation models which is too low number of unstable g - modes .\nas for the observed range of frequencies which occur between the theoretical g- and p - mode maxima , it could be filled in with the high @xmath49 modes of various azimuthal orders , @xmath101 .\nour goal was to study pulsational properties of b - type supergiants with masses @xmath102 , especially to check the possibility whether spbsg stars can undergo core helium burning .\nin addition to previously known spbsg instability strip ( saio et al .\n2006 , d2013 ) which covers the stars that move towards rgb after departure from ms , we found the instability strip for the blue - loop models for the temperatures of b spectral types .\nits width depends on the extension and shape of the blue loops and hence it varies with many parameters , especially with metallicity , overshooting and mass loss .\none of the most important results of our paper is the fact that an inward overshooting from the outer convective zone on the rgb phase is indispensable for the emergence of blue loops at all .\nthe lower values of metallicity in the main sequence and shell hydrogen burning models acts towards decreasing pulsational instability whereas in the case of the blue loops models the most important factor is the effective temperature . for lower values of @xmath25\nthe blue loops have larger extension and the driving layer is located at the proper place for pulsation to be excited .\nwe found unstable modes in the blue loop models with metallicity as low as @xmath103 .\nthere is a difference in behaviour of instability parameter , @xmath53 , between models before and after core helium ignition . as we previously shown ( d2013 ) , in models during shell - hydrogen burning phase\nthere are two groups of unstable mods ; one related to the very high - order g - modes and the second related to the p - mode behaviour . on the contrary , in models on the blue loops\nonly the very high - order g - modes are unstable and the number of unstable modes is much lower than in models that departed from tams and move towards rgb .\nthat might be explained by the difference in the kinetic energy density distribution between those two evolutionary phases . in models that undergo shell hydrogen burning ,\nonly a partial reflection of pulsation mode at the icz is sufficient to efficiently drive the mode , whereas on the blue loop the mode has to be almost entirely reflected in order to be unstable .    comparing the properties of models before and after core helium ignition and frequencies detected in the light curve of hd 163899\n, we drew a conclusion that spbsg stars should rather undergo shell hydrogen burning and not core helium burning on the blue loop .\nhowever , to fully support this statement a better determination of basic parameters of hd 163899 is needed and , in the next step , seismic model of the stars should be constructed taking into account the effects of rotation .\nwe found also that mode identification from multicolour photometry is applicable to spbsg stars and hence multi - colour photometry for hd 163899 would be desirable .\nthe analysis of such data could finally lead to constraining the evolutionary status of the star and help to understand pulsations of spbsg stars .\nthis work was financially supported by the polish ncn grants 2013/09/n / st9/00611 , 2011/01/m / st9/05914 and 2011/01/b / st9/05448 .\n99 asplund , m. , grevesse , n. , sauval , a. j. , scott , p. : 2009\n, ara&a 47 , 481 daszyska - daszkiewicz j. , dziembowski w. a. , pamyatnykh a. a. , goupil m - j . , 2002 , a&a , 392 , 151 daszyska - daszkiewicz , j. , ostrowski , j. , pamyatnykh a.a . : 2013 , mnras 432 , 3153 ( d2013 ) daszyska - daszkiewicz j. , szewczuk w. , 2011 , apj , 728 , 17 dziembowski , w. : 1977 , aca 27 , 95 godart , m. , noels , a. , dupret , m .- a . ,\nlebreton , y. , 2009 , mnras 396 , 1833 herwig , f. : 2000 , a&a , 360 , 952 iglesias , c. a. , rogers , f. j. : 1996 , apj 464 , 943 de jager , c. , nieuwenhuijzen , h. , van der hucht , k. a. : 1988 , a&as 72 , 259 klare , g. , neckel , t. : 1977 , a&as 27 , 215 lanz t. , hubeny i. 2007 , apjs , 169 , 83 lebreton , y. , montalbn , j. , godart , m. , et al . : 2009 , coast 158 , 277 van loon , j. th . ,\ncioni , m .-\nl. , zijlstra , a. a. , loup , c. : 2005 , a&a 438 , 273 nieuwenhuijzen , h. , de jager , c. : 1990 , a&a 231 , 134 pamyatnykh , a. a. : 1999 , aca 49 , 119 pamyatnykh , a. a. , ziomek , w. : 2007 , coast 150 , 207 paxton , b. , bildsten , l. , dotter , a. , et al . :\n2011 , apjs 192 , 3 paxton , b. , cantiello , m. , arras , p. , et al .\n: 2013 , apjs 208 , 4 reimers , d. : 1975 , mem .\nliege 8 , 369 saio , h. , kuschnig , r. , gautschy , a. , et al .\n: 2006 , apj 650 , 1111 saio , h. , georgy , c. , meynet , g. : 2013 , mnras 433 , 1246 schmidt , e. g. , carruthers , g. r. : 1996 , apjs 104 , 101 seaton , m. j. : 2005 , mnras 362 , l1 stellingwerf r. f. : 1978 , aj 83 , 1184 thoul , a. a. , bahcall , j. n. , loeb , a. : 1994 , apj 421 , 828 unno , w. , osaki , y. , ando , h. , saio , h. , shibahashi , h. : 1989 , nonradial oscillations of stars , tokyo , university of tokyo press vink , j. s. , de koter , a. , lamers , h. j. g. l. m. : 2001 , a&a 369 , 574"}
{"lay_summary": " we consider one - dimensional mixtures of an atomic bose - einstein condensate ( bec ) and tonks - giradeau ( tg ) gas . the mixture is modeled by a coupled system of the gross - pitaevskii equation for the bec and the quintic nonlinear schrdinger equation for the tg component . \n an immiscibility condition for the binary system is derived in a general form . under this condition , \n three types of bec - tg interfaces are considered : domain walls ( dws ) separating the two components ; bubble - drops ( bds ) , in the form of a drop of one component immersed into the other ( bds may be considered as bound states of two dws ) ; and bound states of bright and dark solitons ( bdss ) . \n the same model applies to the copropagation of two optical waves in a colloidal medium . \n the results are obtained by means of systematic numerical analysis , in combination with analytical thomas - fermi approximations ( tfas ) . using both methods , families of dw states \n are produced in a generic form . \n bd complexes exist solely in the form of a tg drop embedded into the bec background . on the contrary , \n bdss exist as bound states of tg bright and bec dark components , and vice versa . ", "article": "binary systems , whose behavior crucially depends on the underlying condition of immiscibility or miscibility @xcite , play a fundamentally important role in many areas of physics . in the case of immiscibility , a major effect is the formation of domain walls ( dws ) between regions occupied by immiscible components . commonly known are dws in media featuring a vectorial order parameter , such as ferromagnets @xcite , ferroelectrics @xcite , and liquid crystals @xcite . in self - defocusing optical media ,\ndws separate regions occupied by electromagnetic waves with orthogonal circular polarizations of light haelt , me .\nsimilar interface patterns were predicted in arrays of nonlinear optical waveguides , modeled by discrete nonlinear schrdinger equations ( nlses ) @xcite .\ndws are known in superfluids too , where they are formed by immiscible binary bose - einstein condensates ( becs ) , as predicted theoretically @xcite and demonstrated in experiments @xcite . in the mean - field approximation @xcite ,\nsuch settings are modeled by systems of nonlinearly coupled gross - pitaevskii equations ( gpes ) with the cubic self - repulsive nonlinearity , which are similar to coupled nlses describing the above - mentioned optical dws @xcite . in their stationary form , these equations coincide with coupled cubic ginzburg - landau equations modeling dws in dissipative patterns , such as interfaces between rolls with different orientations in large - area rayleigh - benard convection @xcite .    the analysis of the dws in bec was extended for broader settings , including linear interconversion between the immiscible components  ( this is possible when they represent two different hyperfine states of the same atom coupled by a resonant radiofrequency wave ) @xcite , dipolar @xcite and spinor ( three - component ) condensates @xcite , as well as the bec discretized by trapping in a deep optical - lattice ( ol ) potentials mering .\nfurthermore , the study of the dws was recently extended for immiscible binary becs  with three - particle collisions @xcite , in the case when the related losses may be neglected , the respective coupled gpes featuring the cubic - quintic repulsive nonlinearity @xcite .    in the\neffectively one - dimensional ( 1d ) setting , ultracold bosonic gases with strong inter - atomic repulsion may be cast in the tonks - girardeau ( tg ) state , which emulates the gas of non - interacting fermions @xcite , provided that the energy of the repulsive interaction between bosons exceeds their kinetic energy , while the opposite situation corresponds to the becphase in the bosonic gas ( a review of the tg model was given in ref .\nthe tg gas of hard - core bosons has been realized experimentally , using tight transverse confinement @xcite .\nin particular , a longitudinal ol potential was used to increase the effective mass in the trapped state , thus making the kinetic energy small enough @xcite .\nit is commonly known that gpes furnish very accurate description of the bec in atomic gases . a similar macroscopic model of the tg gas\nis offered by the nlse with the quintic self - repulsion term @xcite . in a rigorous form , the relevance of the corresponding sextic term in the free - energy density of the three - dimensional bosonic gas in its ground state , which reduces to the quasi-1d tg phase , was demonstrated in ref .\n@xcite , under condition @xmath0 , where @xmath1 , @xmath2 , and @xmath3 are , respectively , the inter - atomic repulsion strength , system s length , and the total number o atoms .\nthe quintic model was used in various contexts , including shock waves @xcite , dark @xcite and gap - mode @xcite solitons , as well as bright solitons supported by dipole - dipole interactions @xcite , and , recently , dws in immiscible binary tg gases @xcite .\nfurther , oscillation frequencies derived from fermionic hydrodynamic equations , which apply to the hard - core tg gas , were found to be close to their counterparts predicted by the quintic nlse hydro .\ncoupled quintic nlses also arise in works aimed at constructing the ground state of a binary tg mixture in the harmonic - oscillator potential by means of the density - functional method @xcite . on the other hand , this approach may not apply to tg gases beyond the framework of static configurations and hydrodynamic regimes . in particular\n, it fails for strongly non - equilibrium problems , such as merger of distinct gas clouds @xcite .\nas concerns the mixtures , it may be interesting to consider binary systems including the tg gas and another quantum - gas component .\nin particular , exact solutions  were found for the ground state of tg - fermi mixtures minguzzi .\nthe binary gas of impenetrable bosons is solvable too ctg - ba .\nthe objective of the present work is to introduce basic nonlinear complexes , such as dws , bubble - drop ( bd ) modes ( bound pairs of two dws ) , and dark - bright solitons ( dbss ) , in an immiscible system of tg and bec gases . in the experiment , the system may be realized , in particular , as a bosonic gas composed of two atomic species under tight transverse confinement , with a longitudinal ol potential acing on ( being relatively close to a resonance with ) one species only .\nthen , as the experimental setting presented in ref .\n@xcite suggests , a large effective mass of the near - resonant component will bring it into the tg state , while the other component may stay in the bec phase .    as a model for this system , in section ii we adopt the cubic gpe for the self - repulsive bec component coupled by the cubic ( collisional ) repulsive term to the quintic nlse for the tg species .\nthe use of the latter equation is appropriate , as we study only static configurations of the system .\nthe same model may find a realization in optics as a model of colloidal waveguides .\nit has been recently demonstrated that , selecting the size of metallic nanoparticles in the colloid and their concentration , one can engineer desirable coefficients of the corresponding cubic and quintic nonlinearity @xcite . in particular , it is possible to design a waveguide which features a nearly pure quintic nonlinearity at a particular wavelength , while the cubic response dominates at a different wavelength .\nthe copropagation of optical signals carried by these wavelengths will then emulate the tg - bec system .\ndws separating the bec and tg phases are addressed in section iii .\nwe derive the respective immiscibility condition ( see eq . ( [ g < ] ) below ) , and then generate dw states in a systematic way , using both numerical solutions and the analytical thomas - fermi approximation ( tfa ) .\nthe latter method makes it possible to obtain some dws in an explicit analytical form , as given below by eqs .\n( [ exact ] ) - ( [ wtfa ] ) .\ndb and dbs complexes are considered in sections iv and v , respectively , again using a combination of analytical and numerical methods .\nthe analysis predicts that the db states exist solely in the form of the tg drop embedded into the bec background ( bubble ) , but not in the opposite case ; on the other hand , the dbs are predicted in either case of the bright tg soliton embedded into the bec dark soliton , or vice versa .\nthese predictions are fully corroborated by numerical results .\nthe paper is concluded by section vi .\nthe system of coupled nlses with the cubic and quintic nonlinear terms for the bec and tg components , @xmath4 and @xmath5 , with respective scaled masses @xmath6 and @xmath7(i.e .\n, @xmath8 is the relative effective mass of tg components which , as said above , may be made larger than the actual atomic mass @xcite ) is @xmath9where real parameters @xmath10 and @xmath11 are strengths of the self - repulsion of the bec component , and repulsion between the bec and tg ones , respectively , while @xmath12 and the coefficient of the effective quintic self - repulsion of the tg component are scaled to be @xmath13 ( in the notation of ref .\n@xcite , the natural value of the latter coefficient is @xmath14 ) .\nsubstitution @xmath15makes it possible to further fix @xmath16 and @xmath17 , thus simplifying eq .\n( [ first ] ) to a system with two free coefficients , @xmath8 and @xmath18:@xmath19    for the above - mentioned spatial - domain optical model ( with @xmath20 replaced by the propagation distance , @xmath21 , and transverse coordinate @xmath22 ) , the scaled propagation equations are derived , using the standard procedure @xcite , as@xmath23here @xmath24 and @xmath25 represent amplitudes of the copropagating electromagnetic waves with relative wavenumber and frequency @xmath26 and @xmath27 , cf .\n( [ mmm ] ) .\nfurther , @xmath28 in eq .\n( [ omega ] ) are the cubic and quintic spm coefficients for the two waves , while the cubic xpm coefficient is normalized to be @xmath13\n. additional rescaling,@xmath29transforms eq .\n( [ omega ] ) into the system of equations ( [ bec ] ) and ( [ tg ] ) , with @xmath30 .\nthe hamiltonian corresponding to eqs .\n( [ bec ] ) and ( [ tg ] ) is @xmath31 in addition to @xmath32 , the system preserves the norms ( scaled numbers of atoms in the ultracold gas , or total powers of the two waves , in terms of the optical model ) , @xmath33of the two components , and , for dynamical solutions , also the total momentum , @xmath34 , although , as mentioned above , the use of the quintic nls equation for the description of dynamics of the tg gas may be impugnable .\nstationary solutions to eqs .\n( [ bec ] ) and ( [ tg ] ) with positive chemical potentials @xmath35 are looked for as @xmath36with real functions @xmath37 satisfying equations @xmath38(in the optical model , @xmath39 represent the propagation constants of the two waves ) .\nequations ( [ phi1 ] ) and ( [ phi2 ] ) , if considered as equations of the evolution along @xmath40 , conserve the formal hamiltonian,@xmath41cf .\n( [ h ] ) .    normalizing the stationary wave functions as@xmath42one may fix @xmath43 , which implies that the density of the uniform tg component is also fixed to be @xmath13 , see eq .\n( [ bc ] ) below .\nnumerical results for dws are presented in the following section chiefly for this case , while in sections iv and v  other normalizations are used for bd and dbs states .\nsolutions of stationary equations ( [ phi1 ] ) and ( [ phi2 ] ) for the domain wall ( dw ) separating semi - infinite domains occupied by the bec and tg components ( or the spatial domains occupied by the copropagating waves in the above - mentioned optics model ) are specified by the following boundary conditions ( b.c . ) , which include the respective asymptotic densities , @xmath44 and @xmath45 : @xmath46the condition that formal hamiltonian ( [ h ] ) must take the same values at @xmath47 and @xmath48 across the solution imposes a restriction on b.c . (\n[ bc ] ) , which relates the two chemical potentials:@xmath49 in terms of the asymptotic densities , condition ( [ bc ] ) takes the form of@xmath50which actually implies the balance of the pressure applied to the dw from the two sides .\nnaturally , the mass ratio ( @xmath8 ) does not appear in eqs .\n( mumu ) and ( [ nn ] ) .\nnote that , if condition ( [ nn ] ) between the densities does not hold initially , the dw in a finite system , which corresponds to real experimental settings , will move to a position at which the condition holds for the accordingly modified densities .\nfurther , the _ immiscibility condition _ for the bec  and tg , which is necessary for the existence of the dw separating the two quantum gases , is that the demixed configuration must provide a _\nsmaller _ energy density ( defined as per eq .\n( [ h ] ) ) than a uniformly mixed state with densities which are equal to half of asymptotic densities ( [ bc]):@xmath51the uniform state corresponds to values of the chemical potentials different from @xmath52 and @xmath53 , namely , @xmath54 , @xmath55 .\nthen , the comparison of the average energy densities of the demixed and uniform states gives rise to the immiscibility condition in the following form : @xmath56further , the substitution of relation ( [ mumu ] ) in eq .\n( [ < ] ) transforms it into an inequality for the self - repulsion strength of the bec component , @xmath18 : @xmath57 in particular , for @xmath43 ( as said above , this value will be fixed by rescaling ) , eq .\n( [ g < ] ) yields @xmath58 .\nthe dw may be characterized by an effective width of its core , which may be naturally defined by the following integral expression : @xmath59the analysis should produce @xmath60 as a function of parameters @xmath8 and @xmath18 , once the tg asymptotic density is fixed by setting @xmath43 , see fig .\n[ fig : wvsm ] below .\nclose to the existence boundary of the dw , i.e. , at @xmath61 , the dw becomes very wide . in this limit\n, the dependence between the width and proximity to the threshold may be estimated as follows : the density of the gradient energy in eq .\n( [ h ] ) scales as @xmath62 , hence the full gradient energy scales as @xmath63 , and the respective effective force may be estimated as @xmath64 @xmath65 .\nit must be balanced by the effective bulk force vanishing at @xmath66 , which scales as @xmath67 .\nthus , the equilibrium condition predicts that the dw s width diverges at @xmath68 as@xmath69    accurate analytical results for the dw can be obtained in the limit case corresponding to @xmath70 , or to @xmath71 , when the derivative term in eq .\n( [ phi1 ] ) may be neglected ( which actually implies the use of the tfa book ) , yielding@xmath72strictly speaking , the assumption of @xmath71 may contradict the experimentally relevant way of the realization of the tg gas , based on making the respective effective mass large @xcite .\nnevertheless , the other option justifying the applicability of the tfa , @xmath70 , is quite relevant .    the substitution of expressions ( [ 1/g ] ) and ( [ mumu ] ) in eq .\n( phi2 ) leads to the single stationary equation for @xmath73 , with the cubic - quintic nonlinearity:@xmath74(eq .\n( [ mumu ] ) was used here to eliminate @xmath52 ) .\nthen , using a known particular exact solution for the dw solution of eq .\n( [ single ] ) @xcite , we obtain a solution at the following values of the chemical potentials:@xmath75i.e . , @xmath76 , @xmath77 , in the form of@xmath78note that @xmath79 satisfies condition ( g < ) , and rescaling ( [ tilde ] ) transforms values ( [ exact ] ) into @xmath80 . the width of this solution , defined according to eq .\n( [ w ] ) , is@xmath81comparison of analytical solution ( [ dw ] ) with its numerical counterpart is displayed below in fig .\n[ fig : exact ] .    an analytical approach can also be developed in the opposite limit of @xmath82 ( very heavy tg atoms ) , when the tfa may be applied to eq .\n( [ phi2 ] ) ( i.e. , the derivative term may be dropped in this equation ) , reducing it to@xmath83 in this case , eq .\n( [ phi1 ] ) takes the form of@xmath84cf .\n( [ 1/g ] ) and ( [ single ] ) derived above in the opposite limit of @xmath85 . in the particular case of @xmath86 ( no intrinsic interaction in the bec component ) , eq .\n( [ phi1nophi2 ] ) coincides with the equation considered in ref .\n@xcite , in the context of a completely different physical model , for a resonantly absorbing bragg reflector in optics . the formal hamiltonian for eq .\n( [ phi1nophi2 ] ) is @xmath87cf .\n( [ h ] ) .\nthe dw solution corresponds to a solution of eq .\n( phi1nophi2 ) with the b.c . produced by eq .\n( [ bc ] ) : @xmath88 , and , simultaneously , @xmath89 , the latter relation following from eq .\n( [ phi2phi1 ] .\nobviously , this b.c .\nset is self - consistent solely for @xmath90 . in the combination with this relation , equating values of @xmath91 corresponding to @xmath92 and @xmath93 , as per eq .\n( [ phi1h ] ) , yields @xmath94 , which is impossible , as @xmath18 can not be negative .\nthus , the dw solution does not exist in this approximation .\nnevertheless , it readily produces analytical solutions for complexes of other types , bd and dbs , as shown below .\ngeneric dw structures obtained from numerical solutions of eqs . ( [ bec ] ) and ( [ tg ] ) are displayed in fig .\n[ fig : dw ] .\nstationary solutions have been obtained by means of the imaginary - time - propagation method . the validity and stability of the solutions\nwas then checked by simulations in real time .\nthe simulations in both imaginary and real time were run by means of the split - step crank - nicholson method @xcite .\nstable solutions have been found in a wide range of values of @xmath8 at @xmath95 , and no solutions could be obtained at @xmath96 , which is readily explained by eq .\n( [ g < ] ) ( recall we set @xmath43 ) . actual numerical results for the dws have been obtained for @xmath97 . in other words ,\na natural conclusion is that the dw exists if the bec - tg repulsion is stronger than the intrinsic repulsion of the bec component . in the remaining interval of @xmath98\n( [ g < ] ) ) , it is difficult to generate dws numerically , as the initial guess for finding the solution by means of the imaginary - time propagation should be very close to the true one , in case the solution is sought for close to its existence boundary . unlike @xmath18 , the dependence of the dw solutions on @xmath8 is very weak , as seen in fig .\nfig : dw which displays examples for @xmath99 and @xmath100 ( the comparison of the results obtained for large and small values of @xmath8 , presented here and below , is appropriate even if very small values of @xmath8 may be experimentally irrelevant , as mentioned above ) .    ) , ( [ tg ] ) , and subsequently verified by the real - time propagation , for @xmath101 , @xmath102 , @xmath103 , and two values of the relative mass , @xmath99 and @xmath104 . in terms of the optics model ,\nthe bec and tg densities correspond to power densities of the waves subject to the action of the cubic and quintic self - defocusing nonlinearity , respectively ( in captions to the following figures , they are referred to as  cubic \" and  quintic \" components , respectively).,scaledwidth=35.0% ]    \\(a ) ( b )    in addition , fig .\n[ fig : exact ] displays the comparison of the analytical approximation ( tfa ) based on eqs .\n( [ 1/g ] ) , ( [ exact ] ) , and ( [ dw ] ) with the numerical solution obtained for the same values of parameters .\nit is observed that the analytically predicted density profiles are virtually identical to their numerical counterparts .    ) and ( [ tg ] ) , and its comparison with the analytical prediction ( tfa ) , given by eqs . ( 1/g ) , ( [ exact ] ) and ( [ dw ] ) , for large @xmath18 ( and/or small @xmath8 ) , _ viz_. , @xmath105 , @xmath106.,scaledwidth=45.0% ]    to characterize the entire family of the dw solutions , their width defined as per eq .\n( [ w ] ) has been numerically evaluated , as shown in fig .\nfig : wvsm(a ) , vs. the mass ratio , @xmath8 , in the interval of @xmath107 .\nit is seen that the dependence of the width on @xmath8 is rather weak , in agreement with examples displayed in fig .\n[ fig : dw ] .\nfurther , the dependence of the dw s width on the bec self - repulsion constant , @xmath18 , is shown in fig . [\nfig : wvsm](b ) .\nthe range of values of @xmath18 displayed in the figure is bounded by existence limits of the dw solutions , as given by eq .\n( [ g < ] ) .\nthe increase of the width with @xmath18 is a natural property of the system , as stronger self - repulsion stretches the transient layer [ in the analytical form , this is clearly shown by eq .\n( [ broad ] ) and solution ( [ dw ] ) . ]\n\\(a ) ( b )\nbubble - drop ( bd ) solutions are even ones , with @xmath108 , singled out by b.c .\n@xmath109(a bec drop embedded into the tg background ) , or @xmath110(a tg drop embedded into the bec background ) , cf .\n( [ bc ] ) .\nin fact , the bds may be considered as bound pairs of the dws , with the layer bec or tg trapped between the two semi - infinite tg or bec domains , respectively .\nthe existence and stability of these solutions has been numerically checked by fixing the chemical potential of the background to unity , and varying the norm of the drop , or more precisely :    * setting @xmath43 for the tg background , see eq .\n( [ db2 ] ) , and selecting several fixed values of @xmath111 for the bec drop , see eq .\n( [ n ] ) ; * setting @xmath112 for the bec background , see eq .\n( [ db1 ] ) , and selecting several fixed values of @xmath113 for the tg drop , see eq .\n( [ n ] ) .\nit is relevant to stress that , unlike the dws , the chemical potentials of the bubble and drop components are not related by any condition similar to eq .\n( [ mumu ] ) . in this\nsetting , the remaining free parameters are relative mass @xmath8 and bec self - repulsion coefficient @xmath18 .\nanalytical results for the bd structures are available in the limit case of @xmath82 ( heavy tg atoms ) , which corresponds to eqs .\n( phi2phi1 ) and ( [ phi1nophi2 ] ) . indeed , in this approximation the bd solutions , defined by b.c .\n( [ db2 ] ) or ( [ db1 ] ) correspond , respectively , to bright solitons or bubbles produced by eq .\n( [ phi1nophi2 ] ) (  bubbles \" are solutions of nlses in the form of a local drop of the density supported by the flat background , without zero crossing , and without a phase shift at @xmath114 , unlike dark solitons barash ) .\nfurther , the analysis of the corresponding hamiltonian ( phi1h ) demonstrates that eq .\n( [ phi1nophi2 ] ) can not generate bright solitons , but it readily gives rise to bubbles , i.e. , the bd patterns in the form of the tg drop embedded into the bec background .\nthe fact that the bds exist in the form of the tg drop embedded into the bec bubble , but do not exist in the reverse form , is confirmed by numerical results presented below\n.    analytical results for the bd structures are also available in the limit case of @xmath115 or @xmath85 , when the derivative term may be neglected in eq .\n( [ phi1 ] ) , leading to eq .\n( [ 1/g ] ) , as shown above . the substitution of this approximation into eq .\n( [ phi2 ] ) leads to the single equation with the cubic - quintic nonlinearity . for @xmath52\nnot linked to @xmath53 by relation ( [ mumu ] ) , which was specific for the dw , but is not relevant in the present case , the cubic - quintic equation takes a form slightly more general than eq .\n( [ single ] ) derived above : @xmath116a straightforward consideration demonstrates that eq .\n( [ cq ] ) gives rise to bubbles , i.e. , effectively , the bds of type ( [ db2 ] ) , in the case of@xmath117and to bright solitons , i.e. , the bds of type ( [ db1 ] ) , in the range of@xmath118 in fact , the present limit of @xmath115 or @xmath85 implies that interval ( [ bubble ] ) does not exist , while condition ( bright ) may hold .\nthus , this consideration again predicts that the bd exist solely in the form of a tg  drop ( bright soliton ) embedded into the bec bubble , which is exactly confirmed by numerical results following below .    in terms of the above - mentioned optics model\n, this conclusion means that a bright soliton driven by the quintic self - defocusing may be embedded into the background filled by the optical wave subject to the cubic self - defocusing , but not vice versa .      for the state defined as per eq .\n( [ db2 ] ) ( a bec / cubic drop embedded into the tg / quintic background ) , it was not possible to find solutions in the entire parametric region investigated , which amounts to intervals @xmath119 and @xmath120 , and @xmath121 . in imaginary - time simulations ,\nthis configuration , if taken as an input , transforms into a flat one .\nthe nonexistence of this bd species is readily explained by the analytical results presented above .\non the other hand , also in agreement with the above analysis , in the same parameter region ( with @xmath111 replaced by @xmath113 ) stable solutions have been readily found for the bd state defined by eq .\n( [ db1 ] ) ( a tg / quintic drop embedded into the bec / cubic background ) , see a typical example in fig .\nthe bd may be characterized by the _ missing mass _ of the bubble void , i.e. , @xmath122 ^{-1}\\int_{-\\infty } ^{+\\infty } \\left [ \\left ( n_{1}\\right ) _\n{ \\mathrm{asympt}% } -\\phi _ { 1}^{2}(x)\\right ] dx .   \\label{mvoid}\\]]computations demonstrate that , for the family of the bd states , @xmath123 very weakly depends on relative mass @xmath8 .\nfigure fig : missing_mass displays the missing mass of the bec component as a function of @xmath18 . the dependence observed in fig . [ fig : missing_mass ] may be approximated by relation @xmath124 , which is easy to understand : according to eq .\n( [ phi1 ] ) , the tg component with density @xmath125 replaces the missing bec field with effective density @xmath126 .\nthis argument also explains an approximately linear increase of @xmath127 with the growth of the norm of the tg / quintic drop , @xmath113 , as clearly seen in fig .\n[ fig : missing_mass ] .    , immersed into the bec ( cubic ) background , as produced by the numerical solution of eqs .\n( [ bec ] ) and ( [ tg ] ) with b.c . given by eq .\n( [ db1 ] ) .\nother parameters are @xmath128 , @xmath129 , @xmath130 , @xmath131 , @xmath132.,scaledwidth=35.0% ]    , as defined by eq .\n( [ mvoid ] ) , in the bd state .\nthe bec chemical potential is @xmath133 , and the tg / bec mass ratio is @xmath130.,scaledwidth=35.0% ]\nbright - dark - soliton ( dbs ) solutions represent complexes with one even localized ( bright ) component , and the other delocalized spatially odd zero - crossing one ( the dark soliton ) , the difference from the bd structure being that in the latter case both components were patterned as even ones , without zero crossing in the bubble structure . the corresponding b.c . for the dbs complex\nare given by@xmath134(a bright bec component embedded into the tg background ) , or @xmath135(a bright tg component embedded into the bec background ) , cf .\n( [ db2 ] ) and ( [ db1 ] ) .\nnote that , similar to the case of the bd , the dbs existence condition does not impose any relation on the chemical potentials of its components , unlike eq .\n( [ mumu ] ) for the dw .\nthe limit case of @xmath136 ( heavy tg atoms ) , which is represented by eqs .\n( [ phi2phi1 ] ) and ( [ phi1nophi2 ] ) , makes it possible to produce analytical results for the dbs defined by b.c .\n( dbs1 ) , which corresponds to a dark soliton of eq .\n( [ phi1nophi2 ] ) .\nthe analysis of the hamiltonian ( [ phi1h ] ) demonstrates that eq .\n( phi1nophi2 ) indeed gives rise to dark solitons , i.e. , the dbs patterns in the form of the bright tg soliton embedded into the dark bec soliton .\nthe consideration of the dbs is also possible in the opposite limit of @xmath137 or @xmath85 , which amounts to the consideration of eq .\n( [ cq ] ) .\ndark solitons of that equation correspond to the dbs defined by b.c .\n( [ dbs2 ] ) , and it is easy to see that eq .\n( cq ) gives rise to the dark solitons in the range of @xmath138 .\nobviously , this condition holds in the present limit of @xmath115 or @xmath85 .\nthus , the analysis of the limit cases readily predicts the existence of both species of the dbss , which correspond to b.c .\n( [ dbs2 ] ) and ( [ dbs1 ] ) .\nthis prediction is confirmed by the following numerical results .\nboth types of the dbs have been produced by the numerical computations , as shown in fig .\n[ fig : bds_profile ] .\n\\(a ) ( b )    the dbs complexes have their existence boundaries .\nthey cease to exist when the self - repulsion bec coefficient , @xmath18 , becomes too large .\nthis is shown in fig .\n[ fig : bds_stability ] , that displays the boundaries in the plane of @xmath139 .\nit is seen that a lower chemical potential of the dark component favors the existence of the dbs , as the boundaries move towards higher values of @xmath18 with the decrease of the chemical potential .\nrelative mass @xmath8 plays a different role : the existence area for the dbs complex with the bright bec  ( cubic ) component shrinks with the increase of @xmath8 , while for the case of the bright tg ( quintic ) component the increase of @xmath8 favors the dbs existence .\n\\(a ) ( b )     and @xmath140 , respectively.,scaledwidth=35.0% ]\nwe have introduced a binary system in the form of an immiscible pair of bec and tg quantum gases , in the effectively 1d setting . using the system of the gpe for the bec , nonlinearly coupled to the quintic nlse for the tg component , we have analyzed the possibility of the existence of three types of interfaces in this binary system : dws ( domain walls ) , bds ( bubble - drops ) , and bdss ( bright - dark solitons ) .\nthe same model applies to a bimodal light propagation in a specially designed colloidal medium in optics .\nthe immiscibility condition for the binary system of the present type was obtained in the general form .\nanalytical results were produced by means of the tfas ( thomas - fermi approximations ) , in the combination with the systematic numerical analysis .\nthe dws have been found an explicit analytical form , by means of the tfa , and in the generic form numerically .\nthe analysis and numerical results demonstrate that the bds exist solely in the form of the tg drop immersed into the bec background , while the bds complexes may be built equally well of the tg bright and bec dark components or vice versa .\nthus , the predicted results suggest new experiments with tightly confined two - species mixtures of ultracold bosonic gases . the analysis can be extended for a chain of bds and/or dbss in a long system , including a circular one , which corresponds to the binary gas loaded into a tight toroidal trap @xcite .\nwe appreciate valuable discussions with m. salerno .\ng.f . acknowledges financial support from italian research programs pon ricerca e competitivit 2007 - 2013 , under grant agreement pon nafassy , pona3_00007 , and programma regionale per lo sviluppo innovativo delle filiere manifatturiere strategiche della campania - filiera wisch progetto 2 : ricerca di tecnologie innovative digitali per lo sviluppo sistemistico di computer , circuiti elettronici e piattaforme inerziali ad elevate prestazioni ad uso avionico ."}
{"lay_summary": " primordial black hole ( pbh ) abundance limits constrain the primordial power spectrum , and hence models of inflation , on scales far smaller than those probed by cosmological observations . \n single field inflation models which are compatible with all cosmological data can have large enough perturbations on small scales to overproduce pbhs , and hence be excluded . \n the standard formulae for the amplitude of perturbations do not hold for modes that exit the horizon close to the end of inflation however . \n we use a modified flow analysis to identify models of inflation where the amplitude of perturbations on small scales is large . for these models \n we then carry out a numerical evolution of the perturbations and use the pbh constraints on the power spectrum to eliminate models which overproduce pbhs . \n significant pbh formation can occur in models in which inflation can continue indefinitely and is ended via a secondary mechanism . \n we demonstrate that pbhs constrain these types of inflation models and show that a numerical evaluation of the power spectrum decreases the number of otherwise viable models of inflation . ", "article": "primordial black holes ( pbhs ) can form in the early universe via the collapse of large density perturbations  @xcite .\nthere are tight constraints on the abundance of pbhs formed from their present day gravitational effects and the consequences of their evaporation .\nthese limits can be used to constrain the power spectrum of the primordial density , or curvature , perturbations .\nthe pbh constraints on the curvature power spectrum are fairly weak , being many orders of magnitude larger than the measurements on cosmological scales .\nthey do , however , apply over a very wide range of scales and therefore provide a useful constraint on models of inflation .\npeiris and easther  @xcite have shown that there are single field inflation models , which are compatible with all cosmological observations , for which the perturbation amplitude on small scales is large enough to produce a significant density of pbhs .    for scales which exit the horizon close to the end of inflation\nthe standard ( stewart - lyth  @xcite ) formulae for the amplitude of perturbations do not hold . leach and liddle  @xcite carried out a numerical calculation of the evolution of perturbations for a quadratic inflationary potential .\nthey found that the perturbations on scales which exit the horizon close to the end of inflation were roughly an order of magnitude larger than predicted by the stewart - lyth formula ( see also ref .\n@xcite ) . therefore to fully exploit the power of pbh constraints on inflation models , a numerical calculation of the amplitude of perturbations on small scales is required .\nit has recently been shown  @xcite that pbhs can also form on scales which never leave the horizon .\nwe do not consider this possibility here .    in this paper\nwe use a modified flow analysis to identify inflation models where the perturbations at the end of inflation may be large enough for primordial black holes to be overproduced . for these models\nwe carry out a numerical evolution of the primordial perturbations and use the pbh constraints on the power spectrum to eliminate models which overproduce pbhs .\nwe describe the modified flow analysis in sec .\n[ flow ] and the evolution of perturbations and the calculation of the power spectrum in sec .\nwe apply the primordial black hole abundance constraints and present our results in sec .\n[ results ] and conclude with discussion in sec .  [ discuss ] .\nwe consider the hubble slow roll - parameters  @xcite : @xmath0 where @xmath1 is the planck mass and @xmath2 denotes differentiation with respect to the scalar field , @xmath3 .\nthe flow equations  @xcite encode the variation of the slow - roll parameters in terms of the number of e - foldings from the end of inflation , @xmath4}$ ] and provide a method for stochastically generating inflation models : @xmath5(^l\\lambda_h ) + ^{l+1}\\lambda_h \\ , ,    \\\\ & & \\hspace{50 mm } l\\ge 1                \\nonumber \\label{flowequations}\\end{aligned}\\ ] ] where @xmath6 and @xmath7 .\nfollowing kinney  @xcite we randomly chose ` initial ' values for the slow - roll parameters and @xmath8 , the number of e - foldings between cosmological scales exiting the horizon and the end of inflation , in the ranges : @xmath9 \\ , , \\\\\n\\nonumber \\epsilon_h&=&[0,0.8 ]   \\ , , \\\\    \\nonumber \\sigma_h&=&[-0.5,0.5 ] \\ , , \\\\\n\\nonumber ^2\\lambda_h \\equiv \\xi_h&=&[-0.05,0.05 ]   \\,,\\\\      \\nonumber ^3\\lambda_h&=&[-0.005,0.005 ]   \\ , , \\\\\n\\nonumber & ... & \\\\ ^{m+1}\\lambda_h&=&0 \\ , , \\label{hierarchy}\\end{aligned}\\ ] ] truncating the hierarchy at @xmath10 .\nwe then evolve the flow equations forward in time ( @xmath11 ) from @xmath12 until either @xmath13 or inflation ends with @xmath14 . in the former case\nwe calculate the cosmological observables , the spectral index , @xmath15 , its running , @xmath16 , and the scalar to tensor ratio , @xmath17 , using the initial values of the slow - roll parameters  @xcite : @xmath18   \\ , , \\\\\nr & = & \\epsilon_h [ 1-c_1(\\sigma_h+2\\epsilon_h ) ] \\ , ,   \\end{aligned}\\ ] ] where @xmath19 and @xmath20 . in the latter case\nwe evolve the flow equations backward @xmath8 e - folds and calculate the cosmological observables at this point\n. in some cases inflation also ends when evolving backwards before @xmath8 e - folds are achieved .\nthese models are incapable of supporting the required amount of inflation and are discarded .\nour algorithm differs from that originally proposed by kinney  @xcite in how we handle models chosen from the initial hierarchy that are destined to inflate forever , @xmath21 , but do not reach this limit within @xmath8 e - foldings . in the original flow algorithm in this case\nthe cosmological observables are calculated at the late - time fixed point i.e. the model is forced to evolve to its asymptotic limit . in this limit\nthe running of the spectral index is negligible .\ntherefore for models which are compatible with the wmap 7 year measurement of the spectral index , @xmath22  @xcite , the amplitude of the curvature perturbations can not be large on any scale and pbhs are never formed in significant numbers  @xcite .\nfollowing peiris and easther  @xcite , we do not force these models to evolve to their asymptotic limit but instead terminate them once @xmath8 e - folds of inflation have occurred . at this point\nit is assumed that another mechanism , for example a second - field such as in hybrid inflation  @xcite , terminates inflation . with this treatment\nsome of these models are consistent with the wmap measurements of the spectral index and its running , but have perturbations on small scales which may be large enough to over - produce pbhs  @xcite .\nthe evolution of inflationary curvature perturbations , @xmath23 , is carried out using the mukhanov variable  @xcite , @xmath24 , where @xmath25 the fourier modes , @xmath26 , evolve according to a klein - gordon equation with a time - varying effective mass : @xmath27 where @xmath28 is conformal time , @xmath29 , and @xmath30   \\ , .\n\\label{exactdespite}\\end{aligned}\\ ] ] at early times , @xmath31 , when a mode @xmath32 is well within the horizon , @xmath33 , the initial condition for @xmath34 , is taken to be the bunch - davies vacuum state , @xmath35 in the superhorizon limit , @xmath36 , eq .  ( [ mukhanoveomtau ] ) has a growing mode solution @xmath37 , so that the curvature perturbation @xmath38 ` freezes out ' and becomes constant .\nthe power - spectrum of the curvature perturbations can thus be calculated as @xmath39 eq .\n( [ mukhanoveomtau ] ) can be solved exactly for the special case of power - law inflation .\nthe commonly used stewart - lyth formula is found via a slow - roll expansion around this exact solution  @xcite : @xmath40 ^ 2}{\\pi\\epsilon_h } \\left(\\frac{h}{m_{\\rm{pl}}}\\right)^2_{k = ah } \\ , ,        \\label{stewartlyth}\\ ] ] where @xmath41 .\nthis expression gives the power spectrum in the asymptotic superhorizon limit , @xmath42 , in terms of the hubble parameter and slow - roll parameters evaluated at horizon crossing  @xcite .\nit is valid provided that the slow - roll approximation holds ( specifically that the slow - roll parameters are slowly varying around horizon crossing ) and the asymptotic limit is reached before inflation ends  @xcite . for modes which exit the horizon close to the end of inflation the asymptotic limit will not be reached , and the slow - roll approximation may also be violated .\nleach & liddle  @xcite investigated this for a simple quadratic chaotic inflation model .\nthey found that for scales that exit the horizon very close to the end of inflation the power spectrum is roughly an order of magnitude larger than that found using the stewart - lyth expression .\nin other words , analytic calculations can significantly underestimate the amplitude of perturbations and hence the abundance of pbhs formed .\ntherefore , a numerical calculation of the perturbation evolution is required to accurately compute the primordial power spectrum on the very smallest scales .\nwe use a modified version of the inflation v2 module ( written by lesgourgues & valkenburg )  @xcite to carry out an accurate numerical calculation of the evolution of perturbations . fig .\n[ numericalenhancement ] shows the power spectrum of curvature perturbations of an example inflation model generated using the modified horizon flow formalism .\nthe power spectrum on large scales is compatible with the wmap 7 year data , while the perturbations on small scales are sufficiently large that pbhs may be over - produced .\nthe stewart - lyth calculation is in good agreement with the numerical calculation until the final few e - folds of inflation . on these small scales , the assumptions that are employed in the stewart - lyth calculation break down , and the numerical calculation finds a significant enhancement of the amplitude of the perturbations\n, @xmath43 and @xmath17 , for models generated using the modified flow algorithm described in the text .\nall models which sustain the required number of e - foldings of inflation are shown in the top two plots and those remaining once pbh constraints are applied are shown in the bottom plots.,title=\"fig:\",width=154 ] , @xmath43 and @xmath17 , for models generated using the modified flow algorithm described in the text . all models which sustain the required number of e - foldings of inflation\nare shown in the top two plots and those remaining once pbh constraints are applied are shown in the bottom plots.,title=\"fig:\",width=154 ] , @xmath43 and @xmath17 , for models generated using the modified flow algorithm described in the text . all models which sustain the required number of e - foldings of inflation\nare shown in the top two plots and those remaining once pbh constraints are applied are shown in the bottom plots.,title=\"fig:\",width=154 ] , @xmath43 and @xmath17 , for models generated using the modified flow algorithm described in the text . all models which sustain the required number of e - foldings of inflation\nare shown in the top two plots and those remaining once pbh constraints are applied are shown in the bottom plots.,title=\"fig:\",width=154 ]    we use the modified flow algorithm described in sec .\n[ flow ] to generate a large ensemble ( 250,000 ) of inflation models . in fig .\n[ stochasticresults ] ( top row ) we plot the cosmological observables for all models which are able to sustain the required number of e - foldings of inflation , @xmath8 . in around @xmath44 of the models inflation ends naturally via @xmath45 and these largely populate the concentrated diagonal feature seen in the left hand plots as well as the @xmath46 line ( c.f .\n@xcite ) . in the remaining @xmath47 of models , @xmath48\nand it is assumed , c.f .\n@xcite , that a secondary mechanism , such as hybrid inflation , acts to end inflation in these cases .\nlarge positive running is in principle allowed ( see top right plot ) , however these models may have large amplitude perturbations on small scales and hence overproduce pbhs .\nto apply the pbh constraints we use the stewart - lyth expression for the power spectrum , eq .\n( [ stewartlyth ] ) , to identify inflation models where the amplitude of the perturbations on small scales which exit the horizon close to the end of inflation is large , and may lead to the over - production of pbhs . for these models , we then carry out an accurate numerical evolution of the primordial perturbations , as described in sec .\n[ pert ] .\nthe pbh abundance constraints have recently been compiled and updated in refs .\nthe resulting constraints on the amplitude of the power spectrum are typically in the range @xmath49 with some scale dependence  @xcite .\nto be conservative we use the constraint @xmath50 .\nthe bottom row of fig .\n[ stochasticresults ] shows the cosmological observables for the models which remain once those which over - produce pbhs are excluded .\nthe @xmath44 of the original models for which inflation ends naturally generally have @xmath51 on all scales and so are unaffected by the pbh constraints . of the remaining models , in which inflation continues indefinitely in the absence of a secondary mechanism , @xmath52 are excluded by pbh overproduction\n. of the models initially generated , only approximately @xmath53 end via a secondary mechanism and do not overproduce pbhs . with an accurate numerical calculation of the perturbations\nthe number of these models decreases by approximately @xmath54 .\nlarge positive running is now excluded as expected ( see bottom - right plot ) .\ncosmological constraints on @xmath43 eliminate a significant fraction of the models generated using flow algorithms  @xcite .\na full mcmc analysis of cosmological data is beyond the scope of this work , however a simple application of the observational constraints shows that a significant fraction of cosmologically viable models are excluded by pbh constraints . of the models\ngenerated using our modified flow analysis which have cosmological observables within the 3@xmath55 ranges found by wmap7  @xcite @xmath56 are excluded by pbh over - production .\nthis illustrates that in the era of precision cosmological measurements pbh still provide a powerful constraint on inflation models .\nwe have applied constraints on the primordial power spectrum from the overproduction of primordial black holes to inflation models generated by a modified flow algorithm .\nthe amplitude of inflationary perturbations is usually calculated using the stewart - lyth  @xcite expression , however for scales which exit the horizon close to the end of inflation the assumptions underlying this expression are violated .\na numerical calculation is therefore required , and the amplitude of the perturbations on small scales can be significantly enhanced  @xcite .\nthe models generated by the modified flow algorithm which end naturally ( roughly @xmath44 of the total ) generally have a red spectrum of perturbations on all scales and so are unaffected by pbh constraints .\nthe remaining @xmath47 of models equations have a late time attractor with @xmath57 and it is assumed that an auxiliary mechanism terminates inflation .\nthe majority of these models are however excluded due to pbh over - production .\nthe number of viable models decreases if the power spectrum is calculated numerically . of the models\ngenerated using our modified flow analysis which have cosmological observables within the 3@xmath55 ranges found by wmap7  @xcite @xmath56 are excluded by pbh over - production .\nwe conclude that pbh constraints provide a significant constraint on models of inflation . furthermore to exploit their full power an accurate numerical calculation of the amplitude of primordial perturbations on small scales , which exit the horizon close to the end of inflation , is required .\nwe are grateful to andrew liddle and will hartley for useful discussions and acknowledge the use of the inflation v2 module ( written by julien lesgourgues and wessel valkenburg ) .\naj is supported by the university of nottingham , amg is supported by stfc .      b.  j. carr and s.  w. hawking _ mon . not .\n* 168 * ( 1974 ) 399415 .\nb.  j. carr _ astrophys .\nj. _ * 201 * ( 1975 ) 119 .\nh.  v. peiris and r.  easther _ jcap _ * 0807 * ( 2008 ) 024 [ http://arxiv.org/abs/arxiv:0805.2154[arxiv:0805.2154 ] ] .\ne.  d. stewart and d.  h. lyth _ phys .\n* b302 * ( 1993 ) 171175 [ http://arxiv.org/abs/arxiv:gr-qc/9302019[arxiv:gr-qc/9302019 ] ] .\ns.  m. leach and a.  r. liddle _ phys .\n* d63 * ( 2001 ) 043508 [ http://arxiv.org/abs/arxiv:astro-ph/0010082[arxiv:astro-ph/0010082 ] ] .\ne.  bugaev and p.  klimai _ phys . rev . _\n* d78 * ( 2008 ) 063515 [ http://arxiv.org/abs/arxiv:0806.4541[arxiv:0806.4541 ] ] .\nd.  h. lyth , k.  a. malik , m.  sasaki and i.  zaballa _ jcap _ * 0601 * ( 2006 ) 011 [ http://arxiv.org/abs/arxiv:astro-ph/0510647[arxiv:astro-ph/0510647 ] ] . i.  zaballa and m.  sasaki http://arxiv.org/abs/arxiv:0911.2069[arxiv:0911.2069 ] .\nd.  s. salopek and j.  r. bond _ phys .\n_ * d42 * ( 1990 ) 39363962 .\nm.  b. hoffman and m.  s. turner _\nrev . _ * d64 * ( 2001 ) 023506 [ http://arxiv.org/abs/arxiv:astro-ph/0006321[arxiv:astro-ph/0006321 ] ]\n. w.  h. kinney _ phys .\n_ * d66 * ( 2002 ) 083508 [ http://arxiv.org/abs/arxiv:astro-ph/0206032[arxiv:astro-ph/0206032 ] ] .\ne.  komatsu _ et .\n_ http://arxiv.org/abs/arxiv:1001.4538[arxiv:1001.4538 ] .\ns.  chongchitnan and g.  efstathiou _ jcap _ * 0701 * ( 2007 ) 011 [ http://arxiv.org/abs/arxiv:astro-ph/0611818[arxiv:astro-ph/0611818 ] ] .\na.  d. linde _ phys .\n* d49 * ( 1994 ) 748754 [ http://arxiv.org/abs/arxiv:astro-ph/9307002[arxiv:astro-ph/9307002 ] ] . l.  alabidi and k.  kohri _ phys .\n* d80 * ( 2009 ) 063511 [ http://arxiv.org/abs/arxiv:0906.1398[arxiv:0906.1398 ] ] .\nk.  kohri , d.  h. lyth and a.  melchiorri _ jcap _ * 0804 * ( 2008 ) 038 [ http://arxiv.org/abs/arxiv:0711.5006[arxiv:0711.5006 ] ] .\ne.  bugaev and p.  klimai _ phys .\n* d79 * ( 2009 ) 103511 [ http://arxiv.org/abs/arxiv:0812.4247[arxiv:0812.4247 ] ] .\nv.  f. mukhanov , h.  a. feldman and r.  h. brandenberger _\n* 215 * ( 1992 ) 203333 .\ni.  j. grivell and a.  r. liddle _ phys .\n* d54 * ( 1996 ) 71917198 [ http://arxiv.org/abs/arxiv:astro-ph/9607096[arxiv:astro-ph/9607096 ] ] .\nd.  h. huang , w.  b. lin and x.  m. zhang _ phys .\nrev . _ * d62 * ( 2000 ) 087302 [ http://arxiv.org/abs/arxiv:hep-ph/0007064[arxiv:hep-ph/0007064 ] ] . j.  lesgourgues , a.  a. starobinsky and w.  valkenburg _ jcap _ * 0801 * ( 2008 ) 010 [ http://arxiv.org/abs/arxiv:0710.1630[arxiv:0710.1630 ] ] .\na.  s. josan , a.  m. green and k.  a. malik _ phys .\n_ * d79 * ( 2009 ) 103520 [ http://arxiv.org/abs/arxiv:0903.3184[arxiv:0903.3184 ] ] .\nb.  carr , k.  kohri , y.  sendouda and j.  yokoyama http://arxiv.org/abs/arxiv:0912.5297[arxiv:0912.5297 ] ."}
{"lay_summary": " sofia is a 2.5 meter airborne infrared telescope , mounted in a boeing 747sp aircraft . due to the large size of the telescope , \n only a few degrees of azimuth are available at the telescope bearing . \n this means the heading of the aircraft is fundamentally associated with the telescope s observation targets , and the ground track necessary to enable a given mission is highly complex and dependent on the coordinates , duration , and order of observations to be performed . \n we have designed and implemented a flight management infrastructure ( fmi ) product in order to plan and execute such missions in the presence of a large number of external constraints ( e.g. restricted airspace , international boundaries , elevation limits of the telescope , aircraft performance , winds at altitude , and ambient temperatures ) . \n we present an overview of the fmi , including the process , constraints and basic algorithms used to plan and execute sofia missions . ", "article": "the flight management infrastructure ( fmi ) product is intended to keep the aircraft from interfering with preplanned observations on the sky .\nit predicts the ground tracks necessary to execute its mission , and corrects the plan for actual conditions while airborne . to support this ,\nit contains both a planning component that can run on the ground and in the air , and an execution component that runs in the air .\nthe planning component manages a set of ordered observations and optional aircraft repositioning requests .\nthe execution component compares the plan to actual conditions in flight and requests headings ( indirectly ) from the autopilot .\nsofia mission planning differs from satellite or ground based observatory planning in a few key areas .\nmost importantly , the observatory position is a function of observation target history , which prevents observations from being considered as time - slots alone .\nassignment of flight dates is also nontrivial  targets can not be localized on the sky or the observatory will always fly in about the same direction ( requiring nearly equivalent dead time to return ) ; this suggests entire flight series should be considered at once , for greater target variety .\nflight planning and execution differs from conventional as well .\nall conventional aircraft fly from point to point along specified paths on the ground , and `` drift '' the aircraft to compensate for winds .\ntypical drift angles ( course - heading ) exceed 3@xmath0 , and the worst possible case approaches 30@xmath0 , so sofia can not necessarily observe in this manner .\nexpected winds can be planned for using a weather forecast .\ncorrecting course for _ unexpected _ winds can be accomplished by adjusting observation durations , by relocating the aircraft between observations , or by `` observation triage '' as a last resort .\nthis requires an astronomically - aware airborne monitoring function to compare current conditions to plan .\naircraft capabilities are a strong function of fuel weight , which argues against simple parametrizing by time , in favor of fuel .\nin addition to the geometrical and practical constraints described above , the sofia flight planning problem also has a number of external constraints , all of which prevent a truly automated , or even rigorously sequential , flight planning process . for instance , special use airspace ( sua ) incursions may require external approval , and it can not be known ahead of time whether such approval will be forthcoming in all cases .\nnational airspace boundaries require international agreements . over - ocean operations\nare prohibited for safety reasons for the first flights ; for later flights , fairly complex fuel reserve constraints are required .\ngross takeoff weight has a hard limit of 700,000 pounds , which limits the duration of sofia missions .\nsome science - driven constraints require interaction with scientists or detailed knowledge of the observations ; especially , trading off water vapor overburden estimates with altitude and duration , and for trading off observations against each other .\nprior to any particular mission , several iterations of flight planning are performed .\nthis is expected to include fully integrated automated flight planning ( frank , gross , & krkl 2004 ) , routinely .\nmanual choice of observation ( including order ) will occur subsequently . upon execution , replanning might occur if conditions are sufficiently different from assumptions .\nfigure  [ fig : sampleflight ] shows a color - processed screenshot of a simulated flight intended for april , 2008 , from palmdale , ca .\nactual conditions for the simulation shown differ from planned only by small timing errors of the order of several seconds between segments and at takeoff .\nas mentioned earlier , it is advantageous to consider entire flight series at once , in order to trade observations between flights .\nthe data structure supporting this is shown in fig .\n[ fig : flightseries ] .\nfmi requires substantial input data in order to accurately predict a flight track and its constraints .\nweather forecast time - series are taken from the national center for environmental prediction global forecasting system , quadrilinearly interpolated .\nan alternative is required for dates more than several days in the future , since accurate forecasts are not available then ; we use a set of stacked monthly means for 19972001 ( the last years available ) from the european center for medium ranger weather forcasting 40 year reanalysis ( uppala et .\nal . 2005 ) also quadrilinearly interpolated .\naircraft performance is interpolated from tables generated by boeing inflt runs , for cruising , thrust - limited climbs , and descents .    planned flight track intersections with special use airspace ( sua ) boundaries ( including non - us zones , from the us national imagery and mapping agency ) are evaluated using a quadtree - based search on the 8000 + sua boundaries for each flight segment .\nobservation segments are treated as initial value problems in cartesian coordinates , others may be boundary or initial problems , as appropriate .\ndesired headings are calculated during execution from planned ( not actual ) sky coordinates and actual position ; direct steering by the telescope can not be allowed for safety reasons .    in order to test fmi components and integrate other systems , as well as for training purposes\n, we use a simulation environment .\nthis includes a medium - fidelity aircraft simulator , an automated pilot simulator , a method to set the time arbitrarily , and a telescope simulator ( brggenwirth , gross , nelbach , & shuping 2008 ) .    while airborne , the fmi software components interact with the airborne data acquisition software to acquire the aircraft s position and attitude . while on the ground , the planner portion of fmi interacts with observers planning software and must support multiple simultaneous planning sessions .\nthe airborne configuration is shown in fig .\n[ fig : dataflow ] ; the ground configuration is similar , except there is no flight executor nor mccs data ( except in testing configurations ) , and there is a connection to the observation planning database .\nsofia presents a unique flight planning problem due to the nature of astronomical observation .\nfmi provides a connection between scientific needs of an observatory with the practical constraints of operating an aircraft , without introducing excessive safety considerations or pilot workload , or planner effort .\nbrggenwirth , s. , gross , m.  a.  k. , nelbach , f.  j. , & shuping , r.  y.  2009 , , 485 frank , j. , gross , m.  a.  k. , & krkl , e.  2004 , in proc .\n16th conf . on innovative applications of artificial intelligence , ed .\nd.  l.  mcguinness & g.  ferguson ( boston : mit press ) , 828 uppala , s.  m.  et al .\n2005 , quart .\nj. r. meterol .\nsoc.,131 , 2961"}
{"lay_summary": " we have simulated two - colour four - flavour qcd at non - zero chemical potential @xmath0 for quark number . \n simulations were performed on @xmath1 and @xmath2 lattices . \n clear evidence was seen for the formation of a colourless diquark condensate which breaks quark number spontaneously , for @xmath3 . \n the transition appears to be second order . \n we have measured the spectrum of scalar and pseudoscalar bosons which shows clear evidence for the expected goldstone boson . \n our results are in qualitative agreement with those from effective lagrangians for the potential goldstone excitations of this theory . ", "article": "qcd at finite quark / baryon - number density at zero and at finite temperature describes nuclear matter\n. nuclear matter at high temperatures ( and possibly densities ) was certainly present in the early universe .\nneutron stars consist of dense cold nuclear matter .\nrhic and the cern heavy - ion program promise to produce hot nuclear matter in the laboratory . calculating the properties of high density nuclear matter could predict if and where strange matter could be produced .\nany method which can be used to determine the properties of nuclear matter could be adapted to nuclear physics calculations .\nfinite quark - number density is best achieved by introducing a chemical potential @xmath0 for quark - number , and using the grand - canonical partition function .\nunfortunately , this renders the euclidean - time fermion determinant complex , with a real part which can change sign .\nstandard lattice simulations , which rely on importance sampling , fail in this case . attempting to circumvent these problems by using canonical ( fixed quark number ) ensembles fail except at high temperatures @xcite because of sign problems .    until a simulation method is found\nwhich avoids these difficulties , it is useful to study models which exhibit _ some _ of the properties of qcd at high @xmath0 .\nnow it is expected that , at zero temperature , nuclear matter undergoes a phase transition at @xmath0 of order one third the mass of the nucleon .\nit has been proposed that at still higher @xmath0 the ground state is characterised by a diquark condensate @xcite .\nsuch a condensate would not only cause spontaneous breaking of baryon number , but would also spontaneously break colour . since colour is a gauge symmetry , such breaking\nis realized in the higgs mode .\nthus nuclear matter would become a colour superconductor at high @xmath0 .\nfor this reason we have simulated 2-colour qcd , i.e. su(2 ) yang - mills theory with fermion matter fields ( ` quarks ' ) in the fundamental representation of @xmath4 , and finite @xmath0 . as well as having colour confinement\nthis theory does exhibit diquark condensation as we shall demonstrate in this paper , but for @xmath5 , since the diquark ` baryons ' in the same multiplet as the pions , also have mass @xmath6 .\nfor @xmath7 the phenomenon is describable as a rotation of the condensate from the chiral to the diquark direction as predicted by effective lagrangian analyses @xcite .\nunlike in true ( 3-colour ) qcd , the diquark condensates are colourless , and the broken symmetry is realized in the goldstone mode , and there is no colour superconductivity , but rather superfluidity , as in liquid @xmath8he . despite this , we shall later argue that this theory is more similar to 2-flavour qcd than one might think ( see section 4 ) .\nsince 2-colour qcd has a non - negative determinant and pfaffian , even at non - zero @xmath0 , standard simulation methods can be used .\nwe use the hybrid molelcular - dynamics method and simulate the theory with 4 flavours of staggered quarks @xcite .\npfaffian simulations of a 4-fermion model including a diquark source term have been reported in @xcite .\nwe have run simulations at a moderately large quark mass and an intermediate gauge coupling on @xmath1 and @xmath9 lattices , i.e. at zero temperature .\nwe measured order parameters including the chiral and diquark condensates , the quark - number and energy densities , and the wilson line ( polyakov loop ) .\nthe larger lattice allowed us to observe finite size effects and , more importantly to measure the scalar and pseudoscalar meson and diquark masses , which include all the potential goldstone bosons in the theory .\npreliminary results from these simulations were reported at lattice2000 , bangalore @xcite .\nthe extension of these calculations to finite temperature was reported in a recent letter @xcite .\nthis work builds on early work with 8 quark flavours which presented far less conclusive results @xcite .\nprevious studies of diquark condensation in this model with various numbers of flavours have either used the approximation where @xmath10 in the updating algorithm @xcite ( as does @xcite ) , or been in the strong gauge - coupling regime @xcite .\nsection 2 introduces the staggered - fermion lattice port of 2-colour qcd .\nthe results of our simulation are presented in section 3 .\nsection 4 gives our conclusions and indicates future avenues of research .\nbecause in 2-colour qcd fundamental quarks and antiquarks lie in the same representation of @xmath4 the flavour symmetry group for @xmath11 flavours is enlarged from @xmath12 to @xmath13 .\nthe pattern of chiral symmetry breaking is @xmath14 rather than the usual @xmath15 @xcite .\n3-colour qcd with 1 staggered quark ( 4 continuum flavours ) has a @xmath16 flavour symmetry . for 2 colours this\nis enhanced to @xmath17 @xcite .\nchiral or quark - number symmetry breaking ( the chiral and diquark condensates lie in the same u(2 ) multiplet ) occurs according to the pattern @xmath18 .\nthe quark action for 2-colour qcd with one staggered quark is @xmath19\\chi   + \\frac{1}{2}\\lambda[\\chi^t\\tau_2\\chi + \\bar{\\chi}\\tau_2\\bar{\\chi}^t]\\right\\ } \\label{eqn : lagrangian}\\ ] ] where @xmath20 is the normal staggered covariant finite difference operator with @xmath0 introduced by multiplying the links in the @xmath21 direction by @xmath22 and those in the @xmath23 direction by @xmath24 .\nthe superscript @xmath25 stands for transposition .\nnote that we have introduced a gauge - invariant majorana mass @xmath26 which explicitly breaks quark - number symmetry .\nsuch an explicit symmetry breaking term is needed to observe spontaneous symmetry breaking on a finite lattice\n. we shall be interested in the limit @xmath27 .\nintegrating out these fermion fields yields @xmath28 = \\sqrt{{\\rm det}({\\cal a}^\\dagger { \\cal a } + \\lambda^2 ) } \\label{eqn : pfaffian}\\ ] ] where @xmath29 we note that @xmath30 is positive definite for finite @xmath26 . hence the pfaffian never vanishes and thus , by continuity arguments never changes sign and can be chosen to be positive .\nnote that @xmath31 has been shown to be positive in @xcite . denoting the @xmath32 matrix in equation  [ eqn : pfaffian ] by @xmath33\nwe have seen that its determinant is the determinant of a positive definite matrix and thus can be used directly in our simulations .\nto do this we define @xmath34 by @xmath35            { \\cal m }     \\left[\\begin{array}{cc } \\tau_2      &       0             \\\\                                                          0        &       1                                                                \\end{array}\\right]\\ ] ] so that @xmath36\\ ] ] and @xmath37.\\ ] ] we note that @xmath38 = \\det[{\\cal a}^\\dagger { \\cal a } + \\lambda^2]$ ] .\nbecause we are now dealing with the matrix @xmath39 we can use the hybrid molecular dynamics method with ` noisy ' fermions @xcite to simulate this theory . here , although we generate gaussian noise with both upper and lower components , we keep only the upper components of the pseudo - fermion field to calculate @xmath40 $ ] , which means that we only need to invert @xmath30 at each update .\nkeeping only half the components of the pseudo - fermion field is entirely analogous to keeping only the fermion fields on even sites in normal qcd simulations .\nthe square root of equation  [ eqn : pfaffian ] is obtained by inserting a factor of @xmath41 in front of the fermion term in the stochastic action in the standard manner .\nwe now give a brief discussion of symmetry breaking in this model .\nthis is covered in more detail in @xcite . at @xmath42 ,\nthe @xmath17 symmetry will break spontaneously .\ntwo directions in which it will choose to break are of particular interest .\nthe first is where it breaks to give a non - zero chiral condensate @xmath43 .\nthere will be 3 goldstone bosons corresponding to the 3 broken generators of @xmath17 .\nthese states and their corresponding @xmath17 generators are @xmath44 @xmath45 remains unbroken .\nthe second is where @xmath17 breaks to give a non - zero diquark condensate @xmath46 .\nthis time the 3 goldstone bosons and corresponding generators are @xmath47 @xmath48 remains unbroken .\nwhen @xmath49 only 2 goldstone bosons remain , @xmath50 and @xmath51 .\nwhen in addition @xmath52 , only the latter state remains a goldstone boson .\na more detailed study of the patterns of symmetry breaking can be performed in terms of an effective lagrangian for the goldstone modes as in @xcite .\nthe only difference is that the effective field , denoted @xmath53 in that work , here belongs to a symmetric @xmath32 tensor representation of @xmath17 rather than to the antisymmetric @xmath54 representation of @xmath13 of the continuum case .\none can see the remnant @xmath55 symmetry when @xmath27 by allowing @xmath26 to become complex .\nthe majorana mass term in equation  [ eqn : lagrangian ] then becomes @xmath56 $ ] .\n@xmath57 is replaced by @xmath58 in the pfaffian .\nalthough the 2-flavour theory would be of more interest in the continuum , we have chosen to simulate the 4-flavour theory because this represents a single staggered quark species and thus has well defined symmetries and a well defined spectrum at all lattice spacings . unlike the 8-flavour case simulated in @xcite it probably does have a sensible continuum limit .\nwe have simulated 2-colour qcd with 1 staggered quark species ( 4 continuum flavours ) on @xmath1 and @xmath9 lattices .\nthe simulations reported here are all at @xmath59 which is roughly the @xmath60 for the finite temperature transition on an @xmath61 lattice @xcite .\nthis first set of simulations has been performed with quark mass @xmath62 in lattice units .\nthese simulations are currently being repeated at @xmath63 , where the smaller pion mass will give a richer spectrum of goldstone and pseudo - goldstone bosons and where a larger portion of the relevant phase diagram should be described by effective lagrangians .\n( we have also performed some zero temperature simulations at @xmath64 and @xmath65 .\nthis has been reported in our finite temperature / finite @xmath0 letter @xcite . )\nsince we wished to take the limit @xmath27 , we needed @xmath66 .\nthe values we chose were @xmath67 and @xmath68 for @xmath62 .\n( at low @xmath0 s we also ran at @xmath10 . )\nthe smaller lattice was used to map out the interesting range of @xmath0 values , measuring order parameters including the diquark condensate @xmath69 , the chiral condensate @xmath70 , and the number density @xmath71 .\nin addition to measuring these quantities on the larger lattice , we also calculated the spectrum of potential goldstone bosons .\nthe length of each ` run ' was 2000 molecular dynamics time units .\n@xmath72 had to be chosen as low as @xmath73 for @xmath67 and @xmath74 . in figure\n[ fig : pt2p ] we have plotted the diquark condensate as a function of @xmath0 at each @xmath26 for both lattice sizes .\nsince we are interested in the limit where the symmetry breaking parameter @xmath27 , we have performed a linear extrapolation of the diquark condensate to @xmath10 .\nnote that the effective lagrangian calculations @xcite suggest that linear extrapolations are the correct approach for @xmath26 sufficiently small , except at @xmath75 .\nthe results of these extrapolations are plotted in figure  [ fig : pt2p_0 ] .\nwhat we first notice is that for @xmath76 , the extrapolated diquark condensate is small enough that we can believe that it should be zero .\nfor @xmath77 it is clearly non - zero .\nthe points at @xmath78 would appear to show finite size rounding were it not for the fact that the @xmath1 and @xmath9 points are so close together .\nwe think it more likely that @xmath78 is so close to the transition that the linear extrapolation has broken down .\nwe therfore conclude that the system undergoes a phase transition at @xmath79 .\nif this holds true , the fact that @xmath75 is less than @xmath80 would indicate that the diquark ` baryons ' do not exist as free particles but bind into ` nuclear ' matter . over the range @xmath81 , the condensate increases with a curvature consistent with a critical index @xmath82 ( the tree level effective lagrangian analysis predicts the mean field result @xmath83 ) . since the condensate starts to decrease soon after @xmath84 , the scaling region is narrow and it would require more points to even try to extract this critical index . for @xmath85 , the condensate starts to decrease , approaching zero for large @xmath0 , which would appear to be a saturation effect .\nin fact figure  [ fig : pt2p_0 ] suggests that the condensate vanishes for @xmath86 , indicating a saturation phase transition .\nwe shall have more to say about this later .\nnote that this decrease in the condensate with @xmath0 is not predicted by the effective lagrangian analysis , which is only expected to be valid for small @xmath0 and @xmath6 .\nthis is not surprising if it is indeed a saturation effect .\nsaturation is a result of the fermi statistics of the quarks , and should not be seen in a model which only considers the system s bosonic excitations .\nwe now turn to a consideration of the chiral condensate , @xmath70 .\nthis is plotted in figure  [ fig : pbp ] for our 2 different lattice sizes .    in the @xmath27 limit , this is expected to be constant at its @xmath87 value for @xmath88 .\nthese plots are consistent with this expectation . above @xmath75 ,\neffective lagrangian studies predict that the condensate merely rotates from the chiral direction to the diquark direction , so that the magnitude of the condensate , i.e. @xmath89 , should remain constant and independent of @xmath26 .\nsince the diquark condensate increases up to @xmath90 , this means that the chiral condensate should fall , as it does .\nit , however , continues to fall past this point , because of saturation effects , appearing to vanish for @xmath91 . to test the prediction that the principal effect for @xmath92 is merely a rotation ,\nwe have tabulated @xmath89 in table  [ tab : condensate ] .\n.magnitude of the condensate @xmath89 as functions of @xmath0 and @xmath26 on a @xmath9 lattice .\nerrors are not quoted but they are in the next or a subsequent digit after the least significant quoted digit . [ cols=\"^,^,^ \" , ]     we see that , for @xmath93 , the magnitude of the condensate is approximately constant and independent of @xmath26 , so that the main effect is a rotation of the condensate from the direction of chiral symmetry breaking to that of quark - number breaking .\nfor @xmath94 , it decreases with increasing @xmath0 approaching zero for large @xmath0 .    in figure  [\nfig : j0 ] we plot the quark - number density @xmath71 as a function of @xmath0 for our 2 lattices .\n@xmath95 is consistent with zero as @xmath27 , for @xmath88 .\n( note effective lagrangians predict that it vanishes quadratically with @xmath26 in this region . ) above @xmath75 it increases with increasing @xmath0 approaching the saturation value of 2 ( 1 staggered quark field of each colour / site , the maximum value allowed by fermi statistics ) for large @xmath0 .\nnote that figure [ fig : j0 ] suggests that @xmath96 for @xmath91 with @xmath97 consistent with that predicted from the condensates .\nthis indicates that it is this saturation which causes the condensates to vanish for @xmath91 .\nit also tells us that this transition is an artifact of the finite lattice spacing and would recede to infinite @xmath0 in the continuum limit .    on the @xmath9 lattice we have measured the propagators for all the potential goldstone bosons , both scalar and pseudoscalar using a single noisy point source for the connected propagators and multiple ( 5 ) noisy point sources for the disconnected propagators .\nwe have measured both diagonal and off - diagonal zero momentum propagators .    in figure  [\nfig : goldstone ] we show the masses from fitting the propagator for the diquark state produced by applying the operator @xmath51 to the vacuum , to the form @xmath98 + \\exp[-m_g(n_t - t ) ] \\right\\},\\ ] ] valid for large temporal separations @xmath25 . as argued in section  2 , this is the expected goldstone boson for @xmath99 and @xmath10 .\nthe effective lagrangian approach indicates that , in the low @xmath0 phase , this mass should be quadratic in @xmath26 , while in the high @xmath0 phase , it should vanish as @xmath100 .\nwe have performed extrapolations based on this and plotted them in the figure .\nfor the 3 points closest to the transition @xmath101 , we have performed both extrapolations .\nfor @xmath102 and @xmath10 , we expect @xmath103 with @xmath104 .\nwe see that for @xmath105 , the points obtained from quadratic extrapolation lie on this straight line , the point at @xmath106 is close to the line and that for @xmath107 lies above this line .\nall points for @xmath108 obtained by square root extrapolation are negative .\nthe points at @xmath109 show the most significant negative values ( although both are greater than @xmath110 ) , and should be considered as transitional .\nthe other points are so close to zero that one can easily attribute the difference as being due to a combination of the systematic errors in extracting masses from point source propagators and higher order terms in the extrapolation .\nthus our results are consistent with a transition to a phase with a massless ( goldstone ) scalar diquark at @xmath111 , as expected .\nfinally the large value of this diquark mass at @xmath112 is further indication that the system has passed through the saturation phase transition .\nwe now turn to consideration of the other potential goldstone bosons of the theory .\nsince at this quark mass , @xmath113 is relatively large , we concentrate on those states which are expected to have masses of order @xmath6 or less over the range of interest . for this reason\n, we consider the pion itself . for @xmath88 , its mass should remain constant at @xmath6 , and it is created by the operator @xmath114 . for @xmath99 , it is expected to mix with the pseudoscalar diquark state created from the vacuum by the operator @xmath50 . rather than trying to diagonalize the propagator over these 2 states , we have instead calculated the diagonal propagators for each of these states separately . these we fit to the form @xmath115 + \\exp[-m_\\pi(n_t - t ) ] \\right\\ }           + b ( -1)^t \\left\\ { \\exp[-m_{b1 } t ] + \\exp[-m_{b1}(n_t - t ) ] \\right\\}\\ ] ] or the form with @xmath116 , and a similar form for the diquark state .\nthese masses are plotted in figure  [ fig : pseudo ] .\nnote that these 2 graphs are almost identical .\nfor @xmath99 , this is expected , since the 2 states mix . for @xmath88\nthis is not , a priori , expected since the diquark state should exhibit a linear decrease with @xmath0 for @xmath10 .\nhowever , since @xmath117 this gives a small mixing with the pion state , which is then the lowest mass particle contributing to this pseudoscalar diquark propagator in this region .\nit is precisely because this mixing is so small that the errors are so large .\nthe final indicator that this is the correct interpretation was that the @xmath87 , @xmath10 propagator yielded no sensible mass fit , a sure indicator that the mass was large where there can be no mixing .\nthe pion mass fits in this low @xmath0 domain are consistent with the expectation that the @xmath10 pion mass is independent of @xmath0 in this region .\nfor @xmath99 these masses fall faster than the expected @xmath118 .\nat least part of the reason for this more rapid falloff is the saturation effect .\nnote that the reason that this mass tends to zero at large @xmath0 ( before the saturation transition ) is because the pseudoscalar diquark would be a goldstone boson if @xmath119 , and as @xmath0 increases the relative importance of @xmath120 diminishes .\nthe fact that the @xmath121 mass becomes more poorly determined for large @xmath0 is because here , the lowest mass state in this channel is predominantly the pseudoscalar diquark .    it is interesting to contrast our findings with those of a study of adjoint quarks in 2-colour qcd @xcite with @xmath26 set to zero , implying strictly no mixing ; in this case @xmath6 was found to rise as @xmath122 for @xmath123 , with the signal becoming appreciably noisier in the high density phase .\nboth behaviours are in accord with the predictions of chiral perturbation theory for a meson formed from quarks with a symmetric combination of quantum numbers under the residual global symmetry , the difference arising due to the distinct dyson indices of each model @xcite .\ntwo - colour lattice qcd with one staggered quark species ( 4 continuum flavours ) has been studied at finite chemical potential @xmath0 for quark number .\nwe have shown conclusive evidence that this theory undergoes a phase transition to a phase characterized by a diquark condensate which spontaneously breaks quark - number , at @xmath124 .\nthis transition appears to be second order .\nthe simulations were performed at an intermediate value of the coupling ( close to @xmath60 for the finite temperature transition at @xmath87 on a lattice with @xmath61 ) . because of this , the relevant symmetry was the lattice flavour symmetry @xmath17 rather than the @xmath125 of the continuum 4-flavour theory .\nwe have presented convincing evidence that the scalar diquark is the goldstone boson associated with the spontaneous breaking of quark number for @xmath99 .\nin addition we have measured the lightest mass in the pion channel as a function of @xmath0 . for @xmath7 the chiral condensate and diquark condensate\nare well described as a single condensate of constant magnitude which rotates from the chiral direction for @xmath88 towards the diquark direction as @xmath0 is increased above @xmath75 . despite the fact that the quark mass @xmath62 was large enough that @xmath6 was not small relative to the 2-colour qcd scale , we saw good qualitative agreement with previous calculations in terms of effective lagrangians ( of the chiral perturbation theory form ) for @xmath7 .\nthis includes the fact that the quark number density increases from zero at @xmath126 .\nas @xmath0 becomes large , this relationship with effective lagrangians is no longer valid . both chiral and diquark\ncondensates decrease towards zero as @xmath0 becomes large .\nhowever , because at least part of this is due to the fact that @xmath95 saturates at 2 fermions / site , a finite lattice spacing artifact , and because we see large finite size effects in the condensates for these @xmath0 values , studies at smaller lattice spacings as well as on larger lattices would be needed to determine how much of this observed high @xmath0 behaviour is real .\nwe are currently extending these calculations to lower quark mass ( @xmath63 ) where we should be able to measure the complete spectrum of goldstone and pseudo - goldstone bosons .\nfor this @xmath120 , the pion mass should be half that at @xmath62 and the assumptions of the effective lagrangian approach should have more validity , allowing a more quantitative analysis .\nin addition , there is a larger range of @xmath127 between @xmath75 and the turnover point .\nthis means we can hope to measure the critical index @xmath128 for this transition .\n( preliminary attempts to extract this index from short runs at relatively strong coupling were reported in our letter on finite @xmath25 and @xmath0 . )\nlet us now compare 2-colour qcd with 3-colour qcd , at finite @xmath0 .\nmost of this discussion is condensed from the published literature @xcite . since for 2-colour qcd ,\nthe diquark condensate is a colour singlet , the spontaneous breaking of quark number is realized in the goldstone mode .\nthis contrasts with true ( 3-colour ) qcd where the condensate is , of necessity , coloured and the symmetry breaking is realized in the higgs mode . to see similarities , we consider the mode of symmetry - breaking for normal qcd with 2 light quark flavours . here\nthe expected condensate is a flavour singlet and a colour anti - triplet , i.e. antisymmetric in both flavour and colour .\nthe pattern of colour breaking is @xmath129 where @xmath130 and @xmath131 refer to quark number before and after the breaking .\nthe 5 gluons corresponding to symmetries broken by the condensate , gain masses via the higgs mechanism by combining with the 5 would - be goldstone bosons associated with colour / quark - number breaking .\nwith respect to the remnant @xmath132 colour symmetry , the condensate is a flavour _ and _ colour singlet .\nthis is precisely the condensate that would be formed from the 2 quarks which are in a colour doublet with respect to this unbroken @xmath132 ( the third quark is a singlet with respect to this group ) if we ignored the interactions of the gluons which gain masses due to the higgs mechanism .\nsince the gluon masses produced from the goldstone bosons produced in this manner are of order @xmath133 , ignoring such light particle interactions is presumably a rather drastic approximation .\nhowever , one might hope that it has at least qualitative validity .\n( note that @xmath134 is of the order of @xmath135  mev , @xmath136 , giving gluon masses of the same order of magnitude as previous estimates . )\nsince this remnant @xmath132 theory is also at finite @xmath0 this condensate spontaneously breaks only 1 symmetry , quark number .\nas seen above , the goldstone boson associated with this breaking gives mass to one of the gluons via the higgs mechanism .\nfinally , we note that with an appropriate reinterpretation of the fields , 2-colour qcd with a finite chemical potential for quark number can be reinterpreted as 2-colour qcd with a finite chemical potential for isospin .\nit is clear that one can simulate true 3-colour qcd for 2 flavours with a finite chemical potential for isospin .\nsuch a program is underway .\nthe 2-colour theory can be used as a guide to the pattern of symmetry breaking and what to expect .\nthis work was partially supported by the nsf under grant nsf - phy96 - 05199 and by the u.  s. department of energy under contract w-31 - 109-eng-38 .\nsjh and sem were supported by eu - tmr contract no .\nerbfmrx - ct97 - 0122 .\nthese simulations were performed on the ibm sp and cray sv1 s at nersc and on the ibm sp and cray t90 at npaci .\ndks would line to thank c.  k.  zachos for useful discussions .\n9999 j.  engels , o.  kaczmarek , f.  karsch and e.  laermann , nucl .\nsuppl.)83 369 ( 2000 ) .\nb.  c.  barrois , nucl .\nb129 , 390 ( 1977 ) d.  bailin and a.  love , phys .\n107 , 325 ( 1984 ) .\nm.  alford , k.  rajagopal and f.  wilczek , phys .\nb222 , 247 ( 1998 ) ; m.  alford , k.  rajagopal and f.  wilczek , nucl .\nb537 , 443 ( 1999 ) ; t.  schfer and f.  wilczek , phys .\nd60 , 074014 ( 1999 ) ; t.  schfer and f.  wilczek , phys . rev .\nd60 , 114033 ( 1999 ) .\nr.  rapp , t.  schafer , e.  v.  shuryak and m. velkovsky , phys .\n81 , 53 ( 1998 ) good recent reviews include : m.  alford , nucl .\nb(proc . suppl . ) 73 , 161 ( 1999 ) ; e.  shuryak , nucl .\nb(proc . suppl . )\n83 - 84 , 103 ( 2000 ) ; k.  rajagopal and f.  wilczek , e - print hep - ph/0011333 ( 2000 ) .\nj.  b.  kogut , m.  a.  stephanov , d.  toublan , j.  j.  m.  verbaschot and a.  zhitnitsky , nucl .\nb 582 , 477 ( 2000 ) ; j.  b.  kogut , m.  a.  stephanov and d.  toublan , phys .\n464 , 183 ( 1999 ) .\ns.  duane and j.  b.  kogut , phys .\n55 , 2774 ( 1985 ) ; s.  gottlieb , w.  liu , d.  toussaint , r.  l.  renken and r.  l.  sugar , phys .\nd35 , 2531 ( 1987 ) .\ns.  j.  hands , b.  lucini and s  .e .\nmorrison , phys .\nlett 86 , 753 ( 2001 ) .\ns.  j.  hands , j.  b.  kogut , s.  e.  morrison and d.  k.  sinclair , nucl .\nb(proc . suppl . ) 94 , 457 ( 2001 ) .\nj.  b.  kogut , d.  toublan and d.  k.  sinclair , e - print hep - lat/0104010 ( 2001 ) .\ns.  hands , j.  b.  kogut , m .-\nlombardo and s.  e.  morrison , nucl .\nb 558 , 327 ( 1999 ) .\ns.  e.  morrison and s.  j.  hands , in ` strong and electroweak matter ' 98 ( eds . j. ambjrn et al ) p. 364 hep - lat/9902012 ( 1999 ) ; e.  bittner , m .-\nlombardo , h.  markum and r.  pullirsch , nucl .\nproc . suppl .\n94 , 445 ( 2001 ) .\nr.  aloisio , v  .\nazcoiti , g.  di  carlo , a.  galante and a.  f.  grillo , phys .\nb493 , 189 ( 2000 ) .\nw.  pauli , nuovo cimento 6 , 205 ( 1957 ) ; f.  grsey , nuovo cimento 7 , 411 ( 1958 ) ; m.  e.  peskin , nucl .\nb175 , 197 ( 1980 ) .\ns.  j.  hands , i.  montvay , s.  e.  morrison , m.  oevers , l.  scorzato and j.  skullerud , eur .\nj. c17 , 285 ( 2000 ) .\nj.  b.  kogut , nucl .\nb290 , 1 ( 1987 ) ."}
{"lay_summary": " the mutual dipole - dipole interaction of atoms in a trap can affect their fluorescence . \n extremely large effects were reported for double jumps between different intensity periods in experiments with two and three ba@xmath0 ions for distances in the range of about ten wave lengths of the strong transition while no effects were observed for hg@xmath0 at 15 wave lengths . in this theoretical paper \n we study this question for configurations with three and four levels which model those of hg@xmath0 and ba@xmath0 , respectively . for two systems in the hg@xmath0 configuration \n we find cooperative effects of up to 30% for distances around one or two wave lengths , about 5% around ten wave lengths , and , for larger distances in agreement with experiments , practically none . \n this is similar for two v systems . \n however , for two four - level configurations , which model two ba@xmath0 ions , cooperative effects are practically absent , and this latter result is at odds with the experimental findings for ba@xmath0 . ", "article": "the dipole - dipole interaction is ubiquitous in physics and for example responsible for the ever present van der waals force .\nit is also important for envisaged quantum computers based on atoms or ions in traps .\nconsiderable interest in the literature has also been aroused by its cooperative effects on the radiative behavior of atoms @xcite . in an as yet unexplained experiment @xcite with two and three ba@xmath0 ions , which exhibit macroscopic light and dark periods , a large fraction of double and triple jumps was reported , i.e. jumps by two or three intensity steps within a short resolution time .\nthis fraction was orders of magnitudes larger than for independent ions .\nthe quantitative explanation of such a large cooperative effect for distances of the order of ten wave lengths of the strong transition has been found difficult @xcite .\nexperiments with other ions showed no observable cooperative effects @xcite , in particular none were seen for hg@xmath0 for a distance of about 15 wave lengths @xcite .\nmore recently , an unexpected high number of simultaneous quantum jumps in a linear chain of trapped ca@xmath0 ions was reported @xcite while no such effects were found in another experiment @xcite using the same ion species and a similar setup\n.    systems with macroscopic light and dark periods can provide a sensitive test for cooperative effects of the dipole - dipole interaction .\nthese periods can occur for multi - level systems where the electron is essentially shelved for some time in a meta - stable state without photon emission @xcite . for two v systems with macroscopic light and dark periods\nthe effect of the dipole - dipole interaction was investigated numerically in ref .\n@xcite and analytically in ref .\n@xcite and shown to be up to 30% in the double jump rate compared to independent systems .\nmonitoring the dipole - dipole interaction of two v systems via quantum jumps of individual atoms was investigated in ref .\nthe experimental systems of refs .\n@xcite are , however , not in the v configuration so that the results of ref .\n@xcite do not directly apply .\nthe experiment of ref .\n@xcite used two hg@xmath0 ions , with the relevant three levels as in fig .\n[ dsystem ] , which we call a d configuration .    from a theoretical point of view two such systems were studied in ref .\n@xcite for the special case @xmath1 , where @xmath2 is the distance and the wave lengths refer to the respective transitions of fig .\n[ dsystem ] , and for this case no cooperative effects were found .\nthe general case will be treated explicitly further below .\nthe cooperative effects found here are of similar magnitude as for v systems , and for distances of the above range the result of ref .\n@xcite is confirmed .\nour results are also in agreement with the experimentally observed absence of cooperative effects for distances of about 15 wave lengths @xcite .    the levels of ba@xmath0 used in the experiment of refs .\n@xcite are depicted in fig .\n[ 5niveau ] ( a ) .\nthe ground state @xmath3 and the two upper states @xmath4 and @xmath5 constitute a strongly driven fluorescing @xmath6 system which provides the light periods .\nonly when the system is in the ground state can the weak incoherent driving of the @xmath3 - @xmath7 transition populate the meta - stable @xmath5 state , with ensuing dark period .\ntherefore the details of the two upper states of the @xmath6 system play no significant role for the transition to a dark period , and therefore these two states are here replaced by an _ effective _ single level .\nthis leads to the four - level configuration of fig .\n[ 5niveau ] ( b ) .\nthe present paper is , to our knowledge , the first to theoretically investigate possible cooperative effects for two such four - level systems .\nsurprisingly , these effects turn out to be much smaller than for two v systems for distances @xmath8 , and this shows that cooperative effects sensitively depend on how the meta - stable level is populated .\nour results for two four - level configurations are at odds with the experimental findings of ref .\n@xcite on the magnitude of double jump rates for two ba@xmath0 ions @xcite .\nthe methods presented in this paper can be carried over to describe the ca@xmath0 experiments of refs .\n@xcite although this would of course require the use of a different level system .\nthe plan of the paper is as follows . in section [ 2dpert ]\nwe treat two dipole - dipole interacting d systems and explicitly calculate the transition rates between the various light and dark periods as well as the double jump rate .\nthis is done by means of bloch equations . in section [ 4level ]\nthe method is carried over to two four - level systems of fig .\n[ 5niveau ] ( b ) and the transition rates are calculated . in the appendix a direct quantum jump approach @xcite\nis outlined for two d systems .\nthe d configuration , as displayed in fig .\n[ dsystem ] , is a model of the level system of @xmath9 used in the experiments of refs .\n@xcite . the transition @xmath10 is driven by a strong laser .\nlevel @xmath11 can also decay via a slow transition to the meta - stable level @xmath12 .\nfor simplicity all transitions are treated as dipole transitions .    in the following\nwe will investigate two dipole - interacting d systems a fixed distance @xmath2 apart and calculate the transition rates between the three types of fluorescence periods .\nthis will be done in this section by means of bloch equations . in the appendix\nthe efficient quantum jump approach will be applied to two d systems , not only confirming the bloch equation result but also giving higher - order terms . for simplicity\nthe laser direction will be taken as perpendicular to the line joining the two systems .\nrabi frequency and einstein coefficients satisfy @xmath13 it is convenient to use a dicke basis , @xmath14 in fig .\n[ 2dniveaus ] ( a ) the level configuration for two d systems is displayed in this basis , with the slow decays neglected , while in fig .\n[ 2dniveaus ] ( b ) only the slow decays are shown . from fig .\n[ 2dniveaus ] ( a ) it is seen that without slow decays ( i.e. for @xmath15 ) the configuration decouples into three independent subspaces , denoted by @xmath16 , with @xmath17    by means of the conditional hamiltonian , @xmath18 , and the reset operation , @xmath19 , the bloch equations can be written in the form @xcite @xmath20 + \\mathcal{r}(\\rho)~.\\ ] ] for two d systems one finds by the same method as in refs .\n@xcite @xmath21   \\nonumber \\\\ & & \\hspace{0.4 cm } { }    + \\big(a_2+a_3 + 2\\text{i}\\delta_3\\big)\\big[2|e_3\\rangle\\langle e_3|     \\nonumber \\\\ & & \\hspace{3.6 cm } { } +    \\sum_{j=1}^2|s_{j3}\\rangle\\langle s_{j3}| + |a_{j3}\\rangle\\langle    a_{j3}| \\big ] \\nonumber \\\\    & &   \\hspace{0.4 cm } { } + \\sum_{j=1}^2 c_j\\big[|s_{jj+1}\\rangle\\langle    s_{jj+1}| - |a_{jj+1}\\rangle\\langle a_{jj+1}|\\big ] \\nonumber \\\\ & &    \\hspace{1 cm } { }    + c_3 \\big[|s_{13}\\rangle\\langle    s_{13}| - |a_{13}\\rangle\\langle a_{13}| \\big ] \\big\\ } \\nonumber \\\\      & & { } + \\frac{\\hbar}{2}\\omega_3\\big\\{\\sqrt{2}\\big(|g\\rangle\\langle      s_{13}| + |s_{13}\\rangle\\langle e_3| \\big )   \\nonumber \\\\ & & \\hspace{1.5 cm } { } + |s_{12}\\rangle\\langle      s_{23}| - |a_{12}\\rangle\\langle a_{23}| + \\mbox{h.c . } \\big\\}\\end{aligned}\\ ] ] where @xmath22 is the detuning of the laser .\nthe complex dipole coupling constants @xmath23 depend in an oscillatory way on the distance @xmath2 , @xmath24~,\\end{aligned}\\ ] ] with @xmath25 and @xmath26 the angle between the corresponding dipole moment and the line connecting the systems .\nfor maximal effect we take @xmath27 in the following .\nthe real part of @xmath23 leads to changes of the decay constants and the imaginary part to a level shift in the dicke basis , as seen from the expression for @xmath28 .\nthe reset operation can be written in the form @xmath29 , \\end{aligned}\\ ] ] where @xmath30 to determine the transition rates we write eq .\n( [ bloch ] ) in a liouvillean form as @xmath31 where the super - operator @xmath32 is a perturbation depending on the small parameters , and employ the following important property of the time development .\nstarting with an initial state in one of the subspaces @xmath33 , the system will rapidly  on a time scale of @xmath34 and @xmath35approach one of the quasi - stationary states @xmath36 .\nthereafter  for times much larger than @xmath34 and @xmath35 , but much smaller than @xmath37 and @xmath38small populations in the other subspaces will build up until eventually , on a time scale of @xmath37 and @xmath38 , the true stationary state is approached .\nhence we consider a time @xmath39 with @xmath40 and calculate @xmath41 for initial @xmath42 .\nthe quasi - invariant states are easily calculated from @xmath43 as @xmath44 \\nonumber \\\\\n\\mbox{where } \\qquad     n & = & ( a_3 ^ 2 + 2\\omega_3 ^ 2 + 4\\delta_3 ^ 2)^2 \\nonumber \\\\ & & \\hspace{-1.5 cm }     { } + ( a_3 ^ 2 + 4\\delta_3 ^ 2)(|c_3|^2 +    2a_3\\text{re}\\,c_3 + 4\\delta_3\\text{im}\\,c_3 ) \\nonumber\\end{aligned}\\ ] ] as in ref .\n@xcite one has in perturbation theory @xmath45 but , unlike ref .\n@xcite , @xmath46 is not a superposition of just the eigenstates for nonzero eigenvalues of @xmath47 but also of the @xmath48 s .\nwe therefore decompose @xmath46 into a superposition of all eigenstates ( matrices ) of @xmath47 , @xmath49 where @xmath50 contains the contributions from the eigenstates for nonzero eigenvalues of @xmath47 . for later use\nwe note that these eigenvalues are of the order of @xmath51 and @xmath52 .\nthe coefficients @xmath53 can easily be determined by means of the reciprocal ( or dual ) eigenstates where only those for eigenvalue @xmath54 of @xmath47 are needed .\nthey are denoted by @xmath55 and are defined through @xmath56 @xmath57 the latter means @xmath58 , with the adjoint @xmath59 defined with respect to a scalar product given by @xmath60\n. then one has @xmath61 the reciprocals @xmath55 are easily determined as follows . since the bloch equations conserve the trace one has @xmath62 for any @xmath63 .\nthus @xmath64 for any @xmath63 and therefore @xmath65 .\nnow @xmath66 can be written as a sum of terms purely from @xmath67 , and @xmath68 and , since the subspaces are invariant under @xmath47 , these terms must be annihilated by @xmath59 individually .\nthis yields @xmath69 since the sum of the right - hand sides indeed yields @xmath66 and the normalization condition of eq .\n( [ norm ] ) is fulfilled . from eq .\n( [ alpha ] ) one then obtains the @xmath53 . inserting now @xmath46 into eq .\n( [ rhodeltata1 ] ) one obtains    @xmath70    where for the @xmath50 term the upper integration limit can be extended to infinity since @xmath50 belongs to nonzero eigenvalues of @xmath47 and is therefore rapidly damped .\nnow , @xmath71 is of the order of @xmath35 and @xmath34 on @xmath50 , and thus the last term in eq .\n( [ rhotdeltata ] ) is of the order of @xmath72 which is much smaller than @xmath73 , by eq .\n( [ rela3a1 ] ) .\ntherefore the last term in eq .\n( [ rhotdeltata ] ) can be neglected , and this equation then reveals that the @xmath53 s have the meaning of transition rates from subspace @xmath33 to @xmath74 , i.e. , @xmath75    the transition rates are now obtained from eqs .\n( [ pij ] ) , ( [ alpha ] ) , and ( [ rho0dark])-([rho0outer ] ) as    @xmath76    and    @xmath77}{[a_3 ^ 2 +      2\\omega_3 ^ 2 + 4\\delta_3 ^ 2]^2 + [ a^2_3 + 4\\delta^2_3][|c_3|^2 +      2a_3\\text{re}\\,c_3 + 4\\delta_3\\text{im}\\,c_3 ] } \\nonumber \\\\    & = & \\frac{2a_2\\omega_3 ^ 2}{a_3 ^ 2 + 2\\omega_3 ^ 2 + 4\\delta_3 ^ 2}\\left[1      - 2\\text{re}\\,c_3\\frac{a_3(a_3 ^ 2 + 4\\delta_3 ^ 2)}{(a_3 ^ 2 +        2\\omega_3 ^ 2 + 4\\delta_3 ^ 2)^2 } -      4\\text{im}\\,c_3\\frac{\\delta_3(a_3 ^ 2 + 4\\delta_3 ^ 2)}{(a_3 ^ 2 +        2\\omega_3 ^ 2 + 4\\delta_3 ^ 2)^2 } \\right ] + \\mathcal{o}(c_3 ^ 2)~.\\end{aligned}\\ ] ]    one sees that , for two d systems , only @xmath78 depends on the dipole coupling constants @xmath79 in first order .\nthis contrasts with two v systems where both @xmath78 and @xmath80 depend on @xmath79 .\nthe physical reason for this is that transitions between bright periods for two d systems are due to decays and not due to the laser .\nhence the transition rates should essentially be governed by the einstein coefficients of these decays on the one hand and by the population of the states in the initial subsystem on the other hand .\ntherefore the parameter @xmath79 enters only through the quasi - stationary state @xmath36 of the initial subsystem . the absence of a linear @xmath81 and @xmath82 dependence\ncan be understood from fig .\n[ 2dniveaus ] ( b ) as follows . for most slow transitions between two subspaces\nthere are two channels with rates @xmath83 so that @xmath84 cancels .\nstates with a single decay channel lie in @xmath85 and , by symmetry , they appear in pairs with different sign of @xmath84 .    from the transition\nrates @xmath86 one obtains the double jump rate , @xmath87 , by the formula @xcite @xmath88 where @xmath89 is the defining small time interval for a double jump .\nsignificant cooperative effects occur only as long as @xmath52 and @xmath22 are at least an order of magnitude smaller than @xmath51 .\nwhen compared to non interacting systems , the cooperative effects are up to 30% for distances between one and two wave lengths and 5% around ten wave wave lengths , similar as for two v systems . for longer distances they are practically absent and this is consistent with the experimental results of ref .\n[ 2dp21nds ] shows @xmath78 and @xmath87 versus the relative distance @xmath90 for typical parameters , where @xmath91 is the wave length of the strong transition .\nour explicit results for arbitrary @xmath2 confirm the large - distance result of ref .\n@xcite who argued that for @xmath92 cooperative effects are `` suppressed by the rapid decay on the fast transition '' .\nin fact , we find in the appendix that these effects are only to first order independent of the coupling parameter @xmath82 ; the second order contributions in @xmath82 are , however , negligible for the experimental values of ref .\nthe experiments of refs .  @xcite used @xmath93 . as explained in the introduction we model the relevant level scheme by the effective four - level configuration in fig .\n[ 5niveau ] ( b ) .\nthe @xmath94 transition is driven weakly and incoherently by a lamp , while the @xmath95 transition is driven coherently by a strong laser .\nthis time the bloch equation can be written as @xcite @xmath96 +    \\mathcal{r}_w(\\rho ) + \\mathcal{r}(\\rho)\\\\    & \\equiv & \\left\\{\\mathcal{l}_0^{\\dagger(0)}(a_2,a_3,a_4,\\omega_3,\\delta_3,c_3 ) + \\mathcal{l}_0^{\\dagger(1)}(c_2,c_4)\\right\\}\\rho \\nonumber\\end{aligned}\\ ] ] where @xmath97 describes the incoherent driving as in ref .\n@xcite and is given explicitly below .\nthe dicke states are defined in analogy to eq .\n( [ dicke ] ) , and @xmath18 and @xmath98 can be calculated as in refs .  @xcite as    @xmath99       \\nonumber \\\\ & & \\hspace{0.5 cm }       { } + \\big(a_2 + a_4\\big)\\big[2|e_4\\rangle\\langle      e_4| + \\sum_{j=1}^3 \\left\\{|s_{j4}\\rangle\\langle s_{j4}| +      |a_{j4}\\rangle\\langle a_{j4}|\\right\\ } \\big ]     \\nonumber \\\\ & & \\hspace{0.5 cm } { }      + \\big(a_3 + 2\\text{i}\\delta_3\\big)\\big[2|e_3\\rangle\\langle e_3| +      |s_{13}\\rangle\\langle s_{13}| +      |a_{13}\\rangle\\langle a_{13}| + |s_{23}\\rangle\\langle s_{23}| +      |a_{23}\\rangle\\langle a_{23}| + |s_{34}\\rangle\\langle s_{34}| +      |a_{34}\\rangle\\langle a_{34}|       \\big ] \\nonumber \\\\      & & \\hspace{0.5cm}{}+ w\\big[2|g\\rangle\\langle g| +      2|e_4\\rangle\\langle e_4| +      \\sum_{j=1}^3 \\left\\{|s_{j4}\\rangle\\langle s_{j4}| +      |a_{j4}\\rangle\\langle a_{j4}| \\right\\ } + \\sum_{j=2}^4    \\left\\{|s_{1j}\\rangle\\langle s_{1j}| + |a_{1j}\\rangle\\langle a_{1j}|\\right\\ }      \\big ] \\big\\ } \\nonumber \\\\      & & \\hspace{-0.5 cm } { } + \\frac{\\hbar}{2\\text{i}}\\big\\ {      c_2\\big(|s_{23}\\rangle\\langle s_{23}| - |a_{23}\\rangle\\langle      a_{23}|\\big ) +       c_3\\big(|s_{13}\\rangle\\langle s_{13}| - |a_{13}\\rangle\\langle      a_{13}|\\big ) + c_4\\big(|s_{14}\\rangle\\langle s_{14}| -      |a_{14}\\rangle\\langle a_{14}|\\big ) \\big\\ }      \\nonumber \\\\      & & \\hspace{-0.5 cm } { } + \\frac{\\hbar}{2}\\omega_3\\big\\{\\sqrt{2}\\big(|g\\rangle\\langle      s_{13}| + |s_{13}\\rangle\\langle e_3| \\big ) + |s_{12}\\rangle\\langle      s_{23}| - |a_{12}\\rangle\\langle a_{23}| + |s_{14}\\rangle\\langle      s_{34}| + |a_{14}\\rangle\\langle a_{34}| + \\mbox{h.c . }\n\\big\\}\\end{aligned}\\ ] ]    @xmath100   \\end{aligned}\\ ] ]    with @xmath101 the lamp term is obtained as in ref .  @xcite as @xmath102 where @xmath103 is the product of the spectral energy density of the lamp and the einstein @xmath104 coefficient of the @xmath105 transition .\nnow the procedure is similar as for the d system .\nthe liouvillean @xmath47 possesses three ( quasi- ) stationary states @xmath106 , @xmath107 , and @xmath108 which coincide with those for the d systems in eqs .\n( [ rho0dark]-[rho0outer ] ) and which are associated with the dark and the two bright periods . as before , one calculates @xmath41 as in eq .\n( [ rhodeltata1 ] ) and decomposes @xmath46 as in eq .\n( [ l1rho0 ] ) .\nnow , however , the reciprocals @xmath55 are more difficult to determine since @xmath109 can decay into @xmath110 as well as @xmath12 .\nan exact solution of @xmath111 is rather elaborate .\nwe therefore decompose @xmath112 and , by maple , have calculated @xmath113 to first order in perturbation theory with respect to @xmath82 and @xmath114 , with the same constraint as in eq .\n( [ norm ] ) .\nthe lengthy result will not be given here explicitly .\nthe transition rates are again given by @xmath115 and one obtains for two dipole - interacting four - level systems of fig .\n[ 5niveau ] ( b ) to first order in @xmath82 and @xmath114    @xmath116 } \\\\\np_{12 } & = & a_1 \\end{aligned}\\ ] ]    and    @xmath117 } +    2\\,\\text{re}\\,c_3\\frac{a_3\\omega_3 ^ 2(a_3 ^ 2 + 4\\delta_3 ^ 2)}{(a_2+a_4)[a_3 ^ 2 +      2\\omega_3 ^ 2 + 4\\delta_3 ^ 2]^3 } \\nonumber \\\\    & & \\hspace{5.5 cm } { } + 4\\,\\text{im}\\,c_3\\frac{\\delta_3\\omega_3 ^ 2      ( a_3 ^ 2 + 4\\delta_3 ^ 2)}{(a_2+a_4)[a_3 ^ 2 +      2\\omega_3 ^ 2 + 4\\delta_3 ^ 2]^3}\\bigg ] + \\mathcal{o}(c_3 ^ 2).\\end{aligned}\\ ] ]    it is seen that @xmath118 , @xmath119 , and @xmath80 are independent of the coupling parameters and are thus the same as for non interacting systems .\nthese results for two four - level systems show great similarity with those for the two d systems of the proceeding section . in both cases\nonly @xmath78 depends to first order on @xmath79 , the coupling parameter associated with the laser - driven transition .\nhowever , cooperative effects are significantly smaller for the two four - level systems . for fixed laser detuning ,\nthe effect of @xmath79 becomes maximal for @xmath120 .\nfor this value of @xmath52 , fig .\n[ 24nivp21nds ] shows the transition rate @xmath78 from a double intensity period to a unit - intensity period and the double jump rate @xmath87 over the relative distance @xmath90 , with the other parameters as in the experiment @xcite . despite the optimal choice of the rabi frequency , @xmath52 , the deviations from the value for non - interacting systems are very small .\nalready for a distance of about a wave length @xmath91 , they are not more than @xmath121 for @xmath78 when compared to non interacting systems , while for @xmath87 they are less than 1 .\nwe have investigated the effect of the dipole - dipole interaction for two fluorescing systems with macroscopic light and dark periods , first for three - level d configurations and then for four - level systems .\nthe three - level d configuration models the relevant levels of hg@xmath0 used in the experiments of ref .\n@xcite , and the four - level configuration is an effective model for ba@xmath0 , used in the experiments of ref .  @xcite . for these systems\none has macroscopic light and dark periods , and their statistics can be a sensitive test of the dipole - dipole interaction .\nwe have explicitly calculated the transition rates between the different light and dark periods by employing bloch equations as well as a direct quantum jump approach . from the transition\nrates the double jump rates are obtained .    for two d systems the effect of the dipole - dipole interaction is of similar magnitude as for two v system investigated earlier @xcite and shown to be up to 30 % for distances of the order of a wave length of the strong transition and about 5% around ten wave lengths , when compared to independent systems . for longer distances\nthey are practically absent and this is in agreement with the experimental results of ref .\nwe have also recovered the special case of ref .\n@xcite where distances satisfying @xmath1 were considered and where an argument for the non dependence on the dipole coupling constant @xmath82 was given . here\nwe have shown that this holds to first order and that the explicitly determined second order terms are negligibly small .\nfor the effective model of two ba@xmath0 systems our results yield very small and hardly observable cooperative effects for the double jump rate .\nthis is at odds with experimental result in ref .\nour method also applies to three ba@xmath0 ions , but this is more tedious and requires another paper .\nalso a theoretical investigation of the experiments with ca@xmath0 @xcite is possible with our method . for this\nthe calculations have to be carried over to a level scheme modeling that of ca@xmath0 .\na further conclusion of our work is the observation that the magnitude of cooperative effects due to the dipole - dipole interaction sensitively depends on how the meta - stable level is populated .\nthe procedure will first be explained for a single @xmath122 system which has just two types of periods , light and dark ones . from its level configuration in fig .\n[ dsystem ] it is evident that the onset of a dark period is preceded by a photon from the @xmath123 transition , with frequency @xmath124 .\nhence , starting at @xmath125 in @xmath110 , the probability density for the next photon to occur at time @xmath126 and to come from the @xmath123 transition is @xmath127 since @xmath28 gives the time development between photon emissions @xcite .\nthen its time integral , @xmath128 is the probability for the next emitted photon to come from the @xmath123 transition .\nnow , let the photon rate in a light period be denoted by @xmath129 . then , after each photon of the light period the system is reset to the ground state and thereafter , with probability @xmath130 , emits a photon from the @xmath131 this can be carried over to two dipole interacting @xmath122 systems as follows .\nwe consider an emission trajectory and assume to be in a particular intensity period , of unit intensity , say .\nin contrast to a single @xmath122 system , the reset state after a photon emission in this period is not always quite the same , but it is reasonable to start from @xmath107 and to use @xmath132 as an average reset state .\nthe transition to a double - intensity period is marked by a photon from the @xmath133 transition , and therefore the probability density for such a transition , starting from the above reset state , is @xmath134 integration over @xmath126 gives the total transition probability , denoted by @xmath135 .\nthe photon rate in a period of unit intensity is that of two dipole interacting two level systems and is given by @xcite      thus @xmath80 is given by @xmath137 in a similar way one obtains @xmath119 and @xmath78 .\nthe transition rate @xmath118 can be directly read off from the no - photon probability @xmath138 .\none obtains the same results as in section [ 2dpert ] when one expands in the small parameters . in the case\n@xmath92 one can put @xmath139 and one obtains for example @xmath140"}
{"lay_summary": " we define mutation on coloured quivers associated to tilting objects in higher cluster categories . \n we show that this operation is compatible with the mutation operation on the tilting objects . \n this gives a combinatorial approach to tilting in higher cluster categories and especially an algorithm to determine the gabriel quivers of tilting objects in such categories .    \n [ section ] [ lemma]proposition [ lemma]corollary [ lemma]theorem [ lemma]remark [ lemma]definition [ lemma]example ", "article": "a cluster category is a certain 2-calabi - yau orbit category of the derived category of a hereditary abelian category .\ncluster categories were introduced in @xcite in order to give a categorical model for the combinatorics of fomin - zelevinsky cluster algebras @xcite .\nthey are triangulated @xcite and admit ( cluster-)tilting objects , which model the clusters of a corresponding ( acyclic ) cluster algebra @xcite . each cluster in a fixed cluster algebra comes together with a finite quiver , and in the categorical model this quiver is in fact the gabriel quiver of the corresponding tilting object @xcite .\na principal ingredient in the construction of a cluster algebra is quiver mutation .\nit controls the exchange procedure which gives a rule for producing a new cluster variable and hence a new cluster from a given cluster .\nexchange is modeled by cluster categories in the acyclic case @xcite in terms of a mutation rule for tilting objects , i.e. a rule for replacing an indecomposable direct summand in a tilting object with another indecomposable rigid object , to get a new tilting object .\nquiver mutation describes the relation between the gabriel quivers of the corresponding tilting objects .\nanalogously to the definition of the cluster category , for a positive integer @xmath0 , it is natural to define a certain @xmath1-calabi - yau orbit category of the derived category of a hereditary abelian category .\nthis is called the _\n@xmath0-cluster category_. implicitly , @xmath0-cluster categories was first studied in @xcite , and their ( cluster-)tilting objects have been studied in @xcite .\ncombinatorial descriptions of @xmath0-cluster categories in dynkin type @xmath2 and @xmath3 are given in @xcite .    in cluster categories\nthe mutation rule for tilting objects is described in terms of certain triangles called _ exchange triangles_. by @xcite the existence of exchange triangles generalizes to @xmath0-cluster categories .\nit was shown in @xcite that there are exactly @xmath1 non - isomorphic complements to an almost complete tilting object , and that they are determined by the @xmath1 exchange triangles defined in @xcite .\nthe aim of this paper is to give a combinatorial description of mutation in @xmath0-cluster categories . _ a priori _\n, one might expect to be able to do this by keeping track of the gabriel quivers of the tilting objects .\nhowever , it is easy to see that the gabriel quivers do not contain enough information .    we proceed to associate to a tilting object a quiver each of whose arrows has an associated colour @xmath4 . the arrows with colour 0 form the gabriel quiver of the tilting object .\nwe then define a mutation operation on coloured quivers and show that it is compatible with mutation of tilting objects .\na consequence is that the effect of an arbitrary sequence of mutations on a tilting object in an @xmath0-cluster category can be calculated by a purely combinatorial procedure .\nour definition of a coloured quiver associated to a tilting object makes sense in any @xmath1-calabi - yau category , such as for example those studied in @xcite .\nwe hope that our constructions may shed some light on mutation of tilting objects in this more general setting .    in section 1 , we review some elementary facts about higher cluster categories . in section 2 , we explain how to define the coloured quiver of a tilting object , we define coloured quiver mutation , and we state our main theorem . in sections 3 and 4 , we state some further lemmas about higher cluster categories , and we prove certain properties of the coloured quivers of tilting objects .\nwe prove our main result in sections 5 and 6 . in sections 7 and 8\nwe point out some applications . in section 9\nwe interpret our construction in terms of @xmath0-cluster complexes . in section 10\n, we give an alternative algorithm for computing coloured quiver mutation .\nsection 11 discusses the example of @xmath0-cluster categories of dynkin type @xmath2 , using the model developed by baur and marsh @xcite .\nwe would like to thank idun reiten , in conversation with whom the initial idea of this paper took shape .\nlet @xmath5 be an algebraically closed field , and let @xmath6 be a finite acyclic quiver with @xmath7 vertices .\nthen the path algebra @xmath8 is a hereditary finite dimensional basic @xmath5-algebra    let @xmath9 be the category of finite dimensional left @xmath10-modules .\nlet @xmath11 be the bounded derived category of @xmath10 , and let @xmath12 $ ] be the @xmath13th shift functor on @xmath14 .\nwe let @xmath15 denote the auslander - reiten translate , which is an autoequivalence on @xmath14 such that we have a bifunctorial isomorphism in @xmath14 @xmath16 ) \\simeq\nd{\\operatorname{hom}\\nolimits}(b,\\tau a).\\ ] ] in other words @xmath17 \\tau$ ] is a serre functor .\nlet @xmath18 $ ] .\nthe @xmath0-cluster category is the orbit category @xmath19 $ ] .\nthe objects in @xmath20 are the objects in @xmath14 , and two objects @xmath21 are isomorphic in @xmath20 if and only if @xmath22 in @xmath14 .\nthe maps are given by @xmath23 .\nby @xcite , the category @xmath20 is triangulated and the canonical functor @xmath24 is a triangle functor .\nwe denote therefore by @xmath25 $ ] the suspension in @xmath20 .\nthe @xmath0-cluster category is also krull - schmidt and has an ar - translate @xmath15 inherited from @xmath14 , such that the formula ( [ ar ] ) still holds in @xmath20 . if follows that @xmath17 \\tau$ ] is a serre functor for @xmath20 and that @xmath20 is @xmath1-calabi - yau , since @xmath26 $ ] .\nthe indecomposable objects in @xmath14 are of the form @xmath27 $ ] , where @xmath28 is an indecomposable @xmath10-module and @xmath29 .\nwe can choose a fundamental domain for the action of @xmath18 $ ] on @xmath14 , consisting of the indecomposable objects @xmath27 $ ] with @xmath30 , together with the objects @xmath31 $ ] with @xmath28 an indecomposable projective @xmath10-module .\nthen each indecomposable object in @xmath20 is isomorphic to exactly one of the indecomposables in this fundamental domain .\nwe say that @xmath32 $ ] has degree @xmath33 , denoted @xmath34 ) = d$ ] .\nfurthermore , for an arbitrary object @xmath35 in @xmath36 , we let @xmath37 $ ] be the @xmath10-module which is the ( shifted ) direct sum of all summands @xmath38 of @xmath39 with @xmath40 .    in the following theorem\nthe equivalence between ( i ) and ( ii ) is shown in @xcite and the equivalence between ( i ) and ( iii ) is shown in @xcite .\nlet @xmath41 be an object in @xmath20 satisfying @xmath42 ) = 0 $ ] for @xmath43 .\nthen the following are equivalent    * if @xmath44 ) = 0 $ ] for @xmath43 then @xmath45 is in @xmath46 . * if @xmath47 ) = 0 $ ] for @xmath43 then @xmath45 is in @xmath46 .\n* @xmath41 has @xmath48 indecomposable direct summands , up to isomorphism .\nhere @xmath46 denotes the additive closure of @xmath41 . a ( cluster-)tilting object @xmath41 in an @xmath0-cluster is an object satisfying the conditions of the above theorem . for a tilting object @xmath49 , with each @xmath50 indecomposable , and @xmath51 an indecomposable direct summand , we call @xmath52 an almost complete tilting object .\nwe let @xmath53 denote the @xmath5-space of irreducible maps @xmath54 in a krull - schmidt @xmath5-category @xmath55 .\nthe following crucial result is proved in @xcite and @xcite .\n[ p : number ] there are , up to isomorphism , @xmath1 complements of an almost complete tilting object .\nlet @xmath51 be an indecomposable direct summand in an @xmath0-cluster tilting object @xmath56 .\nthe complements of @xmath57 are denoted @xmath58 for @xmath59 , where @xmath60 . by @xcite\n, there are @xmath1 exchange triangles @xmath61 here the @xmath62 are in @xmath63 and the maps @xmath64 ( resp .\n@xmath65 ) are minimal left ( resp .\nright ) @xmath63-approximations , and hence not split mono or split epi . note that by minimality , the maps @xmath64 and @xmath65 have no proper zero summands .\nwe first recall the definition of quiver mutation , formulated in @xcite in terms of skew - symmetric matrices .\nlet @xmath66 be a quiver with vertices @xmath67 and with no loops or oriented two - cycles , where @xmath68 denotes the number of arrows from @xmath13 to @xmath69 .\nlet @xmath70 be a vertex in @xmath71 .\nthen , a new quiver @xmath72 is defined by the following data    @xmath73 it is easily verified that this definition is equivalent to the one of fomin - zelevinsky .\nnow we consider coloured quivers .\nlet @xmath0 be a positive integer .\nan @xmath0-coloured ( multi-)quiver @xmath71 consists of vertices @xmath67 and coloured arrows @xmath74 , where @xmath75 .\nlet @xmath76 denote the number of arrows from @xmath13 to @xmath70 of colour @xmath77 .\nwe will consider coloured quivers with the following additional conditions .    *\nno loops : @xmath78 for all @xmath79 .\n* monochromaticity : if @xmath80 , then @xmath81 for @xmath82 * skew - symmetry : @xmath83 .\nwe will define an operation on a coloured quiver @xmath71 satisfying the above conditions .\nlet @xmath70 be a vertex in @xmath71 and let @xmath84 be the coloured quiver defined by    @xmath85    in an @xmath0-cluster category @xmath20 , for every tilting object @xmath86 , with the @xmath50 indecomposable , we will define a corresponding @xmath0-coloured quiver @xmath87 , as follows .\nlet @xmath88 be two non - isomorphic indecomposable direct summands of the @xmath0-cluster tilting object @xmath41 and let @xmath89 denote the multiplicity of @xmath90 in @xmath91 .\nwe define the @xmath0-coloured quiver @xmath87 of @xmath41 to have vertices @xmath13 corresponding to indecomposable direct summands @xmath50 , and @xmath92 .\nnote , in particular , that the @xmath93-coloured arrows are the arrows from the gabriel quiver for the endomorphism ring of @xmath41 .    by definition\n, @xmath87 satisfies condition ( i ) .\nwe show in section [ s : higher ] that ( ii ) is satisfied ( this also follows from @xcite ) , and in section [ s : symmetry ] that ( iii ) is also satisfied .    the aim of this paper is to prove the following theorem , which is a generalization of the main result of @xcite .\n[ t : main ] let @xmath86 and @xmath94 be @xmath0-tilting objects , where there is an exchange triangle @xmath95\n. then @xmath96 .    in the case\n@xmath97 the coloured quiver of a tilting object @xmath41 is given by @xmath98 and @xmath99 where @xmath100 denotes the number of arrows in the gabriel quiver of @xmath41\n. then coloured mutation of the coloured quiver corresponds to fz - mutation of the gabriel quiver .\nlet @xmath6 be @xmath101 with linear orientation , i.e. the quiver @xmath102 .\nthe ar - quiver of the 2-cluster category of @xmath103 is @xmath104 & & { i_3 } \\ar[dr ] & & * + + [ o][f-]{p_3[1 ] } \\ar[dr ] & & i_1[1 ] \\ar[dr ] & & p_1[2]\\ar[dr ] \\\\   p_2[2 ] \\ar[ur ] \\ar[dr ] & & { p_2 } \\ar[ur ] \\ar[dr ] & & * + [ o][f-]{i_2 } \\ar[ur ] \\ar[dr ] & & p_2[1 ] \\ar[ur ] \\ar[dr ] & &   i_2[1]\\ar[ur]\\ar[dr ] & & p_2[2 ]    \\\\   & { p_3 } \\ar[ur ] & & * + [ o][f-]{i_1 } \\ar[ur ] & & p_1[1 ] \\ar[ur ] & & i_3[1]\\ar[ur ] & & p_3[2 ] \\ar[ur ] & &   } \\ ] ] the direct sum @xmath105 $ ] of the encircled indecomposable objects gives a tilting object .\nits coloured quiver is @xmath106 & i_2 \\ar@<0.6ex>^{(0)}[r ] \\ar@<0.6ex>^{(2)}[l ] &   p_3[1 ] \\ar@<0.6ex>^{(2)}[l ]   } \\ ] ] now consider the exchange triangle @xmath107 \\to i_3[1 ] \\to\\ ] ] and the new tilting object @xmath108 \\amalg p_3[1]$ ] .\nthe coloured quiver of @xmath109 is @xmath110 \\ar@<0.6ex>^{(1)}[r ] & i_3[1 ] \\ar@<0.6ex>^{(2)}[r ] \\ar@<0.6ex>^{(1)}[l ] &   p_3[1 ] \\ar@<0.6ex>^{(0)}[l ]   \\ar@<0.6ex>^{(2)}@/^3.5pc/[ll ] } \\ ] ]\nin this section we summarize some further known results about @xmath0-cluster categories .\nmost of these are from @xcite and @xcite .\nwe include some proofs for the convenience of the reader\n.    tilting objects in @xmath111 give rise to partial tilting modules in @xmath9 , where a _\npartial tilting module _ @xmath28 in @xmath9 , is a module with @xmath112 .\n[ l : partial ]    * when @xmath41 is a tilting object in @xmath36 , then each @xmath113 is a partial tilting module in @xmath9 . * the endomorphism ring of a partial tilting module has no oriented cycles in its ordinary quiver .\n\\(a ) is obvious from the definition .\nsee ( * ? ? ?\n4.2 ) for ( b ) .    in the following note that degrees of objects are always considered with a fixed choice of fundamental domain , and sums and differences of degrees are always computed modulo @xmath1 .    [\nl : div ] assume @xmath114 .\n* @xmath115 for any indecomposable exceptional object @xmath39 .\n* we have that @xmath116 * the distribution of degrees of complements is one of the following * * there is exactly one complement of each degree , or * * there is no complement of degree @xmath0 , two complements in one degree @xmath117 , and exactly one complement in all degrees @xmath118 . * if @xmath119 , then @xmath120 . * for @xmath121 we have @xmath122 ) = \\begin{cases }\nk & \\text { if $ c'-c+t = 0 ( { \\operatorname{mod}\\nolimits}m+1)$ } \\\\ 0 & \\text { else } \\end{cases}\\ ] ]    \\(a ) follows from the fact that @xmath123 for exceptional objects and the definition of maps in a @xmath0-cluster category .\n\\(b ) follows from the fact that @xmath124 ) \\neq 0 $ ] , since in the exchange triangles , the @xmath125 are not split mono and ( c ) follows from ( b ) .\nconsidering the two different possible distributions of complements , we obtain from ( c ) that if @xmath126 and @xmath127 and @xmath128 , then @xmath129 .\nconsider the case @xmath130 .\nwe can assume @xmath131 , since else the statement is void .\nhence we can clearly assume that @xmath132 .\nthere is an exchange triangle induced from an exact sequence in @xmath9 ,    @xmath133.\\ ] ] it is clear that @xmath134 , t_i^{(c-1 ) } ) = 0 $ ] , since @xmath131 .\nwe claim that also @xmath135 .\nthis holds since @xmath136 is a partial tilting object in @xmath10 , and so there are no cycles in the endomorphism ring , by lemma [ l : partial ] .\nhence also @xmath137 follows , and this finishes the proof for ( d ) .\nfor ( e ) we first apply @xmath138 to the exchange triangle @xmath139 and consider the corresponding long - exact sequence , to obtain that @xmath140 ) = \\begin{cases } k & \\text { if $ t = 1 $ } \\\\ 0 & \\text { if $ t=0 $ or $ t \\in \\{2 , \\dots , m \\}$ } \\end{cases}.\\ ] ] now consider @xmath141)$ ] . when @xmath142 , we have that @xmath143 ) \\simeq { \\operatorname{hom}\\nolimits}(t_i^{(c+u+1 ) } , t_i^{(c)}[v+1 ] ) \\simeq \\\\ { \\operatorname{hom}\\nolimits}(t_i^{(c-1 ) } , t_i^{(c)}[v+m - u ] ) \\simeq { \\operatorname{hom}\\nolimits}(t_i^{(c ) } , t_i^{(c-1)}[1+u - v ] ) .\n\\end{gathered}\\ ] ]    when @xmath144 , we have that @xmath145 ) \\simeq { \\operatorname{hom}\\nolimits}(t_i^{(c+u-1 ) } , t_i^{(c)}[v-1 ] ) \\simeq \\\\ { \\operatorname{hom}\\nolimits}(t_i^{(c ) } , t_i^{(c)}[v - u]).\\ ] ]    combining these facts , ( e ) follows .\n[ l : div2 ] the following statements are equivalent    * @xmath146 ) = 0 $ ] * @xmath90 is not a direct summand in @xmath147 * @xmath50 is not a direct summand in @xmath148    furthermore , @xmath149 ) = 0 $ ] for @xmath150 .\nnote that @xmath151 , so ( b ) and ( c ) are equivalent .\nconsider the exact sequence @xmath152 ) \\to { \\operatorname{hom}\\nolimits}(t_i^{(c ) } , b_j^{(0)}[1 ] ) \\to \\\\   { \\operatorname{hom}\\nolimits}(t_i^{(c ) } , t_j^{(1)}[1 ] ) \\to { \\operatorname{hom}\\nolimits}(t_i^{(c ) } , t_j^{(0)}[2 ] ) \\to \\end{gathered}\\ ] ] coming from applying @xmath153 to the exchange triangle @xmath154 the first and fourth terms are always zero . using [ l : div](e ) we get that the second term ( and hence the third ) is non - zero if and only if @xmath155 and @xmath50 is a direct summand in @xmath148 .\n( @xcite)[l : composing ] for @xmath156 , the composition @xmath157   \\circ h_k^{(v-2)}[2 ] \\circ \\cdots \\circ   h_k^{(v - l+1)}[l-1 ] \\colon t_k^{(v ) } \\to t_k^{(v - l)}[l]\\ ] ] is non - zero and a basis for @xmath158)$ ] .    for @xmath97 ,\nsee @xcite .\nassume @xmath159 .\nfor the first claim see @xcite , while the second claim then follows from lemma [ l : div](e ) .\nwe include an independent proof of the following crucial property .\n@xcite [ l : disjoint ] @xmath160 and @xmath161 has no common non - zero direct summands whenever @xmath162 .    when @xmath97 , this is proved in @xcite .\nassume @xmath163 .\nwe consider two cases , @xmath164 or @xmath165 .\nconsider first the case @xmath166 . without loss of generality\nwe can assume @xmath167 and @xmath168 , and that @xmath169 .\nassume that there exists a ( non - zero ) indecomposable @xmath170 , which is a direct summand in @xmath171 and in @xmath172 .\nwe have that @xmath173 by lemma [ l : div](b ) .\nassume first @xmath174 .\nthen the exchange triangle @xmath175 is induced from the degree 0 part of the derived category , and hence from an exact sequence in @xmath9 .\nthen the endomorphism ring of the partial tilting module @xmath176 has a cycle , which is a contradiction to lemma [ l : partial ] .\nassume now that @xmath177 .\nthen @xmath178 , where 0 can only occur if @xmath179 . if @xmath180 , then clearly @xmath181 , and hence the partial tilting module @xmath182 contains a cycle , which is a contradiction .\nassume that @xmath183 ( and hence @xmath179 ) . then @xmath184 . if @xmath181 , we get a contradiction as in the previous case .\nif @xmath185 , consider the exchange triangle @xmath186 which is induced from an exact sequence in @xmath9 .\nhence there is a _ non - zero _\nmap @xmath187 obtained by composing @xmath188 with the monomorphism @xmath189 , and thus there are cycles in the endomorphism ring of the partial tilting module @xmath190 , a contradiction .\nthis finishes the case with @xmath191 .\nassume now that @xmath192 .\nthen we have @xmath193 .\nsince @xmath194 and @xmath195 , we have by lemma [ l : div](c ) that @xmath196 .\nso without loss of generality we can assume @xmath197 .\nassume that @xmath198 . then @xmath199 using lemma [ l : div](c ) and the fact that @xmath194\n. then also @xmath200 .\nbut @xmath201 , so @xmath202 , contradicting the fact that @xmath195 .\n@xmath87 satisfies condition ( ii ) .\nlet @xmath203 be a tilting object . in this section we show that the coloured quiver @xmath87 satisfies condition ( iii ) .\n[ p : symmetry ] with the notation of the previous section , we have @xmath204 .    by lemma [ l : div2 ]\nwe only need to consider the case @xmath205 .\nit is enough to show that @xmath206 .\nwe first prove    [ l : non - van ] let @xmath207 be irreducible in @xmath208 . then the composition @xmath209\n\\circ \\gamma_i^{(0,c)}[-c ]   \\colon t_j^{(c)}[-c ] \\to t_i^{(m - c+1)}$ ] is non - zero .\nwe have already assumed @xmath210 .\nassume @xmath211 \\circ h_i^{(0)}[-c ] \\colon t_j^{(c)}[-c ] \\to t_i^{(0)}[-c ] \\to t_i^{(m)}[-c+1]\\ ] ] is zero .\nthis means that @xmath212 must factor through @xmath213 .\nsince @xmath50 is by assumption a summand in @xmath214 , we have that @xmath50 is not a summand in @xmath148 by proposition [ l : disjoint ] .\nsince @xmath215 , we have that @xmath90 is not a direct summand in @xmath147 .\nthis means that @xmath216 is not irreducible in @xmath208 , a contradiction .\nso @xmath209 \\circ h_i^{(0)}[-c ] \\colon t_j^{(c)}[-c ] \\to t_i^{(m)}[-c+1]$ ] is non - zero .\nassume @xmath217 .\nif the composition @xmath209 \\circ h_i^{(0)}[-c ] \\circ h_i^{(m)}[-c+1]$ ] is zero , then @xmath209 \\circ h_i^{(0)}[-c]$ ] factors through @xmath218 \\to t_i^{(m)}[-c+1].\\ ] ] we claim that @xmath219 , b_i^{(m-1)}[-c+1 ] ) \\simeq { \\operatorname{hom}\\nolimits}(t_j^{(c ) } , b_i^{(m-1)}[1 ] ) = 0 $ ] .\nthis clearly holds if @xmath90 is not a summand of @xmath220 .\nin addition we have that @xmath221 ) = 0 $ ] since @xmath217 , using lemma [ l : div](e ) .\nthis is a contradiction , and this argument can clearly be iterated to see that @xmath209 \\circ \\gamma_i^{(0,c)}[-c ]   \\colon t_j^{(c)}[-c ] \\to t_i^{(m - c+1)}$ ] is non - zero , using lemma [ l : div](e ) .    we now show that any irreducible map @xmath207 gives rise to an irreducible map @xmath222\n.    consider the composition @xmath223 \\overset{g_j^{(c)}[-c]}{\\longrightarrow } t_j^{(c)}[-c ] \\longrightarrow t_i^{(m - c+1)}.\\ ] ] since @xmath50 is a summand in @xmath214 by assumption , it is not a summand in @xmath224 .\nthus , @xmath224 is in @xmath225 .\nsince @xmath226)= 0 $ ] for any @xmath39 in @xmath227 , the composition vanishes .    using the exchange triangle @xmath223 \\overset{g_j^{(c)}[-c]}{\\longrightarrow } t_j^{(c)}[-c ] \\overset{h_j^{(c)}[-c]}{\\longrightarrow } t_j^{(c-1)}[-c+1],\\ ] ] we see that @xmath209 \\circ \\gamma_i^{(0,c)}[-c ] \\colon t_j^{(c)}[-c ] \\to t_i^{(m - c+1)}$ ] factors through the map @xmath228 \\overset{h_j^{(c)}[-c]}{\\longrightarrow } t_j^{(c-1)}[-c+1]$ ] , i.e. there is a commutative diagram    @xmath229 \\ar^{g_j^{(c)}[-c]}[r ]   & t_j^{(c)}[-c ] \\ar^{h_j^{(c)}[-c]}[r ] \\ar[d ] &   t_j^{(c-1)}[-c+1 ] \\ar[r ]   \\ar^{\\phi_1}[dl ] &   \\\\ & t_i^{(m - c+1 ) } & & } \\ ] ]    similarly , using the exchange triangle @xmath230 \\overset{g_j^{(c-1)}[-c+1]}{\\longrightarrow } t_j^{(c-1)}[-c+1 ] \\overset{h_j^{(c-1)}[-c+1]}{\\longrightarrow } t_j^{(c-2)}[-c+2]\\ ] ] we obtain a map @xmath231 \\to   t_i^{(m - c+1)}$ ]    repeating this argument @xmath79 times we obtain a map @xmath232 , such that @xmath233 \\circ \\phi_c = \\alpha[-c ] \\circ \\gamma_i^{(0,c)}$ ]\n.    @xmath234 \\ar_{h_j^{(c)}[-c]}[d ] \\ar[r ] & t_i^{(m - c+1 ) }   \\\\    t_j^{(c-1)}[-c+1 ] \\ar_{h_j^{(c-1)}[-c+1]}[d ] \\ar^{\\phi_1}[ur ] & \\\\ t_j^{(c-2)}[-c+2 ] \\ar_{h_j^{(c-2)}[-c+2]}[d ] \\ar^{\\phi_2}[uur ] & \\\\\n\\vdots \\ar[d ] &   \\\\\nt_j    \\ar^{\\phi_c}[uuuur ] & \\\\ & } \\ ] ]    we claim that    [ l : irred ] there is a map @xmath235 , such that @xmath233 \\circ \\beta = \\alpha[-c ] \\circ \\gamma_i^{(0,c)}$ ] , and such that @xmath236 is irreducible in @xmath237\n.    let @xmath238 be a minimal left @xmath239-approximation , with @xmath240 in @xmath241 and @xmath242 in @xmath243 .\nlet @xmath244 be as above , and factor it as @xmath245 since @xmath246 factors through @xmath247 $ ] , we have that @xmath233 \\psi '' = 0 $ ] , so we have @xmath248(\\psi ' \\epsilon ' + \\psi '' \\epsilon'')= \\gamma_j^{(c , c)}[-c ] \\psi ' \\epsilon'.\\ ] ] hence , let we let @xmath249 and since the summands in @xmath250 are isomorphisms , it is clear that @xmath236 is irreducible .\nnext , assume @xmath251 is a basis for the space of irreducible maps from @xmath252 to @xmath50 .\nthen , by lemma [ l : non - van ] the set @xmath253 is also linearly independent . for each @xmath254 , consider the corresponding map @xmath255 , such that @xmath233 \\circ \\beta_t = \\alpha_t[-c ] \\circ \\gamma_i^{(0,c)}$ ] , and which we by lemma [ l : irred ] can assume is irreducible . assume a non - trivial linear combination @xmath256 is zero\n. then also @xmath257 \\circ \\beta_t ) =   \\sum k_t \\alpha_t \\circ \\gamma_i^{(0,c)}=0 $ ] . but\nthis contradicts lemma [ l : non - van ] since @xmath258 is irreducible .\nhence it follows that @xmath259 is also linearly independent .\nhence , in the exchange triangle @xmath260 , we have that @xmath90 appears with multiplicity at least @xmath261 in @xmath262 .\nso , we have that @xmath206 , and the proof of the proposition is complete .\nin this section we show how mutation in the vertex @xmath70 affects the complements of the almost complete tilting object @xmath263 . as\nbefore , let @xmath264 be an @xmath0-tilting object , and let @xmath94 .    we need to consider @xmath265 \\ar^{(e)}[r ] & t_j \\ar^{(d)}[r ] & t_k } \\ ] ] for all possible values of @xmath266 . however , we have the following restriction on the colour of arrows .    [\np : limits ] assume @xmath267 and @xmath268\n. then @xmath269 .\nconsider the exchange triangle @xmath270 .\nnote that @xmath90 is a direct summand in the middle term @xmath271 by the assumption that @xmath272 .\nconsider also the exchange triangle @xmath273 .\npick an arbitrary non - zero map @xmath274 , and consider the map @xmath275 .\nit suffices to show that whenever @xmath276 , then @xmath277 is not irreducible in @xmath46 .\nso assume that @xmath276 .\nwe claim that there is a commutative diagram @xmath278 \\ar[d ] &   t_j \\amalg x ' \\ar[r ] \\ar^{\\left ( \\begin{smallmatrix } h & 0 \\\\ 0 & 0 \\end{smallmatrix } \\right)}[d ] &    t_i^{(e+1 ) } \\ar[r ] \\ar[d ] & \\\\\nt_i^{(c ) } \\ar[r ] & t_k \\amalg z \\ar[r ] & t_i^{(c+1 ) } \\ar[r ] &   } \\ ] ] where the rows are the exchange triangles .\nthe composition @xmath279 is zero since    * if @xmath280 @xmath281 by using @xmath276 and lemma [ l : div](e ) * if @xmath282 , there is no non - zero composition @xmath283    hence the leftmost vertical map exists , and then the rightmost map exists , using that @xmath20 is a triangulated category .\nthen , since @xmath284 , t_i^{(c ) } ) = 0 $ ] by lemma [ l : div](e ) , there is a map @xmath285 , such that @xmath286 .\nhence there is map @xmath287 such that @xmath288 . by restriction\nwe get @xmath289    under the assumption @xmath290 we have that @xmath291 can not be irreducible in @xmath292 .\nhence @xmath293 , where @xmath51 is not summand in @xmath294 .\nalso , by proposition [ l : disjoint ] we have that @xmath90 is not a summand in @xmath294 .\nif @xmath295 was irreducible in @xmath296 , then there would be an irreducible map @xmath297 in @xmath298 , and since @xmath299 , this does not hold , by proposition [ l : disjoint ] .\nhence , @xmath300 , where @xmath90 is not a direct summand of @xmath301 . also by proposition [ l : disjoint ] we have that @xmath51 is not a summand of @xmath301 . by ( [ factor ] ) , this shows that @xmath274 is not irreducible in @xmath46 .\nlet @xmath302 .\nfor @xmath303 , let @xmath304 denote the complements of @xmath305 , where there are exchange triangles @xmath306    we first want to compare @xmath304 with @xmath307 .    [ l : samecomp ] assume that @xmath308 for @xmath309 and that @xmath310 .\n* for @xmath311 , the minimal left @xmath312-approximation @xmath313 is also an @xmath314-approximation . * for @xmath315\n, we have @xmath316 .    by assumption @xmath90\nis not a direct summand in any of the @xmath317 .\nassume there is a map @xmath318 and consider the diagram    @xmath319 \\ar[r ] &   t_i^{(u ) } \\ar[r ] \\ar [ d ] & b_i^{(u ) } \\ar [ r ] & \\\\   & t_j^{(1 ) } & & } \\ ] ] since @xmath320)= 0 $ ] by lemma [ l : div2 ] , we see that the map @xmath318 factors through @xmath313 .\nhence the minimal left @xmath312-approximation @xmath313 is also an @xmath314-approximation , so we have proved ( a ) .\nthen ( b ) follows directly .\n[ l : comp ] assume that @xmath321 and there are exchange triangles @xmath322 and @xmath323 where @xmath324 and @xmath325 , i.e. @xmath326 and @xmath327 , where @xmath51 is not isomorphic to any direct summand in @xmath328 .    * the composition @xmath329 is a left @xmath314-approximation .\n* there is a triangle @xmath330 with @xmath331 in @xmath332 and @xmath333 .\n* there is a triangle @xmath334 .\nconsider an arbitrary map @xmath335 with @xmath45 in @xmath314 .\nwe have that @xmath336 ) = 0 $ ] , by lemma [ l : div2 ] .\nhence , by applying @xmath337 to the triangle ( [ i - tri ] ) we get that @xmath338 factors through @xmath339 . by applying @xmath337 to the triangle ( [ j - tri ] ) , and using that @xmath340 ) = 0 $ ] , we get that @xmath338 factors through @xmath341 .\nthis proves ( a ) . for ( b ) and ( c )\nwe use the exchange triangles ( [ i - tri ] ) and ( [ j - tri ] ) and the octahedral axiom to obtain the commutative diagram of triangles    @xmath342 \\ar@{=}[d ] & ( t_j)^p \\amalg x \\ar[r ] \\ar[d ]             & t_i^{(e+1 ) } \\ar[d ] \\ar[r ] & \\\\\nt_i^{(e ) } \\ar[r ]         & ( t_k)^{pq } \\amalg y^p \\amalg x \\ar[r ]   \\ar[d ] & c \\ar[r ] \\ar[d ]          &   \\\\                      & ( t_j^{(1)})^p \\ar@{=}[r ]                     & ( t_j^{(1)})^p \\ar[r ]     &   } \\ ] ] by ( a ) the map @xmath343 is a left @xmath314-approximation , and by lemma [ l : samecomp ] we have that @xmath344 .\nhence @xmath345 , where @xmath331 is in @xmath346 , and with no copies isomorphic to @xmath51 in @xmath328 .\nnote that the induced @xmath314-approximation is in general not minimal .\n[ l : modtri ] assume @xmath321 and @xmath347 .\n* then there is a triangle @xmath348 where @xmath216 is a minimal left @xmath314-approximation , and @xmath331 is as in lemma [ l : comp ] .\n* there is an induced exchange triangle @xmath349 where @xmath350 . *\n@xmath351 .\nconsider the exchange triangle @xmath352 \\to t_i^{(e+1 ) } \\to b_i^{(e+1 ) } \\to\\ ] ] and the triangle from lemma [ l : comp ] ( b ) @xmath353 apply the octahedral axiom , to obtain the commutative diagram of triangles    @xmath354 \\ar[r ] \\ar@{=}[d ] & t_i^{(e+1 ) } \\ar[r ] \\ar[d ]             & b_i^{(e+1 ) } \\ar[d ] \\ar[r ] & \\\\\nt_i^{(e+2)}[-1 ] \\ar[r ]             & ( t_i^{(e+1 ) } ) ' \\amalg c ' \\ar[r ] \\ar[d ]   & g \\ar[r ] \\ar[d ]          & \\\\                                    & ( t_j^{(1)})^p \\ar@{=}[r ]            & ( t_j^{(1)})^p \\ar[r ]     &   } \\ ] ] since @xmath90 does not occur as a summand in @xmath294 by proposition [ l : disjoint ] , we have that @xmath355 ) = 0 $ ] . hence the rightmost\ntriangle splits , so we have a triangle @xmath356 \\to ( t_i^{(e+1 ) } ) ' \\amalg c ' \\to b_i^{(e+1 ) } \\amalg ( t_j^{(1)})^p \\to\\ ] ] by lemma [ l : div2 ] we have that @xmath357)= 0 $ ] . by lemma [ l : div](e )\nwe get that @xmath358 ) = 0 $ ] , and clearly @xmath359 ) = 0 $ ] , for @xmath360 .\nwe hence get that all maps @xmath361 , with @xmath45 in @xmath362 , factor through @xmath363 .\nminimality is clear from the triangle ( [ octa - tri ] ) .\nthis proves ( a ) , and ( b ) follows from the fact that @xmath331 contains no copies of @xmath90 , and hence splits off .\n( c ) is a direct consequence of ( b ) .\n[ p : summarize ]    * if @xmath308 for @xmath364 , then @xmath365 for all @xmath366 . * if @xmath321 and @xmath347 , then @xmath365 for @xmath367 .\n\\(a ) is a direct consequence of [ l : samecomp ] . for\n( b ) note that by lemmas [ l : samecomp ] and [ l : modtri ] we have @xmath365 for @xmath368 and @xmath369 . for @xmath370\nconsider the exchange triangles @xmath371 since @xmath372 ) = 0 $ ] by lemma [ l : div2 ] and @xmath373 , it is clear that the map @xmath374 is a left @xmath375-approximation .\nhence ( b ) follows .\nthis section contains the proof of the main result , theorem [ t : main ] . as before , let @xmath264 be an @xmath0-tilting object , and let @xmath94 .\nwe will compare the numbers of @xmath77-coloured arrows from @xmath13 to @xmath69 , in the coloured quivers of @xmath41 and @xmath109 , i.e. we will compare @xmath376 and @xmath377 .\nwe need to consider an arbitrary @xmath41 whose coloured quiver locally looks like @xmath265 \\ar^{(e)}[r ] & t_j \\ar^{(d)}[r ] & t_k } \\ ] ] for any possible value of @xmath266 . our aim is to show that the formula @xmath378 holds .\nthe case where @xmath379 is directly from the definition .\nthe case where @xmath380 follows by condition ( ii ) for @xmath381 . for the rest of the proof\nwe assume @xmath382 .\nwe will divide the proof into four cases , where @xmath383 denotes the number of arrows from @xmath13 to @xmath70 , and @xmath384 .    * @xmath385 * @xmath386 , @xmath321 and @xmath387 * @xmath386 , @xmath321 and @xmath388 . * @xmath386 and @xmath389    note that in the three first cases , the formula reduces to @xmath390 and in the first two cases it further reduces to @xmath391    case i.\nwe first consider the situation where there is no coloured arrow @xmath392 , i.e. @xmath308 for all @xmath393 .\nthat is , we assume @xmath87 locally looks like this @xmath265   & t_j \\ar^{(d)}[r ] & t_k } \\ ] ] with @xmath394 arbitrary .\nit is a direct consequence of proposition [ p : summarize ] that @xmath395 for all @xmath393 which shows that the formula holds .\n+   + case ii .\nwe consider the setting where we assume @xmath87 locally looks like this @xmath265 \\ar^{(e)}[r ] & t_j \\ar^{(d)}[r ] & t_k } \\ ] ] with @xmath321 and @xmath396 .\nwe then claim that we have the following , which shows that the formula holds .    in the above setting @xmath395 for all @xmath393 .\nit follows directly from proposition [ p : summarize ] that @xmath395 for @xmath397 .\nwe claim that @xmath398 .    by lemma [ l : comp ]\nwe have the ( not necessarily minimal ) left @xmath314-approximation    @xmath399    first , assume that @xmath51 does not appear as a summand in @xmath326 , then the same holds for @xmath400 , and hence for @xmath401 which is a direct summand in @xmath400\n.    next , assume @xmath51 appears as a summand in @xmath271 , and hence in @xmath39 .\nthen @xmath51 is by proposition [ l : disjoint ] not a summand in @xmath294 , and by lemma [ l : modtri ] we have that @xmath51 is also not a summand in @xmath331 .\ntherefore @xmath51 appears with the same multiplicity in @xmath271 as in @xmath401 , also in this case .\nwe now show that @xmath395 for @xmath402 .    if @xmath403 , then @xmath404 for @xmath402 and we are finished .\nso assume @xmath405 , i.e. @xmath51 does not appear as a direct summand of @xmath39 .\nconsider the map @xmath406 we have that @xmath407 . by assumption , @xmath51 is not a direct summand in @xmath408 , and thus not in @xmath331 .\nhence it follows that @xmath409 .\nsince , by proposition [ p : summarize ] we have for @xmath410 , that @xmath316 and the left @xmath411-approximation coincide with the left @xmath412-approximations of @xmath413 , it now follows that @xmath395 for all @xmath393 .\n+ case iii .\nwe now consider the setting with @xmath414 non - zero , @xmath388 and @xmath321 .\nthat is , we assume @xmath87 locally looks like this @xmath265 \\ar^{(e)}[r ] & t_j \\ar^{(0)}[r ] & t_k } \\ ] ] where @xmath415 by proposition [ p : limits ] , and where there are @xmath416 arrows from @xmath50 to @xmath51 .\n[ l : formulas ] in the above setting , we have that @xmath381 is given by    @xmath417    @xmath418    and    @xmath419    we first deal with the case where @xmath420 and @xmath421 . by assumption @xmath39 in the triangle ( [ i - tri ] )\nhas @xmath422 copies of @xmath51 , so @xmath423 has @xmath424 copies of @xmath51 . hence to show ( [ form1 ] ) it is sufficient to show that @xmath331 in the triangle @xmath425 has no copies of @xmath51 .\nthis follows directly from the lemma [ l : modtri ] and the fact that @xmath51 ( by the assumption that @xmath421 and proposition [ l : disjoint ] ) is not a summand in @xmath294 . in this case\n( [ form2 ] ) and ( [ form3 ] ) follow directly from proposition [ l : disjoint ] .\nconsider the case with @xmath426 and @xmath427 .\nwe have that @xmath39 in the triangle ( [ i - tri ] ) does not have @xmath51 as a direct summand .\nassume @xmath51 appears as a direct summand of @xmath331 with multiplicity @xmath428 .\nwe claim that @xmath429 .\nassume first @xmath430 , then on one hand @xmath51 appears with multiplicity @xmath431 in @xmath432 . on\nthe other hand @xmath51 appears with multiplicity @xmath433 in @xmath401 .\nthis contradicts proposition [ l : disjoint ] .\nhence @xmath429 .    therefore @xmath401 has @xmath434 copies of @xmath51 and ( [ form1 ] ) and ( [ form2 ] ) hold . if @xmath435 , then ( [ form3 ] ) follows directly from the above and proposition [ l : disjoint ] . in the case\n@xmath436 , we also need to show that @xmath51 does not appear as a summand in @xmath437 for @xmath438 .\nsince @xmath439 , we have @xmath440 , and the result follows from proposition [ p : summarize ] .\nnow assume @xmath426 and @xmath441 .\nassume @xmath442 , where @xmath51 is not a summand in @xmath443 .\nnow since @xmath444 with @xmath51 not a summand in @xmath328 , is a minimal left @xmath362-approximation , we have that @xmath445 and @xmath51 appears with multiplicity @xmath446 in the minimal left @xmath447-approximation of @xmath448 , hence @xmath51 can not appear as a summand in the minimal left @xmath375-approximation of @xmath449 .\nhence @xmath450 , and we have completed the proof of ( [ form1 ] ) and ( [ form2 ] ) in this case .\nthe case ( [ form3 ] ) , i.e. @xmath451 follows from proposition [ l : disjoint ] .\n+ case iv .\nwe now consider the case with @xmath452 .\nassume first there are no arrows from @xmath70 to @xmath69 .\nthen we can use the symmetry proved in proposition [ p : symmetry ] and reduce to case i. the formula is easily verified in this case .\nassume @xmath453 , again we can use the symmetry , this time to reduce to case iii .\nit is straightforward to verify that the formula holds also in this case .\nassume now that @xmath454 , i.e. we need to consider the following case @xmath455 \\ar@<0.6ex>^{(m)}[r ] & t_j \\ar@<0.6ex>^{(0)}[r ] \\ar@<0.6ex>^{(0)}[l ] & t_k \\ar@<0.6ex>^{(m)}[l ]   \\ar@<0.6ex>^{(m - c)}@/^3.5pc/[ll ] } \\ ] ] now by proposition [ p : limits ] we have that @xmath79 is in @xmath456 .\nassume there are @xmath457 @xmath77-coloured arrows    the coloured quiver of @xmath109 is of the form @xmath458 \\ar@<0.6ex>^{(0)}[r ] & t_j^{(1 ) } \\ar@<0.6ex>^{(m)}[r ] \\ar@<0.6ex>^{(m)}[l ] & t_k \\ar@<0.6ex>^{(0)}[l ]   \\ar@<0.6ex>^{(m - c')}@/^3.5pc/[ll ] } \\ ] ] and applying the symmetry of proposition [ p : symmetry ] we have that if @xmath421 , then @xmath459 by proposition [ p : limits ] .\nhence for all @xmath460 we have that @xmath461 .\ntherefore it suffices to show that @xmath462 , for @xmath463 .\nthis is a direct consequence of the following .\nassume we are in the above setting .\na map @xmath464 or @xmath465 is irreducible in @xmath46 if and only if it is irreducible in @xmath362 .\nassume @xmath464 is not irreducible in @xmath362 , and that @xmath466 for some @xmath467 , with @xmath468 the indecomposable direct summands of @xmath45 .\nnote that by lemma [ l : div](a ) , we can assume that all @xmath469 and all @xmath470 are non - isomorphisms . if there is some index @xmath471 such that @xmath472 , the map @xmath470 factors through some @xmath473 in @xmath474 , since there are no @xmath475-coloured arrows @xmath476 or @xmath477 in the coloured quiver of @xmath41 .\nthis shows that @xmath464 is not irreducible in @xmath46 .\nassume @xmath464 is not irreducible in @xmath46 , and that @xmath478 for some @xmath479 , with @xmath480 the indecomposable direct summands of @xmath481 . if there is some index @xmath471 such that @xmath482 , the map @xmath483 factors through @xmath484 , which is in @xmath485 , since there are no @xmath93-coloured arrows @xmath392 or @xmath486 in the coloured quiver of @xmath41 .\nthis shows that @xmath464 is not irreducible in @xmath362 .    by symmetry\n, the same property holds for maps @xmath465 .\nthus we have proven that the formula holds in all four cases , and this finishes the proof of theorem [ t : main ] .\nan @xmath0-cluster - tilted algebra is an algebra given as @xmath487 for some tilting object @xmath41 in an @xmath0-cluster category @xmath488 . obviously , the subquiver of the coloured quiver of @xmath41 given by the @xmath93-coloured maps is the gabriel quiver of @xmath487 .\nan application of our main theorem is that the quivers of the @xmath0-cluster - tilted algebras can be combinatorially determined via repeated ( coloured ) mutation . for this one\nneeds transitivity in the tilting graph of @xmath0-tilting objects .\nmore precisely , we need the following , which is also pointed out in @xcite .    any @xmath0-tilting object can be reached from any other @xmath0-tilting object via iterated mutation .\nwe sketch a proof for the convenience of the reader .\nlet @xmath109 be a tilting object in an @xmath0-cluster category @xmath20 of the hereditary algebra @xmath489 , and let @xmath490 be the @xmath491-cluster category of @xmath10 .\nby @xcite , there is a tilting object @xmath41 of degree 0 , i.e. all direct summands in @xmath41 have degree 0 , such that @xmath41 can be reached from @xmath109 via mutation .\nit is sufficient to show that the canonical tilting object @xmath10 can be reached from @xmath41 via mutation .\nsince @xmath41 is of degree 0 , it is induced from a @xmath10-tilting module .\nespecially @xmath41 is a tilting object in @xmath490 . since @xmath41 and @xmath10 are tilting objects in @xmath490 , by @xcite there are @xmath490-tilting objects @xmath492 , such that @xmath50 mutates to @xmath493 ( in @xmath490 ) for @xmath494 .\nnow each @xmath50 is induced by a tilting module for some @xmath495 where all @xmath496 are derived equivalent to @xmath497 . hence , each @xmath50 is easily seen to be an @xmath0-cluster tilting object . since @xmath493 differs from @xmath50 in only one summand the mutations in @xmath490 are also mutations in @xmath20 .\nthis concludes the proof .\na direct consequence of the transitivity is the following .\nfor an @xmath0-cluster category @xmath111 of the acyclic quiver @xmath71 , all quivers of @xmath0-cluster - tilted algebras are given by repeated coloured mutation of @xmath71 .\nin this section , we discuss concrete computation with tilting objects in an @xmath0-cluster tilting category .\nan exceptional indecomposable object in @xmath9 is uniquely determined by its image @xmath498 $ ] in the grothendieck group @xmath499 .\nthere is a map from @xmath500 to @xmath499 which , for @xmath501 , takes @xmath502 $ ] to @xmath503 $ ] .\nan exceptional indecomposable in @xmath500 can be uniquely specified by its class in @xmath499 together with its degree .\nthe map from @xmath500 to @xmath499 does not descend to @xmath504 .\nhowever , if we fix our usual choice of fundamental domain in @xmath500 , then we can identify the indecomposable objects in it as above .\nlet us define the combinatorial data corresponding to a tilting object @xmath41 to be @xmath87 together with @xmath505 , \\deg t_i)$ ] for @xmath506 .\ngiven the combinatorial data for a tilting object @xmath41 in @xmath504 , it is possible to determine , by a purely combinatorial procedure , the combinatorial data for the tilting object which results from an arbitrary sequence of mutations applied to @xmath41 .    clearly , it suffices to show that , for any @xmath13 , we can determine the class and degree for @xmath507 .\nif we can do that then , by the coloured mutation procedure , we can determine the coloured quiver for @xmath508 , and by applying this procedure repeatedly , we can calculate the result of an arbitrary sequence of mutations .    since we are given @xmath87 , we know @xmath509 , and we can calculate @xmath510 $ ] .\nnow we have the following lemma :    [ one ] @xmath511=[b_i^{(0)}]-[t^{(0)}_i]$ ] , and @xmath512 or @xmath513 , whichever is consistent with the sign of the class of @xmath511 $ ] , unless this yields a non - projective indecomposable object in degree @xmath0 , or an indecomposable of degree @xmath1 .\nthe proof is immediate from the exchange triangle @xmath514 .    applying this lemma , and supposing that we are not in the case where its procedure fails\n, we can determine the class and degree @xmath515 . by the coloured mutation procedure\n, we can also determine the coloured quiver for @xmath516 .\nwe therefore have all the necessary data to apply lemma  [ one ] again . repeatedly applying the lemma\n, there is some @xmath69 such that we can calculate the class and degree of @xmath507 for @xmath517 , and the procedure described in the lemma fails to calculate @xmath518 .\nwe also have the following lemma :    [ two ] @xmath519=[b_i^{(m)}]-[t^{(0)}_i]$ ] , and @xmath520 or @xmath521 , whichever is consistent with the sign of @xmath519 $ ] , unless this yields an indecomposable in degree @xmath522 .\napplying this lemma , starting again with @xmath41 , we can obtain the degree and class for @xmath523 .\nwe can then determine the coloured quiver for @xmath524 , and we are now in a position to apply lemma  [ two ] again . the last complement which lemma  [ two ] will successfully determine is @xmath525 .\nit follows that we can determine the degree and class of any complement to @xmath263 .\nin this section , we discuss the application of our results to the study of the @xmath0-cluster complex , a simplicial complex defined in @xcite for a finite root system @xmath526 .\nwe shall begin by stating our results for the @xmath0-cluster complex in purely combinatorial language , and then briefly describe how they follow from the representation - theoretic perspective in the rest of the paper . for simplicity ,\nwe restrict to the case where @xmath526 is simply laced .\nnumber the vertices of the dynkin diagram for @xmath526 from 1 to @xmath48 .\nthe @xmath0-coloured almost positive roots , @xmath527 , consist of @xmath0 copies of the positive roots , numbered @xmath491 to @xmath0 , together with a single copy of the negative simple roots .\nwe refer to an element of the @xmath13-th copy of @xmath528 as having colour @xmath13 , and we write such an element as @xmath529 .\nsince the dynkin diagram for @xmath526 is a tree , it is bipartite ; we fix a bipartition @xmath530 .\nthe @xmath0-cluster complex , @xmath531 , is a simplicial complex on the ground set @xmath527 .\nits maximal faces are called @xmath0-clusters .\nthe definition of @xmath531 is combinatorial ; we refer the reader to @xcite .\nthe @xmath0-clusters each consist of @xmath48 elements of @xmath527 ( * ? ? ? * theorem 2.9 ) .\nevery codimension 1 face of @xmath531 is contained in exactly @xmath1 maximal faces ( * ? ? ?\n* proposition 2.10 ) .\nthere is a certain combinatorially - defined bijection @xmath532 , which takes faces of @xmath531 to faces of @xmath531 ( * ? ? ?\n* theorem 2.4 )\n.    it will be convenient to consider _ ordered @xmath0-clusters_. an ordered @xmath0-cluster is just a @xmath48-tuple from @xmath527 , the set of whose elements forms an @xmath0-cluster .\nwrite @xmath533 for the set of ordered @xmath0-clusters .    for each ordered @xmath0-cluster @xmath534\n, we will define a coloured quiver @xmath535 .\nwe will also define an operation @xmath536 , which takes ordered @xmath0-clusters to ordered @xmath0-clusters , changing only the @xmath70-th element .\nwe will define both operations inductively .\nthe set @xmath537 of negative simple roots forms an @xmath0-cluster .\nits associated quiver is defined by drawing , for each edge @xmath538 in the dynkin diagram , a pair of arrows .\nsuppose @xmath539 and @xmath540 .\nthen we draw an arrow from @xmath13 to @xmath70 with colour @xmath541 , and an arrow from @xmath70 to @xmath13 with colour @xmath0 .\nsuppose now that we have some ordered @xmath0-cluster @xmath542 , together with its quiver @xmath535 .\nwe will now proceed to define @xmath543 . write @xmath544 for the number of arrows in @xmath535 of colour @xmath541 from @xmath70 to @xmath69 .\ndefine :    @xmath545    let @xmath79 be the colour of @xmath546 .\nwe define @xmath543 by replacing @xmath546 by some other element of @xmath527 , according to the following rules :    * if @xmath546 is positive and @xmath236 is positive , replace @xmath546 by @xmath547 . *\nif @xmath546 is positive and @xmath236 is negative , replace @xmath546 by @xmath548 . *\nif @xmath546 is negative simple @xmath549 , define @xmath550 by @xmath551 , and then replace @xmath546 by @xmath552 , with colour zero .\ndefine the quiver for the @xmath0-cluster @xmath543 by the coloured quiver mutation rule from section 2 .\nsince any @xmath0-cluster can be obtained from @xmath537 by a sequence of mutations , the above suffices to define @xmath543 and @xmath535 for any ordered @xmath0-cluster @xmath542 .\nthe operation @xmath553 defined above takes @xmath0-clusters to @xmath0-clusters , and the @xmath0-clusters @xmath554 for @xmath555 are exactly those containing all the @xmath556 for @xmath557 .\nthe connection between the combinatorics discussed here and the representation theory in the rest of the paper is as follows .\n@xmath527 corresponds to the indecomposable objects of ( a fundamental domain for ) @xmath36 .\nthe cluster tilting objects in @xmath36 correspond to the @xmath0-clusters .\nthe operation @xmath558 corresponds to @xmath25 $ ] . for further details on the translation ,\nthe reader is referred to @xcite .\nthe above proposition then follows from the approach taken in section [ sec : cc ] .\nhere we give an alternative description of coloured quiver mutation at vertex @xmath70 .    1 .   for each pair of arrows @xmath559 & j\\ar^{(0)}[r ] & k } \\ ] ] with @xmath560 , the arrow from @xmath13 to @xmath70 of arbitrary colour @xmath79 , and the arrow from @xmath70 to @xmath69 of colour @xmath541 , add a pair of arrows : an arrow from @xmath13 to @xmath69 of colour @xmath79 , and one from @xmath69 to @xmath13 of colour @xmath561 .\n2 .   if the graph violates property ii , because for some pair of vertices @xmath13 and @xmath69 there are arrows from @xmath13 to @xmath69 which have two different colours , cancel the same number of arrows of each colour , until property ii is satisfied .\n3 .   add one to the colour of any arrow going into @xmath70 and subtract one from the colour of any arrow going out of @xmath70 .\nthe above algorithm is well - defined and correctly calculates coloured quiver mutation as previously defined .\nfix a quiver @xmath71 and a vertex @xmath70 at which the mutation is being carried out .    to prove that the algorithm is well - defined\n, we must show that at step 2 , there are only two colours of arrows running from @xmath13 to @xmath69 for any pair of vertices @xmath13 , @xmath69 .\n( otherwise there would be more than one way to carry out the cancellation procedure of step 2 . )    since in the original quiver @xmath71 , there was only one colour of arrows from @xmath13 to @xmath69 , in order for this problem to arise , we must have added two different colours of arrows from @xmath13 to @xmath69 at step 1 .\ntwo colours of arrows will only be added from @xmath13 to @xmath69 if , in @xmath71 , there are both @xmath93-coloured arrows from @xmath70 to @xmath69 and from @xmath70 to @xmath13 . in this case , by property iii , there are @xmath562-coloured arrows from @xmath13 to @xmath70 and from @xmath69 to @xmath70 .\nit follows that in step 1 , we will add both @xmath93-coloured and @xmath562-coloured arrows . applying proposition 5.1 , we see that any arrows from @xmath13 to @xmath69 in @xmath71 are of colour 0 or @xmath0 . thus , as desired , after step 1 , there are only two colours of arrows in the quiver , so step 2 is well - defined .\nwe now prove correctness .\nlet @xmath563 .\nwrite @xmath76 for the number of @xmath79-coloured arrows from @xmath13 to @xmath70 in @xmath71 , and similarly @xmath564 for @xmath565 .\nwrite @xmath566 and @xmath567 for the result of applying the above algorithm .\nit is clear that only the final step of the algorithm is relevant for @xmath568 where one of @xmath13 or @xmath69 coincides with @xmath70 , and therefore that in this case @xmath569 as desired .\nsuppose now that neither @xmath13 nor @xmath69 coincides with @xmath70 .\nsuppose further that in @xmath71 there are no @xmath93-coloured arrows from either @xmath13 or @xmath69 to @xmath70 , and therefore also no @xmath0-coloured arrows from @xmath69 to @xmath13 or @xmath70 .\nin this case , @xmath570 . in the algorithm , no arrows will be added between @xmath13 and @xmath69 in step 1 , and therefore no further changes will be made in step 2 .\nthus @xmath571 , as desired .\nsuppose now that there are @xmath93-coloured arrows from @xmath70 to both @xmath13 and @xmath69 . in this case ,\n@xmath572 . in this case , as discussed in the proof of well - definedness , an equal number of @xmath93-coloured and @xmath562-coloured arrows will be introduced at step 1 .\nthey will therefore be cancelled at step 2 .\nthus @xmath573 as desired .\nsuppose now that there is a @xmath93-coloured arrow from @xmath70 to @xmath69 , but not from @xmath70 to @xmath13 .\nlet the arrows from @xmath13 to @xmath70 , if any , be of colour @xmath79 .\nat step 1 of the algorithm , we will add @xmath574 arrows of colour @xmath79 to @xmath71 . by proposition 5.1 ,\nthe arrows in @xmath71 from @xmath13 to @xmath69 are of colour @xmath79 or @xmath575 .\none verifies that the algorithm yields the same result as coloured quiver mutation , in the three cases that the arrows from @xmath13 to @xmath69 in @xmath71 are of colour @xmath79 , that they are of colour @xmath575 but there are fewer than @xmath574 , and that they are of colour @xmath575 and there are at least as many as @xmath574 .    the final case , that there is a @xmath93-coloured arrow from @xmath70 to @xmath13 but not from @xmath70 to @xmath69 , is similar to the previous one .\nin @xcite , a certain category @xmath576 is constructed , which is shown to be equivalent to the @xmath0-cluster category of dynkin type @xmath2 .\nthe description of @xmath576 is as follows .\ntake an @xmath577-gon @xmath578 , with vertices labelled clockwise from 1 to @xmath577 .\nconsider the set @xmath39 of diagonals @xmath550 of @xmath578 with the property that @xmath550 divides @xmath578 into two polygons each having a number of sides congruent to 2 modulo @xmath0 . for each @xmath579 , there is an object @xmath580 in @xmath576 .\nthese objects @xmath580 form the indecomposables of the additive category @xmath576 .\nwe shall not recall the exact definition of the morphisms , other than to note that they are generated by the morphisms @xmath581 which exist provided that @xmath538 and @xmath582 are both diagonals in @xmath39 , and that , starting at @xmath70 and moving clockwise around @xmath578 , one reaches @xmath69 before @xmath13 .\na collection of diagonals in @xmath39 is called non - crossing if its elements intersect pairwise only on the boundary of the polygon\n. an inclusion - maximal such collection of diagonals divides @xmath578 into @xmath583-gons ; we therefore refer to such a collection of diagonals as an @xmath583-angulation .\nif we remove one diagonal @xmath550 from an @xmath583-angulation @xmath584 , then the two @xmath583-gons on either side of @xmath550 become a single @xmath585-gon .\nwe say that @xmath550 is a _ diameter _ of this @xmath585-gon , since it connects vertices which are diametrically opposite ( with respect to the @xmath585-gon ) .\nif @xmath586 is another diameter of this @xmath585-gon , then @xmath587 is another maximal noncrossing collection of diagonals from @xmath39 .\n( in particular , @xmath588 . )    for @xmath584 an @xmath583-angulation , let @xmath589\n. then we have that @xmath590 is a basic ( @xmath0-cluster-)tilting object for @xmath576 , and all basic tilting objects of @xmath576 arise in this way .\nit follows from the previous discussion that if @xmath591 is a basic tilting object , and @xmath592 , then the complements to @xmath593 will consist of the objects @xmath594 where @xmath586 is a diameter of the @xmath585-gon obtained by removing @xmath550 from the @xmath583-angulation determined by @xmath584 .\nin fact , we can be more precise . define @xmath595 to be the diameter of the @xmath585-gon obtained by rotating the vertices of @xmath550 by @xmath13 steps counterclockwise ( within the @xmath585-gon )\n. then @xmath596 .      the coloured quiver @xmath598 of @xmath591 has an arrow from @xmath550 to @xmath586 if and only if @xmath550 and @xmath586 both lie on some @xmath583-gon in the @xmath583-angulation defined by @xmath584 . in this case\n, the colour of the arrow is the number of edges forming the segment of the boundary of the @xmath583-gon which lies between @xmath550 and @xmath586 , counterclockwise from @xmath550 and clockwise from @xmath586 .\nwe return to the example from section 2 .\nthe quadrangulation of a decagon corresponding to the tilting object @xmath41 is on the left .\nthe quadrangulation corresponding to @xmath109 is on the right .\npassing from the figure on the left to the figure on the right , the diagonal 27 ( which corresponds to the summand @xmath599 ) has been rotated one step counterclockwise within the hexagon with vertices 1,2,3,4,7,10 ."}
{"lay_summary": " we compute the one - loop corrections to the @xmath0 vertex in the @xmath1 symmetric minimal supersymmetric extension of the standard model . we find that the predicted value of @xmath2 is consistent with experiment if the mass of the lighter top squark is no more than 180 gev . \n furthermore , other data combines to place a lower bound of 88 gev on the mass of the light top squark . \n a top squark in this mass range should be accessible to searches by experiments at fnal and lep .    \n * @xmath0 in @xmath1 symmetric supersymmetry * 3em elizabeth h. simmons & yumian su 2em _ dept . of physics , boston university , + 590 commonwealth ave . , \n boston , ma 02215 _ \n 3em 3em    pacs : 12.60.jv , 13.38.dg , 14.80.ly    6em ", "article": "this paper explores the phenomenology of the standard model s minimal supersymmetric @xcite extension with a continuous @xmath1 symmetry ( hereafter called the ` mr model')@xcite .\nthis model of low - energy supersymmetry has a much smaller - dimensional parameter space than the minimal supersymmetric model with a discrete @xmath3-parity ( mssm @xcite ) . as a result , it has two attractive features .\nfirst , the mr model makes specific predictions of the values of a number of observables , such as the gaugino masses .\nin addition , the mr model is free of the superpotential term @xmath4 and the soft supersymmetry breaking terms @xmath5 that cause well - known theoretical difficulties in the mssm .\nwe focus , in particular on the recent measurements of @xmath2 @xmath6 which yield a value @xmath7 @xcite that differs markedly from the one - loop standard model prediction @xmath8 @xcite .\nthe oblique and qcd corrections to the @xmath9-quark and hadronic decay widths of the @xmath10 each largely cancel when the ratio is formed , making @xmath2 very sensitive to direct corrections to the @xmath11 vertex  especially those involving the heavy top quark .\nour work complements some recent papers on susy models with discrete r - parity .\nthe implications of the @xmath2 measurement for the mssm are discussed in refs .\n@xcite , @xcite and @xcite .\na region of the mssm parameter space that has some phenomenology similar to that of the mr model is studied in @xcite .\nthe following section describes the mr model in more detail .\nwe then compute the vertex corrections to @xmath2 in the mr model and find that the result is within @xmath12 of the experimental value so long as the lighter top squark is light enough ( and the charged higgs boson is heavy enough ) .\nsection 4 discusses additional constraints that place a lower bound on the mass of the lighter top squark .\nthe information that future experiments may yield is studied in section 5 ; ongoing and upcoming experiments at fnal and lep should be capable of confirming or excluding the mr model .\nthe last section briefly summarizes our findings .\nthe model explored in this paper is the minimal supersymmetric extension of the standard model in which @xmath3-parity is extended to a continuous @xmath13 symmetry .\nthe continuous @xmath3-symmetry is defined by assigning @xmath3 charges + 1 to the superspace coordinate @xmath14 , + 1 to matter superfields and 0 to higgs superfields . in terms of component fields ,\nall ordinary particles carry zero @xmath3 charge while their superpartners have non - zero @xmath3-charge .\nthe most general @xmath1-symmetric lagrangian is described by the superpotential @xmath15 where each term has @xmath16 , and the quark and lepton superfields @xmath17 @xmath18 have the usual @xmath19 gauge interactions .\nnote the absence of a @xmath4 term which would violate the @xmath1 symmetry .\nthe most general symmetry forbids majorana gaugino masses , the model contains an additional color octet chiral superfield to give a dirac mass to the gluino .\nthis field appears only in the soft supersymmetry breaking potential .\nthe gluino mass is relevant to this work in that it renders the 1-loop correction to @xmath2 from diagrams with internal gluinos and bottom squarks negligible compared to the effects of the diagrams considered here .\nwe will therefore not mention the color octet superfield further .\nthe effects of allowing the gluino to be extremely light in a @xmath1-symmetric model will be considered in future work . ]\nsoft supersymmetry breaking potential consistent with our symmetries and a gim - like mechanism to naturally suppress flavor - changing neutral currents is : @xmath20 where we neglect small yukawa - suppressed corrections to the superpartners masses .\nnote the characteristic absence of gaugino mass terms ( @xmath21 ) and trilinear scalar terms ( @xmath22 ) . for a more detailed description of the model\nwe refer the reader to  @xcite .\nthe non - standard one - loop corrections to @xmath2 considered in this paper are of two kinds .\none involves the charged - higgs / top / bottom vertex ; the other , the chargino / stop / bottom vertex .\nthey therefore involve the following parameters : charged higgs mass @xmath23 , chargino masses @xmath24 , stop mass eigenvalues @xmath25 , stop mixing angle @xmath26 , and ratio of higgs vacuum expectation values @xmath27 . in the remainder of this section , we focus on those aspects of the model that are directly relevant to determining the above parameters .\nfirst we should discuss masses .\nthe charged higgs mass is given in terms of the @xmath28 mass as @xmath29 which implies that @xmath30 is heavier than @xmath31 .\nthe charginos masses are @xmath32 @xmath33 we will soon find that in this model the charginos are nearly degenerate with the @xmath31 bosons . as it is relevant to the limits we will ultimately set on the top squark masses , we also note that at the one - loop level , the light neutral higgs boson has a mass of of the @xmath34 term in the superpotential and the coefficient @xmath35 of the trilinear scalar operators in the supersymmetry breaking terms .\nthose two coefficients vanish in the mr model because of the continuous @xmath1 symmetry . ]\n@xmath36 in the limit that @xmath37 , which allows bottom squark contributions to be neglected ; the reason this limit is preferred will become clear shortly .\nthe values of the top squark masses are intimately connected to the physics of the lightest superpartner ( the photino ) .\nthe photino is massless at tree level but , together with its dirac partner @xmath38 ( or @xmath39 in the notation of @xcite , acquires a dirac mass at one loop that is generated by the exchange of left- and right - handed top squarks@xcite @xmath40  from the cosmological point of view , the present mass density is bounded from above by @xmath41 .\nthis implies a lower bound on the cross section for photino annihilation , @xmath42 .\nsince @xmath42 grows as the square of the photino mass , the result is a lee - weinberg  @xcite type of lower bound on the photino mass @xmath43^{-1 } ( \\omega_{\\tilde{\\gamma}}h^2)^{-1}\\ ] ] where @xmath44 runs over all squarks and sleptons of charge @xmath45 and mass @xmath46 such that the corresponding quarks and leptons are the possible final states of photino annihilation @xcite .\nsince the photino can not be massless , equation ( [ photstop ] ) implies that the top squarks @xmath47 and @xmath48 can not be degenerate in the mr model .\nif one supposes @xmath48 to be lighter than @xmath47 , then , for a given mass of @xmath48 , one will find a lower bound on the mass of @xmath47 .\nfor example , if @xmath49 gev , then @xmath50 gev .\nthe top squark mass eigenstates @xmath51 and @xmath52 are related to @xmath48 and @xmath47 by @xmath53 which defines the mixing angle @xmath26 .\nwe find that in order for the stop mass eigenvalues @xmath54,@xmath55 to be real , the stop mixing angle @xmath26 must be less than 10 degrees .\nthus , in the mr model , @xmath56 .    finally , we need to discuss @xmath57 .\nwe have already seen that the overall scale of @xmath58 is of the order of 1 gev .\nthis makes the decay @xmath59 possible , which in turn makes the @xmath10 invisible width larger than it is in the standard model .\nthe branching fraction of @xmath60 is suppressed by a factor of @xmath61 relative to the standard model branching fraction for one @xmath62 species , @xmath63 .\nthus we have @xmath64 the experimental limit on the number of light neutrino species  @xcite , @xmath65 , therefore implies that at 95% c.l .\n@xmath27 lies very close which naturally appears in gut - inspired models with radiative electroweak symmetry breaking . ] to unity : @xmath66    the several parameters of the mr model are now essentially reduced to two .\nthe stringent constraint @xmath67 forces the charginos to be approximately degenerate with the @xmath31 .\nthe requirement that the photino not be massless forces the top squark mixing angle to be less than @xmath68 ; we take @xmath69 throughout our calculations . when @xmath69 , the superpartner of the right - handed top quark , @xmath48 is identical to the light top squark mass eigenstate @xmath51 ; since only @xmath48 enters the loop affecting the @xmath10 coupling to left - handed @xmath9 quarks , @xmath2 depends on @xmath54 but not @xmath55 .\nwe are left with only two parameters on which @xmath2 will depend : @xmath23 and @xmath54 .\nin order to test the mr model , we can separate contributions to @xmath2 into those occurring in both the standard and mr models and those additional effects present only in the mr model . in the notation of refs .\n@xcite , @xmath70\\\\ \\nonumber \\\\ { \\nabla_b^{mr } } \\equiv { \\nabla_b}^{mr}(m_t ) -{\\nabla_b}^{mr}(0)\\nonumber \\label{citr}\\end{aligned}\\ ] ] where @xmath71 is the one - loop level standard model prediction using a top quark mass of @xmath72 gev , @xmath73 is the standard model prediction assuming a massless top quark  @xcite , and @xmath74 is the sum of the one - loop interference with the tree graph divided by the squared amplitude of the tree graph . in the mr model ,\nthere are two relevant types of non - standard one - loop vertex diagrams : those with internal charged - higgses and top quarks , and those with internal charginos and top squarks .\ntheir contributions to @xmath74 are proportional to @xmath75 ; the details of the calculation are presented in the appendix .\nanother type of vertex diagram with internal neutralinos and bottom squarks makes contributions proportional to @xmath76 , which is negligible in the mr model because @xmath77 ; we omit these .\n-.5 in    -2em    -2em    in figure 1 , we plot @xmath78 , the contribution from the @xmath79  t vertex diagrams to @xmath80 , as a function of @xmath81 , when @xmath27 is taken to be 1 , 0.9 or 1.1 .\nthe overall sign is negative and the value of @xmath82 shifts by @xmath83 as @xmath27 varies from 1 to 1.1 or 0.9 .\nfigure 2 shows the corresponding contribution from @xmath84  @xmath85 loops to @xmath86 , as a function of the light top squark mass @xmath54 when the mixing angle @xmath26 between top squarks is @xmath87 ( @xmath88 ) .\nthe result is positive , and the deviation due to a 10@xmath89 shift in @xmath27 is negligible .\nthus the net shift in @xmath2 is due to a balance between the oppositely - signed contributions from the two types of loop diagrams . in figure 3\n, we set @xmath90 gev and plot @xmath2 as a function of @xmath23 for a range of @xmath27 ; we can clearly infer a lower bound on the allowed value of @xmath23 at fixed @xmath54 .\nlikewise , figure 4 shows the dependence of @xmath2 on @xmath54 for @xmath91 gev ; we can infer an upper bound on @xmath54 for fixed @xmath23 . in subsequent diagrams we plot results only for @xmath92 and\nkeep in mind that an increase of 10% in @xmath57 corresponds to an increase of about 0.1% in @xmath2 for given @xmath23 and @xmath54 .    -2em\n-2em    figure 5 shows how the experimental 95% c.l .\nlower bound on @xmath2 separates the @xmath23 vs. @xmath54 parameter space into allowed and disallowed regions .\nrecall that the @xmath93 loop gives negative corrections to @xmath2 , while the @xmath94 loop gives positive corrections . since the standard model prediction for @xmath2 lies well below the experimental lower bound ,\nsome positive contribution is required to bring the mr prediction for @xmath2 into agreement with experiment .\nhence , by taking the charged higgs mass to infinity , one finds an asymptotic upper limit on the light stop mass of 180 gev at 95% c.l .\nthe precise upper bound on @xmath54 will be smaller than 180 gev for any finite @xmath23 , due to the negative contribution to @xmath2 from the @xmath93 loop .\nfor any fixed @xmath23 , the corresponding upper bound on @xmath54 can be read from figure 5 .    -1.5em\ncombining the information gleaned from @xmath2 with other experimental data yields additional constraints on the mr model .\nfirst , we can use the lower bounds on the mass of the light neutral higgs ( @xmath95 ) boson to set a limit on @xmath55 . recall that the @xmath95 mass depends on the product of the top squark masses at the one - loop level .\nthus for a given light top squark mass , the heavier the heavy stop , the heavier the neutral higgs . then by setting the light top squark s mass to the maximum value of 180 gev and using the lower bound of 56 gev coupling lies between the extremes of the other two models .\nthe @xmath96 coupling is proportional to @xmath97 where @xmath98 is the mixing angle that diagonalizes the neutral higgs mass matrix . throughout the parameter space of the mr model\n, @xmath99 is greater than about 0.75 ; it can take on smaller values in the mssm and is 1.0 in the standard model . ] that aleph @xcite sets on the @xmath95 mass in the mr model , we find that @xmath100 tev .\nif the mass of the @xmath51 is less than 180 gev , the lower bound on @xmath55 increases accordingly .\n-.25 in    -0.5em    the information on the masses of the top squarks provides limits on the photino mass , which depends on the masses of both top squarks at the one - loop level . to maintain naturalness\n, the masses of the sparticles should be of the order of a tev .\nif the mass of the heavy stop lies between 0.7 and 10 tev , the photino mass is between 2.5 and 10 gev .\nthis is very helpful because both d0 @xcite and the lep collaborations have set limits on the allowed region of the @xmath101 vs.@xmath54 plane . for the narrow range of photino masses allowed in the mr model , these experiments essentially constrain the light stop mass to take values only in the ranges : ( 0  12 gev ) , ( 44 gev  46 gev ) , and ( 88 gev  180 gev ) .\nthis is shown in figure 6 .\na closer look then excludes the case @xmath102 gev .\nif the @xmath51 is this light , then in order for the @xmath95 mass to exceed the lep lower bound of 56 gev , the heavy stop would have to be heavier than about 24 tev . as a result ,\nthe stop mixing angle would be almost precisely zero .\nthe combination of such a light @xmath51 and such a small mixing angle has already been ruled out by opal  @xcite .\nthe mass of the @xmath51 in the mr model must therefore lie in one of the upper two allowed ranges .\nin fact , preliminary results from the l3 collaboration based on the recent lep run at a center - of - mass energy of 130  140 gev show no signs of a top squark in the mass range below about 50 gev@xcite .\nit is therefore likely that the middle mass range for @xmath51 in the mr model is also excluded .\nwe now briefly discuss several measurements that may provide useful information on the mr model in the future .\nthese run the gamut from precision measurements to searches for new particles .\nsince a light top squark could have an appreciable effect on the branching ratio for @xmath103 , we compare the ratio measured at cleo with that predicted by the mr model .\nthe branching ratio of @xmath104 measured in cleo  @xcite is @xmath105 the mr model predicts a branching ratio within @xmath12 of the cleo result whenever the light stop weighs in the regions of ( 44 gev  46 gev ) and ( 88 gev  180 gev ) .\nuntil future experiments reduce the errors on the @xmath106 branching ratio , this particular quantity will not help constrain the mr model .\nthe relatively light mass of the @xmath51 in the mr model makes it possible for the top quark to decay to a top squark and a neutralino . as a result\n, the branching ratio for the standard top quark decay mode @xmath107 , which is approximately 100% in the standard model , would be only 70 \n80% in the mr model .\nthe limits on this branching ratio from cdf data @xcite are not strong enough to constrain the mr model  yet .\nonce all of the 1994  5 data from lep are analyzed , the precise experimental limits on @xmath2 may shift .\nthe potential consequences for the mr model are quite interesting .\nfigure 7 shows contours corresponding to several values of @xmath2 near the current experimental @xmath12 lower bound .\nthese curves imply that while the value of @xmath2 in the mr model is consistent with the present experimental value of @xmath2 , the theoretical prediction generally lies well below the experimental central value of 0.2205 @xcite .    as a result\n, the size of the allowed parameter space of the mr model depends sensitively on the experimental determination of @xmath2 .\nclearly even a very small downward shift in the central value of @xmath2 would allow @xmath54 to be heavier than 180 gev .\non the other hand , an upward shift in the central value or an improvement in the errors on the current central value of @xmath2 could reduce the upper bound on @xmath54 to a value below 88 gev \ni.e. into the region already excluded by d0 and lep .\n-.5 in    -0.5em    searches for top squarks in the d0 and cdf experiments should explore the remaining parameter space of the mr model .\nfor example , the mass range @xmath108 gev can be probed by seeking top squarks in the decay channels @xmath109 , in addition to the @xmath110 channel already explored by d0 .\nthe upcoming experiments at lep ii will also be sensitive to part of the allowed mass range for light top squarks .\nin addition , combining our upper bound on @xmath54 and the ` naturalness ' upper bound on @xmath55 with equation ( 7 ) implies an upper bound of @xmath111 90 gev on @xmath112 .\nsearches for @xmath113 are discussed in ref .\nby considering the value of @xmath2 predicted by minimal @xmath1 symmetric supersymmetry , we have shown that this model is consistent with experiment so long as the light top squark weighs no more than 180 gev .\nother considerations , including top squark searches at lep and d0 , further restrict the top squark mass to satisfy @xmath114 gev .\nthe light top squark of the mr model should therefore be accessible to d0 , cdf and the lep ii experiments .\nwe thank g. bonini , d. brown , j. butler , r.s .\nchivukula , i. dasgupta , b. dobrescu , d. finnell , and b. zhou for useful discussions and comments on the manuscript .\ne.h.s . acknowledges the support of an nsf faculty early career development ( career ) award and of a doe outstanding junior investigator award .\n_ this work was supported in part by the national science foundation under grant phy-9501249 , and by the department of energy under grant de - fg02 - 91er40676 . _\nthis appendix contains more detail on the calculation of the shift in @xmath2 . we take the explicit formulas from ref .\n@xcite . for the reader\ns convenience , we list the formulas below ; note that we set @xmath115 to zero in our calculations since @xmath92 in the mr model . starting from equation ( [ citr ] ) @xmath70\\\\ \\\\ { \\nabla_b^{mr } } \\equiv { \\nabla_b}^{mr}(m_t ) -{\\nabla_b}^{mr}(0)\\end{aligned}\\ ] ] we can separate @xmath116 into the pieces contributed by the diagrams with charged higgs bosons and by those with charginos @xmath117 where @xmath118 @xmath119 the functions @xmath120 and @xmath121 are each of the form @xmath122,\\ ] ] where @xmath123 explicit expressions for the functions @xmath124 are given below ; those for diagrams with internal higgs bosons are first , followed by those for diagrams with internal charginos .\nthe contributions from diagrams with internal charged higgs bosons are ( see figure 8 for the meaning of the superscripts on the @xmath124 ) @xmath125 @xmath126 v^{(t)}_{r , l}\\\\\\\\            + \\frac{m^2_t}{\\mu^2_{r}}c_2(m_{h^+},m_t , m_t)v^{(t)}_{l , r }            \\bigg ) \\lambda^2_{l , r } ,    \\end{array}\\ ] ] @xmath127 where @xmath128 @xmath129 and @xmath130 is the mass scale which arises in dimensional regularization .\n@xmath133o^{r , l}_{ij}\\nonumber\\\\       \\nonumber\\\\         \\ \\ \\ \\ \\ \\ \\ \\ \\ + \\frac{m_im_j}{\\mu^2_r }         c_2(\\tilde{m}_k , m_i , m_j)o^{l , r}_{ij}\\bigg)\\lambda^{l , r}_{ki }         \\lambda^{*l , r}_{kj } ,   \\end{array}\\ ] ]    where @xmath134 t_{i2}v^*_{j2},\\ \\ \\ \\lambda^r_{ij}=-\\left[\\frac{m_b}{\\sqrt{2}m_w\\cos{\\beta}}\\right ] t_{i1}u_{j2},\\end{aligned}\\ ] ] @xmath135 are the chargino masses , @xmath136 are the stop mass eigenvalues , and , @xmath137 @xmath138 note that in the limit where @xmath92 the matrices u and v need only satisfy @xmath139 ; for instance , the pair @xmath140 are also appropriate .\n@xmath142(m_1,m_2,q^2 ) = \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ & \\\\ \\int_0 ^ 1 dx \\ln [ -q^2x(1-x)+ xm_1 ^\n2+&\\!\\!\\!\\!\\!(1-x)m_2 ^ 2-i\\epsilon]/\\mu^2_r               \\big[-1,x,(1-x),x(1-x)\\big ] \\\\\n\\\\      \\big[c_0,c_1\\big](m_1,m_2,m_3)\\ = \\int dx dy dz \\delta   ( & \\!\\!\\!\\!\\!x+y+z-1)\\ln(\\delta/\\mu^2_r)[1,z ] \\\\\n\\\\      \\big[c_2,c_3,c_4,c_5,c_6,c_7\\big](m_1,m_2,m_3)\\ = & \\\\ \\int dx dy dz \\delta ( x+y+z-1)(\\mu^2_r/&\\!\\!\\!\\!\\!\\delta)[1,z , z^2,z^3,xy , xyz ] ,   \\end{array}\\ ] ]        p. fayet , nucl .\nb90 * ( 1975 ) 104 , and phys . lett . *\nb69 * ( 1977 ) 489 ; g.r .\nfarrar and p. fayet , phys .\nb76 * ( 1978 ) 575 ; e. witten , nucl . phys .\n* b188 * ( 1981 ) 513 ; s. dimopoulos and h. georgi , nucl . phys .\n* b193 * ( 1981 ) 150 ; n. sakai , z. phys .\n* c11 * ( 1981 ) 153 ; l. ibaez and g. ross , phys .\nb105 * ( 1981 ) 439 ; r.k .\nkaul , phys . lett .\n* b109 * ( 1982 ) 19 ; m. dine , w. fischler and m. srednicki , nucl . phys .\n* b189 * ( 1981 ) 575 ; s. dimopoulos and s. raby , nucl . phys .\n* b192 * ( 1981 ) 353 .\nsee e.g. the following reviews : h.p .\nnilles , phys .\nrep * 110 * ( 1984 ) 1 ; h.e . haber and g.l .\nkane , phys .\n* 117 * ( 1985 ) 75 ; j.f .\ngunion and h.e .\nhaber , nucl .\nb272 * ( 1986 ) 1 , and erratum ibid . *\nb402 * ( 1993 ) 567 .\np. langacker , hep - ph/9408310 ; p. langacker and j. erler , phys . rev .\n* d50 * ( 1994 ) 1304 , http://www-pdg.lbl.gov/rpp/book/page1304.html ; a. blondel , cern ppe/94 - 133 , @xmath146 http://alephwww.cern.ch/alephgeneral/reports/reports.html .\n`` cdf top quark production and mass . ''\ntalk presented by j. incandela at the 6th international symposium on heavy flavor physics , june 1995 , pisa , italy .\nfermilab - conf-95/237-e ; cdf / pub / top / public/3273 ."}
{"lay_summary": " multiplication is one of the most important operation in computer arithmetic . \n many integer operations such as squaring , division and computing reciprocal require same order of time as multiplication whereas some other operations such as computing gcd and residue operation require at most a factor of @xmath0 time more than multiplication . we propose an integer multiplication algorithm using nikhilam method of vedic mathematics which can be used to multiply two binary numbers efficiently .    \n integer multiplication , algorithm , computer arithmetic , vedic mathematics , computation ", "article": "the classical method of adding two integers of @xmath1-bits takes @xmath2 bit operations but the classical method of multiplying them takes @xmath3 bit operations .\ncomplexity of addition is optimal in number of bit operations , whereas optimal multiplication algorithm for integers is an open problem .\nthe classical approach to multiply two @xmath1-bit integers requires @xmath3 bit operations .\nkaratsuba multiplication [ 9 ] uses divide - and - conquer technique to multiply two @xmath1-bit integers in @xmath4 bit operations(logarithms are to the base 2 unless otherwise specified ) by replacing some of the multiplication by less costly addition and subtraction .\ntoom - cook algorithm further improves the above bound [ 3 ] .\ntoom - cook method is the generalization of karatsuba method which split each number to be multiplied in multiple parts [ 12 ] . given two large integers , toom - cook splits up multiplicand and multiplier into @xmath5 smaller parts each of length @xmath6 , and performs operations on the parts .\nas @xmath5 grows , one may combine many of the multiplication sub - operations , thus reducing the overall complexity of the algorithm . for @xmath7 toom - cook\nreduces 9 multiplication to 5 , with asymptotic complexity of @xmath8 .\nschonhage - strassen integer multiplication algorithm [ 10 ] uses fast fourier transform ( fft ) by selecting the principal roots of unity as evaluation point to perform multiplication in @xmath9 bit operations .\nfft method employs a divide - and - conquer strategy by taking advantage of the special properties of the complex root of unity to perform multiplication of two polynomials in only @xmath10 arithmetic complexity [ 4 ] .\nin fact many multiplication algorithms can viewed as schemes for the evaluation of polynomials then multiplication of their values and followed by interpolation .\ncurrently , the asymptotically fastest algorithm for multiplication of two @xmath1-bit integers is by furer [ 7 ] which runs in @xmath11 . where @xmath12 is iterated logarithm function [ 5 ] defined as : @xmath13 furer algorithm uses arithmetic over complex number .\nsame asymptotic bound can also be achieved using modular arithmetic [ 6 ] .\n+ the schonhage - strassen algorithm and furer algorithm are asymptotically fast but they are suited for extremely large numbers .\nfurer algorithm although asymptotically fastest , only achieves an advantage for astronomically large values and as such it is currently not used in practice .\nthe crossover points between these algorithms are usually very high when the algorithms are implemented [ 8 ] . for small inputs\neven karatsuba algorithm runs slower than the classical multiplication algorithm because of recursion overhead . in this paper\nwe use nikhilam sutra or method from vedic mathematics [ 11 ] to perform efficient multiplication for small inputs .\nnikhilam sutra performs large multiplication by converting it to small multiplication along with some addition and shifting operations . +\nthis paper is organized as follows .\nsection 2 describes background and motivation .\nsection 3 presents our proposed work , the multiplication algorithm and its features . in section 4\n, we present some applications .\nfinally , section 5 contains conclusion .\nthe simplest method to multiply two @xmath1-digit integers is using classical or long multiplication method which requires @xmath3 multiplication operations .\nwhereas to add or subtract two @xmath1-digit integers using traditional method requires at most @xmath1 number of addition or subtraction which is optimal in terms of number of addition / subtraction operation performed . to improve the @xmath3 bound of multiplication\n, several algorithms have been discovered .\nthe simplest one is karatsuba algorithm which is based on divide - and - conquer paradigm [ 1 ] .\nkaratsuba algorithm is based on the fact that two - digit multiplication can be done with only three instead of four multiplications required by standard method .\nsuppose we want to multiply two @xmath14-digit decimal numbers\n@xmath15 :    1 .   compute @xmath16 2 .\ncompute @xmath17 3 .\ncompute @xmath18 4 .\ncompute @xmath19 , here @xmath20 is equal to @xmath21 5 .\nresult @xmath22    for large number of digits we can apply this method recursively by splitting the multiplicand and multiplier in two parts . the complexity of this method is @xmath23 . since multiplication operation is costly as compared to addition and shift\n, some constant number of addition and shift operations can be safely ignored . in this paper\nwe assume that multiplicand and multiplier are having equal number of digits .\n+ for example suppose we want to multiply @xmath24 .\nthe standard method of long multiplication requires 4 one - digit multiplication along with some addition and shift . using karatsuba algorithm\nwe can compute it as follows :    1 .   compute @xmath25 2 .\ncompute @xmath26 3 .\ncompute @xmath27 ; @xmath28 4 .\ncompute @xmath29 5 .\nresult @xmath30    a schematic view of above multiplication is shown in fig .\nthe three multiplication operations are enclosed in ellipse .\nin fact the total number of @xmath31-digit multiplication required in above example is 5 . note that to compute @xmath32 in step @xmath33 requires , three @xmath31-digit multiplication by applying this method one s more .\nusing karatsuba method , width=264,height=151 ]    nikhilam sutra is one of the 16 sutras of vedic mathematics [ 11 ] .\nit can be used to convert large - digits multiplication to small - digits multiplication with the help of few extra add , subtract and shift operations . in some cases\ntwo - digit multiplication can be performed using only @xmath31 one - digit multiplication instead of @xmath33 one - digit multiplication as required by karatsuba algorithm .\nsuppose we have to perform same multiplication @xmath24 using this method .\nwe can use the nikhilam sutra as follows :    1 .   compute @xmath34 ; subtract the multiplicand from nearest base 2 .\ncompute @xmath35 ; subtract the multiplier from the same base 3 .\ncompute @xmath36 4 .\ncompute @xmath37 5 .\nresult @xmath38    in the fig .\n2 , we can see that there is only one multiplication operation involved .     using nikhilam method , width=264,height=151 ]    above multiplication is also shown in table 1 . in this multiplication\nwe have used @xmath31 multiplication , @xmath31 addition , @xmath33 subtraction and @xmath31 shift operation .\nthis particular multiplication is more efficient than both standard multiplication and karatsuba method .\nsuppose multiplicand is @xmath39 and multiplier is @xmath40 where @xmath41 is nearest base .\nwe have : @xmath42 the general scheme of multiplication @xmath43 is shown in table 2 .\n.multiplication of @xmath44 [ cols=\"^,^,^ \" , ]     correctness of the nikhilamsquaring can be easily established using induction on the bit length of the input @xmath45 .\nnote that in each column of table 8 , the partial result is , in fact multiplication of corresponding multiplicand and multiplier in that column . +\n* theorem 1 . * _ nikhilamsquaring algorithm computes square of the input @xmath45 . _ + * proof * : we prove this using induction on the bit length @xmath1 of @xmath45 . for @xmath46 ,\nnumber @xmath45 has only one bit and @xmath47 when @xmath45 is @xmath31 and @xmath48 when @xmath45 is @xmath49 .\ntherefore it works for @xmath46 .\nassume it is true for @xmath50 .\nnow we show it for @xmath5 .\nassume @xmath51 , therefore @xmath52 .\n+ case 1 : if @xmath5th bit is @xmath31 then @xmath53 , and the processing of @xmath5th step is @xmath54 also we have @xmath55 and therefore @xmath56 @xmath57 and hence @xmath58 , and the statement of theorem follows .\n+ case 2 : if @xmath5th bit is @xmath49 , then the statement is trivial and @xmath59 , and theorem is proved .\n+ nikhilammultiplication is described in algorithm 2 .\nit takes two binary numbers @xmath45 and @xmath60 as input and compute their multiplication@xmath61 as output .\nit performs two calls to nikhilamsquaring algorithm and using that , outputs the desired result .\nnikhilammultiplication uses only @xmath31 multiplication , @xmath31 division and @xmath62 add / subtract and shift operations for some constant @xmath63 . to show\nthe correctness of nikhilammultiplication is trivial given the correctness of nikhilamsquaring .\n+    * input * : @xmath64 * output * : @xmath65 @xmath66 * nikhilamsquaring * @xmath67 @xmath68 * nikhilamsquaring * @xmath69 @xmath70    * theorem 2 . *\n_ nikhilammultiplication algorithm computes the product of @xmath45 and @xmath60 . _ + * proof * : the statement of the above theorem follows from theorem 1 and the fact that : @xmath71 +\nsince , asymptotically fast multiplication algorithms like schonhage - strassen and furer algorithms are only useful for extremely large numbers , for small to medium size numbers we can apply nikhilam multiplication .\nwe can use nikhilam multiplication even in conjunction with some other fast algorithm like karatsuba . if @xmath72 is the threshold between classical multiplication and karatsuba algorithm then up to threshold limit @xmath72 we can use nikhilam multiply and beyond that limit we can use karatsuba multiply .\nwe can write the karatsuba algorithm as given in [ 2 ] , with the only modification that if @xmath73 nikhilammultiplication is called .\nthe corresponding pseudo code is given in algorithm 3 .\nkaratsuba multiplication has relatively small threshold with the classical multiplication . the optimal threshold for karatsuba algorithm can vary from about ten to hundred words .\nnikhilammultiplication can also be used as a stand alone multiplication algorithm . + further optimization to nikhilammultiplication is also possible .\nleast significant @xmath49 s can be truncated from input numbers , and in the end corresponding modification can be done in single operation .\nwe can process the multiplicand and multiplier for consecutive @xmath49 s to skip some of the steps of the algorithm .\nthe proposed algorithm is particularly efficient because multiplication operation is least involved in it .\n* input * : @xmath64 * output * : @xmath65 * nikhilammultiplication * @xmath74 @xmath75 @xmath76 mod @xmath77 div @xmath78 @xmath79 sign@xmath80 , @xmath81 sign@xmath82 @xmath83 * karatsubamultiplication * @xmath84 @xmath85 * karatsubamultiplication * @xmath86 @xmath87 * karatsubamultiplication * @xmath88 @xmath89\nin this paper we have explored the possibility of applying the nikhilam sutra of vedic mathematics to binary number multiplication .\nwe can take advantage of the fact that this sutra can convert large - digit multiplication to corresponding small digit multiplication .\nnikhilam method is particularly efficient when both multiplicand and multiplier are near to some base ( radix ) power . to take this advantage ,\nwe have first performed square operation in nikhilamsquaring and then we have used this to finally compute multiplication . future work can be to extend this method to large - digit multiplication and exploit it s properties to perform fast integer multiplications ."}
{"lay_summary": " we present new equilibrium component distribution functions that depend on three analytic integrals in a stckel potential , and that can be used to model stellar discs of galaxies . \n these components are generalizations of two - integral ones and can thus provide thin discs in the two - integral approximation . \n their most important properties are the partly analytical expression for their moments , the disc - like features of their configuration space densities ( exponential decline in the galactic plane and finite extent in the vertical direction ) and the anisotropy of their velocity dispersions . \n we further show that a linear combination of such components can fit a van der kruit disc .    \n epsf rotate    = =    = =    = =    = =    # 1 # 1    # 1 # 1    @mathgroup@group    @mathgroup@normal@groupeurmn    @mathgroup@bold@groupeurbn    @mathgroup@group    @mathgroup@normal@groupmsamn    @mathgroup@bold@groupmsamn    = \" 019    = \" 016    = \" 040    = \" 336    = \" 33e    = =    = =    = =    = =    # 1 # 1    # 1 # 1    = =    = =    = =    = =    [ firstpage ]    galaxies : kinematics and dynamics  galaxies : stucture  stars : kinematics . ", "article": "it has been known for a long time that the classical two - integral equilibrium theory in axisymmetric geometry is not sufficient to adequately describe the stellar discs of galaxies . in accordance with jeans theorem ( jeans 1915 )\n, the phase space distribution function of a stellar system in a steady state depends only on the isolating integrals of the motion ; the binding energy @xmath0 and the vertical component of the angular momentum @xmath1 are isolating integrals in a stationary and axisymmetric system .\nit is a fundamental property of all two - integral distribution functions @xmath2 that the dispersion of the velocity in the radial direction equals the dispersion in the vertical direction : we know that , for example , the disc of the milky way does not have that property  ( binney & merrifield 1998 ) .\nillustrations of other shortcomings of a two - integral model in a galactic context can be found in durand , dejonghe & acker  ( 1996 ) .\nthe introduction of a third integral of the motion helps to overcome these constraints : in that case , the velocity dispersions can be different in all the directions .\nnumerical experiments show that a third isolating integral seems to exist for most orbits in realistic galactic potentials  ( ollongren 1962 , innanen & papp 1977 , richstone 1982 ) .\nthis third integral can be taken into account numerically in the models by using extensions of schwarzschild s  ( 1979 ) orbit superposition technique  ( cretton et al .\n1999 , zhao 1999 , hfner et al .\nit is also possible to define an analytic third integral specific to particular orbital families  ( de zeeuw , evans & schwarzschild 1996 , evans , hfner & de zeeuw 1997 ) or an approximate global third integral  ( petrou 1983ab , dehnen & gerhard 1993 ) , but we choose to construct models with an exact analytic third integral by using a stckel potential  ( stckel 1890 , de zeeuw 1985 ) .\nit is not quite obvious to define suitable global distribution functions @xmath3 that depend on three exact analytic integrals and that can somewhat realistically represent our ideas of a real stellar disc .\nfor example , bienaym  ( 1999 ) made three - integral extensions of the two - integral parametric distribution functions described in bienaym & schaud  ( 1997 ) , but these ones were built to model the kinematics of neighbouring stars in the milky way only .\ndejonghe & laurent  ( 1991 ) also defined the three - integral abel distribution functions , but these ones could not provide very thin discs in the two - integral approximation .\nrobijn & de zeeuw  ( 1996 ) constructed three - integral distribution functions for oblate galaxy models , but they also had problems to recover the two - integral approximation .    in this paper\nwe continue the work of batsleer & dejonghe  ( 1995 ) , who constructed component distribution functions that are two - integral , but that can represent ( very ) thin discs when a judicious linear combination of them is chosen .\nwe use these components as a basis for new component distribution functions that are three - integral , of which the batsleer & dejonghe components are a special case .    in the next section\n, we outline some fundamentals of two - integral equilibrium systems and we show how to model discs with a finite extent in the vertical direction . in section 3 , we present some general facts about stckel potentials and we present new analytic three - integral distribution functions that can represent stellar discs .\nan analytical expression for the moments of these distribution functions is calculated in section 4 . in the next section\n, we discuss their physical properties and show their realistic disc - like character . finally ,\nin section 6 , we show that these distribution functions can be used as basis functions in the modeling of a van der kruit disc . for the conclusions ,\nwe refer to section 7 .\nwe denote the gravitational potential in cylindrical coordinates @xmath4 by @xmath5 . the two classical isolating integrals of the motion are the binding energy , @xmath6 , and the @xmath7-component of the angular momentum , @xmath8 .\nwhen we use the term orbit , we do not consider the information contained in the phases of the orbital motion : an orbit is thus shorthand for an orbital density .\neven with this definition , each pair @xmath9 represents a family of orbits ; to uniquely identify one particular orbit , we need the presence of a third effective integral of the motion ( i.e.  we need a triple @xmath10 ) .\nthe axisymmetric nature of the system implies we can focus on the motion in a meridional plane ( i.e.  a plane with constant @xmath11 ) . for a position @xmath12 in the meridional plane ,\nthe expressions for @xmath0 and @xmath1 imply that all families of orbits that visit this position have isolating integrals of the motion @xmath9 that meet the requirement @xmath13 since we know that @xmath14 for given @xmath0 and @xmath1 , this relation restricts possible motion for the corresponding family of orbits to a toroidal volume in configuration space .    in @xmath15-space , eq .\n( [ eq : ele ] ) defines the region in which the points correspond to families of orbits passing through @xmath12 . the boundary line ( equality in eq .\n( [ eq : ele ] ) ) contains orbits that reach the given position with zero velocity ( [ eq : mv ] ) in the meridional plane .\nkeeping @xmath16 fixed while allowing @xmath17 to vary then gives us a family of such boundary lines , of which we denote the envelope by @xmath18 with the parametric equations  ( batsleer & dejonghe 1995 , eq .\n4 & 5 ) @xmath19                  l_z^2 & = \\displaystyle & - \\varpi^3 \\frac{\\partial \\psi}{\\partial \\varpi }                          ( \\varpi , z_0 ) .\n\\end{array }          \\right.\\end{aligned}\\ ] ] all points in integral space with @xmath20 represent families of orbits that will pass through @xmath21 at a certain @xmath17 .\norbits for which @xmath22 also do reach the height @xmath23 , but can never go any higher .\nall points in integral space with @xmath24 represent families of orbits that can not reach @xmath25 .\n@xmath26 is thus the minimal binding energy of an orbit that can not bring a star higher than @xmath23 above the galactic plane .    for every height @xmath27 we find a similar curve @xmath28 , with @xmath29 for every value of @xmath1 .\nsimilarly , the envelope for the orbits that can not go higher than @xmath30 is given by @xmath31 , which gives us all circular orbits in the galactic plane .\norbits belonging to a disc with a maximum height @xmath23 are thus given by @xmath9 for which @xmath32 ( the shaded area in figure 1 ) .\nbatsleer & dejonghe  ( 1995 ) constructed disc - like component distribution functions with a finite extent in vertical direction by setting them equal to zero for @xmath20 . in order to fully understand the components that we present here , that paper should probably be considered as preparatory reading .\n[ fig : fig2int ]\nwe will work in _ spheroidal coordinates _\n, since these coordinates allow a simple expression for our ( axisymmetric ) stckel potential . spheroidal coordinates are given by @xmath33 , with @xmath34 and @xmath35 the roots for @xmath36 of @xmath37 and @xmath4 cylindrical coordinates .\nthe parameters @xmath38 and @xmath39 are both constant and smaller than zero .\na potential is of _ stckel form _ , if there exists a spheroidal coordinate system @xmath33 , in which the potential can be written as @xmath40 for an arbitrary function @xmath41 , @xmath42 .\nthe function @xmath43 then represents the potential in the @xmath30 plane .    for this kind of potential ,\nthe hamilton - jacobi equation is separable in spheroidal coordinates , and therefore the orbits admit three analytic isolating integrals of the motion .\nthe third integral of galactic dynamics has the form @xmath44}\\ ] ]    more details can be found in de zeeuw  ( 1985 ) and in dejonghe & de zeeuw   ( 1988 ) .\nas mentioned before , we intend to create three - integral stellar distribution functions , for the construction of stellar discs : we want to achieve an exponential decline in the mass density for large radii , while we want to introduce a preference for ( almost ) circular orbits .\nit has been known for some time that two - integral models can describe very thin disc systems , with the restriction that both vertical and radial dispersions are equal  ( jarvis & freeman 1985 ) .\nso we want to create three - integral distribution functions that can describe very thin discs in the two - integral approximation , unlike the abel distribution functions  ( dejonghe & laurent 1991 ) .    the fricke components  ( fricke 1952 ) @xmath45 favour that part of phase space where stars populate circular orbits , so they could be taken as a starting point\nhowever , they can not be used in their basic form to model discs with a finite extent because they populate orbits which can reach arbitrary large heights : therefore , we will take as a starting point the components defined in batsleer & dejonghe  ( 1995 , eq . 19 ) .    in order to make the components depending on the third integral @xmath46\n, we introduce the factor @xmath47 in which the parameter @xmath48 ( and @xmath49 ) will be responsible for the three - integral character of the components .\nthe coefficients @xmath50 , @xmath51 , @xmath52 and @xmath48 can , in the most general case , be functions of @xmath1 .\nthis leads us towards a general three - integral disc component of the form    @xmath53    if @xmath54 the distribution function is identically zero in all other cases .\nthe function @xmath55 is defined as @xmath56    the parameter @xmath57 is the rotation parameter ( the value of @xmath57 influences only the odd moments of @xmath58 , see section 4 ) . if @xmath59 , there is no rotation for the component , and if @xmath60 , @xmath58 represents a _\nmaximum streaming _\ncomponent with no counter - rotating stars .\nthe requested exponential decline in the mass density with large radii is controlled by the parameter @xmath61 ( and to some extent by the parameter @xmath62 , see section 5 ) .\nthe parameter @xmath63 is responsible for the favouring of almost circular orbits , i.e. orbits with a binding energy @xmath0 as close as possible to that of circular orbits in the galactic plane ( see section 5 ) .\nfurthermore , if we want to favour ( almost ) circular orbits , we have to suppose the distribution function to be an increasing function of @xmath0 : this forces @xmath51 to be positive .\nsince a large @xmath46 implies that the orbit can reach a large height above the galactic plane  ( see de zeeuw 1985 for a complete analysis of the orbits in a stckel potential ) , the orbits with small @xmath46 s have to be favoured in order to describe thin discs : this forces @xmath48 to be negative .\nother constraints ( on @xmath50 , @xmath51 , @xmath52 , @xmath48 and @xmath63 ) will be imposed in section 4 , in order to enable the analytical calculations of the moments .\nthe moments of a distribution function @xmath58 at the point @xmath33 of a spheroidal coordinate system are defined as @xmath64 with @xmath65 , @xmath66 , @xmath67 the components of the velocity in the @xmath34 , the @xmath11 and the @xmath35 direction of the spheroidal coordinate system , and @xmath68 , @xmath69 , @xmath70 integers .    the mass density , the mean velocity and the velocity dispersions of the stellar system represented by @xmath58 can easily be expressed in terms of the moments ( [ defmoments ] ) by @xmath71    to obtain the value of one of these moments , we have to integrate over the volume in velocity - space corresponding to all orbits that pass through the point @xmath33 .\nsince all three integrals of the motion are quadratic in @xmath65 and @xmath67 , if @xmath68 or @xmath70 is an odd integer , the moment @xmath72 is identically zero .\nif @xmath68 and @xmath70 are even integers , the moment @xmath72 can be written as an integral computed in the integral space . we assume in sections 4.1 and 4.2 that @xmath59 ( in that case , there is no rotation and if @xmath69 is odd , the moment is zero ) and that @xmath69 is an even integer ( the general case will easily be derived from this one in section 4.3 ) . under these assumptions ,    @xmath73    where @xmath74 and @xmath75 are given by @xmath76 -                         \\frac{\\lambda+\\gamma}{2(\\lambda+\\alpha ) } l_z^2 \\\\[2 mm ]                    i_3 ^ -(e , l_z^2 ) = ( \\nu+\\gamma ) [ g(\\nu)-e ] -                         \\frac{\\nu+\\gamma}{2(\\nu+\\alpha ) } l_z^2 .\n\\end{array }          \\right.\\ ] ]    more details can be found in dejonghe & de zeeuw  ( 1988 ) .    for our components given by equation ( [ eq:3icomp ] ) ,\nthe integration surface in the @xmath77-plane is defined by @xmath78                  s_{z_0}(l_z ) \\leq e \\leq \\psi-\\frac{l_z^2}{2\\varpi^2}\\\\[2 mm ]                  p + qe + rl_z^2 + s i_3   \\geq   0 .\n\\end{array }          \\right.\\ ] ]    the integration limits for the integral in @xmath79 will be determined in section 4.3 .\nwe want to reduce the triple integral ( 13 ) to a simple one by solving the innermost double integral analytically .\nthe reader not interested in the mathematical details might step directly to section 5 .    for this double integral\nto be analytically solved , however , we will have to make use of those combinations of @xmath50 , @xmath51 , @xmath52 and @xmath48 ( see section 4.3 ) for which the integration area is transformed into the triangle bounded by @xmath80 as shown in figure [ fig : integration_areas ] .\nin this situation , we can express the factor @xmath81 as a linear combination of the other three factors in the integrandum ( corresponding to the bounding lines of the integration surface ) : @xmath82 we impose @xmath63 to be an integer : then the double integral in the @xmath77-plane transforms into a sum of integrals : @xmath83 for each integral in this summation , the integrandum consists of factors whose zero - points define the bounding lines for the integration surface in the @xmath77-plane .\nthese integrals can be solved analytically .\nwe will be in this situation ( for all the points @xmath33 of configuration space , where the moments are calculated ) whenever @xmath84 does intersect the @xmath0-axis for @xmath85 .    in order to solve the integrals analytically\n, one uses the new integration variables @xmath86 and @xmath87 , defined by ( for a fixed @xmath79 ) @xmath88 the line in the @xmath77-plane @xmath84 becomes @xmath89 , and the root of @xmath90 is @xmath91 ( see figure [ fig : integration_areas ] ) .    to make a more compact notation possible , we first define the auxiliary functions @xmath92 and @xmath93 , as @xmath94 and @xmath95    we then have @xmath96 and @xmath97    solving the integral part of one of the terms in eq.([eq : dedi3sum ] ) for @xmath87 then yields @xmath98^{\\delta+i } dy \\hspace{.5 cm } \\nonumber}\\\\           \\lefteqn{=\\frac{(-h(\\lambda))^{\\delta+i}}{(\\lambda-\\nu)^{\\delta+i+1 } }               b(\\frac{n-1}{2}+j+1,\\delta+i+1 )               \\int_0^{x_{\\mathrm { max } } } x^{\\eta + \\frac{l-1}{2}-i - j }              y_{\\mathrm { max}}(x)^{\\frac{n-1}{2}+i+j+\\delta+1 } dx } \\label{eq : dedi3term}\\end{aligned}\\ ] ]    after solving for @xmath86 ( analogous to what we did for @xmath87 ) , one obtains for the whole summation ( [ eq : dedi3sum ] )    @xmath99    the coefficients @xmath100 , @xmath101 and @xmath102 are calculated by equalizing term by term in equation ( [ eq : summation ] ) @xmath103                  0   =   -t + u + vs \\\\[2 mm ]                  -\\frac{s_{z_0}}{s_0-s_{z_0 } }   =   t(\\lambda+\\gamma){\\left[g(\\lambda)-\\frac{l_z^2}{2(\\lambda+\\alpha)}\\right]}-u(\\nu+\\gamma )                   { \\left[g(\\nu)-\\frac{l_z^2}{2(\\nu+\\alpha)}\\right]}+vrl_z^2+vp                 \\end{array }          \\right.\\ ] ]    we find for the coefficients @xmath104    with @xmath105    now we have a one - dimensional numerical integration to perform , like for the abel components  ( dejonghe & laurent 1991 ) .\nthe triple integral ( 13 ) is reduced to a simple one if we judiciously choose the parameters @xmath50 , @xmath51 , @xmath52 and @xmath48 .\nthe double integral in the @xmath77-plane ( for a fixed @xmath1 ) can be solved analytically whenever @xmath106 does intersect the @xmath0-axis for @xmath85 .\nit has to be the case for all the @xmath1 relevant in the integration .\nso if we take @xmath107 , @xmath108 and @xmath109 , the double integral can be solved analytically because @xmath110 intersects the @xmath0-axis for the value @xmath111 . in that case\n, the double condition ( [ eq : cond ] ) becomes a simple one because the condition @xmath112 is automatically verified when @xmath113 since @xmath114 and @xmath115 .\nwe now have to determine the integration limits of the simple integral in @xmath1 .\nsince conditions ( [ eq : ele ] ) and ( [ eq : cond ] ) imply that @xmath116 the integration limits for the integral in @xmath79 are , in a first time , determined by the intersections of @xmath117 and the line @xmath118 in the @xmath15-plane ( see figure 3 ) .\nfurthermore , in order to have a non - degenerate ( i.e. not empty ) triangle in figure [ fig : integration_areas ] , we must have @xmath119 since the condition @xmath120 is automatically verified when condition ( [ eq : xmax ] ) is verified , the equality in ( [ eq : xmax ] ) fixes the minimal and maximal angular momentum to take into account in the integration .\nknowing that @xmath121 , the resulting expression for the moment ( with @xmath59 and @xmath69 even ) becomes @xmath122    this integration has to be performed numerically\n.    in the general case @xmath123 , the expression ( [ eq : final ] ) is still valid for the even moments .\nwhen @xmath69 is odd , the integrandum has to be multiplied by a factor @xmath124 : @xmath125    [ fig : intarealz ]\nin this section , we show the realistic disc - like character of our stellar distribution functions : their mass density has a finite extent in the vertical direction and an exponential decline in the galactic plane , they favour almost circular orbits and their velocity dispersions are different in the vertical and radial direction . by varying the parameters\n, we can give a wide range of shapes to the components .    in order to illustrate the role of the different parameters , we calculate the moments of many component distribution functions with different values for the parameters .\nas galactic potential , we use one of the stckel potentials described by famaey & dejonghe  ( 2001 ) , that are extensions of the ones described by batsleer & dejonghe  ( 1994 ) . in the implementation of the theory\nwe choose @xmath107 , @xmath108 , and @xmath126 .\nthis parameter was introduced in order to impose a maximum height above the galactic plane for the disc - like component ( figure [ fig : parz0 ] ) : indeed , when @xmath127 , an orbit can not go higher than @xmath16 , and the distribution function ( [ eq:3icomp ] ) is null for @xmath128 . in order to model samples of stars belonging to populations with different characteristic heights above the galactic plane\n, we can use a set of components with different values for this parameter .\nthe parameter @xmath62 enters eq .\n( 10 ) as the exponent of @xmath26 : so , for non - negative values of @xmath62 , the factor where it appears will behave as a declining function of @xmath1 , in the same way as @xmath117 does , showing a steeper decline for larger @xmath62 ( see figure [ fig : a1 ] ) .\na large @xmath62 thus results in a distribution function that favours a large fraction of bound orbits .\nwhen it is increasing , this parameter helps to produce mass close to the center .\nwhen a given exponential decline is requested , @xmath62 will be a function of the other parameters rather than a fixed parameter ( see section 5.3 ) .\nthe parameter @xmath61 occurs as exponent in the distribution function s exponential factor .\nincreasing values of this parameter will contribute to the mass distribution near the center ( figure [ fig : a2 ] ) , like in the @xmath62 case ( but exponentially ) .\non the other hand , our potential is approximately keplerian at very large radii : this implies that , in the galactic plane , @xmath129 and that ( batsleer & dejonghe 1995 ) @xmath130    so , at very large radii , @xmath61 is the reciprocal of the component s scale length , if the contribution of the other factors to the mass density does not vary much with respect to @xmath17 ( for very large @xmath17 ) . in practice , it is often desirable to use components for which an exponential decline and a given scale length ( as determined by @xmath61 ) is already built - in between two radii ( say @xmath131 and @xmath132 ) . in such cases ,\nthe parameter @xmath62 is adjusted in such a way that it corrects for the non - constant behaviour of the other factors at large radii , making the global contribution of all factors ( except the one in @xmath61 ) constant at @xmath131 and @xmath132 .      for this parameter , there are two distinct cases : @xmath134 and @xmath135 . in the first case ,\nthe density is maximum in the center and falls off smoothly . in the latter case ,\nthe density is null in the center since @xmath136 for @xmath137 . in order to model real stellar systems , we need components with @xmath134 to have some mass in the center .\nhowever , in a real galaxy , the maximum number of stars occurs in the intermediate region where the bulge meets the disc : this justifies the utilization of components with @xmath135 when modelling real stellar systems .\nwe see the maximum density moving away from the center when @xmath133 is rising ( figure [ fig : parb ] ) .\nwe also see on figure ( [ fig : parb ] ) that an increasing @xmath133 will concentrate the mass in a smaller region of configuration space .\n[ fig : parg ]    for a given @xmath1 , the largest value of the factor @xmath138 is obtained when the binding energy @xmath139 corresponds to the circular orbits in the galactic plane ( see figure 1 ) .\nso , the parameter @xmath63 is responsible for the favouring of almost circular orbits : a larger @xmath63 implies a larger contribution of almost circular orbits ( figure [ fig : parg ] ) and thus a mass density located closer to the plane .\ncondition ( [ eq : cond ] ) @xmath140 implies that for @xmath141 and a strictly negative @xmath48 , the orbits can not reach the height @xmath23 above the galactic plane .\nwe see on figure ( [ fig : pars ] ) that the height @xmath23 is reached only in the case @xmath142 . furthermore , since a large @xmath46 corresponds to an orbit that can reach a large height , the factor @xmath143 favours orbits that stay low .\nso , by setting @xmath48 more negative , we confine the orbits closer to the galactic plane .\na very important property of our components is the possibility of introducing a certain amount of anisotropy in the stellar disc : if we denote by @xmath144 the dispersion of the velocity in the direction perpendicular to the galactic plane , and by @xmath145 the dispersion of the radial velocity in the galactic plane , then any nonzero @xmath48 will produce a ratio @xmath146 less than 1 ( figure [ fig : dispratio ] ) .\nthe ratio is closer to unity in the center than in the outer regions : this indicates the physically realistic character of our components . for @xmath142 , we find @xmath147 since we are dealing with a two - integral component again .\na large @xmath49 has partly the same effects as a large @xmath63 : it favours circular orbits .\nfurthermore , a large @xmath49 augments the effects of the negative @xmath48 and forces the stars to stay close to the plane by favouring low @xmath46-values . as we can see on figure ( [ fig : pard ] ) , a component with a larger @xmath49 has more stars in the galactic plane but shows a steeper decline with respect to @xmath7 .\nthe component distribution functions described in this paper are very useful as basis functions in the method described by dejonghe  ( 1989 ) , in order to model any observable quantities ( spatial mass density , velocity dispersions , average radial velocities on a sky grid , ... ) . as an illustration , we present the application of the method to fit a given spatial density @xmath148 ( see batsleer & dejonghe 1995 for a similar application in the two - integral approximation ) .\nwe look for a linear combination of our components @xmath149 that fits @xmath148 , with @xmath150 and @xmath151 the coefficients that are to be determined .    in practice , to find this linear combination we must introduce a grid @xmath152 in configuration space and minimize the quadratic function in @xmath153 : @xmath154 ^ 2 \\label{eq : chi2}\\ ] ] this minimization , together with the constraint that the distribution function must be positive in phase space , is a problem of quadratic programming ( hereafter qp ) described by dejonghe  ( 1989 ) .    here , we choose to adopt for @xmath155 a spatial density which closely resembles that of a real disc , i.e. a van der kruit law , for which the vertical disribution is a good compromise between an exponential and an isothermal sheet  ( van der kruit 1988 ) .\n@xmath156 in order to have a zero derivative with respect to @xmath17 on the rotation axis , we adopt a mass density that follows closely the van der kruit law , without a cusp in the center ( see also batsleer & dejonghe  1995 ) :    @xmath157    with @xmath158 and @xmath159 denoting the horizontal and vertical scale factor , respectively .\nsince the moments @xmath160 are dependent on the potential of the galaxy ( including the dark matter ) , we have to choose a potential for the galaxy that contains the stellar disc we want to model .\nwe adopt a stckel potential with three mass components that produces a flat rotation curve and that therefore is a candidate potential for a disc galaxy ( famaey & dejonghe 2001 , see also batsleer & dejonghe 1994 ) .\nthe actual modelling follows the same strategy as followed by batsleer & dejonghe  ( 1995 ) , which we briefly repeat here for easy reference .\nthe first step in the actual modelling consists in the selection of a subset of components out of the ( infinite ) set of possible components .\nthis subset is chosen so that certain features , that we suppose to be present in the stellar disc , such as circular orbits , are included .\nfor example , we expect the mass density corresponding to a component to have an exponential behaviour close to the mass density we want to model .\nthe qp program first minimizes the function ( [ eq : chi2 ] ) for one component @xmath161 and chooses the component of the initial subset that produces the lowest minimum for that function ( [ eq : chi2 ] ) . then the program iterates , selecting and adding at each iteration the component which , together with the components already chosen in a previous run , produces the best fit .\nonce the minimum of the @xmath162-variable does not change significantly any more with the addition of extra components , the program is halted because too low a value for @xmath162 could imply that the qp program starts producing a distribution function featuring unnecessary oscillations .    as an example\n, we model a modified van der kruit disc with @xmath163kpc and @xmath164kpc .\nbatsleer & dejonghe  ( 1995 ) already showed that a linear combination of two - integral components ( with @xmath142 and @xmath165 ) could fit such a disc , but with @xmath166 . in order to model real anisotropic velocity data in the future\n, the dependence on the third integral will be needed .\nwe show that , by choosing components with @xmath167 ; @xmath168 ; @xmath169 ; @xmath170 ; @xmath171 ; @xmath172 ; @xmath173 and @xmath59 in the initial subset , a fit with components featuring @xmath174 and @xmath175 can be obtained too ( see figure 12 ) .\nthe fit is obtained for a linear combination of @xmath176 components at @xmath177 configuration space points ( @xmath178 degrees of freedom ) .\nif we assume relative errors of @xmath179 , we obtain for our minimum @xmath180 , and the probability that a value of @xmath162 larger than @xmath181 should occur by chance is @xmath182  ( abramowitz & stegun 1972 ) , which makes the goodness - of - fit believable  ( press et al . 1986 ) .    by using stckel dynamics to model a galactic disc ,\nwe construct a completely explicit and analytic distribution function , with an explicit dependence on the third integral .\nfigure ( 13 ) displays the distribution function obtained by qp in function of @xmath0 , for @xmath183 and for two values of @xmath46 ( @xmath184 and @xmath185 ) . for @xmath184 , the distribution function is non - zero if @xmath186 ( with @xmath187kpc ) ; for @xmath188 , instead , the maximum value of @xmath0 is the one corresponding to infinitesimally thin short axis tubes and is smaller than @xmath189 .\nwe see on figure ( 13 ) that the distribution function is decreasing with increasing @xmath46 ( particularly near @xmath190 ) , and that it has some clumps .\nthese clumps at @xmath185 are not discontinuities since the distribution function is a linear combination of continuous components .\nmany different three - integral distribution functions correspond to a given spatial density , and there is no guarantee that they will yield realistic velocity dispersions .\nit is a major result of this paper to show that it is possible to find a linear combination of our components yielding realistic velocity dispersions .\nfigure ( 14 ) displays the ratio @xmath146 in the galactic plane : at the radius corresponding to the solar position in the milky way ( @xmath191-@xmath192 kpc ) , the classical value of @xmath193 is obtained .\nthe local maximum in the @xmath146 curve is due to the individual shapes of the velocity dispersions curves ( figure 14 ) .\nin this paper , we have constructed new analytic three - integral stellar distribution functions yielding @xmath194 : they are generalizations of two - integral ones that can describe thin discs with the restriction that @xmath195  ( batsleer & dejonghe 1995 ) .\nwe first reduced the triple integral defining their moments to a simple one , like in the abel case  ( dejonghe & laurent 1991 ) , by making some assumptions on the parameters .\nthen we looked for the effects of the different parameters and showed the disc - like ( physically realistic ) features of our distribution functions : they have a finite extent in vertical direction and an exponential decline in the galactic plane , while favouring almost circular orbits .\na very important feature induced by the dependence on the third integral is their ability to introduce a certain amount of anisotropy , by varying the parameters responsible for this dependence ( @xmath48 and @xmath49 ) .\nwe finally showed that a van der kruit disc can be modelled by a linear combination of such distribution functions with an explicit dependence on the third integral and a realistic anisotropy in velocity dispersions .\nthis implies that they are very promising tools to model real data with @xmath194 ( hipparcos data for example ) by using the quadratic programming algorithm described by dejonghe  ( 1989 ) .\nthis will provide information on the dynamical state of tracer stars in the milky way ( or on external galaxies ) .\nwe thank dr alain jorissen very much for his permanent assistance .\nwe thank the referee dr stephen levine for his thorough reading of the manuscript and many helpful suggestions .\n99 abramowitz m. , stegun i.a .\n, 1972 , handbook of mathematical functions , dover , new york batsleer p. , dejonghe h. , 1994 , a&a , 287 , 43 batsleer p. , dejonghe h. , 1995 , a&a , 294 , 693 bienaym o. , 1999 , a&a , 341 , 86 bienaym o. , schaud n. , 1997 , a&a , 323 , 781 binney j.j .\n, merrifield m.r . , 1998 , galactic astronomy , princeton univ .\npress , princeton cretton n. , de zeeuw p.t .\n, van der marel r.p . ,\nrix h .- w . , 1999 , apjs , 124 , 383 dehnen w.d . , gerhard o.e . , 1993 , mnras , 261 , 311 dejonghe h. , 1989 , apj , 343 , 113 dejonghe h. , de zeeuw p.t . , 1988 , apj , 333 , 90 dejonghe h. , laurent d. , 1991 , mnras , 252 , 606 de zeeuw p.t . , 1985 , mnras , 216 , 273 de zeeuw p.t .\n, evans n.w .\n, schwarzschild m. , 1996 , mnras , 280 , 903 durand s. , dejonghe h. , acker a. , 1996 , a&a , 310 , 97 evans n.w . , hfner r. , de zeeuw p.t . , 1997 , mnras , 286 , 315 famaey b. , dejonghe h. , 2001 , astro - ph/0112065 fricke w. , 1952 , astron .\n, 280 , 193 hfner r. , evans n.w .\n, dehnen w.d . , binney j.j . , 2000 ,\nmnras , 314 , 433 innanen k.p . , papp k.a . , 1977 , aj , 82 , 322 jarvis b.j . , freeman k.c . , 1985 , apj , 295 , 314 jeans j.h . , 1915 ,\nmnras , 76 , 70 kruit p.c .\nvan der , 1988 , a&a , 192 , 117 ollongren a. , 1962 , bull .\nnetherlands , 16 , 241 petrou m. , 1983a , mnras , 202 , 1195 petrou m. , 1983b , mnras , 202 , 1209 press w.a . , flannery b.p .\n, teukolsky s.a . , vetterling w.t .\n, 1986 , numerical recipes , cambridge univ . press , cambridge richstone d.o . , 1982 ,\napj , 252 , 496 robijn f.h.a .\n, de zeeuw p.t . , 1996 , mnras , 279 , 673 schwarzschild m. , 1979 , apj , 232 , 236 stckel p. , 1890\nann . , 35 , 91 zhao h.s . , 1999 ,\ncemda , 73 , 187"}
{"lay_summary": " we analyze the dynamics of a single - level quantum dot with coulomb interaction , weakly tunnel coupled to an electronic reservoir , after it has been brought out of equilibrium , e.g. by a step - pulse potential . \n we investigate the exponential decay towards the equilibrium state , which is governed by three time scales . \n in addition to the charge and spin relaxation time there is a third time scale which is independent of the level position and the coulomb interaction . \n this time scale emerges in the time evolution of physical quantities sensitive to two - particle processes . ", "article": "the control and manipulation of single electrons in mesoscopic systems constitutes one of the key ingredients in nanoelectronics .\nthe study of single - electron sources@xcite in the high - frequency regime has attracted a great interest due to their potential application in quantum electron optics experiments , in metrology , and in quantum information processing based on fermionic systems.@xcite in this work we study the time evolution of a quantum dot ( qd ) tunnel coupled to a single electronic reservoir , as depicted schematically in fig .  [ fig_scheme](a ) . in the presence of some time - dependent voltage modulations ,\nthis system defines the building block of the typical single - electron source , namely the mesoscopic capacitor.@xcite in the linear - response regime , the relaxation behavior of such a mesoscopic capacitor has been extensively studied theoretically@xcite and experimentally,@xcite revealing the quantization of the charge relaxation resistance.@xcite on the other hand , the application of _ nonlinear _ periodic potentials to the mesoscopic capacitor yields the controlled emission and absorption of electrons at giga - hertz frequencies.@xcite from these experiments the average charge as well as current correlations@xcite after each cycle of the potential applied have been extracted .\nthese results demonstrate the importance of investigating the dynamics of this kind of single - electron sources . in some of the recent realizations@xcite\nthe coulomb interaction is weak ; however , in small - sized qds the coulomb blockade is , in general , strong and it is , therefore , desirable to include it in the theoretical analysis @xcite since it may even dominate time - dependent phenomena , see e.g. ref .  .\nthe time - evolution of interacting quantum dots after the coupling to the leads has been switched on , has , e.g. , been studied in refs .   and references therein .    , coupled to a normal lead with a tunneling strength @xmath0 .\ndot occupations can be measured via the current passing through a nearby quantum point contact ( qpc ) capacitively coupled to the dot .\nb ) qd attached to an additional superconducting contact .\nc ) qd coupled to a ferromagnetic lead . ]    here we investigate the exponential relaxation of a qd towards its equilibrium state after its has been brought out of equilibrium by applying , e.g. , a voltage step pulse .\nwe consider a voltage pulse that affects the occupation of only a single orbital energy level .\nthe level can be spin split due to coulomb interaction . in an earlier work,@xcite some of the present authors investigated the decay of charge and spin of such a single level qd .\nit was found that the relaxation of charge and spin are given by rates which differ from each other due to coulomb repulsion . since the reduced density matrix of a qd with a single orbital level with spin is four dimensional , there are thus three rates which govern the relaxation of the diagonal elements of the density matrix towards equilibrium ( plus one which is always zero and corresponds to the stable stationary state ) .\nin addition to the rates that govern charge and spin there is a third rate that appears in the relaxation of a single level qd with spin and with interaction .\nthis additional rate is the subject of this paper .\ninterestingly , this additional time scale is independent of the interaction and of the dot s level position .\nit is shown to be related to two - particle effects and appears , e.g. , in the time - evolution of the mean squared deviations of the charge from its equilibrium value .\nwe study in detail the perturbations leading to a relaxation of the system with the additional decay rate only , and find that it is indeed related to two - particle correlations .\nwe also propose a procedure to separately read out the different relaxation rates occurring in the dynamics of the qd exploiting the sensitivity of a nearby quantum point contact to the occupation of the qd , see fig .\n[ fig_scheme ] ( a ) .    in order to further clarify the properties of the additional time scale , we extend our study to two other setups :\na qd proximized by an extra , superconducting electrode and tunnel coupled to a normal lead ; and a qd tunnel coupled to a ferromagnetic lead , see fig .\n[ fig_scheme ] ( b ) and ( c ) .\nwe consider a quantum dot coupled to an electronic reservoir .\nwe assume that the single - particle level spacing in the dot is larger than all other energy scales , so that only one , spin - degenerate level of the qd spectrum is accessible . at a certain time\n@xmath1 the system is brought out of equilibrium , e.g. by applying a gate potential , and afterwards relaxes to an equilibrium dictated by the hamiltonian @xmath2 .\nthe hamiltonian @xmath3 of the decoupled dot @xmath4 contains the spin - degenerate level @xmath5 and the on - site coulomb energy @xmath6 for double occupation of the dot .\nthe creation ( annihilation ) operator of an electron with spin @xmath7 on the dot is denoted by @xmath8 and @xmath9 is the corresponding number operator .\nthe reservoir is modeled by the hamiltonian @xmath10 , in which @xmath11 creates ( annihilates ) an electron with spin @xmath12 and momentum @xmath13 in the lead .\nthe coupling between the dot and the reservoir is described by the tunneling hamiltonian @xmath14 , where @xmath15 is a tunneling amplitude , which we assume to be independent of momentum and spin . by considering a constant density of states @xmath16 in the reservoir ,\nthe tunnel coupling strength @xmath0 is defined as @xmath17 .    in the remainder of this paper , we focus on the relaxation behavior of the quantum dot to its equilibrium state and in particular on how this relaxation manifests itself in measurable quantities .\nwe are not interested in the dynamics of the reservoir , thus the trace over its degrees of freedom is performed to obtain the reduced density matrix of the qd .\nthe hilbert space is spanned by the four eigenstates of the decoupled dot hamiltonian , @xmath18 , where @xmath19 represents the unoccupied dot , the dot is in the state @xmath20 when being singly occupied with spin @xmath7 , and @xmath21 is the state of double occupation .\nthe energies related to these states are @xmath22 and @xmath23 , where we set the electrochemical potential of the reservoir to zero .\nas we consider spin - conserving tunneling events , the off - diagonal elements of the reduced density matrix evolve independently of the diagonal ones ( which are the occupation probabilities ) .\nwe can , therefore , consider these probabilities alone , which arranged in a vector are given by @xmath24 and fulfill the condition @xmath25 .\nthe time evolution of the occupation probabilities is governed by the generalized master equation @xmath26 where the matrix elements @xmath27 of the kernel @xmath28 describe transitions from the state @xmath29 at time @xmath30 to a state @xmath31 at time @xmath32 .\nwe consider now the dynamics of the system after being brought out of equilibrium at time @xmath1 .\nsince for @xmath33 the total hamiltonian is time independent , the transition matrix elements depend only on the time difference @xmath34 , i.e. @xmath35 .\nfurthermore , we are interested in the exponential decay towards equilibrium . to be more specific , we will therefore consider only the leading , time - independent , prefactor of the exponential functions .\ntime - dependent corrections to the pre - exponential functions , that generally may appear,@xcite are disregarded .\nfurthermore , when focussing on times @xmath32 distant from the switching time @xmath1 , such that the difference @xmath36 is hence much larger than the decay time of the kernel @xmath37 , we can replace the lower limit of the integral in eq .\n( [ eq_master ] ) by @xmath38 . expanding the probability vector @xmath39 in eq .\n( [ eq_master ] ) around the measuring time @xmath32 we find@xcite @xmath40 here we introduced the laplace transform of the kernel @xmath41 , with @xmath42 and the @xmath43-th derivative of the kernel with respect to the laplace variable @xmath44_{z=0}$ ] .\nthe formal solution of eq .\n( [ eq_masterexpand ] ) is given by @xmath45 which depends on the initial probability vector @xmath46 at @xmath47 , where the initial values for the system parameters are given by the ones just after the switching time @xmath1 .\nthe matrix @xmath48 includes markovian and non - markovian processes.@xcite in the following , we consider the limit of weak coupling between quantum dot and reservoir and limit ourselves to a perturbation expansion up to second order in @xmath0 , which is valid for the regime where the tunnel coupling @xmath0 is much smaller than the energy scale set by the temperature @xmath49 .\nthe perturbative expansion of @xmath48 is @xmath50 with @xmath51 and @xmath52 , where the number in the superscript represents the power of @xmath0 included in the transition matrix @xmath53 .\nnotice that the first non - markovian correction , i.e. the term @xmath54 is present in second - order in the tunnel coupling .\nthe evaluation of the kernel within a perturbative expansion can be performed using a real - time diagrammatic technique,@xcite which has been used in ref .   in order to extract the exponential decay of spin and charge in the system studied here .\nconsidering eq .\n( [ eq_exp ] ) , we see that the rates defining the decay of the state into equilibrium are found from the eigenvalues of the matrix @xmath48 , which turn out to be real and non - positive .\nthe matrix @xmath48 is not hermitian , as expected since we deal with a dissipative system , and hence has different left and right eigenvectors , @xmath55 and @xmath56 .\nthe time - dependent probability vector , @xmath57 , can be expressed in terms of the right eigenvectors of @xmath48 , each being related to a decay with a different rate .\nthe left eigenvectors determine the observable that decay with a single time scale only , see also the appendix .\n+ in the following we discuss the exponential relaxation towards equilibrium of the vector of occupation probabilities , in first order in the tunneling strength @xmath0 .\nwe start by briefly discussing the simplest case of a single spinless particle .\nthis limit is obtained , when a magnetic field much larger than the temperature is applied , @xmath58 .\nthe hilbert space of the system is two dimensional and spanned by the states @xmath19 and @xmath59 for the empty and singly - occupied dot respectively , whose occupation probabilities are arranged in the vector @xmath60 .\nthe decay to the stationary state is governed by matrix @xmath61 ( defined equivalently to @xmath62 but for the two - dimensional hilbert space for the problem at hand ) which contains a single relaxation rate , namely the tunnel coupling @xmath0 , as intuitively expected .\nwe now include the spin degree of freedom but disregard interactions .\nthe system is described by two independent hilbert spaces spanned by the states @xmath63 and @xmath64 with @xmath7 .\nthe probability vector for each spin @xmath12 can be written in terms of the eigenvalues and eigenvectors of the matrix @xmath61 ( for the two - dimensional hilbert space ) as @xmath65 \\label{eq_psigma}\\ ] ] where the right eigenvector corresponding to the eigenvalue zero of @xmath61 defines the occupation probabilities for the equilibrium state , @xmath66 , with the fermi function @xmath67^{-1}$ ] and the inverse temperature @xmath68 .\nfurthermore , @xmath69 is the vector representation of the number operator for dot electrons with spin @xmath12 , whose initial / equilibrium expectation value is obtained by multiplying it from the left into the initial / equilibrium probability vector , @xmath70 . the rate @xmath71 is obtained as the negative of the non - zero eigenvalue of @xmath61 , with the corresponding left eigenvector being @xmath72 .\nthe time evolution of the occupation of each spin state is governed by a single decay rate @xmath0 , @xmath73 this equation can be obtained making use of the fact that the time evolution of the expectation value of any operator , which describes an observable of the qd , is given by projecting its vector representation from the left onto eq .\n( [ eq_psigma ] ) .\nthe time evolution of the total charge of the dot , @xmath74 , is also determined by a single relaxation rate @xmath71 .\nthis means that both charge and spin , which are quantities related with single - particle processes , do not evolve independently from each other and the corresponding decay is given by the same rate .\na similar non - interacting problem has been studied _ non - pertubatively _ in refs . and .    as a next step we consider the squared deviation of the charge from its equilibrium value , @xmath75 ^ 2 $ ] .\nits time evolution is obtained from eq .\n( [ eq_psigma ] ) as @xmath76 ^ 2\\rangle(t)-[\\langle\\hat{n}\\rangle^{\\text{eq}}]^2\\\\ & & = \\sum_{\\sigma=\\uparrow,\\downarrow}[1+\\langle\\hat{n}_{\\sigma}\\rangle^{\\text{eq}}]\\langle\\hat{n}_{\\sigma}\\rangle(t)+2\\langle\\hat{n}_{\\uparrow}\\hat{n}_{\\downarrow}\\rangle(t)\\nonumber\\end{aligned}\\ ] ] the last , two - particle term of this expression exhibits a decay rate given by @xmath77 .\nthis is in contrast to the spinless case , where such a term does not appear since double occupation is not possible .\nsuch an additional exponential decay with the rate @xmath78 appears directly in the time evolution of the probability vector , when considering the full two - particle hilbert space spanned by the basis @xmath79 . in this basis , eq .\n( [ eq_exp ] ) for the non - interacting regime can be written as :    @xmath80\\\\ \\frac{1}{2}\\left[1 - 2f(\\epsilon)\\right]\\\\ \\frac{1}{2}\\left[1 - 2f(\\epsilon)\\right]\\\\ f(\\epsilon ) \\end{array}\\right ) e^{-\\gamma t}\\left(\\langle\\hat{n}\\rangle^\\mathrm{in}-\\langle\\hat{n}\\rangle^\\mathrm{eq}\\right)\\nonumber \\\\\n+ \\left(\\begin{array}{c } 0\\\\ \\frac{1}{2}\\\\ -\\frac{1}{2}\\\\ 0 \\end{array}\\right ) e^{-\\gamma t}\\langle\\hat{s}\\rangle^\\mathrm{in } + \\left ( \\begin{array}{c } -1\\\\1\\\\1\\\\-1 \\end{array } \\right ) e^{-2\\gamma t}\\left ( \\langle\\hat{m}\\rangle^\\mathrm{in}-\\langle\\hat{m}\\rangle^\\mathrm{eq } \\right ) \\nonumber\\\\\\end{aligned}\\ ] ]    where as before , @xmath81 defines the state at equilibrium . the decaying part of the probability vector can be divided into three contributions which appear depending on how the initial state at @xmath1 differs from the equilibrium state .\ndeviations of charge and spin from their equilibrium value relax with the same rate @xmath0 .\nthe corresponding expectation values are calculated by multiplying the probability vector eq .\n( [ ptot ] ) from the left with the vector representation of the operators @xmath82 and @xmath83 which represent the charge and spin , respectively , in this two - particle basis .\nthe two left eigenvectors of the matrix @xmath84 with the same eigenvalue @xmath85 , are given by @xmath86 and @xmath87 .\nthe third contribution to the decay of the system into the equilibrium comes from the relaxation rate @xmath78 , which enters the probability vector in connection with a quantity @xmath88 , defined by the operator in vector notation @xmath89 the left eigenvector of @xmath62 with the eigenvalue @xmath90 is given by @xmath91 .\nin contrast to charge and spin , the quantity represented by @xmath88 does not have a straightforward intuitive interpretation , since it depends on the quantum dot parameters at @xmath33 and on the temperature and chemical potential of the reservoir via the fermi functions .      from now on we assume a finite on - site coulomb repulsion @xmath6 on the dot .\nanalogously to the noninteracting case discussed before , from eq .\n( [ eq_exp ] ) we can write the time - dependent probability vector in terms of contributions exhibiting different decay times    @xmath92\\\\ \\frac{1}{2}\\left[1-f(\\epsilon)-f(\\epsilon+u)\\right]\\\\ \\frac{1}{2}\\left[1-f(\\epsilon)-f(\\epsilon+u)\\right]\\\\ f(\\epsilon+u ) \\end{array}\\right)e^{-\\gamma_n t}\\left(\\langle\\hat{n}\\rangle^\\mathrm{in}-\\langle\\hat{n}\\rangle^\\mathrm{eq}\\right ) \\nonumber \\\\ & & + \\left(\\begin{array}{c } 0\\\\ \\frac{1}{2}\\\\ -\\frac{1}{2}\\\\ 0 \\end{array}\\right ) e^{-\\gamma_s t}\\langle\\hat{s}\\rangle^\\mathrm{in}+\\left ( \\begin{array}{c } -1\\\\1\\\\1\\\\-1 \\end{array } \\right ) e^{-\\gamma_m t}\\left ( \\langle\\hat{m}\\rangle^\\mathrm{in}-\\langle\\hat{m}\\rangle^\\mathrm{eq } \\right)\\ .\\end{aligned}\\ ] ]    again , @xmath93 is the eigenvector of @xmath51 with the zero eigenvalue and represents the equilibrium state in lowest order in the tunnel coupling ( the explicit form of the four - dimensional matrix @xmath62 , together with its entire set of eigenvalues and eigenvectors , is given in the appendix ) .\nin the two - particle basis , again @xmath94 represents the charge operator , and @xmath95 represents the spin operator .\nthe form of the operator @xmath88 is modified by the presence of finite coulomb interaction ; the explicit form will be discussed later in this sub - section ( see eq .\n( [ eq_def_m ] ) below ) .\nthe initial and equilibrium expectation values for these operators , entering in the above eq .\n( [ eq_solution ] ) , are obtained as @xmath96 , with @xmath97 .\nexplicit expressions for @xmath98 and @xmath99 are shown below .\nthe negative of the other three eigenvalues of @xmath62 directly determine the decay of charge , spin,@xcite and the quantity denoted by @xmath88 .\nthese decay rates read    @xmath100\\label{eq_lcharge1}\\\\ \\gamma_s&=&\\gamma\\left[1-f(\\epsilon)+f(\\epsilon+u)\\right]\\label{eq_lspin1}\\\\ \\gamma_m&=&2\\gamma . \\label{eq_lmal1}\\end{aligned}\\ ] ]    notice that due to interaction , the relaxation rates for charge and spin ( @xmath101 and @xmath102 respectively ) differ from each other and depend on the level position @xmath5 , in contrast to the non - interacting case .\ntheir dependence on the level position is shown in fig .\n[ fig_decay ] . in the region for @xmath103 , @xmath101 is enhanced as the charge decays into the twofold degenerate state of single - occupation , whereas the spin relaxation in first order in @xmath0 is suppressed , since spin - flip processes are not possible .\nhowever , the third decay rate , @xmath104 , remains fully energy independent as in the case with @xmath105 .\n( blue , dashed line ) , @xmath101 ( red , dash - dotted line ) and @xmath102 ( green , solid line ) in units of @xmath0 as a function of the dot level position @xmath5 .\nthe temperature is @xmath106 and the interaction energy is @xmath107 . ]\nthe right eigenvectors occurring in eq .\n( [ eq_solution ] ) each represent a change to the steady state density matrix that decays exponentially with rate @xmath108 ( @xmath109 ) .\ntherefore , a system being brought out of equilibrium by a symmetric deviation between @xmath110 and @xmath111 only , is decaying with a rate @xmath102 .\na deviation from equilibrium in which the occupation of the even sector , @xmath112 is symmetrically shifted from the odd sector , @xmath113 , is governed solely by the relaxation rate @xmath104 .\nthis right eigenvector is found to play an important role also in the low - temperature renormalization of this model .\n@xcite an energy - dependent change in the occupation probabilities as prescribed by the second vector in eq .\n( [ eq_solution ] ) yields a decay of the total charge of the system with the rate @xmath101 .\nthe conditions under which specific deviations from the equilibrium state should be performed in order to obtain a specific decay rate , are discussed in the following section .\nthe attribution of these relaxation rates to the charge , spin , and @xmath88 arises from the independent decay of these quantities , due to the explicit form of the _ left _ eigenvectors of @xmath62 .\nthe spin operator coincides with the left eigenvector associated to the eigenvalue @xmath114 and since it has a vanishing equilibrium value , the time evolution of its expectation value is given by @xmath115    equivalently , the left eigenvector corresponding to the eigenvalue @xmath116 , is @xmath117 .\nit contains the charge operator @xmath118 and its equilibrium value @xmath119 $ ] .\nhence , for the time evolution of the charge we find @xmath120     as a function of the dot level position @xmath5 .\nthe other parameters are : @xmath106 and @xmath107 . ]    the quantity decaying with the rate @xmath104 alone is related to the left eigenvector @xmath91 , where the operator @xmath88 is given by @xmath121 its expectation value follows a time evolution equivalent to the one for the charge in eq .\n( [ eq_nrelax ] ) : @xmath122 .\nits equilibrium value @xmath123 $ ] , plotted in fig .\n[ fig_meh ] , is - in contrast to spin and charge - not sensitive to the regime of single occupation on the quantum dot .\ninstead , it exhibits a feature close to the electron - hole symmetric point of the anderson model , indicating that @xmath88 represents a quantity which is affected by two - particle effects and it decays with a rate that is not modified by the coulomb interaction @xmath6 . already for the noninteracting case , we found that the rate @xmath78 appears as a consequence of introducing two particles in the system , and we considered the deviations from equilibrium charge as a quantity involving two - particle processes leading to such a decay rate .\nalso in the case for finite coulomb interaction , the time - dependent mean squared deviations @xmath124\n^ 2\\rangle(t)$ ] are suitable to reveal the relaxation rate @xmath125 .\ntheir time evolution is obtained by means of eq .\n( [ eq_solution ] ) and reads @xmath126 ^ 2\\rangle(t ) - [ \\langle \\hat{n}\\rangle^\\mathrm{eq}]^2 & = & c\\cdot\\langle \\hat{n}\\rangle(t)-2\\cdot\\langle \\hat{m}\\rangle(t)\\nonumber\\\\   \\label{eq_variance}\\end{aligned}\\ ] ]     ( red , solid line ) and the coefficient @xmath127 ( blue , dashed line ) as a function of the dot level position @xmath5 .\nthe other parameters are : @xmath106 and @xmath107 . ]    where in front of the time - dependent charge @xmath128 the following coefficient appears : @xmath129 with @xmath130    the quantity @xmath131/\\left[1+f(\\epsilon)-f(\\epsilon+u)\\right]$ ] is the difference between the probability of doubly occupied and empty dot in equilibrium , which can also be related with the occupation of electrons and holes , @xmath132 . the behavior of @xmath133 is shown in fig .  [ fig_coeff ] . for @xmath134 ,\nwhen the dot is doubly occupied , @xmath135 ; for @xmath103 , when one electron and one hole are present in the system ( singly occupied dot ) , @xmath136 ; and for @xmath137 , when the system is completely `` filled with holes '' ( empty dot ) , @xmath138 .\nthe quantity @xmath127 is also shown in fig .  [ fig_coeff ] ( blue dashed line ) , exhibiting a sign change around @xmath139 , the point at which the anderson model is electron - hole symmetric . by replacing @xmath140 , we go from the electron - like to the hole - like behavior , finding an inversion in the sign of @xmath127 , @xmath141 .\nthe function @xmath127 therefore indicates whether the spectrum of the quantum dot is electron - like or hole - like .\nthe mean squared deviations of the charge from its value at equilibrium is an example for a physical quantities showing a decay with @xmath104 ; it also includes the charge relaxation rate @xmath101 , which is found independently from the time evolution of the charge .\nequivalently also the time - resolved charge variance , @xmath142 ^ 2\\rangle(t)$ ] , or the time - resolved spin variance,@xcite @xmath143 , contain a contribution decaying with @xmath104 .\nwe now consider in detail which external perturbations are necessary in order to induce a decay of the _ full _ occupation probability vector with one certain relaxation rate only , in a controlled way .\nfurthermore , we address the conditions under which a single decay rate can be extracted more easily from the occupation of a single state by a measurement with a nearby quantum point contact ( qpc ) .\nwe first address the case of an infinitesimal perturbation ( linear response ) .\na small variation of the gate potential leads to a decay of the charge governed by the charge relaxation rate @xmath101 .\nsimilarly , the infinitesimal variation of the zeeman splitting in the dot yields a decay with the spin relaxation rate @xmath102 . in order to obtain a decay of the state with the rate @xmath104 only , it is not sufficient to modulate the gate voltage , also the two - particle term in the hamiltonian , @xmath144 , needs to be varied .\nthe on - site repulsion @xmath6 could be changed , for example , by tuning the carrier density in a nearby two - dimensional electron gas , thereby controlling the screening of the electron - electron interaction in the dot . from eq .\n( [ eq_solution ] ) we know that a dynamics given only by @xmath104 is obtained if the occupation of the even states are changed in the same direction , opposite to that of the single occupied states ; this condition is fulfilled if infinitesimal variations of the gate , @xmath145 , and of the interaction , @xmath146 , obey the relation : @xmath147)}{1+\\exp(\\beta\\epsilon)}d\\epsilon . \\label{dvarm}\\ ] ] this expression is represented in terms of field lines in fig .  [ fig_field ] . an infinitesimal change tangential to the field line passing through the point corresponding to the initial values of @xmath5 and @xmath6 leads to a pure decay with @xmath104 .\nfor parameter variations that are not infinitesimal ( beyond linear response ) , a change only of the gate voltage results in a decay of the state with both rates @xmath101 and @xmath104 . from eq .\n( [ eq_solution ] ) we find that a finite variation of the energy level and the interaction from an initial condition @xmath148 to @xmath149 resulting in a relaxation containing solely @xmath101 , satisfies the equation @xmath150 . \\label{varn}\\ ] ] a relaxation given _ only _ by the rate @xmath104 is found when the relation : @xmath151 \\label{varm}\\ ] ] is fulfilled . for different values of @xmath152 and @xmath153 , eq .\n( [ varm ] ) produces again the field lines shown in fig .\n[ fig_field ] . therefore ,\nfinite variations of the parameters between two points lying on _ the same _ field line yield a dynamics for the entire occupation probabilities vector @xmath154 governed only by @xmath104 . obviously , a generic variation in both @xmath5 and @xmath6 which does not fulfill the conditions specified by eqs .\n( [ varn ] ) or ( [ varm ] ) exhibits a dynamics of the probabilities with two time scales : @xmath101 and @xmath104 .    in fig .\n[ fig_field ] it is observed that in the region @xmath155 the field lines are approximately horizontal , i.e , only the interaction @xmath6 needs to be varied while keeping the level position constant in order to see a dynamics of the probability governed by @xmath104 only .\nin fact , in this regime the qd is predominantly empty and variations of the interaction strength @xmath6 do not affect the occupation of the dot .\nthis is the reason why this variation yields a dynamics in which the rate @xmath101 does not contribute . on the other hand , in the region for @xmath156 in order to avoid that the number of particles on the dot changes , which would lead to a relaxation with rate @xmath101 , a variation in @xmath6 needs to be accompanied by an opposite variation in @xmath5 , that is @xmath157 .\nthe crossover between the two regimes appears around the symmetry point of the anderson model , @xmath139 .\nimportantly , it is also possible to read out either the rate @xmath101 or the rate @xmath104 by varying the gate voltage only ( and , thus , not fulfilling eqs .\n( [ dvarm ] ) and ( [ varm ] ) ) , which is easier to realize in an experiment . this can be done by measuring an observable that is sensitive to only one occupation probability , for instance the probability of the quantum dot being empty .\nsuch a time - resolved read - out of the probability can be achieved by considering a qpc located nearby the system and tuned such that it conducts only if the qd is empty .\n@xcite in the simplest model of the qpc , which assumes a very fast response , the operator corresponding to the current in the qpc is given by @xmath158 where @xmath159 is a constant current , given by the characteristics of the qpc potential .\nthe expectation value of the qpc current is simply @xmath160 . in this way\n, the qpc effectively measures the dynamics of the occupation probability @xmath161 . according to eq .\n( [ eq_solution ] ) , a modulation of the gate in which the initial value @xmath162 equals the equilibrium value @xmath99 leads to a pure decay with @xmath101 . instead , for a decay given by @xmath104 either the factor @xmath163 or the factor @xmath164/\\left[1-f(\\epsilon)+f(\\epsilon+u)\\right]$ ] in eq .\n( [ eq_solution ] ) has to vanish .    .\nthe on - site coulomb repulsion @xmath6 is constant and takes the value @xmath165 .\ndashed blue line : @xmath5 changes from @xmath166 to @xmath167 , its slope yields the relaxation rate @xmath104 .\nred dot - dashed line : in this case @xmath168 to @xmath169 , and the slope leads to @xmath101 . the black line is obtained if @xmath5 changes from @xmath170 to @xmath169 , in which both rates @xmath104 and @xmath101 are present . in all cases\nwe have subtracted the corresponding value for the current in the long - time limit . ]\nresults for the qpc current for different variations of the level position @xmath5 while @xmath6 is kept constant , are shown in the logarithmic plot in fig .\n[ lines ] .\nfor clarity , we also subtracted the corresponding current in the long time limit , @xmath171 .\nin particular , for a fixed value of @xmath6 equal to @xmath172 , we find that if the level position is changed from @xmath166 to @xmath167 , the time evolution of @xmath161 is governed entirely by the rate @xmath104 , giving rise to the straight , blue - dashed line in fig .\n[ lines ] .\nits slope is given by @xmath104 , making it possible to extract this relaxation rate from measurements of the current in the qpc .\nhowever we can obtain a dynamics of @xmath161 given mainly by the rate @xmath101 by performing a variation in @xmath5 from @xmath166 to @xmath169 which results in the red dot - dashed straight line in fig .\n[ lines ] ; again , the slope yields the corresponding relaxation rate which takes the value @xmath173 . finally , we show an example in which variations from @xmath170 to @xmath169 ( solid black line ) produce a dynamics of @xmath161 which includes two exponential decays with rates @xmath104 and @xmath101 . as a result ,\nthe curve exhibits a change in the slope , showing that a single rate will not be obtained by arbitrary variations of the parameters .      in the previous sections we investigated the relaxation rates in first order in the tunnel coupling strength @xmath0 .\nhowever , corrections due to higher order tunneling processes appear when the tunnel coupling gets stronger . besides quantitative corrections , this reveals an interesting new aspect . in second order in the tunnel coupling ,\nthe matrix @xmath174 included in the exponential decay takes the form @xmath175 .\nthe second - order corrections to the relaxation rates for charge and spin are given by:@xcite @xmath176w_{\\mathrm{d}0 }                    }                     { 1-f(\\epsilon)+f(\\epsilon+u ) } \\label{eq_charge_corr}\\\\ \\gamma_\\mathrm{s}^{(2 ) } & = & \\sigma(\\epsilon,\\gamma , u ) \\frac{\\partial}{\\partial\\epsilon}\\gamma_\\mathrm{s}+\\sigma_\\gamma(\\epsilon,\\gamma , u)\\gamma_\\mathrm{s}+2w_\\mathrm{sf}\\ .\n\\label{eq_spin_corr}\\end{aligned}\\ ] ] these corrections contain renormalization terms as well as real cotunneling contributions .\non one hand , the renormalization terms contain an effect due to the level renormalization @xmath177 , with @xmath178 $ ] , @xmath179 and @xmath180 is the digamma function . on the other hand , the renormalization of the tunnel coupling appears , @xmath181 $ ] , with @xmath182 $ ] and where @xmath127 was defined in eq .\n( [ eq_coeff ] ) .\nreal cotunneling contributions are manifest in terms of spin flips , @xmath183 , and coherent transitions changing the particle number on the dot by @xmath184 , @xmath185 and @xmath186 .\nthese cotunneling terms read @xmath187\\\\ w_{\\mathrm{d}0 } & = & - \\frac{2 \\gamma } { e^{\\beta(2\\epsilon+u)}-1 }   \\left[\\gamma\\phi'(\\epsilon)+\\gamma\\phi'(\\epsilon+u)-\\frac{2}{u}\\sigma(\\epsilon , u)\\right],\\nonumber\\\\\\end{aligned}\\ ] ] and @xmath188 w_{\\mathrm{d}0}$ ] .\nthe way in which the cotunneling contributions enter in the respective charge and spin relaxation rates is related to the deviation of the state of the qd from equilibrium , given by eq .\n( [ eq_solution ] ) in first order in @xmath0 . as an example we discuss the correction to the charge decay rate , second line of eq .\n( [ eq_charge_corr ] ) . there\nthe factor @xmath184 appears due to the change in the charge by @xmath189 in a process bringing the dot from zero to double occupation and vice versa .\n@xcite the fraction with which the transition from zero to double occupation , @xmath186 , enters the correction to the charge relaxation rate , @xmath190 , is given by the deviation from equilibrium of @xmath57 in the direction of @xmath161 , of the contribution which actually decays with @xmath101 only .\nthis is the first component of the second vector in eq .\n( [ eq_solution ] ) .\nequivalently , the transition from double to zero occupation , @xmath185 , enters with the fraction given by the fourth component of the same vector , namely by the deviation from equilibrium of @xmath57 in the direction of @xmath191 .\nstrikingly , in contrast to the charge and spin relaxation rates , @xmath104 does not get renormalized at all by second order tunneling processes : @xmath192 the reason for this is that the contribution due to @xmath0 renormalization and those due to coherent processes between empty and doubly occupied dot , cancel each other .\nthe lack of second order corrections , confirms that this relaxation rate is related to a quantity which is not sensitive to the coulomb interaction .\nthe fact that corrections are missing , is also found using a renormalization - group approach .\nanother important aspect of this missing second - order correction is that it is due to an exact cancelation of the contribution due to virtual second order processes , namely the @xmath0-renormalization , with real cotunneling contributions .\nthis is in contrast to , e.g. the conductance , where only the real cotunneling processes contribute far from resonances , while renormalization terms are limited to the resonant regions .      until now , we considered the quantum dot to be coupled to a normal conducting lead .\nhowever , the vicinity of a superconducting or a ferromagnetic reservoir induces correlations between electrons and holes or between charge and spin , respectively . in the following we study , in first order in the tunnel coupling strength @xmath0 , the influence of induced correlations on the relaxation rates of the dot .\nthe charge response of a noninteracting mesoscopic scattering region coupled to both normal and superconducting leads has been studied in refs .  .\nin the previous sections we have seen that the rate @xmath104 , which together with the time decay of charge and spin determines the relaxation of the qd to the equilibrium state , is independent of the level position and the coulomb interaction and that it enters in the time evolution of quantities sensitive to two - particle effects . it is therefore expected that the rate @xmath104 will directly influence the relaxation of the charge towards the equilibrium in a setup that naturally mixes the empty and doubly occupied states of the dot .\nthis situation is obtained if the qd is not only coupled to a normal lead ( with tunnel coupling strength @xmath0 ) but also to an _ additional _ superconducting contact ( with tunnel coupling strength @xmath193 ) , as shown in fig .\n[ fig_scheme ] ( b ) .\nwe consider only the case when the superconductor is kept at the same chemical potential as the normal lead and we set both chemical potentials to zero .\nthe only purpose of the extra lead is here to induce superconducting correlations on the dot via the proximity effect .\nto the original hamiltonian , @xmath194 , we now add the hamiltonian for the superconducting contact and its tunnel coupling to the qd , @xmath195 where @xmath196 is the the annihilation ( creation ) operator of electrons in the lead . in the limit of a large superconducting gap @xmath197\nthe effect of the additional contact can be cast in an effective hamiltonian of the dot which includes a coupling between electrons and holes in the qd , @xmath198 .\nthe eigenstates of the proximized dot are the states of single occupation @xmath20 and other two states which are superpositions of the empty and double occupied states of the dot ( due to andreev reflection ) : @xmath199 with energies given by @xmath200 , where the level detuning between @xmath19 and @xmath21 is @xmath201 and @xmath202 is the energy splitting between the @xmath203 and @xmath204 states.@xcite in the new basis @xmath205 , the vector representing the charge operator is expressed as @xmath206 and we expect that the effect of the mixing of electrons and holes will be visible in its time evolution . in first order in the tunnel - coupling strength to the normal reservoir @xmath0 and assuming @xmath207 , we find the relaxation rates @xmath208\\\\ \\gamma_{s , s}&= & \\gamma\\left[1-f(\\epsilon - e_-)+f(e_+-\\epsilon)\\right]\\\\ \\gamma_{s,2}&=&2\\gamma.\\end{aligned}\\ ] ]    remarkably the eigenvalue @xmath209 remains unaffected , i.e. @xmath210 is not modified by the presence of the additional superconducting lead .\nthe spin on the dot , which is determined by the occupation probabilities of singly occupied states , still decays with a single relaxation rate given by @xmath211 , i.e. @xmath212 is an eigenvector of the kernel @xmath62 ( in the proximized basis ) .\nin contrast , the decay of the charge to its equilibrium value is given by @xmath213                    \\left(e^{-\\gamma_{s,2 } t}+e^{-\\gamma_{s,1}t }\n\\right )                          + \\langle \\hat{n}\\rangle^{\\mathrm{eq}}\\nonumber\\\\ & & + a_{sc }        \\frac{1}{2}\\left[\\langle x\\rangle^{\\mathrm{in}}-\\langle x\\rangle^{\\mathrm{eq}}\\right ]        \\left(e^{-\\gamma_{s,2 } t}-e^{-\\gamma_{s,1}t}\\right ) \\nonumber \\\\ & & + \\frac{1}{2}\\left[\\langle y\\rangle^{\\mathrm{in}}-\\langle y\\rangle^{\\mathrm{eq}}\\right ]        \\left(e^{-\\gamma_{s,2 } t}-e^{-\\gamma_{s,1}t}\\right ) \\label{eq_nsct}\\end{aligned}\\ ] ] with @xmath214 and where we defined the difference in the occupation of the @xmath215 states , @xmath216 and the quantity @xmath217 , with @xmath218 .\nthe charge evolves with two different time scales , @xmath219 and @xmath220 , instead of only one as in the normal case .\nthis is a direct consequence of the mixing of the states @xmath19 and @xmath21 induced by the superconducting contact .\nthis effect opens the possibility to extract this rate by measuring the time evolution of the charge in the proximized dot .      even though the presence of a superconducting lead couples electrons and holes , the relaxation rate @xmath104 has not been modified .\nsince we associate this rate with processes involving two particles each with spin @xmath12 , it is expected that if the spin symmetry is broken by introducing a ferromagnetic contact , the rate @xmath104 will now be the sum of the tunneling rates for spin up and spin down electrons . in order to verify this\n, we consider the hamiltonian used for the normal case and assume a spin - dependent density of states in the only reservoir attached to the quantum dot , see fig .\n[ fig_scheme ] ( c ) .\nthis leads to spin - dependent tunnel couplings , @xmath221 and @xmath222 , which are included in the corresponding transition matrix @xmath62 .\ndiagonalization of @xmath62 yields the three relaxation rates : @xmath223 ^ 2 } \\\\\n\\gamma_{f,2 } & = & \\gamma-\\frac{1}{2}\\sqrt{\\left(\\delta\\gamma\\right)^2 + 4\\gamma_\\uparrow\\gamma_\\downarrow\\left[f(\\epsilon)-f(\\epsilon+u)\\right]^2 } \\\\\n\\gamma_{f , m}&= & 2 \\gamma\\end{aligned}\\ ] ] with @xmath224 and @xmath225 .    as in the normal case\n, there is an eigenvalue which does not depend on the level position nor on the interaction but on the sum of the different tunneling rates : @xmath226 .\nthe appearance of such a combination of the spin - dependent tunneling strengths in the relaxation rate , confirms the statement that two - particle processes involving electrons with both spin polarizations are at the basis of the decay rate @xmath104 .    due to the ferromagnetic lead ,\nthe dynamics of spin and charge are now mixed .\nthe corresponding time evolution in first order in the tunnel coupling takes the form : @xmath227(e^{-\\gamma_{f,1}t}-e^{-\\gamma_{f,2}t } ) \\nonumber \\\\\n\\langle\\hat{n}\\rangle_f(t ) & = & \\frac{1}{2}\\left[\\langle \\hat{n}\\rangle^{\\mathrm{in}}-\\langle \\hat{n}\\rangle^{\\mathrm{eq}}\\right](e^{-\\gamma_{f,1}t}+e^{-\\gamma_{f,2}t } ) + \\langle \\hat{n}\\rangle^{\\mathrm{eq}}\\nonumber \\\\ & & + a_c\\left[\\langle \\hat{n}\\rangle^{\\mathrm{in}}-\\langle \\hat{n}\\rangle^{\\mathrm{eq}}\\right](e^{-\\gamma_{f,1}t}-e^{-\\gamma_{f,2}t})\\nonumber \\\\ & & + b_c\\langle \\hat{s}\\rangle^{\\mathrm{in}}(e^{-\\gamma_{f,1}t}-e^{-\\gamma_{f,2}t})\\label{eq_decay_ferro}\\end{aligned}\\ ] ] where we introduced the abbreviations : @xmath228}{2\\sqrt{\\delta\\gamma^2 + 4\\gamma_\\uparrow\\gamma_\\downarrow\\left[f(\\epsilon)-f(\\epsilon+u)\\right]^2 } } \\nonumber \\\\ b_s & = & \\frac{\\delta\\gamma[1+f(\\epsilon)-f(\\epsilon+u)]}{2\\sqrt{\\delta\\gamma^2 + 4\\gamma_\\uparrow\\gamma_\\downarrow\\left[f(\\epsilon)-f(\\epsilon+u)\\right]^2 } } \\nonumber \\\\ a_c & = & a_s\\nonumber \\\\ b_c & = & \\frac{\\delta\\gamma[1-f(\\epsilon)+f(\\epsilon+u)]}{2\\sqrt{\\delta\\gamma^2 + 4\\gamma_\\uparrow\\gamma_\\downarrow\\left[f(\\epsilon)-f(\\epsilon+u)\\right]^2}}. \\nonumber\\end{aligned}\\ ] ] the last term in eq .\n( [ spin_ferro ] ) shows that at finite time @xmath32 the initial charge influences the time evolution of the spin ; similarly , the initial spin enters explicitly in the dynamics of the charge , eq .\n( [ eq_decay_ferro ] ) .\nthese terms persist in the non - interacting limit , revealing that the coupled evolution of charge and spin including two relaxation rates ( which for the non - interacting case take the form @xmath229 and @xmath230 ) is a direct consequence of the presence of the ferromagnetic contact .\nin contrast , the factor @xmath231 vanishes for @xmath105 implying that it stems from the combined effect of the coulomb interaction and the breaking of the spin symmetry . as expected the independent evolution of charge and spin\nis recovered in the limit @xmath232 .\nthe mixing of the dynamics of both , charge and spin , induced here by a ferromagnetic lead was found in ref .\nfor the case of lifted spin - degeneracy in the dot due to a finite zeeman splitting . note that for the hybrid as well as for the normal system , the sum of the energy - dependent relaxation rates equals @xmath78 , as long as the tunnel coupling @xmath0 is treated in first order , only .\nwe have studied the different time scales present in the evolution of the reduced density matrix of a single - level qd with coulomb interaction and tunnel coupled to a single reservoir , after being brought out of equilibrium . besides the relaxation rates for charge and spin\n, we find an additional rate @xmath125 , which is independent of the energy level of the dot as well as of the interaction strength .\nthis relaxation is related to the presence of two particles in the dot and is found to be not sensitive to the coulomb interaction .\nthe time evolution of the square deviations of the charge from its equilibrium value is proposed as a physical quantity related with processes involving two - particles leading to the rate @xmath78 . in order to further elucidate the properties of this decay\n, we analyzed the response of the system to specific variations of both , the interaction strength @xmath6 and the level position @xmath5 , finding that @xmath104 can be extracted from time - resolved measurements of the current passing through a nearby quantum point contact .\nadditionally , we analyzed two other setups : a dot proximized by a superconductor and coupled to a normal reservoir , and a dot coupled to a ferromagnetic lead .\nin the hybrid normal - superconducting systems , we found that the time - resolved read - out of the charge represents another possibility to get access to the rate @xmath104 .\nwe thank michael moskalets , roman riwar and maarten wegewijs for fruitful discussion .\nfinancial support by the ministry of innovation , nrw , the dfg via spp 1285 and ko 1987/5 , the european community s seventh framework programme under grant agreement no .\n238345 ( geomdiss ) , as well as the swiss national science foundation , the swiss centers of excellence manep and qsit and the european marie curie itn , nanoctm is acknowledged .\nthe transition matrix for the normal case in the eigenbasis of the isolated qd @xmath233 , in first order in the tunneling strength @xmath0 , is calculated by means of fermi s golden rule and is given by :    @xmath234 & 0 & 1-f(\\epsilon+u))\\\\ f(\\epsilon ) & 0 & -\\left[1-f(\\epsilon)+f(\\epsilon+u)\\right ] & 1-f(\\epsilon+u))\\\\ 0 & f(\\epsilon+u ) & f(\\epsilon+u ) & -2\\left[1-f(\\epsilon+u)\\right ] \\end{array } \\right)\\end{aligned}\\ ] ]      as @xmath62 is non - hermitian it has different right and left eigenvectors , @xmath56 and @xmath55 . for a system with a well - defined steady state ( as the one we are considering here ) there must be at least a zero eigenvalue , @xmath238 .\n@xcite the other eigenvalues are found to be the negative of @xmath100 \\nonumber \\\\\n\\gamma_s&=&\\gamma\\left[1-f(\\epsilon)+f(\\epsilon+u)\\right ] \\\\\n\\nonumber \\label{evalues}\\end{aligned}\\ ] ] the right eigenvector corresponding with the zero eigenvalue , @xmath239 , determines the stationary density matrix ( which we also label as @xmath81 ) , whereas each one of the rest of the right eigenvectors represents a deviation out of the equilibrium density matrix which decays exponentially with a rate given by the negative of the corresponding eigenvalue :    @xmath240[1-f(\\epsilon+u)]\\\\ f(\\epsilon)[1-f(\\epsilon+u)]\\\\ f(\\epsilon)[1-f(\\epsilon+u)]\\\\ f(\\epsilon)f(\\epsilon+u)\\\\ \\end{array}\\right ) , \\\n\\mathbf{r}_s=\\frac{1}{2}\\left(\\begin{array}{c}0\\\\1 \\\\-1 \\\\\n0\\end{array}\\right),\\\\ \\mathbf{r}_n    = \\frac{1}{1-f(\\epsilon)+f(\\epsilon+u)}\\left(\\begin{array}{c } -[1-f(\\epsilon)]\\\\ \\frac{1}{2}\\left[1-f(\\epsilon)-f(\\epsilon+u)\\right]\\\\ \\frac{1}{2}\\left[1-f(\\epsilon)-f(\\epsilon+u)\\right]\\\\ f(\\epsilon+u ) \\end{array}\\right ) , \\ \\mathbf{r}_m\n= \\left(\\begin{array}{c } -1\\\\1\\\\1\\\\-1\\end{array}\\right)\\ .\\end{aligned}\\ ] ]              these left eigenvectors contain the operators for spin , charge and @xmath88 in vector representation , which can be understood in the following manner .\nwhile in general the expectation value of an operator @xmath247 is found from @xmath248 , with the full density matrix @xmath249 , this can be considerably simplified in the situation considered here , where only diagonal elements of the reduced density matrix of the quantum dot , collected in the vector @xmath154 , play a role .\nthe expectation value of a quantum dot operator is then obtained by multiplying its vector representation from the left hand side onto the vector @xmath154 . to show an example the expectation value of the spin on the dot\nis obtained by multiplying @xmath154 from left by the vector @xmath250 , yielding @xmath251 .\nsimilarly , all other operators for quantum dot observables can be expressed in such a vector representation ."}
{"lay_summary": " mesoscopic dynamics of self - organized structures is the most important aspect in the description of complex living systems . \n the belousov  zhabotinsky ( b  z ) reaction is in this respect a convenient testbed because it represents a prototype of chemical self - organization with a rich variety of emergent wave - spiral patterns . using a multi - state stochastic hotchpotch model , \n we show here that the mesoscopic behaviour of the non - stirred b  z \n reaction is both qualitatively and quantitatively susceptible to the description in terms of stochastic multilevel cellular automata . \n this further implies that the mesoscopic dynamics of the non - stirred b  z reaction results from a delicate interplay between a ) a maximal number of available states within the elementary time lag ( i.e. a minimal time interval needed for demise of a final state ) and b ) an imprecision or uncertainty in the definition of state . \n if either the number of time lags is largely different from 7 or the maximal number of available states is smaller than 20 , the physicochemical conditions are inappropriate for a formation of the wave - spiral patterns . \n furthermore , a white noise seems to be key for the formation of circular structures ( target patterns ) which could not be as yet systematically explained in existing models . ", "article": "during the last two decades , a number of new paradigms for understanding complex living systems have emerged .\nthese include , e.g. theory of dynamical systems , theory of complexity , nonlinear dynamics , evolutionary physics , and critical phenomena@xcite . among these , chaotic attractors , ( multi-)fractals , self - assemblies , dissipative structures and self - organization represent some of the most promising recent concepts .\na particularly important testbed for a conceptualization of pattern formation in self - organizing systems is the b  z reaction@xcite which belongs among the most extensively studied examples of chemical self - organization .\nhowever , despite decades of intensive research , there are still ongoing controversies over the actual chemical kinetics ( i.e. details of rates of chemical reactions involved ) and the mesoscopic dynamics ( i.e. exact nature and mechanism of patterns formation at the mesoscopic scale ) of the b  z reaction@xcite .\nthe b  z reaction is considered as a textbook example of the so - called excitable medium@xcite . majority of available chemical models which aim to explain the chemical self - organization are based on the standard reaction - diffusion analysis and the law of mass action applied to a few selected reactions@xcite . on the other hand ,\nself - organization is a hallmark of a far - from - equilibrium dynamics which appears difficult to reconcile with a common - sense chemical reaction scheme based on the law of mass action .\nturing patterns that appear in some reaction - diffusion models are often considered as a theoretical embodiment of the b \nz patterns@xcite .\nthis is wrong for at least three reasons : turing patterns ( a ) can explain only wave b  z patterns but not spirals@xcite , ( b ) appear only at specific parameter values in the reaction - diffusion equations , therefore they are unstable under fluctuations of parameters ( in contrast to experiments where patterns are observably robust ) , ( c ) are stable solutions of turing s reaction - diffusion equations while , in the experiment , we observe a dynamic system on a trajectory through the state space towards a limit cycle with alternating spirals and wave fragments .    the mesoscopic description of the b  z reaction is typically modeled with a cyclic cellular automaton which often generates patterns similar to the b  z wave patterns found near to the final stage of the reaction .\nthe morphological characterization of patterns is pivotal in these approaches while chemical aspects are often of a secondary interest .\nso far , mesoscopic studies of the b  z reaction have been limited to a low - level cellular automata@xcite which can reasonably well account only for some of the observed b \nz wave patterns , while it is as yet unclear how to generalize these approaches to obtain a full - fledged evolution of wave patterns together with dynamics of spiral patterns .\nto the best of our knowledge , the influence of the number of levels has been systematically studied only in one case@xcite while most of the systematic studies in the literature have been confined to maximally 8 levels@xcite .    in order to numerically implement a hotchpotch model ,\nwe have adopted an approach based on the version of wilensky netlogo model@xcite . in our case\nthe model is limited to 200 achievable state levels and simulated on a square 50 @xmath0 50 grid .\nafter a random setup of the space distribution of initial centers of @xmath1 $ ] as @xmath2 where @xmath3 is the maximally achievable number of levels of the cell state . the model at each time step\n@xmath4 may proceed in four possible ways :    1 .\nwhen a cell is at the @xmath5 , so - called _ quiescent _ , it may be `` infected '' by surrounding cells according to the equation @xmath6 where @xmath7 and @xmath8 is a number of cells at the @xmath9 and @xmath10 , respectively , @xmath11 and @xmath12 are characteristic constants of the process and @xmath3 is a maximum allowed level of state / excitation .\nwhen a cell is at the @xmath13 , its new state is calculated as @xmath14 where @xmath15 is a state of the @xmath16-th cell in the moore neighbourhood , which directly surrounds the examined cell , and @xmath17 is another arbitrary constant . for simplicity s sake ,\nwe denote in the following text @xmath18 and @xmath17 as 2a and 2b , respectively .\n3 .   when a cell is at the @xmath19 , then @xmath20 4 .\nwhen a cell achieves the @xmath21 , then @xmath22    here we posit that our improved stochastic version of the multilevel hotchpotch model not only faithfully represents the dynamics of wave - spiral patterns of the b  z reaction but also provides insight into underlying chemical reactions in terms of the eyring activated complex theory@xcite .\nthe emergence of correct spatial structures in our model depends on the ratio between the number of available states within the elementary time lag and on the rate of the internal increase in excitation process . at appropriate levels of noise ,\nwe observe a dynamical evolution of the system through circular waves up to the final stage  spiral - wave interchange .\nthis structure - stabilizing mechanism via the noise is a typical trademark of a mesoscopic description and is not simply attainable via microscopic deterministic rules . by the presence of the noise\n, we can explain many controversies in self - organization in the nature .\nthe b  z reaction is not easily comprehensible in terms of the standard law of mass action ( which represents the `` canonical method '' of interpretation of the chemical reactivity ) .\nthis is due to the fact that the reaction space is separated into regularly evolving / travelling structures and that one has to consider a large number of interlocked chemical processes involved . in this work\n, we report on a new cellular - automaton based stochastic model of the b  z reaction .\nthe model retains some of the key features of the multi - level hotchpotch machine which , however , outperforms both in its ability to faithfully mimic the onset stage of the b  z reaction and its potential to correctly describe the morphology of the interacting wave - spiral patters during their evolution .\nfigure 1a compares a late stage of the b  z reaction ( full data are accessible in supplementary material 1 ) in our least possible spatial constraining ( a 200-mm petri dish ) and roily conditions ( gentle mixing at 1400 rpm using an orbital mixer ) with simulation of the modified wilensky model of excitable medium@xcite .\nthe structures are , for some parameter ranges , astonishingly similar .\nhowever , the most regular spirals and waves , best comparable to the model , are expected to arise in a very gently mixed , homogenous solution of thin layer in a vessel of the unlimited size which does not spatially constrain the evolution of waves .    in order to achieve the manifest morphological similarity between the b  z experiments and our simulation , we implemented the following changes into the wilensky model :    1 .\nthe enlargement of the cellular grid to 1000 @xmath0 1000 , 2 .   start from a very few points which enabled to analyze the behaviour of individual centers of emanation , 3 .   a sequence of switching the values of cell states from natural to decimal numbers which extended the span of each cellular state , 4 .\nthe addition of a uniform white noise to each automaton step which compensated for our limited knowledge of precise underlying mechanism , and 5 .\nthe extension of the number of achievable states @xmath3 and rate of the internal cell excitation @xmath17 up to 2000 and 280 , respectively , to smooth the model waves .    the first modification  usage of the finer grid\n suppressed the influence of the nonidealities of the periodic boundaries on the evolution of the model system .\nthe second intervention into the wilensky model was performed using random - exponential function for generation of the starting ( ignition ) points .\nmultiplication of each cell state by the @xmath23 of the exponential distribution , i.e. @xmath24\\ , , \\ ] ] ensured that the simulation started with a small number of the ignition points .    at this initial condition , we first tested the influence of the @xmath25 of natural numbers due to the rounding in processes 12 ( see eqs .\n( [ eq2])-([eq3 ] ) ) , thus new states in time @xmath4 were calculated as @xmath26 and @xmath27 this modification , which was originally implemented to start the process from these few centers ( ignition points ) quite surprisingly increased the structural - patterns similarity between the b  z experiment and the simulation .\nthe results are shown in  figure 1b  c and  supplementary materials 24 and were discussed in some detail in@xcite . in  figure 1b , we present early simulation steps 2 , 4 , 14 , and 16 after the ignition in process 1 . for @xmath28 and @xmath29 ,\nat least two non - zero points in a proper configuration @xmath7 , @xmath8 were required for the evolution of the waves in the simulation , since at least one addend in process 1 has to be equal to 1 . in this case , the early evolution gave octagons ( figure 1b , i ) and final state was formed by spirals ( figure 1c , i ) . in contrast , if @xmath30 and @xmath31 , then , e.g. @xmath32 and the non - zero cell was surrounded by evolving wave of 8 cells in @xmath33 .\nthis early evolution resulted in squares with central circular objects ( figure 1b , ii ) which further led to the filamentous structures ( figure 1c , ii ) .\nthe next step softened the definition of the state by allowing 1 decimal place in eqs .\n( [ eq2])-([eq3 ] ) , i.e. @xmath34 and @xmath35 and kept @xmath28 and @xmath29 ( supplementary material 5 ) .\nif @xmath36 , the first layer of 8 cells in @xmath37 evolves in the moore neighbourhood .\nthis modification provided the trajectory as observed for @xmath30 and @xmath31 with natural number states .\nmore decimal places did not change the state space trajectory any more .\nthis proves that the trajectory is determined by the ratio of the @xmath17 constant to the number of levels @xmath3 .\nthe @xmath38 ratio close to 7 ( 28/200 ) showed the highest structural similarity to the experiment .\nthere seems to be also a lower limit for the proper development of the system trajectory . in case of @xmath39 and @xmath40 , we observed evolution of square spirals and the simulation grid was never fully covered by spirals and waves . at the 2/14 ratio ,\nthe grid was already completely covered . at the 3/20 ratio ,\nthe circular structures similar to those observed in the experiment were firstly observed . at keeping the @xmath38 ratio ,\nthe next increase of the @xmath3 value smoothed only the edges of the structures .\nobviously , 7 state levels does not allow to cover the moore space with 8 neighbouring cells and 14 state levels are not yet sufficient enough to create an appropriate curvature .\nthe course of the simulation and the type of the limit set ( late state ) depends on the type of the _ garden of eden _ as follows : a ) the emergence of the ignition point needs one or two neighbouring non - zero points and determines the overall type of the trajectory and b ) the number and distribution of ignition centers determines the duration of each trajectory phase .\nthere are as many gardens of eden as possible geometrical set - ups of the ignition points , however , the thickness of square and circular waves , shapes of the central objects and the structure of the limit set remain the same .\nthe multilevel cellular automata exhibit less versatile trajectory than the low - level ones@xcite .    in order to compensate our lack of knowledge of the details of the process , we introduced noise into each sub - process in eqs .\n( [ eq2])-([eq3 ] ) by multiplication of the terms @xmath41 , @xmath18 , and @xmath17 , respectively , by the factor @xmath42 .\nthe noise was generated by a computer random number generator and its level was upper limited to be the uniform noise within certain range . at @xmath28 , @xmath29 and\nprecision of 10 decimal places , levels of noise were 6% , 12% , and 30% for @xmath41 , @xmath18 , and @xmath17 , respectively .\nwhen ignition led to circular structures with filled interior , the noise restored spiral formation ( figure 1b  c , iii and supplementary material 5 ) and the simulation was the most similar to the experiment ( figure 2 and supplementary material 1 ) .\nin other experiments at @xmath30 and @xmath31 ( data not shown ) , we observed that the respective noise levels gave the same trajectory .\na formation of circular structures which arose as watersheding of regular structures was also the same as observed for the natural - number states .\nthe proper combination of @xmath38 values and uniform noise range ( figure 2a ) generates a sequence of simulated structures as follows :    * the simulation grid is filled with systems of square dense waves\n. this has not been observed in the experiment and we interpret it as a _ lag phase _ , which precedes the observed formation of circular waves .\n* circular structures emanate from the centre of square waves .\n* at the certain state , the simulation grid is nearly covered by large circular structures .\na few spirals occur and break into a new generation of spirals . * final state is similar to that in the simulation where the states are natural numbers , @xmath28 and @xmath29 ( supplementary material 4 ) , however , the waves are about 2 grid elements thicker . * in the terminology of the multilevel cellular automata@xcite , the uniform ( white ) noise shifts the system to the basin of attraction similar to the system where only natural numbers are allowed and open a novel system trajectory through the state space .\nlet us mention further key similarities between our simulation and actual experiments ( figure 2b  c ) :    * the chemical waves do not interfere like material waves but merge . * the chemical waves\ndo not maintain the shape ( as is the case , e.g. , for solitons@xcite ) .\n* the morphology of interacting patterns ( merger patterns ) in simulations has comparable traits as in real experiments . * quantitative features of the limit sets ,\ni.e. , the last evolutionary stage of the wave - spiral patterns can be set as close as possible to actual experimental data by an appropriate choice of the parameter range .\nit should be stressed that the possibility to replace partly the elementary anisotropy by the uniform noise ( see figure 4 )  the constructive role of the noise  is a novel observation , which can be viewed as a superposition of starting conditions .      when noise matters , an observed process is typically mesoscopic\nit does follow neither the deterministic rules of the microscopic ( or purely mechanical ) system nor the statistical - physics tenet of boltzmann that only the most frequent events are observed@xcite .\nso , in case of the b  z reaction , a chemical origin of mesoscopicity should be sought .\nthe key process at the end of the reaction scheme is the breakage of a crucial chemical bond in the eyring transition state complex , possibly the decomposition of brominated malonic acid to formic acid and carbon dioxide@xcite .\na sketch of molecules involved in the last reaction step is outlined in  figure 3 .\nthis process is hidden in the experiment in which we observe only the reduction of the fe@xmath43-phenanthroline complex .\nthe rest of , known and unknown , reactions in all their reaction intermediates contributes to the restoration of this activated complex .\nthe activated complex consequently reduces fe@xmath43 which enables our measurement .\nthe scheme described here still includes breakage of a few individual bonds , possibly in certain orders .\nmoreover , it is not certain that this redox process is the bottleneck process .\nit should be also noted that there is a deep controversy about the actual details of the mechanism including the role of molecules involved in the carbon dioxide evolution .\nthus the proposed chemical mechanism must be understood more as illustration of the complexity and of the origin of time extent of key reaction steps .\nthe chemical reaction is certainly not occurring at timeless instant as it is assumed in the reaction  diffusion model .\nwe propose that the state changes of the activated complex are described by processes 23 ( see eqs .\n( [ eq3])-([eq4 ] ) ) .\nprocess 4 ( see eq .\n( [ eq5 ] ) ) represents the breakage of the complex , which vacates the space for the restoration of a new activated complex in process 1 ( see eq .\n( [ eq2 ] ) ) . the mesoscopicity may be explained from the multitude of processes involved in these elementary steps .    to examine properties of the elementary spatial unit ( pixel in the simulation )\n, we analyzed the properties of process 2 .\nwe assume that process 2 ( see eq .\n( [ eq3 ] ) ) reflects all reorganization processes and reactions of all parts of the complex , down to the level of a bond which breaks upon the disruption of the complex .\nwe split the process into sub - processes 2a and 2b .\nprocess 2a is the sum of all processes which occur between the elementary spatial unit and the immediate surroundings .\nlarger surroundings were ignored , since their influence was assumed to be mediated by neighbouring elementary units .\nprocess 2b represents all processes within this unit .\nthe relatively high noise level of 0.14 and 0.30 for process 2a and 2b , respectively , includes our ignorance of the details and randomness of the process .\nfigure 4a and supplementary material 6 show the results of the noise - free simulation at @xmath44 , @xmath28 , @xmath29 and different @xmath17 . at the @xmath45 ,\nthe process exhibited the same trajectory as at the @xmath46 . at the @xmath47 ,\nthe process was in its initial part similar to the course at the @xmath46 , @xmath30 and @xmath31 , later , it tended to give round structures . at the @xmath48 ,\nthe course of the simulation was very different from any previous simulation .\nthe final state of this simulation was characterized by spiral doublets  ram s horns@xcite . at the @xmath49 ,\nthe process was already very diffusive .\nobviously , the ratio between the constants of processes 2a and 2b determines the geometry of the process .\nfor the course of the simulation similar to the experiment , the suitable @xmath38 ratio is equal to 7 .\nthe values of constants @xmath17 and @xmath3 themselves do not significantly influence the course of the simulation .\nthe time needed for the decay of the active state complex and its restoration in process 4 determines the characteristic timescale of the whole simulation .\nthe ratio @xmath38 determines properties of waves and the size of the spatial unit .\nthis ratio represents an aliquot of energy / entropy needed for the decay of the transition state complex in process 2b . in order to observe waves , process\n2b needs to be significantly faster than the transition from the neighbourhood in process 2a and , also , the neighbourhood has to be asymmetric . in other words , noise represents geometric asymmetry ( 2a noise ) and internal kinetic irregularity ( 2b noise ) of the neighbourhood .\nfigure 5 shows the analysis of wave profiles in the b  z experiment .\nthe striking similarity of the simulation to real experiment intensity profiles of dense waves ( figures 1 , 2 and 5 ) motivated us to guess the number of molecules per an elementary spatial unit ( i.e. the pixel of experimental wave ) .\nthe number of elementary units per the width of the wave was in the range of 1020 .\nsince the average width of the wave was 1.5 mm , the elementary unit had 0.070.15 mm .\nthe solution above the elementary unit had thickness and volume of 0.5 mm and 10@xmath50 mm@xmath51 , respectively .\nthen , the solution contained ca .\n3 @xmath0 10@xmath52 and 10@xmath53 molecules of water and reactants per elementary unit , respectively .\nthis number lies within the thermodynamic limit .\nthe source of the mesoscopicity has to be sought in the physico  chemical dynamics .\nit means that only a few energetic / re - organizational events occur within a given time . since\nan elementary spatial unit contains roughly 10@xmath53 molecules of reactants , it is probably unsatisfactory to explain the energetic transition only due to one eyring - type reaction complex .\nit is likely that we are dealing with a phase separation which gives rise to structures of an analogous type as , e.g. , in liquid crystals@xcite .\nboth wavy and spiral patterns often occur in the nature . however , despite being usually formed in continuous media , they can also be generated artificially in the threshold - range of cyclic multilevel cellular automata@xcite .\nthe generation of waves and spirals in cellular automata has been initially perceived by the scientific community with scepticism@xcite .\nthe reasons why the formation of spirals by cellular automata is not easily accepted by general chemical community is a ) the enforcement of the natural number states ( i.e. , a coarsening of the configuration space ) b ) and the need of discrete dynamics on a regular grid which is driven by deterministic albeit not differential rules . in our simulation , the former limitation is completely suppressed by a ( near)continuous set of levels .\nthe latter limitation seems to be only a prejudice . whereas the formation of bnard cells in rayleigh \nbnard convection is driven by temperature gradient@xcite and the speed gradient generate cells in the taylor \ncouette flow , the gibbs energy gradient drives the discrete cells formation in the b  z reaction .\nthe basic principles of the formation of waves and spirals , i.e. the specific mesoscopic behaviour , are in our simulation following :    * proper @xmath38 ratio for a given spatial discretization@xcite .\na high and low @xmath38 ratio promotes structural asymmetry and diffussiveness , respectively .\n* presence of sufficient amount of irregularities due to other processes of comparable rates and leads to a noise , which is specific to each ( sub)-process . only at the appropriate combination of noise in processes 2a and 2b , we observed concentric circular waves followed by spirals .\nwhen the specific noise , given by decimal places in state levels , by the pulsed white noise , we may conclude that an increase of the noise in process 2a  i.e. increase of the diffusiveness  leads to the faster formation of spirals without any circular waves .\nthe asymmetry of the surroundings of the elementary unit , as observed in the simulation with natural number state levels , @xmath28 and @xmath29 , is probably a sub - set of the appropriate specific noises modulating the wavefront .\nwe call the whole range of state - level distributions , which attenuate the specific mesoscopic behaviour , a mesoscopic noise\n.    main differences between the experiment and the simulation are following :    1 .   in the simulation ,\nformation of a few dense waves precedes the emanation of circular waves ( never observed in the experiment ) .\n2 .   in the experiment ,\nfour different wave frequencies are observed ( not yet achieved in the simulation ) .\n3 .   in the simulation\n, dense waves / spirals are arising from remnants of broken initial dense waves . in the experiment\n, we observe a formation of new centers of dense waves , often at place of evolving micro - bubbles . but\nscenario of broken waves may also be found by careful inspection of the experiment .\n4 .   in the experiment\n, after the state of dense waves / spirals , the system still evolves .\nthe waves broaden due to the exhaustion of chemical energy ( see a re - started experiment in supplementary material 1 ) .\nmany differences may be attributed to our ignorance of the proper character of the underlying mesoscopic noise .\nthe introduction of two noise levels into the simulation indicates that the mesoscopic noise originates from two different physico - chemical processes which lead to the geometrical and kinetic asymmetry .    even if we use the square tessellation and neighbourhood which allows to cover the whole simulation grid\n the moore neighbourhood , the simulation exhibits the formation of _ circles_. a symmetrical ignition rule gives rise to circles and filamentous structures , whereas the simplest asymmetrical ignition leads to interchanges of spirals and waves ( with fractal - like structure )\n. the noise provides a proper condition for switching between these two tendencies .\nthe question remains whether the same rules of ignition and noise introduction give rise to the same geometrical structures in any tessellation or whether the neighbourhood of the active complex is , for some reason , due to the physico - chemical , or a more fundamental physical or geometric , principle , always a moore - like neighbourhood .\nwe can imagine some organization of molecules into a near - regular square lattice which is maintained by chemical dynamics ( i.e. , by movement of the molecules ) , similar to that by which the bnard cell arises in thin layers of viscous liquids .\nwe assume that the time is discretized by a step needed for the bottleneck process , i.e. for the restoration of the original concentrations of molecules in spatial element after their depletion .\nit is described by processes 34 ( see eqs .\n( [ eq4])-([eq5 ] ) ) and represented by 2 time elements .\nall other processes are related to this time measure .\nthus , for the formation of the proper structures , a near regular structure ( lattice ) where the processes of depletion and repletion take 7 and 2 time elements , respectively , is needed . in the noise - free hotchpotch machine ,\nmixtures of spirals and waves are formed in a relatively broad range of the @xmath38 ratio@xcite  between @xmath54 and @xmath55 .\nall these arguments , including the trajectory of any described multilevel cellular automaton , explain the great similarity to the reaction .\nlet us conclude that a computer - based reaction - diffusion model of the b  z reaction is calculated on a regular grid and all but the fastest process are represented by a stepwise increase / decrease . from this point of view , any reaction - diffusion model is a special kind of the cellular automaton@xcite .\napart from a few special cases when an analytic solution of turing patterns may be used@xcite , the threshold - range cellular automaton offers promising and very realistic tool for description and modelling of the chemical self - organization .     and @xmath29 ( * ii * ) .\nimages were expanded so as to have comparable widths of traveling waves .\n( * b * ) starting points of the simulations ( steps 2 , 4 , 14 , 16 ) . the noise - free simulation with natural number states , @xmath28 and @xmath29 in step 2,000 ( * i * ) , the noise - free simulation with natural number states , @xmath30 and @xmath31 in step 2,596 ( * ii * ) and the process described under * a * in step 18,400 ( * iii * ) .\n( * c * ) final states ( limit sets ) of processes defined in *\nb*. for all processes , @xmath56 and @xmath57 . in the simulation ,\nthe black and white corresponds to 0 and @xmath3 , respectively .\noriginal datasets supplied in supplementary material 3 .\nthe intensity is colour - coded in the blue colour , the darkest blue represents value 200 , the white colour the intensity 0 .\nthe unquestionably inspection of the data has to be done using the original data matrices as demonstrated in fig .\n4 . ]    , @xmath57 , @xmath28 and @xmath29 . in the simulation ,\nthe black and white corresponds to 0 and @xmath3 , respectively . ]\n-phenanthroline complex to the fe@xmath58-phenanthroline complex is monitored .\nthe absorbance of the fe@xmath58 complex is negligible in comparison to the fe@xmath43 form@xcite.,scaledwidth=60.0% ]     ratios , @xmath28 , @xmath29 and @xmath59 . at @xmath48 ( * i * ) , spirals evolve into forms of ram s horns . to the opposite ,\n@xmath47 ( * ii * ) does not form spirals . at @xmath49 ( * iv * ) , the process is fully diffusive . at @xmath45 ( * iii * ) , the trajectory is almost identical to the experimental trajectory .\n( * b * ) the intensity profiles of waves at different @xmath38 ratios .\ndecrease of the @xmath38 ratio leads to the broadening of waves .\nthe intensity profile of the circular structure is very noisy . in the simulation ,\nthe black and white corresponds to 0 and @xmath3 , respectively . ]\nfor experiments , the oscillating bromate - ferroin - bromomalonic acid reaction ( the b  z reaction recipe@xcite provided by dr .\njack cohen ) was chosen .\nthe reaction mixture included 0.34-m sodium bromate , 0.2-m sulphuric acid , 0.057-m sodium bromide ( all from penta ) , 0.11-m malonic acid ( sigma - aldrich ) as substrates and a redox indicator and 0.12-m 1,10-phenanthroline ferrous complex ( penta ) as a catalyst .\nall reagents were mixed by hand directly in a dish  a circular petri dish with diameter of 35 , 90 , 120 and 200 mm and square dish with side of 75 and 30 mm , respectively  in the above - mentioned sequence for 1 min .\na special thermostat , which was constructed from a plexiglas aquarium and a low - temperature circulating water bath - chiller , was keeping a reaction temperature at @xmath60c .\nthe chemical waves were recorded by a nikon d90 camera in the regime of time lapse ( 10 s / snapshot ) with exposure compensation @xmath61 ev , iso 320 , aperture @xmath62 and shutter speed @xmath63 s. the original 12-bit nef raw image format was losslessly transformed to the 12-bit png format .\nsee supplementary materials .\nall results and protocols are freely available ( supplementary material 3 ) .\nthis work was financially supported by the ministry of education , youth and sports of the czech republic \nprojects cenakva ( no .\ncz.1.05/2.1.00/01.0024 ) , cenakva ii ( no . lo1205 under the npu i program ) and the cenakva centre development ( no . cz.1.05/2.1.00/19.0380 ) . p.j . was supported by the gar grant no .\nga14 - 07983s .      * supplementary material 1 : video of the belousov \nzhabotinsky reaction + the movies videobz.avi and videobzreshake.avi were made from sections of the image series bzexperiment and bz reshake as described below . in the movies , every 5th frame of the series is shown with the frequency of 10 frames per second . +\nthe image series bzexperiment is a dataset from an experiment in a 200-mm petri dish .\nthe experiment was preceded by a 2-min preparation period , which included mixing of chemicals , shaking on an orbital shaker and lag period under which no travelling waves evolved .\nthe image series bzreshake is a dataset from the re - shaken , i.e. re - started , experiment in a 200-mm petri dish .\nimages were captured in 10s intervals . * supplementary material 2 : video of the noise - free simulation  original excitable medium simulation with spirals +\nthe movie video_rounding0_noise0.avi was made from the simulation when only natural numbers were allowed , no noise was included , @xmath17 = 28 , @xmath3 = 200 , @xmath28 and @xmath29 . in the movie , every 30th simulation step is shown with the frequency of 100 frames per second . *\nsupplementary material 3 : original data + all original data for experiments and simulations are available upon request to the authors .\nwe apologise for not placing all datasets freely , because some simulations resulted in files of 250 gb size .\ncomplete datasets of a few tb size will be sent upon request on respective hardware media . *\nsupplementary material 4 : video of the noise - free simulation  original excitable medium simulation with filaments + the movie video_rounding1_noise0_k3.avi was made from the simulation when one decimal place was allowed , no noise was included , @xmath17 = 28 , @xmath3 = 200 , @xmath28 and @xmath29 . in this case , similarly as in the case when @xmath30 and @xmath31 it is sufficient to have one non - zero point to start ignition .\nthis further illustrates the conclusion depicted in  figure 4 . in the movie , every 30th simulation step is shown with the frequency of 100 frames per second . *\nsupplementary material 5 : video of the simulation at optimal noise + the movie video_rounding1_noise_appropriate.avi was made from the simulation at @xmath28 and @xmath29 , 10 decimal places were allowed and optimal levels of noise for each process , i.e. , 0.00 , 0.12 , and 0.30 for process 1 , 2a , and 2b , respectively . in the movie , every 100th simulation step is shown with the frequency of 100 frames per second . *\nsupplementary material 6 : video of the noise - free simulation at different @xmath38 ratios + files video_rounding0_noise0_g1_levels2000.avi , video_rounding0_noise0_g280_levels2000.avi , and video_rounding0_noise0_g1000_levels2000.avi show results of simulations at @xmath28 and @xmath29 , @xmath44 , @xmath59 , and @xmath17 as noted in the file name .\nsimulations exhibit distinct state space trajectories . in the movie ,\nevery 30th simulation step is shown with the frequency of 100 frames per second . *\nsupplementary material 7 : netlogo 5.2 model of the b  z reaction as an excitable medium    1 pikovsky , a. ; rosenblum , m. ; kurths , j. _ synchronization : a universal concept in nonlinear sciences _ , cambridge university press : cambridge , uk , 2001 .\ntiezzi , e. _ steps towards an evolutionary physics _ , wit press : southampton , uk , 2006 .\nbelousov , b. p. _ collection of short papers on radiation medicine _ ,\n: moscow , ussr , _ 145 _ , 1959 .\nzhabotinsky , a. m. periodical process of oxidation of malonic acid solution ( a study of the belousov reaction kinetics ) .\n_ biofizika _ * 1964 * , _ 9 _ , 306311 .\nbiosa , g. ; masia , m. ; marchettini , n. ; rustici , m. a ternary nonequilibrium phase diagram for a closed unstirred belousov - zhabotinsky system .\n_ j. chem .\nphys . _ * 2005 * , _ 308 _ , 712 .\nbelmonte , a. l. ; ouyang , qi ; flesselles , j .-\nexperimental survey of spiral dynamics in the belousov - zhabotinsky reaction . _ j. phys .\nii france _ , * 1997 * , _ 7 _ , 14251468 .\nkitahata , h. _ spatio - temporal pattern formation in reaction - diffusion systems coupled with convection and geometrical effect _ ,\nopen access thesis and dissertation , 2006 , available at http://hdl.handle.net/2433/64953 .\nliveri , m. l. t. ; lombardo , r. ; masia , m. ; calvaruso , g. ; rustici , m. role of the reactor geometry in the onset of transient chaos in an unstirred belousov - zhabotinsky system .\n_ j. phys .\n* 2003 * , _ 107 _ , 48344837 .\nrustici , m. ; branca , m. ; brunetti , a. ; caravati , c. ; marchettini , n. inverse ruelle - takens - newhouse scenario in a closed unstirred cerium catalyzed belousov - zhabotinsky system .\n_ * 1998 * , _ 293 _ , 145151 cross , m. c. ; hohenberg , p. s. pattern formation outside of equilibrium . _\nphys . _ * 1993 * , _ 65 _ , 8511112 .\nbudroni , m. a. ; rustici , m. ; tiezzi , e. on the origin of chaos in the belousov - zhabotinsky reaction in closed and unstirred reactors . _ math . model .\nnat . phenom .\n_ * 2011 * , _ 6 _ , 226242 .\nholley , j. ; adamatzky , a. ; bull , l. ; costello , b. ; jahan , i. computational modalities of belousov - zhabotinsky encapsulated vesicles .\n_ nano commun .\nnetw . _ * 2011 * , _ 2 _ , 5061 .\nvon neumann , j. _ the general and logical theory of automata _ ; jeffress , l .\na. , ed . ; in : cerebral mechanisms in behavior  the hixon symposium , 1951 , pp . 131 .\ndewdney , a.k .\ncomputer recreations : the hodgepodge machine makes waves . _\n* 1988 * , _ 225 _ , 104 .\nwilensky , u. netlogo b  z reaction model , available athttp://ccl.northwestern.edu / netlogo / models / b - zreaction . center for connected learning and computer - based modeling , northwestern institute on complex systems , northwestern university , evanston , il , 2003 .\nkinoshita , s. ; iwamoto , m ; tateishi , k. ; suematsu , j. b. ; ueyama , d. mechanism of spiral formation in heterogeneous discretized excitable media .\ne * 2013 * , _ 87 _ , 062815 .\nkrapivsky , p. l. ; redner , s. , ben - naim , e. _ a kinetic view of statistical physics _ , cambridge university press : cambridge , uk , 2010 .\nortiz de zrate , j. m. ; sengers , j. v. _ hydrodynamics fluctuations in fluids and fluid mixtures _ , elsevier : oxford , uk , 2006 .\nturing , a. m. the chemical basis of morphogenesis .\n. london _ * 1952 * , _ 237 _ , 3772 .\nhiltemann , s. _ multi - coloured cellular automata _ ,\nbachelor thesis , erasmus universiteit : rotterdam , netherlands , 2008 .\nwuensche , a. _ exploring discrete dynamics _ , luniver press , 2011 .\neyring , h. the activated complex in chemical reactions .\n_ j. chem .\nphys . _ * 1935 * , _ 3 _ , 107115 .\ntys , d. ; nhlk , t. ; zhyrova , a. ; rychtrikov , r. ; papek ,  .\n, csa , p. model of the belousov - zhabotinsky reaction , in press in _ lncs_. field , r. j. ; krs , e. ; noyes , h.m .\noscillations in chemical systems .\nthorough analysis of temporal oscillation in the bromate - cerium - malonic acid system .\nsoc . _ * 1972 * , _ 94 _ , 86498664 .\nrovinsky , a. b. ; zhabotinsky , a. m. mechanism and mathematical model of the oscillating bromate - ferroin - bromomalonic acid reaction .\n_ j. phys .\nchem . _ * 1988 * , _ 88 _ , 60816084 .\nfisch , r. ; gravner , j. ; griffeath , d. threshold - range scaling of excitable cellular automata .\ncomput . _ * 1991 * , _ 1 _ , 2339 .\nblasone , m. ; jizba , p. ; vitiello , g. _ quantum field theory and its macroscopic manifestations , boson condensation , ordered patterns and topological defects _ ,\nimperial college press : cambridge , uk , 2011 .\nlauzeral , j. ; halloy , j. ; goldbeter , a. desynchronization of cells on the developmental path triggers the formation of spiral waves of camp during _\ndictyostelium aggregation_. _ proc .\nusa _ * 1997 * , _ 94 _ , 91539158 .\ngetling , a. v. _ rayleigh - bnard convection : structures and dynamics_. world scientific , 1998 .\nkapral , r. ; lawniczak , a. ; masiar , p. oscillations and waves in a reactive lattice - gas automaton . _\nlett . _ * 1991 * , _ 66 _ , 25392542 .\nkinoshita , s. _ pattern formations and oscillatory phenomena _\n, 1st edition , elsevier : 2013 .\ncohen , j. at http://drjackcohen.com/bz01.html ."}
{"lay_summary": " the hires collaboration has recently announced preliminary measurements of the energy spectrum of ultra - high energy cosmic rays ( uhecr ) , as seen in monocular analyses from each of the two hires sites . \n this spectrum is consistent with the existence of the gzk cutoff , as well other aspects of the energy loss processes that cause the gzk cutoff . \n based on the analytic energy loss formalism of berezinsky _ et al . \n _ , the hires spectra favor a distribution of extragalactic sources that has a similar distribution to that of luminous matter in the universe , both in its local over - density and in its cosmological evolution . ", "article": "the cosmic ray energy spectrum is nearly featureless over ten orders of magnitude in energy , from @xmath0 ev to @xmath1 ev , with the differential flux falling approximately as @xmath2 .\nthere are three small , though widely discussed , features : the `` knee '' , a hardening of the spectrum at @xmath3 ev ; the `` second knee '' , another hardening at about @xmath4 ev ; and the `` ankle '' , a softening of the spectrum at about @xmath5 ev .\nthese features may represent changes in the sources , composition or dynamics of the cosmic rays .\ntwo often asked questions are : how do cosmic rays come to have such high energies ( a joule or more of kinetic energy in a proton or other sub - atomic particle ) , and does the spectrum continue above @xmath1 ev ?    there are two types of models describing the sources of ultra - high energy cosmic rays ( uhecrs ) : astrophysical models ( `` bottom - up '' ) , in which cosmic rays are accelerated to very high energies by magnetic shock fronts moving though plasmas ; and cosmological models ( `` top - down '' ) , in which the cosmic rays are the result of the decays of super heavy particles which are relics of the big bang .\ni will only be discussing the former .\none can evaluate the plausibility of various astrophysical sources by considering the magnetic field of the object and its size.@xcite the overall magnetic field contains the nascent cosmic rays during their acceleration and thus must be large enough to keep the cosmic rays within the object .\nsmaller objects need larger fields ; larger objects , smaller fields . by this criterion\nwe have several candidate sources : neutron stars , active galactic nuclei ( agn ) and clusters of galaxies among others .\nall these sources could plausibly , by the above argument , give cosmic rays at @xmath1 ev , but , in all cases , one is pushing the bounds of plausibility at the highest energies .\nif uhecrs are extragalactic , then they must traverse the intergalactic medium in order to be observed .\nthis medium is filled with cosmic microwave background ( cmb ) photons , which should lead to a fourth , and not so small , feature of the uhecr spectrum . because of their large kinetic energies , uhecrs interact with the cmb to produce resonances ( in the case of protons ) or to dissociate ( in the case of nuclei ) . in the proton case\n, the resonance ( e.g. @xmath6 ) will decay quickly into proton or neutron and a meson ( e.g. @xmath7 ) . in either case ,\nthe result is a reduction in the energy of the leading particle . at somewhat lower energies ,\ncosmic rays lose energy by creating electron - positron pairs in their interaction with the cmb .\nthese energy loss mechanisms imply that there should be a sharp reduction in the uhecr flux above @xmath8 ev , assuming the uhecrs are protons and that they come from distances greater than a few tens of megaparsecs .\nnuclei should have an even lower energy threshold .\nthis fact , first pointed out by greisen , zatsepin and kuzmin , has become known as the gzk cutoff.@xcite by measuring the shape of the uhecr spectrum and , crucially , modeling the spectrum at the source , one can hope to deduce which of the plausible sources listed above , if any , contribute to the uhecrs we see .\nif uhecrs are produced in our galaxy they are not subject to the gzk cutoff . however , there are no plausible astrophysical accelerators of uhecrs within our galaxy\n. any such object would appear as a point source in a map of the sky made with uhecrs , due to the short propagation distances and relatively weak magnetic fields .\nno such point source has been observed .\nuhecrs have a very low flux , so one must have a large collection area to obtain a reasonable event rate .\nthis precludes direct observations of uhecr above the earth s atmosphere in satellite experiments .\nhowever , one may also use that atmosphere as a giant calorimeter , because uhecrs create extensive air showers ( eass ) when they encounter the atmosphere .\nthis allows access to very large areas .\nthere are two ways to instrument this atmospheric calorimeter : readout the particle multiplicities at the back end by putting arrays of detectors on the ground , or collect the light produced as the eas gives up its energy to the atmosphere .\nthe former technique ( ground arrays ) has the advantage of 100% duty cycle : one can run at all times of the day .\nit has the disadvantage that one usually observes only the tail end of the eas and has to infer the properties of the primary particle rather indirectly . to illustrate , consider the lead - scintillator sandwich type calorimeter used in many fixed - target experiments at accelerators .\none normally collects the light produced by the shower as it goes through the scintillator segments .\nthe total light is proportional to the energy of the initial particle , and one can in principle measure the longitudinal development of the shower .\nnow imagine throwing away the signals from all but the last scintillator segment and one can understand the difficulties faced by ground arrays .\none must also make a trade - off between density of detectors on the ground and the total area over which one places detectors .\ncollecting the fluorescence light from eass has complementary advantages and disadvantages .\nthe main advantage is that one observes light from all stages in the development of the eas , and the amount of this light is directly proportional to the primary energy .\nthe disadvantage is that one is subject to the optical changes inherent in the atmosphere and one can only run when and where it is dark and clear . as a counterpart to the example above\n, fluorescence detectors are like lead - glass calorimeters , where one collects light from the whole detector element . however , the glass may be somewhat smoky .    the akeno giant air shower array ( agasa)@xcite is the largest , currently active example of a ground array .\nthe agasa collaboration claims to see no evidence for the gzk cutoff,@xcite which has motivated a great deal of theoretical work on possible mechanisms by which the gzk cutoff could be avoided .\nthe fly s eye experiment@xcite is an example of a fluorescence detector , and the experiment that has observed the highest energy cosmic ray ever detected at @xmath9 ev.@xcite the pierre auger observatory,@xcite currently under construction , will combine both a very large ground array and a fluorescence detector , in an effort to have the advantages of both types of detectors .\nthe high resolution fly s eye experiment ( hires ) is a direct descendant of fly s eye , designed with bigger mirrors and finer pixels , to give a larger aperture by a factor of ten .\nit consists of two sites , separated by 12 km , in order to observe eass in stereo .\nstereo observation greatly reduces the uncertainty in the geometrical reconstruction of the eas .\nthe sites are located on hills on the dugway proving grounds in the west desert of utah .\nthe remote desert provides a dark , optically clean atmosphere , while the hills put the detectors above much of the remaining aerosols .\neach detector consists of mirror units viewing a @xmath10 patch of the sky with 256 photomultiplier tubes ( pmts ) , each of which views about @xmath11 , in a @xmath12 array .\neach mirror has an area of about 5 m@xmath13 .\nthe hires - i site , the first of the two to be built , has one ring of mirrors covering from @xmath14@xmath15 and nearly the complete azimuth . the pmts are read out using a sample - and - hold technique , that gives the time and size of the signal for each tube .\nthe hires - ii site has two rings of mirrors covering @xmath14@xmath16 .\nthese pmts are read out using a flash adc ( fadc ) system , which samples each of the tubes every 100 ns .\nthis provides the shape of the signal in each tube and allows one to combine the light from different tubes that were active at the same time .\nhires - i began operation in june of 1997 .\nhires - ii began in october of 1999 .\nthe reader is referred to the published fly s eye@xcite and hires@xcite papers for details of the reconstruction techniques .\nonly a brief summary will be given here .\nalthough hires was designed as a stereo experiment , there are two reasons for continuing to consider monocular analyses .\nfirst , since hires - i was running for two years before hires - ii came on - line , the largest uhecr data sample is the hires - i monocular sample .\nsecond , low - energy events are close to one or the other of the two sites , and trigger that site only .\nthus , the low - energy reach of the detector will always be in monocular mode .\nhires - ii is a better detector for reconstructing monocular events , due to its two rings : longer tracks lead to a better determination of the eas geometry .\nthere are two tasks in determining the geometry of an eas : finding the shower - detector plane ( sdp ) and determining the angle of the shower within the sdp .\nthe geometry of the shower within the sdp is determined by fitting the time of the tube signals @xmath17 for @xmath18 , @xmath19 and @xmath20 , where @xmath21 is the signal time in the @xmath22th tube , @xmath18 is the impact parameter , @xmath20 is the time the shower core reaches the @xmath18 point , @xmath19 is the angle of the eas in the sdp and @xmath23 is the viewing angle in the sdp of the @xmath22th tube .\nlonger tracks make it easier to distinguish the tangent function from a straight line\n. hires - i tracks are often too short to resolve all the ambiguities from timing alone , and one must look to the reconstructed shower profile ( see below ) for assistance in determining the geometry .    as an example , a picture of a 50 eev cosmic ray event from hires - ii , given in fig .  [\nfig : mirror - tvsa ] , shows the azimuthal and elevation angles of all the tubes in the mirrors that were part of the event .\ninactive tubes are shown as dots ; active tubes are shown as filled circles , where the radius is proportional to the tube signal .\nactive tubes that are used in fitting the sdp are shaded according to the average time of the fadc measurements of the tube .\nthe fitted sdp is also shown in the figure .\nthe average time of the signal for each tube as a function of the angle ( @xmath23 ) in the sdp is also shown for the same event , including three fits to eq .\n[ eq : tvsa ] , one with @xmath24 ( light grey ) , one with @xmath25 ( dark grey ) and the best fit @xmath19 ( black ) .\nev ) uhecr event , as seen on the mirrors / pmts of the detector ( left ) and in a time vs ( sdp ) angle plot ( right ) . in the mirror / pmt display dots represent inactive tubes , circles represent active tubes where the size of the tube is proportional to the signal .\nshaded tubes are included in the fit , with the shading representing the relative times : light to dark , early to late . in the time\nvs angle plot , the time is shown in units of 100 ns .\nthe three fits are from eq  [ eq : tvsa ] with @xmath24 ( light grey ) , @xmath25 ( dark grey ) the best fit @xmath19 ( black).,title=\"fig : \" ]   ev ) uhecr event , as seen on the mirrors / pmts of the detector ( left ) and in a time vs ( sdp ) angle plot ( right ) . in the mirror / pmt display dots represent inactive tubes , circles represent active tubes where the size of the tube is proportional to the signal .\nshaded tubes are included in the fit , with the shading representing the relative times : light to dark , early to late . in the time\nvs angle plot , the time is shown in units of 100 ns .\nthe three fits are from eq  [ eq : tvsa ] with @xmath24 ( light grey ) , @xmath25 ( dark grey ) the best fit @xmath19 ( black).,title=\"fig : \" ]      once the geometry of the eas is determined , one can use the photoelectron ( npe ) signal of the pmts to determine the number of charged particles , @xmath26 , in the shower . in making this @xmath27 conversion ,\ntwo important calibration issues come into play : the gains of the pmts , and the atmospheric transparency to light .\npmt gains are monitored nightly and monthly using a xenon flash lamp and yag laser .\nthe atmosphere is monitored using a bistatic lidar system .\nthe hires - ii analysis combines the pe signal from all the tubes in a given time bin , and converts this into a given number of charged particles in the eas at a given depth in the atmosphere ( measured in g / cm@xmath13 ) .\nthis conversion is strongly dependent on the geometry .\none can estimate the energy of a shower from the number of charged particles , the amount of material traversed , and the average energy deposited per particle : @xmath29 since one often does not see the entire eas , one must assume some profile of the number of charged particles for the unobserved part of the shower .\nwe use the gaisser - hillas parameterization @xmath30 where @xmath31 is the depth at the maximum extent of the eas , @xmath32 is the number of particles at that depth , @xmath33 corresponds to the depth of the first interaction , and @xmath34 is the interaction length .\nwe fitted the observed portion of the shower to determine @xmath31 and @xmath32 , holding @xmath35 g / cm@xmath13 ( which is not physical , but gives the best fits when applied to simulations using corsika@xcite ) and @xmath36 g / cm@xmath13 .\nsome of the observed light comes from the beam of erenkov light generated by the eas and scattered into the detector .\nthis light is subtracted from the signal in an iterative procedure .\nthe photoelectron signal as a function of time and the calculated @xmath26 as a function of depth for the same 50 eev event are shown in fig .\n[ fig : profile ] .     profiles in the 50 eev event of fig .\nfig : mirror - tvsa . in the the upper plot , points with error bars show the photoelectron signal ( npe ) from all tubes included within a given time bin .\nthe dashed and doted lines show calculations for the fluorescence and erenkov components of the signal , respectively , for this event at the best fit values of @xmath31 and @xmath32 ; the solid line shows the sum of the components . in the lower plot ,\nfilled points with error bars show the calculated @xmath26 extracted from the npe signal as a function of depth in the atmosphere .\nthe open points without error bars show the result of the calculation without subtracting off the erenkov component . ]\nthe energy is calculated from the hires - i signals in a similar way , except that the expected number of pe for a given shower is compared with the observed value .\nin other words , the fit is done using the number of pe at the detector rather than the extracted number of charged particles in the shower .\nthe comparison is also done on a tube - by - tube basis rather than in time bins .\nafter events are reconstructed , one must select the sample from which to calculate the flux .\nthis sample should be as large as possible and contain only well reconstructed events .\nthe criteria used to make this selection are listed in table  [ tab : cuts ] .\n[ tab : cuts ]\nto determine the flux of uhecr , one needs to know the aperture over which the uhecrs are collected .\nthis aperture varies with energy and must be determined through monte carlo ( mc ) simulation .\nhowever , one can also use mc simulation to check that one understands the data and its reconstruction in the detector . extensive comparisons of distributions in data and in simulated samples of events provides confidence that the calculated aperture is correct .\nthe details of mc event generation have been published elsewhere.@xcite it is clear , however , that one needs to model the details of the trigger , the extra tube distribution , and the transmission of light in the atmosphere to sufficient accuracy to obtain good agreement between data and mc .\ni will show four comparisons between data and mc , all taken from the hires - ii analysis .\nthe first , in fig .\n[ fig : mcnpe - geo ] , shows the distribution of observed light ( npe ) divided by the track length .\nthe light distribution is sensitive to the yield , trigger , and geometry , among other things .\nthe second and third comparisons , also in fig .\n[ fig : mcnpe - geo ] , show the distributions of @xmath18 and @xmath19 .\nthe good agreement gives us confidence in our calculation of the aperture . finally , there is the energy distribution in fig  [ fig : mcenergy ] , which enters directly into the calculation of the flux .\nnote that the energy distribution has a binning such that there are no bins with less than two events .\nthe hires - ii aperture , with the same binning , is shown in fig .\n[ fig : aperture ] .     and\n@xmath19 ( right ) between data ( points ) and mc ( histogram ) where in each case the mc distribution has been normalized to have the same area as the data .\nthe bottom plots show the ratio of the two above distributions : data / mc.,title=\"fig : \" ]   and @xmath19 ( right ) between data ( points ) and mc ( histogram ) where in each case the mc distribution has been normalized to have the same area as the data .\nthe bottom plots show the ratio of the two above distributions : data / mc.,title=\"fig : \" ]\nwith the event samples in hand , and confidence in our calculated aperture , we can extract the flux . fig .\n[ fig : fluxm3 ] , shows the calculated flux from hires - i ( triangles ) and hires - ii ( circles ) .\nthe fluxes have been multiplied by @xmath37 in order to emphasize changes in the spectral index .    , as measured by hires - i ( triangles ) and hires - ii ( circles ) .\nthe solid line is a two component fit to the data consisting of a galactic ( dotted line ) and extragalactic ( dashed line ) spectrum .\nthe extragalactic sources evolve as @xmath38 with @xmath39 and have a distribution modified by the observed density of galaxies . ]    to evaluate the significance of these spectra , i have fitted the measured points to an astrophysical model of the sources and propagation of uhecrs . in choosing this model ,\ni have been motivated by occam s razor , sticking with known physical processes , and assuming only that the extragalactic sources of uhecr are distributed throughout the universe , and evolve in their density in the same way as the luminous matter in galaxies . to this\nis added a phenomenologically motivated galactic spectrum at lower energies .\nthe extragalactic spectrum is assumed to consist of protons , and have a power law spectrum at the source , with a fitted spectral slope parameter .\nthis spectrum is modified by energy losses as the uhecrs traverse the intra - galactic medium .\nthe energy loss formalism is taken from the work of berezinsky _\net al_.@xcite the sources are taken to be uniformly distributed out to a red - shift of @xmath40 , with a density at any given @xmath41 modified by the observed density of galaxies at that red - shift@xcite and evolving as @xmath38 with @xmath39 ( which is the best fit value and approximately the same as the observed stellar formation rate@xcite ) . using @xmath42 , increases the @xmath43 of the fit by 3.5 while not accounting for the observed density of galaxies increases the @xmath43 by 1.5 .\nthe galactic component of the spectrum is assumed to consist of iron nuclei .\nmotivation for this assumption comes from the fly s eye composition measurement,@xcite which shows an approximately linear ( in @xmath44 ) change from a heavy composition ( iron ) to a light one ( protons ) .\nthe spectral form is assumed to be @xmath2 , consistent with the uhecr spectrum below @xmath45 ev , multiplied by a linear ( in @xmath44 ) factor going from unity at @xmath45 ev , to zero at @xmath46 ev .\nthe fact that this model fits the data so well is due to agreement in its three features .\nfirst , the model clearly has a drastic reduction in flux above the gzk energy , a reduction which is also observed in the data , but with not as yet overwhelming statistical significance .\nmore strongly constrained by observation are the `` second knee '' and `` ankle '' , which in this model are the result of electron pair production.@xcite the strength of the astrophysical source model is that it fits both the electron pair - production features and the pion production feature ( the gzk cutoff ) in the spectrum .\nhires has recently announced preliminary measurements of the uhecr energy spectrum using each of its two detectors in monocular mode .\nwe have fitted this spectrum to a two - component model of the uhecr sources , the extragalactic component of which conforms to the expectation of a nearly unform distribution of sources , modified by the observed distribution of luminous matter and its evolution as a function of red - shift .\nthis model fits all the recognized features of the uhecr spectrum , not just the gzk cutoff .\nmuch has been made of the discrepancies between hires and agasa , with agasa seeing no evidence for the gzk cutoff , and hires being consistent with its presence .\nhowever , at energies below the gzk cutoff , the two experiments agree nicely in the shape of the spectrum , with only an offset in the flux , which can be attributed to a difference in energy scale within the stated systematic uncertainty of either experiment.@xcite\nwhile comments about the conformity of the hires spectra with the gzk cutoff are my own opinions , the measurement of the spectra themselves would not have been possible without my colleagues in the hires collaboration , to whom i feel indebted for the realization of this work .\nthis work is supported by the us nsf grant phy 0073057 ."}
{"lay_summary": " dynamics is considered as a corollary of the space - time geometry . \n evolution of a particle in the space - time is described as a chain of connected equivalent geometrical objects . \n space - time geometry is determined uniquely by the world function @xmath0 . \n proper modification of the minkowskian world function for large space - time interval leads to wobbling of the chain , consisted of timelike straight segments . statistical description of the stochastic world chain coincides with the quantum description by means of the schrdinger equation . \n proper modification of the minkowskian world function for small space - time interval may lead to appearance of a world chain , having a shape of a helix with timelike axis . \n links of the chain are spacelike straight segments . \n such a world chain describes a spatial evolution of a particle . \n in other words , the helical world chain describes the particle rotation with superluminal velocity . the helical world chain associated with the classical dirac particle , \n whose world line is a helix . \n length of world chain link can not be arbitrary . \n it is determined by the space - time geometry and , in particular , by the elementary length . \n there exists some discrimination mechanism , which can discriminate some world chains . ", "article": "geometrical dynamics is a dynamics of elementary particles , generated by the space - time geometry . in the space - time of minkowski\nthe geometrical dynamics coincides with the conventional classical dynamics , and the geometrical dynamics may be considered to be a generalization of classical dynamics onto more general space - time geometries .\nhowever , the geometric dynamics has more fundamental basis , and it may be defined in multivariant space - time geometries , where one can not introduce the conventional classical dynamics .\nthe fact is that , the classical dynamics has been introduced for the space - time geometry with unlimited divisibility , whereas the real space - time has a limited divisibility .\nthe limited divisibility of the space - time is of no importance for dynamics of macroscopic bodies .\nhowever , when the size of moving bodies is of the order of the size of heterogeneity , one may not neglect the limited divisibility of the space - time geometry .\nthe geometric dynamics is developed in the framework of the program of the further physics geometrization , declared in @xcite .\nthe special relativity and the general relativity are steps in the development of this program .\nnecessity of the further development appeared in the thirtieth of the twentieth century , when diffraction of electrons has been discovered .\nthe motion of electrons , passing through the narrow slit , is multivariant .\nas far as the free electron motion depends only on the properties of the space - time , one needed to change the space - time geometry , making it to be multivariant . in multivariant geometry\nthere are many vectors @xmath1 , @xmath2, ... at the point @xmath3 , which are equal to the vector @xmath4 , given at the point @xmath5 , but they are not equal between themselves , in general .\nsuch a space - time geometry was not known in the beginning of the twentieth century .\nit is impossible in the framework of the riemannian geometry . as a result\nthe multivariance was prescribed to dynamics . to take into account multivariance ,\ndynamic variables were replaced by matrices and operators .\none obtains the quantum dynamics , which differs from the classical dynamics in its principles .\nbut the space - time conception remains to be newtonian ( nonrelativistic ) .\nmultivariant space - time geometry appeared only in the end of the twentieth century @xcite .\nthe further geometrization of physics became to be possible .\nit should note that there were numerous attempts of further geometrization of physics .\nthey were based on the riemannian space - time geometry .\nunfortunately , the true space - time geometry of microcosm does not belong to the class of riemannian geometries , and approximation of real space - time geometry by a riemannian geometry can not be completely successful . in particular , the riemannian geometry can not describe such a property of real space - time geometry as multivariance .\nthe multivariance of the space - time geometry was replaced by the multivariance of dynamics ( quantum theory ) .\nunderstanding of nature of elementary particles is the aim of the further geometr - ization of physics .\nthis aim distinguishes from the aim of the conventional theory of elementary particles .\nlet us explain the difference of aims in the example of history the chemical elements investigation .\ninvestigation of chemical elements reminds to some extent investigation of elementary particles .\nchemical elements are investigated from two sides .\nchemists systematized chemical elements , investigating their phenomenological properties .\nthe results of these investigations were formulated in the form of the periodical system of chemical elements in 1870 .\nformulating this system , d.i.mendeleev conceived nothing about the atom construction\n. nevertheless the periodical system appears to be very useful from the practical viewpoint .\nphysicists did not aim to explain the periodical system of chemical elements , they tried to understand simply the atom structure and the discrete character of atomic spectra .\nafter construction of the atomic theory it became clear , that the periodical system of chemical elements can be obtained and explained on the basis of the atomic theory . as a result\nthe `` physical '' approach to investigation of chemical elements appeared to be more fundamental , deep and promising , than the `` chemical '' one . on the other hand ,\nthe way of the `` physical '' approach to explanation of the periodical system is very long and difficult .\nexplanation of the periodical system was hardly possible at the `` physical '' approach , i.e. without the intermediate aim ( construction of atomic structure ) .\nthus , using geometrization of physics , we try to approach only intermediate aim : explanation of multivariance of particle motion ( quantum motion ) and capacity of discrimination of particle masses .\ndiscrete character of masses of elementary particles can be understood , only if we understand the reason of the elementary particle discrimination .\ncontemporary approach to the elementary particle theory is the `` chemical '' ( phenomenological ) approach .\nit is useful from the practical viewpoint .\nhowever , it admits hardly to understand nature of elementary particles , because the nature of the discrimination mechanism , leading to discrete characteristics of elementary particle , remains outside the consideration .\nthe most general geometry is a physical geometry , which is called also the tubular geometry ( t - geometry ) @xcite , because straights in t - geometry are hallow tubes , in general .\nthe t - geometry is determined completely by its world function @xmath6 , where @xmath7 is interval between the points @xmath8 and @xmath9 in space - time , described by the t - geometry .\nall concepts of t - geometry are expressed in terms of the world function @xmath0 .\ndynamics of particles ( geometric dynamics ) is also described in terms of the world function .\nthe elementary particle is considered as an elementary geometrical object ( ego ) in the space - time .\nthe elementary geometrical object @xmath10 is described by its skeleton @xmath11 and its envelope @xmath12 .\nthe envelope @xmath12 is defined as a set of zeros of the envelope function @xmath13@xmath14the envelope function @xmath13 is a real function of arguments @xmath15 .\nany argument @xmath16 @xmath17 is a world function @xmath18 , @xmath19 .\nit is supposed that ego with skeleton @xmath20 is placed at the point @xmath5 .    in t - geometry\nthe vector @xmath21 is an ordered set of two points @xmath22 .\nthe length @xmath23 of the vector @xmath4 is defined via the world function by means of the relation@xmath24    the scalar product @xmath25 of two vectors @xmath4 and @xmath1 is defined by the relation@xmath26equivalence @xmath4eqv@xmath1 of two vectors @xmath4 and @xmath1 is defined as follows .\ntwo vectors @xmath4 and @xmath1 are equivalent ( equal ) , if@xmath27 in the developed form we have@xmath28    skeletons @xmath20 and @xmath29 are equivalent ( @xmath30eqv@xmath31 , if corresponding vectors of both skeletons are equivalent@xmath32    the skeleton @xmath20 of ego at the point @xmath5 may exist as a skeleton of a physical body , if it may exist at any point @xmath33 of the space - time @xmath34 .\nit means that there is a solution for system of equations @xmath35for any point @xmath33 .\nfurther for brevity we take , that an existence of a skeleton means an existence of corresponding geometrical object .    in the space - time of minkowski the problem of the skeleton existence is rather simple , because at given @xmath30 and @xmath3 the system ( [ c1.6 ] ) of @xmath36 algebraic equations has a unique solution , although the number of equations may distinguish from the number of variables to be determined .\nindeed , in the four - dimensional space - time the number of coordinates of @xmath37 points @xmath38 is equal to @xmath39 ( the point @xmath3 is supposed to be given ) . if @xmath40 the number @xmath36 of equations is larger than the number ( @xmath39 ) of variables . in the case of an arbitrary space - time geometry ( arbitrary world function @xmath0 )\nexistence of solution of the system ( [ c1.6 ] ) is problematic , and the question of existence of the skeleton as a skeleton of a physical body is an essential problem . on the contrary ,\nif @xmath41 , the number of coordinates to be determined is less , than the number of equations , and one may have many skeletons @xmath42placed at the point @xmath3 , which are equivalent to skeleton @xmath30 , but they are not equivalent between themselves .\nthis property is a property of multivariance of the space - time geometry .\nthis property is actual for simple skeletons , which contain less , than four points ( @xmath41 ) .\nfor instance , for the skeleton of two points @xmath43 , which is described by the vector @xmath4 , the problem of multivariance is actual . in the space - time of minkowski\nthe equivalence of two vectors ( @xmath44 ) is single - variant for the timelike vectors , however it is multivariant for spacelike vectors . in the general space - time\nthe equivalence relation @xmath44 is multivariant for both timelike and spacelike vectors .\nthe problem of multivariance is essential for both existence and dynamics of elementary geometrical objects ( elementary particles ) .\nlet us formulate dynamics of elementary particles in the coordinateless form .\ndynamics of an elementary particle , having skeleton @xmath11 , is described by the world chain @xmath45direction of evolution in the space - time is described by the leading vector @xmath4 . if the motion of the elementary particle is free , the adjacent links @xmath46 and @xmath47 are equivalent in the sense that @xmath48    relations ( [ c1.7 ] ) - ( [ c1.9 ] ) realizes coordinateless description of the free elementary particle motion . in the simplest case ,\nwhen the space - time is the space - time of minkowski , and the skeleton consists of two points @xmath49 with timelike leading vector @xmath4 , the coordinateless description by means of relations ( [ c1.7 ] ) - ( [ c1.9 ] ) coincides with the conventional description .\nthe conventional classical dynamics is well defined only in the riemannian space - time . the coordinateless dynamic description ( [ c1.7 ] ) - ( [ c1.9 ] ) of elementary particles is a generalization of the conventional classical dynamics onto the case of arbitrary space - time geometry .\nany geometry is constructed as a modification of the proper euclidean geometry .\nbut not all representations of the proper euclidean geometry are convenient for modification .\nthere are three representation of the proper euclidean geometry @xcite .\nthey differ in the number of primary ( basic ) elements , forming the euclidean geometry .\nthe euclidean representation ( e - representation ) contains three basic elements ( point , segment , angle ) .\nany geometrical object ( figure ) can be constructed of these basic elements .\nproperties of the basic elements and the method of their application are described by the euclidean axioms .\nthe vector representation ( v - representation ) of the proper euclidean geometry contains two basic elements ( point , vector ) .\nthe angle is a derivative element , which is constructed of two vectors .\na use of the two basic elements at the construction of geometrical objects is determined by the special structure , known as the linear vector space with the scalar product , given on it ( euclidean space ) .\nthe scalar product of linear vector space describes interrelation of two basic elements ( vectors ) , whereas other properties of the linear vector space associate with the displacement of vectors .\nthe third representation ( @xmath0-representation ) of the proper euclidean geometry contains only one basic element ( point ) .\nsegment ( vector ) is a derivative element .\nit is constructed of points .\nthe angle is also a derivative element .\nit is constructed of two segments ( vectors ) .\nthe @xmath50-representation contains a special structure : world function @xmath0 , which describes interrelation of two basic elements ( points ) .\nthe world function @xmath51 , where @xmath52 is the distance between points @xmath5 and @xmath53 .\nthe concept of distance @xmath54 , as well as the world function @xmath0 , is used in all representations of the proper euclidean geometry . however , the world function forms a structure only in the @xmath0-representation , where the world function @xmath0 describes interrelation of two basic elements ( points ) .\nbesides , the world function satisfies a series of constraints , formulated in terms of @xmath0 and only in terms of @xmath0 .\nthese conditions ( the euclideaness conditions ) will be formulated below .\nthe euclideaness conditions are equivalent to a use of the vector linear space with the scalar product on it , but formally they do not mention the linear vector space , because all concepts of the linear vector space , as well as all concepts of the proper euclidean geometry are expressed directly via world function @xmath0 and only via it .\nif we want to modify the proper euclidean geometry , then we should use the @xmath0-representation for its modification . in the @xmath0-representation the special geometric structure ( world function )\nhas the form of a function of two points . modifying the form of the world function , we modify automatically all concepts of the proper euclidean geometry , which are expressed via the world function .\nit is very important , that the expression of geometrical concepts via the world function does not refer to the means of description ( dimension , coordinate system , concept of a curve ) .\nthe fact , that modifying the world function , one violates the euclideaness conditions , is of no importance , because one obtains non - euclidean geometry as a result of such a modification .\na change of the world function means a change of the distance , which is interpreted as a deformation of the proper euclidean geometry .\nthe generalized geometry , obtained by a deformation of the proper euclidean geometry is called the tubular geometry ( t - geometry ) , because in the generalized geometry straight lines are tubes ( surfaces ) , in general , but not one - dimensional lines .\nanother name of t - geometry is the physical geometry .\nthe physical geometry is the geometry , described completely by the world function .\nany physical geometry may be used as a space - time geometry in the sense , that the set of all t - geometries is the set of all possible space - time geometries .\nmodification of the proper euclidean geometry in v - representation is very restricted , because in this representation there are two basic elements .\nthey are not independent , and one can not modify them independently .\nformally it means , that the linear vector space is to be preserved as a geometrical structure .\nit means , in particular , that the generalized geometry retains to be continuous , uniform and isotropic .\nthe dimension of the generalized geometry is to be fixed . besides\n, the generalized geometry , obtained by such a way , can not be multivariant .\nsuch a property of the space - time geometry as multivariance can be obtained only in @xmath0-representation .\nas far as the @xmath0-representation of the proper euclidean geometry was not known in the twentieth century , the multivariance of geometry was also unknown concept .\ntransition from the v - representation to @xmath0-representation is carried out as follows .\nall concepts of the linear vector space are expressed in terms of the world function @xmath0 . in reality ,\nconcepts of vector , scalar product of two vectors and linear dependence of @xmath37 vectors are expressed via the world function @xmath55 of the proper euclidean geometry .\nsuch operations under vectors as equality of vectors , summation of vectors and multiplication of a vector by a real number are expressed by means of some formulae .\nthe characteristic properties of these operations , which are given in v - representation by means of axioms , are given now by special properties of the euclidean world function @xmath55 .\nafter expression of the linear vector space via the world function the linear vector space may be not mentioned , because all its properties are described by the world function .\nwe obtain the @xmath0-representation of the proper euclidean geometry , where some properties of the linear vector space are expressed in the form of formulae , whereas another part of properties is hidden in the specific form of the euclidean world function @xmath55 . modifying world function , we modify automatically the properties of the linear vector space ( which is not mentioned in fact ) . at such a modification\nwe are not to think about the way of modification of the linear vector space , which is the principal geometrical structure in the v - representation . in the @xmath0-representation the linear vector space is a derivative structure , which may be not mentioned at all .\nthus , at transition to @xmath0-representation the concepts of the linear vector space ( primary concepts in v - representation ) become to be secondary concepts ( derivative concepts of the @xmath0-representation ) .    in @xmath0-representation\nwe have the following expressions for concepts of the proper euclidean geometry .\nvector @xmath56 is an ordered set of two points @xmath8 and @xmath9 .\nthe length @xmath57 of the vector @xmath58 is defined by the relation@xmath59the scalar product @xmath25 of two vectors @xmath4 and @xmath1 is defined by the relation@xmath60where the world function @xmath0@xmath61is the world function @xmath55 of the euclidean geometry .    in the proper euclidean geometry\n@xmath37 vectors @xmath62 , @xmath63 are linear dependent , if and only if the gram s determinant @xmath64 where the gram s determinant @xmath65 is defined by the relation @xmath66using expression ( [ a1.1 ] ) for the scalar product , the condition of the linear dependence of @xmath37 vectors @xmath62 , @xmath63 is written in the form@xmath67    definition ( [ a1.1 ] ) of the scalar product of two vectors coincides with the conventional scalar product of vectors in the proper euclidean space .\n( one can verify this easily ) . the relations ( [ a1.1 ] ) , ( [ a1.7b ] ) do not contain a reference to the dimension of the euclidean space and to a coordinate system in it . hence , the relations ( [ a1.1 ] ) , ( [ a1.7b ] ) are general geometric relations , which may be considered as a definition of the scalar product of two vectors and that of the linear dependence of vectors .\nequivalence ( equality ) of two vectors @xmath4 and @xmath1 is defined by the relations@xmath68where @xmath23 is the length ( [ a1.0 ] ) of the vector @xmath4@xmath69    in the developed form the condition ( [ a1.3 ] ) of equivalence of two vectors @xmath4 and @xmath1 has the form@xmath70    let the points @xmath49 , determining the vector @xmath4 , and the origin @xmath3 of the vector @xmath1 be given .\nlet @xmath4eqv@xmath1 .\nwe can determine the vector @xmath1 , solving two equations ( [ a1.5 ] ) , ( [ a1.6 ] ) with respect to the position of the point @xmath71 .\nin the case of the proper euclidean space there is one and only one solution of equations ( [ a1.5 ] ) , ( [ a1.6 ] ) independently of the space dimension @xmath37 . in the case of arbitrary t - geometry\none can guarantee neither existence nor uniqueness of the solution of equations ( [ a1.5 ] ) , ( [ a1.6 ] ) for the point @xmath71 .\nnumber of solutions depends on the form of the world function @xmath0 .\nthis fact means a multivariance of the property of two vectors equivalence in the arbitrary t - geometry . in other words ,\nthe single - variance of the vector equality in the proper euclidean space is a specific property of the proper euclidean geometry , and this property is conditioned by the form of the euclidean world function . in other t - geometries\nthis property does not take place , in general .\nthe multivariance is a general property of a physical geometry .\nit is connected with a necessity of solution of algebraic equations , containing the world function . as far as the world function is different in different physical geometries\n, the solution of these equations may be not unique , or it may not exist at all .    if in the @xmath37-dimensional euclidean space @xmath72 , the vectors @xmath62 , @xmath63 are linear independent .\nwe may construct rectilinear coordinate system with basic vectors @xmath62 , @xmath63 in the @xmath37-dimensional euclidean space .\ncovariant coordinates @xmath73 of the vector @xmath74 in this coordinate system have the form@xmath75    now we can formulate the euclideaness conditions .\nthese conditions are conditions of the fact , that the t - geometry , described by the world function @xmath0 , is @xmath37-dimensional proper euclidean geometry .\ni. definition of the dimension and introduction of the rectilinear coordinate system : @xmath76where @xmath77  is the gram s determinant ( a1.7 ) .\nvectors @xmath78 , @xmath79  are basic vectors of the rectilinear coordinate system @xmath80  with the origin at the point @xmath5 . in @xmath80\nthe covariant metric tensor @xmath81 ,  @xmath82  and the contravariant one @xmath83 ,  @xmath82  are defined by the relations @xmath84@xmath85    \\ii .\nlinear structure of the euclidean space : @xmath86where coordinates @xmath87  @xmath88  of the point @xmath8  are covariant coordinates of the vector @xmath74 , defined by the relation ( [ a1.8 ] ) .\niii : the metric tensor matrix @xmath89  has only positive eigenvalues\n@xmath90    \\iv .\nthe continuity condition : the system of equations @xmath91considered to be equations for determination of the point @xmath8  as a function of coordinates @xmath92 ,  @xmath88  has always one and only one solution . _ _  _ _ all conditions i @xmath93 iv contain a reference to the dimension @xmath37  of the euclidean space .\none can show that conditions i @xmath93 iv are the necessary and sufficient conditions of the fact that the set @xmath34 together with the world function @xmath0 , given on @xmath94 , describes the @xmath37-dimensional euclidean space @xcite .\ninvestigation of the dirac particle ( dynamic system , described by the dirac equation ) has shown , that the dirac particle is a composite particle r2004 , whose internal degrees of freedom are described nonrelativistically @xcite .\nthe composite structure of the dirac particle may be explained as a relativistic rotator , consisting of two ( or more ) particles , rotating around their inertia centre .\nthe relativistic rotator explains existence of the dirac particle spin , however , the problem of the rotating particles confinement appears . in this paper\nwe try to explain the problem of spin in the framework of the program of the physics geometrization , when dynamics of physical bodies is determined by the space - time geometry .\nalthough the first stages of the physics geometrization ( the special relativity and the general relativity ) manifest themselves very well , the papers on further geometrization of physics , which ignore the quantum principles , are considered usually as dissident .\ndynamics in the space - time , described by a physical geometry ( t - geometry ) , is presented in @xcite . here\nwe remind the statement of the problem of dynamics .\ngeometrical object @xmath95 is a subset of points in the point set @xmath34 . in the t - geometry\nthe geometric object @xmath10 is described by means of the skeleton - envelope method .\nit means that any geometric object @xmath10 is considered to be a set of intersections and joins of elementary geometric objects ( ego ) .    the elementary geometrical object @xmath12 is described by its skeleton @xmath30 and envelope function @xmath13 .\nthe finite set @xmath96 of parameters of the envelope function @xmath13 is the skeleton of elementary geometric object ( ego ) @xmath97 .\nthe set @xmath97 of points forming ego is called the envelope of its skeleton @xmath30 .\nthe envelope function @xmath13@xmath98determining ego is a function of the running point @xmath99 and of parameters @xmath100 .\nthe envelope function @xmath13 is supposed to be an algebraic function of @xmath101 arguments @xmath15 , @xmath102 .\neach of arguments @xmath103 is the world function @xmath0 of two points @xmath104 , either belonging to skeleton @xmath30 , or coinciding with the running point @xmath105 .\nthus , any elementary geometric object @xmath12 is determined by its skeleton @xmath30 and its envelope function @xmath13 .\nelementary geometric object @xmath12 is the set of zeros of the envelope function @xmath106__definition .\n_ _ two egos @xmath107 and @xmath108 are equivalent , if their skeletons @xmath30 and @xmath109 are equivalent and their envelope functions @xmath13 and @xmath110 are equivalent .\nequivalence ( @xmath30eqv@xmath109 ) of two skeletons @xmath111 and @xmath112 means that @xmath113equivalence of the envelope functions @xmath13 and @xmath110 means , that they have the same set of zeros .\nit means that @xmath114where @xmath115 is an arbitrary function , having the property@xmath116    evolution of ego @xmath117 in the space - time is described as a world chain @xmath118 of equivalent connected egos .\nthe point @xmath5 of the skeleton @xmath11 is considered to be the origin of the geometrical object @xmath119 the ego @xmath117 is considered to be placed at its origin @xmath5 .\nlet us consider a set of equivalent skeletons @xmath120 @xmath121which are equivalent in pairs @xmath122the skeletons @xmath123 @xmath121are connected , and they form a chain in the direction of vector @xmath4 , if the point @xmath53 of one skeleton coincides with the origin @xmath5 of the adjacent skeleton @xmath124the chain @xmath118 describes evolution of the elementary geometrical object @xmath117 in the direction of the leading vector @xmath4 . the evolution of ego @xmath117 is a temporal evolution , if the vectors @xmath125 are timelike @xmath126 @xmath127 .\nthe evolution of ego @xmath117 is a spatial evolution , if the vectors @xmath125 are spacelike @xmath128 @xmath127 .\nnote , that all adjacent links ( egos ) of the chain are equivalent in pairs , although two links of the chain may be not equivalent , if they are not adjacent .\nhowever , lengths of corresponding vectors are equal in all links of the chain @xmath129we shall refer to the vector @xmath125 , which determines the form of the evolution and the shape of the world chain , as the leading vector .\nthis vector determines the direction of 4-velocity of the physical body , associated with the link of the world chain .\nif the relations@xmath130@xmath131are satisfied , the relations@xmath132are not satisfied , in general , because the relations ( [ a6.11 ] ) contain the scalar products @xmath133 .\nthese scalar products contain the world functions @xmath134 , which are not contained in relations ( [ a6.9 ] ) , ( [ a6.10 ] ) .\nthe world chain @xmath118 , consisting of equivalent links ( [ a6.1 ] ) , ( [ a6.2 ] ) , describes a free motion of a physical body ( particle ) , associated with the skeleton @xmath30 .\nwe assume that _ the motion of physical body is free , if all points of the body move free _ ( i.e. without acceleration ) . if the external forces are absent , the physical body as a whole moves without acceleration .\nhowever , if the body rotates , one may not consider a motion of this body as a free motion , because not all points of this body move free ( without acceleration ) . in the rotating body\nthere are internal forces , which generate centripetal acceleration of some points of the body . as a result\nsome points of the body do not move free .\nmotion of the rotating body may be free only on the average , but not exactly free .\nconception of non - free motion of a particle is rather indefinite , and we restrict ourselves with consideration of a free motion only\n.    conventional conception of the motion of extensive ( non - pointlike ) particle , which is free on the average , contains a free displacement , described by the velocity 4-vector , and a spatial rotation , described by the angular velocity 3-pseudovector @xmath135 .\nthe velocity 4-vector is associated with the timelike leading vector @xmath4 . at the free on the average motion of a rotating body some of vectors @xmath136 ... of the skeleton @xmath30 are not in parallel with vectors @xmath137 , although at the free motion all vectors @xmath138 are to be in parallel with @xmath137 as follows from ( [ a6.1 ] ) .\nit means that the world chain @xmath118 of a freely moving body can describe only translation of a physical body , but not its rotation .\nif the leading vector @xmath4 is spacelike , the body , described by the skeleton @xmath30 , evolves in the spacelike direction .\nit seems , that the spacelike evolution is prohibited .\nbut it is not so .\nif the world chain forms a helix with the timelike axis , such a world chain may be considered as timelike on the average . in reality\nsuch world chains are possible . for instance , the world chain of the classical dirac particle is a helix with timelike axis .\nit is not quite clear , whether or not the links of this chain are spacelike , because internal degrees of freedom of the dirac particle , responsible for helicity of the world chain , are described nonrelativistically .\nthus , consideration of a spatial evolution is not meaningless , especially if we take into account , that the spatial evolution may imitate rotation , which is absent at the free motion of a particle .\nfurther we consider the problem of the spatial evolution .\ndirac particle @xmath139 is the dynamic system , described by the dirac equation .\nthe free dirac particle @xmath139 is described by the free dirac equation @xmath140where @xmath141 is the four - component complex wave function , and @xmath142 , @xmath143 are @xmath144 complex matrices , satisfying the relations@xmath145@xmath146 is the @xmath144 unit matrix , @xmath147 is the metric tensor .\nexpressions of physical quantities : the 4-flux @xmath148 of particles and the energy - momentum tensor @xmath149 have the form@xmath150where @xmath151 , @xmath152 is the hermitian conjugate to @xmath141 .\nthe classical dirac particle is a dynamic system @xmath153 , which is obtained from the dynamic system @xmath139 in the classical limit .    to obtain the classical limit\n, one may not set the quantum constant @xmath154 in the equation ( [ f1.2 ] ) , because in this case we do not obtain any reasonable description of the particle .\nthe dirac particle @xmath139 is a quantum particle in the sense , that it is described by a system of partial differential equations ( pde ) , which contain the quantum constant @xmath155 .\nthe classical dirac particle @xmath153 is described by a system of ordinary differential equations ( ode ) , which contain the quantum constant @xmath155 as a parameter .\nmay the system of ode carry out the classical description , if it contains the quantum constant @xmath155 ?\nthe answer depends on the viewpoint of investigator .\nif the investigator believes that _ the quantum constant is an attribute of quantum principles and only of quantum principles _ , he supposes that , containing @xmath155 , the dynamic equations can not realize a classical description , where the quantum principles are not used .\nhowever , if the investigator consider the classical description simply as method of investigation of the quantum dynamic equations , it is of no importance , whether or not the system of ode contains the quantum constant .\nit is important only , that the system of pde is approximated by a system of ode .\nthe dynamic system , described by pde , contains infinite number of the freedom degrees .\nthe dynamic system , described by ode , contains several degrees of freedom .\nit is simpler and can be investigated more effectively .    obtaining the classical approximation\n, we use the procedure of dynamic disquantization @xcite .\nthis procedure transforms the system of pde into the system of ode .\nthe procedure of dynamic disquantization is a dynamical procedure , which has no relation to the process of quantization or disquantization in the sense , that it does not refer to the quantum principles .\nthe dynamic disquantization means that all derivatives @xmath156 in dynamic equations are replaced by the projection of vector @xmath157 onto the current vector @xmath148 @xmath158this dynamical operation is called the dynamic disquantization , because , applying it to the schrdinger equation , we obtain the dynamic equations for the statistical ensemble of classical nonrelativistic particles .\nthese dynamic equations are ode , which do not depend on the quantum constant @xmath155 .    applying the operation ( [ b3.1 ] ) , to the dirac equation ( [ f1.2 ] ) ,\nwe transform it to the form@xmath159the equation ( [ b3.2 ] ) is the dynamic equation for the dynamic system system @xmath160 .\nthe equation ( [ b3.2 ] ) contains only derivative @xmath161 in the direction of the current 4-vector @xmath148 . in terms of the wave function\n@xmath141 the dynamic equation ( [ b3.2 ] ) for @xmath160 looks rather bulky . however , in the properly chosen variables the action for the dynamic system @xmath160 has the form @xcite @xmath162=\\int \\left\\ { -\\kappa _ { 0}m\\sqrt{\\dot{x}^{i}\\dot{x}_{i}}+\\hbar { \\frac{(\\dot{\\mathbf{\\xi } } \\times \\mathbf{\\xi } ) \\mathbf{z}}{2(1+\\mathbf{\\xi z})}}+\\hbar \\frac{(\\dot{\\mathbf{x}}\\times \\ddot{\\mathbf{x}})\\mathbf{\\xi } } { 2\\sqrt{\\dot{x}^{s}\\dot{x}_{s}}(\\sqrt{\\dot{x}^{s}\\dot{x}_{s}}+\\dot{x}^{0})}\\right\\ } d^{4}\\tau   \\label{a5.18}\\]]where the dot means the total derivative @xmath163 .\nthe quantities @xmath164 , @xmath165 , @xmath166 , @xmath167 are considered to be functions of the lagrangian coordinates @xmath168 , @xmath169 .\nthe variables @xmath170 describe position of the dirac particle .\nhere and in what follows the symbol @xmath171 means the vector product of two 3-vectors .\nthe quantity@xmath172 is the constant unit 3-vector , @xmath173 is a dichotomic quantity @xmath174 , @xmath175 is the constant ( mass ) taken from the dirac equation ( [ f1.2 ] ) .\nin fact , variables @xmath170 depend on @xmath176 as on parameters , because the action ( [ a5.18 ] ) does not contain derivatives with respect to @xmath177 ,  @xmath167 .\nlagrangian density of the action ( [ a5.18 ] ) does not contain independent variables @xmath178 explicitly .\nhence , it may be written in the form @xmath162=\\int \\mathcal{a}_{\\mathrm{dcl}}[x,\\mathbf{\\xi } ] d\\mathbf{\\tau , \\qquad } d\\mathbf{\\tau } = d\\tau _ { 1}d\\tau _ { 2}d\\tau _ { 3 }   \\label{b3.8}\\]]where @xmath179=\\int \\left\\ { -\\kappa _ { 0}m\\sqrt{\\dot{x}^{i}\\dot{x}_{i}}+\\hbar { \\frac{(\\dot{\\mathbf{\\xi } } \\times \\mathbf{\\xi } ) \\mathbf{z}}{2(1+\\mathbf{\\xi z})}}+\\hbar   \\frac{(\\dot{\\mathbf{x}}\\times \\ddot{\\mathbf{x}})\\mathbf{\\xi } } { 2\\sqrt{\\dot{x}^{s}\\dot{x}_{s}}(\\sqrt{\\dot{x}^{s}\\dot{x}_{s}}+\\dot{x}^{0})}\\right\\ } d\\tau _ { 0 }   \\label{b3.9}\\ ] ]    the action ( [ b3.8 ] ) is the action for the dynamic system @xmath160 , which is a set of similar independent dynamic systems @xmath153 . such a dynamic system is called a statistical ensemble . dynamic systems @xmath153 are elements ( constituents ) of the statistical ensemble @xmath160 .\ndynamic equations for each @xmath153 form a system of ordinary differential equations .\nit may be interpreted in the sense , that the dynamic system @xmath153 may be considered to be a classical one , although lagrangian of @xmath153 contains the quantum constant @xmath155 .\nthe dynamic system @xmath180 will be referred to as the classical dirac particle .    the dynamic system @xmath153 has ten degrees of freedom .\nit describes a composite particle @xcite .\nexternal degrees of freedom are described relativistically by variables @xmath170 .\ninternal degrees of freedom are described nonrelativistically @xcite by variables @xmath181 .\nsolution of dynamic equations , generated by the action ( [ b3.9 ] ) , gives the following result @xcite . in the coordinate system , where the canonical momentum four - vector @xmath182 has the form @xmath183the world line of the classical dirac particle is a helix , which is described by the relation @xmath184where the speed of the light @xmath185 , and @xmath186 is an arbitrary constant ( lorentz factor of the classical dirac particle ) .\nthe velocity @xmath187 of the classical dirac particle is expressed as follows @xmath188    helical world line of the classical dirac particle means a rotation of the particle around some point . on the one hand ,\nsuch a rotation seems to be reasonable , because it explains freely the dirac particle spin and magnetic moment . on the other hand ,\nthe description of this rotation is nonrelativistic .\nbesides , it seems rather strange , that the world line of a free classical particle is a helix , but not a straight line .\nattempt of consideration of the dirac particle as a rotator , consisting of two particles @xcite , meets the problem of confinement of the two particles .\nalthough the pure dynamical methods of investigation are more general and effective , than the investigation methods , based on quantum principles , the purely dynamical methods of investigation meet incomprehension of most investigators , who believe , that the dirac particle must be investigated by quantum methods . the papers , devoted to investigation of the dirac equation by the dynamic methods , are considered as dissident .\nthey are rejected by the peer review journals ( see discussion in @xcite ) .\nsuddenly it is discovered that the helical world line , which is characteristic for the classical dirac particle , can be obtained as a result of a spatial evolution of geometric objects in the framework of properly chosen space - time geometry .\nlet us consider the flat homogeneous isotropic space - time @xmath189 , described by the world function @xmath190@xmath191@xmath192where @xmath193 is the world function of the @xmath194-dimensional space - time of minkowski .\n@xmath195 is some elementary length .\nin such a space - time geometry two connected equivalent timelike vectors @xmath4 and @xmath196 are described as follows @xcite @xmath197where @xmath198 is an arbitrary unit 3-vector .\nthe quantity @xmath199 is the length of the vector @xmath4 ( geometrical mass , associated with the particle , which is described by the vector @xmath4 ) .\nwe see that the spatial part of the vector @xmath196 is determined to within the arbitrary 3-vector of the length @xmath200 .\nthis multivariance generates wobbling of the links of the world chain , consisting of equivalent timelike vectors @xmath201 , @xmath196 , @xmath202 , ... statistical description of the chain with wobbling links coincides with the quantum description of the particle with the mass @xmath203 , if the elementary length @xmath204 , where @xmath205 is the speed of the light , @xmath155 is the quantum constant , and @xmath206 is some universal constant , whose exact value is not determined @xcite , because the statistical description does not contain the quantity @xmath206 .\nthus , the characteristic wobbling length is of the order of @xmath195 .    to explain the quantum description of the particle motion as a statistical description of the multivariant classical motion , we should use the world function ( [ a4.1 ] )\nhowever , the form of the world function ( [ a4.1 ] ) is determined by the coincidence of the two descriptions only for the value @xmath207 , where the constant @xmath208 is determined via the mass @xmath209 of the lightest massive particle ( electron ) by means of the relation @xmath210where @xmath211 is the geometrical mass of the lightest massive particle ( electron ) .\nthe geometrical mass @xmath212 of the same particle , considered in the space - time geometry of minkowski , has the form@xmath213as far as @xmath214 , and , hence , @xmath215 , we obtain the following estimation for the universal constant @xmath206@xmath216    intensity of wobbling may be described by the multivariance vector @xmath217 , which is defined as follows .\nlet @xmath196 , @xmath218 be two vectors which are equivalent to the vector @xmath219 .\nlet @xmath220let us consider the vector @xmath221which is a difference of vectors @xmath196 , @xmath218 .\nwe consider the length @xmath222 of the vector @xmath223 in the minkowski space - time .\nwe obtain@xmath224the length of the vector ( [ a4.3a ] ) is minimal at @xmath225 . at @xmath226\nthe length of the vector ( [ a4.3a ] ) is maximal , and it is equal to zero . by definition\nthe vector @xmath223 at @xmath225 is the multivariance 4-vector @xmath217 , which describes the intensity of the multivariance .\nwe have @xmath227where @xmath198 is an arbitrary unit 3-vector .\nthe multivariance vector @xmath217 is spacelike    in the case , when @xmath228 , the corresponding wobbling length @xmath229where @xmath230 is the electron compton wave length .\nthe relation ( [ a4.3 ] ) means that @xmath231for other values @xmath232 the form of the world function @xmath233 may distinguish from the relation ( [ a4.4 ] ) .\nhowever , @xmath234 , if @xmath235 .\ntwo equivalent connected spacelike vectors @xmath1 , @xmath236 have the form @xcite@xmath237where constants @xmath238 and @xmath239 are arbitrary . the result is obtained for the space - time geometry ( [ a4.0 ] ) .\narbitrariness of constants @xmath240 generates multivariance of the vector @xmath236 even in the space - time geometry of minkowski , where @xmath241 .\nvectors @xmath236 , @xmath242 @xmath243are equivalent to the vector @xmath1 . the difference @xmath244 of two vectors @xmath236 , @xmath242 has the form@xmath245the vector @xmath244 may be spacelike and timelike\n. its length has an extremum , if @xmath246 and @xmath247 . in this case the length @xmath248    however , the length@xmath249has neither maximum , nor minimum , and one can not introduce the multivariance vector of the type ( [ a4.3c ] ) .\nthe multivariance of the spacelike vectors equality is not introduced by the distortion @xmath250 , defined by ( [ a4.0a ] ) .\nit takes place already in the space - time of minkowski . in the conventional approach to the geometry of minkowski one\ndoes not accept the multivariance of spacelike vectors equivalence .\nfurthermore , the concept of multivariance of two vectors parallelism ( and equality ) is absent at all in the conventional approach to the geometry .\nfor instance , when in the riemannian geometry the multivariance of parallelism of remote vectors appears , the mathematicians prefer to deny at all the fernparallelism ( parallelism of two remote vectors ) , but not to introduce the concept of multivariance .\nthis circumstance is connected with the fact , that the multivariance may not appear , if the geometry is constructed on the basis of a system of axioms .\nthe world chain , consisting of timelike equivalent vectors , imitates a world line of a free particle .\nthis fact seems to be rather reasonable .\nconsidering the vectors @xmath1 and @xmath236 in ( [ a6.50 ] ) from the viewpoint of the geometry of minkowski , we see that the vector @xmath236 is obtained from the vector @xmath1 as a result of spatial rotation and of an addition of some temporal component .\none should expect , that the world chain , consisting of spacelike equivalent vectors , imitates a world line of a free particle , moving with a superluminal velocity .\nthe motion with the superluminal velocity seems to be unobservable .\nsuch a motion is considered to be impossible . however , if the spacelike world line has a shape of a helix with timelike axis , such a situation may be considered as a free rotating particle .\nthe fact , that the particle rotates with the superluminal velocity is not so important , if the helix axis is timelike .\nthe world line of a classical dirac particle is a helix .\nit is not very important , whether the rotation velocity is tardyon or not .\nespecially , if we take into account that the dirac equation describes the internal degrees of freedom ( rotation ) nonrelativistically , ( i.e. the description of internal degrees of the classical dirac particle is incorrect from the viewpoint of the relativity theory ) .\nwe investigate now , whether a world chain of equivalent spacelike vectors may form a helix with timelike axis .\nif it is possible , then we try to investigate , under which world function such a situation is possible .\nwe consider the world function @xmath233 of the form @xmath251where the function @xmath252 should be determined from the condition , that the world chain , consisting of spacelike links , forms a helix with timelike axis .\nto estimate the form of @xmath233 as a function of @xmath193 at @xmath232 , we consider the chain , consisting of equivalent spacelike vectors ... @xmath4 , @xmath196 , @xmath253 ... we suppose that the chain is a helix with timelike axis in the space - time .\nlet the points @xmath254 . have the coordinates@xmath255all points ( [ a4.6 ] ) lie on a helix with timelike axis .\nin the space - time of minkowski the step of helix is equal to @xmath256 , and @xmath105 is the radius of the helix .\nthe constants @xmath257 and @xmath258 are parameters of the helix .\nall vectors @xmath259 have the same length .\nintroducing designations [ 02beg]@xmath260we obtain coordinates of vectors @xmath259 in the form @xmath261where @xmath262 are parameters of the helix .\nlet us investigate , under which conditions the relation @xmath263eqv@xmath259 takes place .\nwe suppose that all vectors of the helix are spacelike @xmath264 .\nit is evident , that it is sufficient to investigate the situation for the case @xmath265 , when @xmath4eqv@xmath196 .\nlet coordinates of vectors @xmath4 , @xmath196 be @xmath266 in this case the coordinates of the points @xmath267 may be chosen in the form@xmath268and the vector @xmath219 has coordinates @xmath269we choose the world function ( [ a4.5 ] ) in the form@xmath270and introduce the quantity @xmath271    thus , we have @xmath272the space - time geometry ( [ a4.15 ] ) is a special case of the space - time geometry ( [ a4.4 ] ) .\nwe do not pretend to the claim , that ( [ a4.15 ] ) is the world function of true space - time geometry .\nwe shall show only that in the space - time geometry ( [ a4.15 ] ) the spacelike vectors ( [ a4.9 ] ) may be equivalent at some proper choice of parameters @xmath273 , @xmath274 and @xmath257 .    in our calculations we shall use two geometries : the geometry @xmath275 of minkowski and the space - time geometry @xmath276 , described by the world function @xmath233 , determined by ( [ a4.15 ] ) .\nthen expressions of the geometry @xmath276 may be reduced to expressions of the geometry @xmath275 by means of relations@xmath277@xmath278@xmath279the geometrical relations in @xmath276 are expressed via the same relations , written in @xmath275 with additional terms , containing the distortion @xmath250 .\nthis additional terms in dynamic relations are interpreted as additional metric interactions , acting on a particle , when the real space - time geometry @xmath276 is considered to be the geometry @xmath275 .\nappearance of additional interactions reminds appearance of inertial forces at a use of accelerated coordinate systems instead of inertial ones .\ncondition @xmath4eqv@xmath196 of equivalence of vectors @xmath4 , @xmath196 is written in the form of two equations@xmath280@xmath281where index m means , that the corresponding quantities are calculated in @xmath275 .\nthe function @xmath250 is determined by the relation ( [ a4.15 ] ) , and the quantity @xmath282 is determined by the relation @xmath283which follows from the definition of the scalar product ( [ a4.15c ] ) . using the conventional relations for the scalar product in @xmath275 , we can rewrite the relations ( [ a4.16 ] ) , ( [ a4.17 ] ) in the form @xmath284@xmath285where@xmath286    to obtain the relation ( [ a4.21 ] ) from ( [ a4.18 ] ) , we use the relations@xmath287@xmath288the equation ( [ a4.20 ] ) is the identity .\nlet us introduce pure quantities\n@xmath289 , @xmath290 , defining them by relations@xmath291@xmath292then the equation ( [ a4.19 ] ) takes the form@xmath293where the function @xmath294 is defined by the relation ( [ a4.15])@xmath295and the constant @xmath296 is defined by the relation ( [ a4.14a ] ) .\nlet us note , that in the case , when @xmath297 is a linear function @xmath298 , for @xmath299 $ ] , the equation ( [ a4.25a ] ) has the unique solution @xmath300 .\nthe solution with @xmath301 describes a straight but not a helix .\nconsidering solutions of equation ( [ a4.25a ] ) with respect to @xmath302 , we are interested in positive values of @xmath290 , because the quantity @xmath290 is nonnegative by definition ( [ a4.25 ] ) . at @xmath303 numerical solutions of equation ( [ a4.25a ] ) with respect to @xmath290\nare presented in the form@xmath304    according to ( [ a4.7 ] ) , ( [ a4.24 ] ) and ( [ a4.25 ] ) we have the following relations for the helix radius @xmath105 @xmath305we obtain the helix step @xmath306 in the form@xmath307    negative values of @xmath289 correspond to helix with timelike vectors @xmath263 .\npositive solutions of equation ( [ a4.25a ] ) take place only for @xmath308 ( spacelike vectors ) and @xmath309 ( timelike vectors ) .\nthe values of parameter @xmath310 belong to intervals    @xmath311 , \\qquad a\\in \\left ( 0,3\\right )   \\label{a4.38}\\ ] ]    for spacelike and timelike vectors correspondingly .\nthus , we see that in the space - time geometry with the world function ( a4.15 ) the spatial evolution , determined by the spacelike vectors @xmath259 , may lead to a helical world chain with timelike axis .\nhowever , equivalence of spacelike vectors @xmath259 is multivariant even in the space - time of minkowski .\nit is valid for the space - time geometry ( [ a4.15 ] ) also . as a result\nthe wobbling of the spacelike vectors appears .\nit may lead to destruction of the helix .    in reality the conditions @xmath312 determines vector @xmath313to within the vector @xmath314 , and we have instead of equations ( [ a4.9 ] ) @xmath315where @xmath316 , @xmath317 , @xmath318 are 4-vectors with coordinates@xmath319    instead of equations ( [ a4.19 ] )  ( [ a4.21 ] ) we have the following equations@xmath320@xmath321where @xmath322 and @xmath323 mean scalar products of vectors @xmath324 in the space - time of minkowski . the relation ( [ a4.25a ] ) is the necessary condition of the fact , that @xmath325 is a solution of equations ( [ a4.41 ] ) , ( [ a4.42 ] ) .\nwe obtain from ( [ a4.41 ] ) @xmath326where @xmath327 means the scalar product of 3-vectors @xmath328 and @xmath329 .\ntaking into account the relation ( [ a4.25a ] ) , we obtain from relation ( [ a4.42 ] ) @xmath330supposing , that @xmath322 is a small quantity we obtain from ( [ a4.44 ] ) by means of ( [ a4.43])@xmath331    the relation ( [ a4.45 ] ) may be transformed to the equation@xmath332where@xmath333as far as @xmath334 , we obtain , that @xmath335 , and the surface ( [ a4.46 ] ) is a hyperboloid in the 3-space of quantities @xmath336 .\nit means that solutions of the equations ( [ a4.43 ] ) , ( [ a4.44 ] ) may deflect arbitrarily far from the helix solution ( [ a4.9 ] ) .\nthis deflection is a manifestation of the multivariance of the space - time geometry .\nsuppression of multivariance and stabilization of the world chain , consisting of spacelike vectors , can be achieved , if we consider the world chain with composed links , whose skeleton consists of three points @xmath337 , @xmath338 ( see figure 1 ) .\nlet @xmath259 be a spacelike vector , whereas the vector @xmath339 be a timelike vector in @xmath275 . to investigate the effect of stabilization , it is sufficient to consider the points @xmath340 , having coordinates@xmath341the following vectors\nare associated with these points of the skeletons@xmath342where the quantities @xmath343 are the given 4-vectors , whereas the quantities @xmath344 are 4-vectors , which are to be determined from the condition @xmath345    expressions for 4-vectors @xmath317 and @xmath54 are chosen in such a way , that vectors @xmath196 and @xmath346 ( at @xmath347 ) were a result of rotation of vectors @xmath4 and @xmath348 in the plane @xmath349 by the angle @xmath350 .\nthe quantities @xmath351are supposed to be given . the 4-vectors @xmath352are to be determined from the relations ( [ a5.3a ] ) .    the 4-vectors @xmath316 and @xmath317 coincide with vectors ( [ a4.9 ] ) .\nwe are interested in the following question , whether the stabilizing vector @xmath353 can be chosen in such a way , that equations ( [ a5.3a ] ) have the unique solution @xmath347 .\nif such a stabilizing vector @xmath354exists , the world chain will have a shape of a helix without wobbling .\nit may be , that the complete stabilization is impossible .\nthen , maybe , a partial stabilization is possible , when the quantities @xmath318 , @xmath355 are small , although they do not vanish . in any case\nthe problem of the stabilizing vector existence is a pure mathematical problem .    solving this problem\n, we shall use relations ( [ a4.15a ] ) , ( [ a4.15b ] ) to reduce all geometrical relations to the geometrical relations in the space - time of minkowski .\nworking in the space - time of minkowski , we shall use the conventional covariant formalism , where the expressions of the type @xmath356 and @xmath357 mean@xmath358index \" will be omitted for brevity .\nit follows from the condition @xmath4eqv@xmath196@xmath359where@xmath360after transformations we obtain@xmath361@xmath362these equations coincide with ( [ a4.41 ] ) , ( [ a4.42 ] ) . if @xmath363 the equations ( [ b5.11 ] ) , ( [ b5.12 ] ) coincide with ( [ a4.20 ] ) , ( a4.25a ) respectively .\nwe obtain from the condition @xmath348eqv@xmath346@xmath364@xmath365where@xmath366    the equations ( [ b5.14 ] ) and ( [ b5.15 ] ) are transformed to the form@xmath367@xmath368@xmath369    let us suppose that the stabilizing vector @xmath101 is long in the sense that @xmath370then in ( [ b5.17 ] ) the functions @xmath250 , which contains @xmath101 in its argument will be equal to @xmath371 and all terms , containing @xmath101 compensate each other .\nthe necessary condition of the fact , that @xmath372 is a solution of equations ( [ b5.16 ] ) , ( [ b5.17 ] ) , has the form@xmath373@xmath374the equation ( [ b5.18 ] ) is satisfied identically by the choice ( b5.4a ) , ( [ b5.4b ] ) of vectors @xmath101 and @xmath54 .\nwe obtain from the condition @xmath375eqv@xmath376@xmath377@xmath378@xmath379@xmath380    the necessary conditions of the fact , that @xmath381 is a solution of equations ( [ b5.23 ] ) , ( [ b5.24 ] ) , have the form@xmath382@xmath383    the equation ( [ b5.27 ] ) is satisfied identically by the relations ( b5.4a ) , ( [ b5.4b ] ) .\nthe difference of equations ( [ b5.19 ] ) and ( b5.28 ) leads to the equation    @xmath384    let us substitute expressions for @xmath385 , determined by the relations ( [ b5.4a ] ) , ( [ b5.4b ] ) , in ( [ b5.29 ] ) .\nafter transformations we obtain the connection between the quantities @xmath386 and @xmath387 in the form@xmath388    the equation ( [ b5.19 ] ) by means of ( [ b5.30 ] ) is reduced to the form@xmath389where according to ( [ a4.15 ] ) the function @xmath390 is substituted by @xmath391 .    setting @xmath392and using designations ( [ a4.24 ] ) , ( [ a4.25 ] ) , we transform the equation ( [ b5.31 ] ) to the form @xmath393    the equations ( [ a4.25a ] ) and ( [ b5.33 ] ) form a system of two necessary conditions , imposed on parmeters of the helical world chain .\neach link of the chain consists of two vectors : leading vector @xmath394 and stabilizing vector @xmath395 .\nparameter @xmath396 is determined by the space - time geometry .\nthe quantity @xmath397 describes the length of the spacelike leading vector @xmath394 .\nparameter @xmath398 describes the length of the projection of the leading vector @xmath394 on the plane of rotation .\nfinally , @xmath399 describes the angle @xmath350 of rotation of the leading vector in the plane of rotation .\nnumerical solutions of equations ( [ a4.25a ] ) and ( [ b5.33 ] ) are presented for the parameter @xmath303\nsolutions of equations , which describe the necessary conditions of the fact , that the world chain may be a helix , are not unique\n. there may be solutions of ( [ a5.3a ] ) , described by nonvanishing @xmath318 and @xmath355 , which generate wobbling and violate the helical character of world chain .\nwe write six equation ( [ a5.3a ] ) as equation for @xmath401 with parameters @xmath343 , satisfying the necessary conditions ( [ a4.25a ] ) and ( b5.33 ) .\nwe obtain instead of equations ( [ b5.11 ] ) , ( [ b5.12 ] ) the following two equations@xmath402@xmath403where the quantities @xmath404 satisfy the necessary conditions ( [ b5.33 ] ) ( [ a4.25a ] ) , and @xmath405 is a derivative of the function ( [ a4.26 ] ) , which is always nonnegative\n. then it follows from ( [ b6.2 ] ) @xmath406    equations ( [ b6.1 ] ) , ( [ b6.3 ] ) contain only the variable @xmath318 ( but not @xmath355 ) and coincide with the equations ( [ a4.41 ] ) , ( a4.42 ) . however , there are additional constraints , containing @xmath318 . as a result the constraints on @xmath318 distinguish from the relation ( a4.46 ) , describing values of @xmath318 without the stabilizing vector @xmath395 .    in the developed\nform the relations ( [ b5.16 ] ) , ( [ b5.17 ] ) have the form @xmath407@xmath408they contain only the variable @xmath355 ( but not @xmath318 )    finally the relations ( [ b5.23 ] ) , ( [ b5.24 ] ) in the developed form can be written as follows@xmath409@xmath410the relation ( [ b6.7 ] ) is a linear combination of equations ( [ b5.17 ] ) and ( [ b5.24 ] ) , which does not contain the function @xmath294 . relations ( b6.6 ) and ( [ b6.7 ] ) contain both quantities @xmath401 and @xmath411 . the constraints ( [ b6.6 ] ) and ( [ b6.7 ] )\nmodify the constraints ( [ a4.46 ] ) , transforming the hyperboloid into ellipsoid .\nwe suppose for simplicity , that the vector @xmath395 is very long ( @xmath412 ) .\nwe suppose , that @xmath413 . in this case\nwe obtain from the relation ( [ b6.5 ] ) , that @xmath414 .\nit follows from ( [ b6.7 ] ) , that @xmath415 .\nbesides , it follows from ( [ b6.3 ] ) , that @xmath416 .\nthus , solutions of the equations ( [ b6.5 ] ) , ( [ b6.7 ] ) and ( [ b6.3 ] ) have the form @xmath417    at the constraints ( [ b6.8 ] ) three other equations ( [ b6.1 ] ) , ( b6.4 ) and ( [ b6.6 ] ) take the form @xmath418@xmath419@xmath420solution of equation ( [ b6.9 ] ) has the form @xmath421where @xmath422 is an arbitrary angle .\nsolution of equation ( [ b6.10 ] ) has the form@xmath423where the quantities @xmath424 @xmath425 are arbitrary . and the quantity @xmath426 is determined by the relation ( [ b5.30 ] ) .    substituting ( [ b6.12 ] ) - ( [ b6.14c ] ) in ( [ b6.11 ] ) , one obtains a constraint on the quantities @xmath427 @xmath424 @xmath425 .\nindependently of this constraint the 3-vector @xmath428has the same 3-length @xmath274 , as the length of 3-vector @xmath429 .\nthe angle between the 3-vectors @xmath430 and @xmath431is equal to @xmath350 . if @xmath432 , then @xmath325 , and vectors @xmath394 and @xmath433 are elements of the same helix .    we see that the stabilizing vector @xmath395 reduces wobbling of vector @xmath394 . in the case of equation ( [ a4.46 ] )\nthe spatial component @xmath329 of the 4-vector @xmath318 may be infinite . in the case of the equation ( [ b6.9 ] )\nthe length @xmath434 of the spatial component @xmath329 of the 4-vector @xmath318 is less , than @xmath435 thus , the stabilizing vector @xmath395 reduces the wobbling of the world chain .\none can not be sure , that this wobbling does not destroy the helical character of the world chain .\nhowever , the main question is , whether or not the evolution of the world chain in the spacelike direction lead to the world chain , which is timelike on the average .\nany next point @xmath436 of the world chain jumps along the timelike direction at the distance @xmath273 and in the 3-space , which is orthogonal to this direction , the point jumps at the distance @xmath437 .\ndirection of the jump in the 3-space is described by the vector @xmath430 , which is given by the relation ( [ c5.17 ] ) .\nthe length of @xmath430 is @xmath274 . if the direction of jump is completely random , the displacement @xmath438 for @xmath37 steps ( @xmath439 is proportional to @xmath440 , whereas displacement in the temporal direction is @xmath441 .\nit means that the mean velocity @xmath442tends to zero for @xmath443 , although @xmath444 . in the case , if @xmath363 and the 3-vector @xmath430 * *  * * determined by ( [ c5.17 ] ) is not random , the world chain form a helix with timelike axis . in this case\nthe mean velocity tends to zero also .\nit should expect that in the case , when the vector ( [ c5.17 ] ) is stochastic , but its stochasticity is restricted by the relation ( [ c5.17 ] ) ( the angle @xmath422 is completely random ) , the mean world chain will be also timelike on the average .\nwe can not prove this fact strictly now , but this result seems to be very probable .\nthe obtained classical helical world chain ( [ a4.6 ] ) associates with the classical dirac particle , which has alike world line ( [ e6.33 ] ) , ( e6.34 ) .\nthe direction of the mean momentum distinguishes from the direction of the 4-velocity .\nthis fact is characteristic for both particles ( the dirac particle , and the particle , described by the world chain ( a4.6 ) ) .\nboth particles have angular moment . for the dirac particle the mass @xmath175 , which enters in the dirac equation , distinguishes from the mass @xmath445 of the particle moving along the world line ( [ e6.33 ] ) , ( [ e6.34 ] ) @xcite . as to the mass of the particle , described by the world chain ( [ a4.6 ] ) , it is not yet determined . for determination of the mass , one needs to consider the world chain ( [ a4.6 ] ) of charged particle with the skeleton @xmath446 in the distorted space - time of klein - kaluza , containing electromagnetic field .\nexistence of helical world chain with timelike axis seems to be rather unexpected , because leading vectors @xmath259 of the chain are spacelike , and it corresponds to superluminal motion of a particle .\nsuperluminal motion seems to be incompatible with the relativity principle , which admits only motion with the speed less , than the speed of the light .\nhowever , this constraint is valid only for continuous space - time geometry , which admits unlimited divisibility . in a discrete geometry\nthere are no distances less , than some elementary length , and it is difficult to formulate the relativity principle statement on impossibility of superluminal motion .\none needs another more adequate formulation of the relativity principle .    is the space - time geometry ( [ a4.14 ] ) discrete ? at @xmath447 the space - time geometry ( [ a4.14 ] ) turns to the space - time geometry@xmath448which is certainly discrete , because in the space - time there no timelike intervals @xmath57 , which are less , than @xmath195 , and there are no spacelike intervals @xmath449 , which are less , than @xmath195 . in such a space - time geometry\nthere are no particles , whose geometrical mass @xmath199 is less than @xmath195 .\nhowever , if @xmath214 , is the space - time geometry discrete ? to answer this question , we introduce the parameter of discreteness : the relative density of points in the space - time with respect to the point density in the space - time of minkowski .\nlet us define the quantity @xmath450 by means of the relation @xmath451 in the case ( [ a4.14 ] ) we have for @xmath452 $ ] @xmath453resolving ( [ a7.3 ] ) with respect to @xmath193 , we obtain @xmath454where@xmath455    taking into account ( [ a7.4 ] ) we obtain the world function @xmath193 as a function of @xmath233@xmath456the relative density of points in the space - time geometry @xmath276 with respect to the standard geometry @xmath275 of minkowski is given by the relation ( [ a7.2 ] ) .\nthe expression for @xmath457 is given by the relation@xmath458where @xmath459 is given by the relation @xmath460if @xmath461 and @xmath462 , we have approximately@xmath463 in the limit @xmath461 , when the world function ( [ a4.14 ] ) turns into the world function ( [ a7.1 ] ) of the completely discrete geometry , we obtain for the relative density@xmath464    thus , @xmath465 for @xmath466 , and this fact correspond to the space - time geometry ( [ a7.1 ] ) , where close points , for which @xmath467 , are absent . the relative density @xmath450 of points may serve as quantity , describing the discreteness of the space - time geometry and the character of this discreteness .\nthe discreteness may be complete , when the density @xmath468vanishes in some region as in the case ( [ a7.10 ] ) .\nbut the discreteness may be incomplete , as in the case ( [ a7.7 ] ) . in this case for @xmath469\nwe have @xmath470{g_{1}\\left ( \\sigma _ { \\mathrm{d}}\\right ) } + \\frac{1}{3}\\frac{1}{\\sqrt[3]{g_{1}\\left ( \\sigma _ { \\mathrm{d}}\\right ) } } \\right ) , \\qquad \\sigma _ { \\mathrm{d}}\\in \\left ( -2\\lambda _ { 0}^{2},2\\lambda _ { 0}^{2}\\right )   \\label{a7.11}\\]]where@xmath471the expression ( [ a7.11 ] ) is a symmetric function of @xmath472 , as one can see from ( [ a7.3 ] ) .\nit is symmetric , indeed , although it does not look formally as a symmetric function of @xmath233 .\nnumerical values of @xmath473 @xmath474 are presented in the table @xmath475the relative density @xmath450 is less , than unity .\nit may be interpreted in the sense , that the space - time geometry is discrete only partly .\nnevertheless the incompletely discrete space - time geometry discriminates most of world chains with spatial leading vector , remaining only some of them .\nmultivariance of particle motion and discrimination of some states of motion play the crucial role in structure of elementary particles , as well as in the structure of atoms .\nlet us explain this circumstance in the example of the hydrogen atom . according to laws of the classical mechanics the electron of the hydrogen atom is to fall onto the nucleus due to the coulomb attraction .\ntwo reasons prevent from this falling : ( 1 ) multivariant ( stochastic ) motion of the electron , and ( 1 ) rotation of electron around the nucleus .    the multivariant motion of the electron leads to escape of the electron from the nuclear surface .\nthis process has the same nature , as an escape of dust from the earth surface . moving multivariantly ( as brownian particles ) , the flecks of dust form a stationary distribution in the gravitational field of the earth .\nif multivariance of their motion is cut out , the flecks of the dust fall onto the surface of the earth .\nstatistical description of the electron distribution and the dust distribution are different , because the multivariant electron motion is conceptually relativistic , whereas the brownian particles motion is nonrelativistic .\none may describe brownian particles by means of probabilistic statistical description , whereas one may use only dynamical conception of statistical description for statistical description of multivariant motion of relativistic particles .\nrotation of the electron around the nucleus creates the field of centrifugal force , which is added to the coulomb force . as a result\nadditional distributions of the electrons appear .\nif the obtained distribution of electrons is nonstationary , the electrons emanate the electromagnetic radiation until the electron distribution becomes to be stationary .\nthus , the electromagnetic radiation carries out discrimination of nonstationary states ( electron distributions ) .\nthe multivariance of the electron motion and mechanism of discrimination of non - stationary states generates the structure of the hydrogen atom and discrete character of the radiation spectra . from the mathematical viewpoint\nthe discrete character of the electron states is conditioned by procedure of the eigenstates determination .\nonly eigenstates of the hamilton operator appear to be stationary and stable .\nthe multivariance of the particle motion and some mechanism of discrimination play also the crucial role in the understanding of the structure of elementary particles .\nhowever , in the case of the elementary particle structure the discrimination mechanism is conditioned by some metric ( geometric ) forces , which appear , when we use space - time geometry of minkowski instead of the real multivariant space - time geometry .\nformally these forces have the form of additional terms of the type ( [ a4.18 ] ) in dynamic equations .\nthese additional terms are expressed via the space - time distortion @xmath250 .\nthey describe both multivariance of motion and the discrimination mechanism .\nthe multivariance of motion is associated with the multivariance of the vector equivalence definition ( [ a1.3 ] ) , whereas the discrimination mechanism is associated with the zero - variance of the same definition ( [ a1.3 ] ) for some vectors .\nbesides , as we have seen , the zero - variance ( discrimination ) is associated with the discreteness ( or partial discreteness ) of the space - time geometry .\nit is very important , that consideration of multivariant space - time geometry _ is not a hypothesis _ , which needs an experimental test .\nconsideration of the multivariant space - time geometry is a corollary of correction of our imperfect conception of geometry .\nconception of geometry , based on supposition that any space - time geometry may be axiomatized ( i.e. may be concluded from some system of axioms ) , is imperfect , because it does not admit one to construct multivariant geometry conceptually .\nhowever , the motion of electrons and other elementary particles is multivariant .\nmultivariance of this motion is an experimental fact , which can not be ignored .\nas far as the imperfect conception of geometry did not admit one to construct multivariant space - time geometry , investigators were forced to ascribe multivariance to dynamics , introducing quantum principles with all their attributes .\nthe quantum principles look enigmatic and artificial , because multivariance is ascribed to dynamics , whereas it should be ascribed to the space - time geometry .\nmultivariance and zero - variance as properties of the space - time geometry look as quite natural properties of the definition ( [ a1.3 ] ) .\nindeed , it does not follow from anywhere , that equations ( [ a1.3 ] ) are to have unique solution for arbitrary world function , which determines the form of these equations\n. absence of any hypotheses is a very important property of the geometrical approach to the structure of elementary particles . besides\n, the geometrical dynamics is very general and simple .\ndynamic equations of the geometric dynamics do not use even differential equations .\nformulation of dynamic equations does not contain a reference to the coordinate system . on the other hand , when the geometric dynamics in the real space - time is described in terms of the space - time of minkowski , one obtains additional metric forces , which look rather exotic .\nthey can be obtained hardly in the framework of the conventional approach .\nthe conventional approach to the theory of elementary particles contains a lot of secondary concepts and properties .\none may not see any discrimination mechanism in wave functions , field equations , branes , symmetries and other remote corollaries of the unknown structure of elementary particles .\nbut it is impossible to obtain and to understand the discrete properties of elementary particles without a reliable mechanism of discrimination .\neven if investigating and systematizing these remote corollaries , one succeeds to obtain a perfect systematization of elementary particles , one can obtain structure of elementary particles from the perfect systematization with the same success , as one can obtain the atomic structure from the periodical system of chemical elements .\nconsideration of t - geometry as a space - time geometry admits one to obtain dynamics of a particle as corollary of its geometrical structure .\nevolution of the geometrical object in the space - time is determined by the skeleton @xmath476 of the geometrical object and by fixing of the leading vector @xmath4 .\nthe skeleton and the leading vector determine the world chain , which describes the evolution completely .\nthe world chain may wobble , it is manifestation of the space - time geometry multivariance .\nquantum effects are only one of manifestation of the multivariance .\nit is remarkable , that for determination of the world chain one does not need differential equations , which may be used only on the space - time manifold .\none does not need space - time continuity ( continual geometry ) .\nof course , one may introduce the continual coordinate system and write dynamic differential equation there .\none may , but it is not necessary . in general , the geometrical dynamics ( i.e. dynamics generated by the space - time geometry ) is a discrete dynamics , where step of evolution is determined by the length of the leading vector .\nit is possible , that one will need a development of special mathematical technique for the geometrical dynamics .\nthe real space - time geometry contains the quantum constant @xmath155 as a parameter . as a result\nthe geometric dynamics explains freely quantum effects , but not only them .\nthe particle mass is geometrized ( the particle mass is simply a length of some vector ) . as a result\nthe problem of mass of elementary particles is simply a geometrical problem .\nit is a problem of the structure of elementary geometrical object and its evolution .\none needs simply to investigate different forms of skeletons of simplest geometrical objects .\nin general , not all skeletons are possible , because at the spatial evolution the world chain is observable ( helical ) only for several skeletons .\nadditional points of skeleton lead to additional ( sometimes unexpected ) properties of corresponding elementary geometrical objects ( elementary particles ) .\nnote that the geometric dynamics does not contain a rotational motion .\nit contains only a shift .\nall vectors of the skeleton @xmath477 of the link @xmath478 are equivalent to vectors of the skeleton @xmath479 of the adjacent link @xmath480 .\nsuch a situation is quite reasonable , because the geometrical dynamics describes evolution of free particles . the rotating particle can not be completely free , because in the rotating particle there is centripetal acceleration .\nhowever , acceleration of all parts of the body has to be absent for completely free motion . on the other hand ,\nthe geometric dynamics contains the spatial evolution , which absent in the conventional dynamics . from the geometrical viewpoint\nwe may not discriminate spatial evolution on the basis , that the leading vector @xmath4 is spacelike and its length is imaginary .\nin fact the spatial evolution discriminates itself , by the fact , that the corresponding world chain is unobservable , in general .\nit appears to be observable only for some complex skeletons , consisting of more , than two points .\nthe world chain , describing the spatial evolution is observable only in the case , when it may be localized near the world chain of the observer .\nit takes place , when the world chain has a shape of a helix with timelike axis , or some other shape , which may be localized near the world chain of the observer . as a result\nnot all skeletons appear to be observable .\nalthough the geometric dynamics does not contain a rotation , but the corollaries of the rotation ( angular momentum , magnetic momentum ) may be obtained as a result of the spatial evolution , when the world chain is a helix .\napparently , the fact , that such a `` particle rotation '' is a corollary of the spatial evolution , leads to the spin discreteness of the dirac particle .\nof course , such statements are to be tested by exact mathematical investigations of different types of skeletons and of different space - time geometries .\nhowever , such a statement of the problem is quite concrete and realizable .\nnote , that the geometric dynamics in the real ( non - minkowskian ) space - time contains additional terms with respect to dynamics in the space - time of minkowski . from viewpoint of the space - time of minkowski\nthese additional terms may be interpreted as some ( metric ) interactions , which take place inside the elementary particles . from the conventional viewpoint\nthese interactions look very exotic and strange .\nit is impossible ( or very difficult ) to guess at them , starting from conventional conception of the space - time and dynamics . in the geometric dynamics\nthere are no additional interactions , if we use the true space - time geometry . however , additional interactions appear , if we use inadequate geometry ( for instance , geometry of minkowski , or riemannian geometry ) . in other words , it is possible to compensate false space - time geometry by introduction of additional interactions .\nit is well known from the general relativity , that the motion of free body in the curved space - time looks as a motion in the gravitational field , if one interprets this motion as a motion in the space - time of minkowski .\ndescription of conceptually new unknown phenomena by means of a change of the space - time geometry is simpler , than an introduction of additional interactions , because the space - time geometry is described by the world function , which is a function of two points .\nthe form of the world function for large distances is determined by the necessity of obtaining the nonrelativistic quantum mechanics .\nrestrictions , imposed on the world function at small distances , are determined by the condition , that the spatial evolution may describe the dirac particle .\n( very many elementary particles are the dirac particles ) .\nbesides , the condition of localization of the world chain ( helical world chain ) imposes restrictions on parameters of the particle .\nnot all parameters of particles appear to be possible .\nthis condition is a condition of `` peculiar quantization '' of the particle parameters , which include the particle mass .\nlet us note that the contemporary theory of elementary particles returns to geometrical considerations ( strings , branes ) .\nhowever , these considerations are restricted by the framework of the riemannian geometries and geometries close to the riemannian geometry .\nfor instance , the quantum geometry , which uses operators instead of the point coordinates . this is some way of introduction of multivariance in the geometry .\nhowever , this geometry is developed on the basis of the linear vector space , which is a restriction on the space - time geometry . in any case\nthe conventional approach to the space - time geometry considers only a part of all possible space - time geometries .\none can not be sure , that the class of considered geometries contains true space - time geometry .\nof course , if one uses a false space - time geometry , there is a possibility to correct the false space - time geometry by means of additional interaction , generated by difference with the true space - time geometry .\nbut such a correction is difficult , especially if the true geometry is discrete or close to the discrete geometry .\nnote , that the geometry ( [ a4.0 ] ) is discrete , although it is given on the continuous manifold of minkowski .\nit is discrete , because the module of distance between any two points is more , than @xmath195 .\nit is very unexpected , because it is a common practice to consider any geometry on the manifold as a continuous geometry , although in reality the geometry is determined by the world function and only by the world function .\na discrete geometry is associated with a grid .\nof course , a geometry , given on a grid , can not be continuous .\nhowever , a geometry , given on the continuous set of points ( manifold ) , may be discrete .    why the microcosm physics of the twentieth century did leave the successful program of the physics geometrization and choose the alternative program of quantum theory ?\ndiscovery of the electron diffraction need of multivariance of the microcosm physics .\nmultivariance may be taken into account either on the level of the space - time geometry , or on the level of dynamics .\nthe multivariant space - time geometry was not known in the thirtieth , when the electron diffraction was discovered .\nthe nonrelativistic quantum mechanics had been constructed already , and it was applied successfully for explanation of the electron diffraction .    the space - time geometry is a basis of dynamics . introducing multivariance in dynamics , one can describe not only nonrelativistic phenomena of microcosm .\none can describe also relativistic phenomena and that part of the microcosm physics , which is known as the theory of elementary particles .\nthe principles of quantum mechanics , which introduce multivariance in the microcosm physics , were invented for the newtonian conception of the space - time , and their extrapolation to the relativistic phenomena appeared to be problematic .\nof course , some properties of the true space - time geometry may be taken into account by introduction of additional interactions .\nhowever , it is very difficult to invent and introduce additional interactions without understanding of these innovations .\ncapacities of the geometrical approach are very large , especially if one takes into account all possible space - time geometries .\nthe theory of elementary particles returns to the geometrical description , but this description is burthened by such concepts as wave function , string , brane , which have very abstracted relation to the structure of elementary particles and microcosm physics .\na. rylov , tubular geometry construction as a reason for new revision of the space - time conception . in _\nwhat is geometry ?\n_ polimetrica publisher , italy , pp.201 - 235 http://www.polimetrica.com/polimetrica/406/              yu .\na. rylov , author s comments to referee s reports on the paper by y. a. rylov `` dynamical methods of investigation in application to the dirac particle '' , submitted to a scientific journal .\n( available at _ http://rsfq1.physics.sunysb . edu / rylov /comm1e . pdf _ )"}
{"lay_summary": " specially - designed microlensing searches , some of which have been underway for several years , are sensitive to extrasolar planets orbiting the most common stars in our galaxy . \n microlensing is particularly well - suited to the detection of jupiter - mass planets orbiting their parent stars at several au . since jovian analogs are thought to influence the subsequent evolution of most planetary systems , they are particularly important to study . the orbital radii and distances to the planetary systems probed by microlensing are larger than those currently studied by radial velocity techniques ; the two methods are thus complementary . \n recent results from microlensing searches are discussed , including constraints on jovian analogs orbiting typical galactic stars . \n benefits and drawbacks of the technique for the characterization of planetary systems , and future prospects are briefly reviewed .    \n # 1_#1 _ # 1_#1 _ =    # 1 1.25 in .125 in .25 in ", "article": "the first detection of an extrasolar planet around a normal star ( mayor & queloz 1995 ) and subsequent deluge of similar discoveries by the radial velocity technique ( marcy , cochran & mayor 2000 ) , have taught us that @xmath05% of solar type stars harbor planetary systems very _ unlike _ our own .\nwhat remains to be determined is the abundance of planetary systems _ similar _ to that of the sun s ( eg . , terrestrial planets at @xmath00.5 - 2  au or jovian analogs at @xmath03 - 12  au ) and the frequency of planets around the most common stars in our galaxy , m dwarfs .\nmicrolensing is providing the first partial answers to these questions .\nmicrolensing occurs whenever a massive compact object ( such as a star , black hole , etc . )\npasses very near the line - of - sight to a background luminous source . in the case of a single point lens , two images of the source\nare formed with a separation that scales with the angular radius of the einstein ring , @xmath1^{-1/2}$ ] , where @xmath2 , and @xmath3 , @xmath4 , and @xmath5 are the mass of the lens , its distance , and the distance to the source , respectively . for sources in the galactic bulge ,\nthis separation is @xmath01  mas , and thus generally too close to be resolved .\nthe combined image brightness , however , can be observed and is a function of the changing projected distance between the lens and the observer - source line - of - sight . as the source moves through the axisymmetric magnification pattern generated by a single lens , a symmetric light curve results .\nthis symmetry is destroyed for multiple lenses such as binary star systems or planetary systems .\nmore complicated magnification patterns are formed , and the resulting light curve depends on the angle @xmath6 of the source trajectory . for binary lenses , the topology of the magnification map ( fig .\n1 ) depends on only two parameters : the mass ratio @xmath7 of the lenses and their projected separation @xmath8 in units of the einstein ring radius . for typical galactic lenses , m dwarfs in the bulge or inner disk ,\nthe physical size of the einstein radius is @xmath9  au . because typical @xmath10 are comparable to the orbital radius of many solar system planets , microlensing is an excellent way to search for planets , as first suggested by mao & paczynki ( 1991 ) and further developed by gould & loeb ( 1992 ) .\n0.0cm=12.5 cm -4.25 cm    -0.5 cm    figure  1 shows the differential magnification effect of binary lenses as a function of their mass ratio @xmath11 and separation @xmath12 .\neach panel covers an area @xmath13 on a side centered on the more massive primary lens .\nthe brightness of an image is proportional to @xmath14 , where @xmath15 is the jacobian that describes the coordinate transformation between the image and source planes .\nthe locus of points in the source plane for which @xmath16 is called the `` caustic curve . '' a source crossing the caustic will be highly magnified .\n-8.5 cm -0.5 cm\n-1 cm    since most microlensing events are alerted in real time only when the source lies near or inside @xmath17 , a light curve will reveal the binarity of the lens ( via an anomaly @xmath18 ) only if the source trajectory passes over the contours shown in fig  1 .\notherwise , the light curve will be indistinguishable from that due to a single isolated lens .\nfigure  2 illustrates this effect ; two possible source trajectories are shown passing the same distance from the `` central '' caustic , but different distances from the two , outer `` planetary '' caustics ( all three caustics are caused by the lens - planet combination ) .\nthe light curve associated with only one of these trajectories betrays the presence of the planet . since the deviation contours are most extended for @xmath11 and @xmath12 of order unity ( fig .  1 )\n, these types of binary lenses will be the easiest to detect .\neven planets as small as the earth generate caustic structures as they orbit galactic lenses ; background sources passing over or near these caustics will experience a substantial additional microlensing effect due to the binarity of the lens .\nthe cross section of the planetary caustic and thus the probability that a random trajectory will pass over or near it decreases slowly with mass ratio ( dominik 1999 ) .\nfor this reason , microlensing  unlike most other planet detection methods  has _ sensitivity _ to terrestrial - mass planets .\nthis sensitivity is limited primarily by the sampling rate and precision of the photometry required to see signals that are reduced in amplitude by finite source effects for @xmath19 .\nthe _ efficiency _ with which planets of given @xmath11 and @xmath12 can be detected in a given light curve is a statistical quantity that depends on the photometric precision , sampling and duration of the photometric data and on the characteristics of the underlying event sampled , most notably its minimum impact parameter , @xmath20 , and the amount of blended non - lensed light in the same resolution element ( gaudi & sackett 2000 ) .\ndetermination of detection efficiencies for individual light curves allows non - detections to be translated into statistical upper limits for a given class of planet .      in principle\n, the _ detection _ of a microlensing anomaly can be quantified statistically , but its clear identification with a planetary lens relies on the _ characterization _ of the planet through determination of @xmath11 and @xmath12 . since any given event will not repeat , characterization must be obtained at the time of detection , and will require better data . with sufficient data quality , both @xmath12 and @xmath11 can be determined from light curve modeling , although in some cases the well - known @xmath21 `` degeneracy '' ( griest & safizadeh 1998 ; dominik 1999 ) will prevent a unique identification .\nhigh magnification events are sensitive and reasonably efficient to the detection of small mass planets since their small @xmath20 brings them close to the central caustic generated by companions ( griest & safizadeh 1998 ) .\nunfortunately , such detections may be particularly difficult to characterize , since all planets orbiting the primary lens will distort the central caustic ( gaudi , naber & sackett 1998 ) ; more massive ones will have an effect over a larger range of @xmath12 .\ndi  stefano and scalzo ( 1999 ) point out that current programs typically halt intensive monitoring when @xmath22 ; extended high - precision monitoring may detect and characterize planets at larger separation from their host lenses\n.    0.25 cm -5.30 cm 5.25cm=5.5 cm -7.25 cm 8.9cm=8.5 cm -1.75 cm    -0.2 cm\nof 21 light curves consistent with binary lenses analyzed by macho , two produced acceptable fits with companion masses as small @xmath23 ( alcock et al .\nthe first suggestion of possible planetary - mass lenses ( bennett et al .  1997 ) came from macho survey data for macho  1994-blg-4 , which could be modelled as an m - dwarf/5@xmath24 pair , and macho  1995-blg-3 , a very short duration event modelled as an isolated 2@xmath24 lens .\nhowever , many alternate interpretations were allowed by the infrequently sampled light curves inherent to survey data ( which must sample @xmath0@xmath25 stars nightly ! ) ; no firm planetary detection was claimed in either case .\nthe timescale @xmath26 ( @xmath27 is the relative proper motion of lens and source ) of typical galactic microlensing events is weeks to months ; whereas planetary ( @xmath28 ) anomalies would have durations of hours to days . the necessity of round - the - clock monitoring for detection and characterization of short - lived planetary deviations prompted the establishment of international collaborations such as mps ( rhie et al .\n2000 ) and planet ( albrow et al .  1998 ) , which obtain sub - day to sub - hourly photometry on events discovered by the survey teams macho , ogle and eros .\nalthough tantalizing hints have been seen in some light curves ( see below ) , no clear _ planetary _ anomaly has been detected .\n2.25 cm -4.0 cm    -0.25 cm    * macho 1997-blg-41 : * the very unusual event macho 1997-blg-41 caused a stir in the community : although clearly multiple lens microlensing , static stellar binary models did not fit the data .\nbennett et al .\n( 1999 ) interpreted the double caustic structure as coming from a static triple system , a jovian planet orbiting a stellar binary .\nthe planet team , modeling their own data , instead showed that the light curve could be fit as a normal stellar binary ( albrow et al .\n2000a ) whose rotation brings one of the triangular caustics across the source trajectory ( fig .  3 ) .\nthe proposed binary+jovian model was incompatible with planet data .    *\nogle 2000-bul-12 : * recently , yock et al .\n( 2000 ) have suggested that a planet may be orbiting the primary lens of event ogle  2000-bul-12 , based on analysis of public domain ogle data ( udalski & szymanski 2000 ) that displayed a possible anomaly at peak .\nunpublished planet team data indicates no anomaly and much smaller scatter at the same temporal position ( fig .  4 ) .\n0.5cm=6.5 cm -6.75 cm 6.75cm=6.75 cm -0.25 cm    -0.25 cm    * macho 1998-blg-35 : * although ruling out a large class of high - mass planets orbiting the lens of macho  1998-blg-35 (  4.1 ) , the mps and moa groups ( rhie et al .\n2000 ) noticed a weak anomaly near the peak of this high amplification event that they interpreted as intriguing evidence of a low - mass companion with @xmath29 .\nthe signal fell below the formal mps / moa detection limit .\nplanet team data for this event did not confirm this detection ; the planet light curve was consistent with an isolated point lens ( albrow et al .\ncurrent microlensing planet searches have appreciable efficiency for the detection of companions with mass ratio @xmath30 , ie . , planets with masses of order @xmath31 .\nthe lack of detected perturbations consistent with planets in this mass range allows constraints to be placed on the abundance of jovian analogs around typical stars ( ie , lenses ) in the milky way .    the first published exclusion diagram ( fig .\n5 ) for companions in an individual lensing system was presented by the mps / moa collaborations for macho  98-blg-35 ( rhie et al .\n2000 ) . due to the high amplification of this event\n, the source would have passed very near any ( central ) caustic structure due to massive companions . since no anomaly consistent with jovian - mass companions\nwas seen , exclusion contours could be derived as a function of @xmath11 and @xmath12 for this lensing system ( fig .\nthe planet collaboration performed a similar analysis for another high amplification event , ogle  1998-bul-14 ( albrow et al .\n1999b ) . when converted to parameters appropriate to a solar - type lens in the bulge and averaged over all orbital inclinations , the exclusion contours for jovian and super - jovian planets in the ogle  1998-bul-14 overlap the region of parameter space inhabited by current planet detections by the radial velocity technique ( fig .  5 ) .\nfor the most part , however , microlensing is sensitive planets at larger orbital radii ( 1 - 10  au ) than is the doppler technique .\n0.5cm=6.5 cm -6.5 cm 6.5cm=6.5 cm -0.25 cm    -6.6 cm 5.1 cm\n@xmath32 0.05cm5.4 cm @xmath33 0.05cm5.4 cm @xmath34 0.05cm5.4 cm @xmath35 0.05cm5.4 cm @xmath36 -0.75 cm 1.5 au@xmath374 au -2.5cm10.2 cm 1@xmath387 6.75 cm    based on 43 microlensing events collected from five years of photometric observations , the planet team has recently announced constraints on the abundance of jovian and super - jovian planets orbiting typical stars ( ie . , lenses ) in the galaxy ( gaudi 2000 , albrow et al .\nno clear planetary anomalies were observed in these 43 events , implying that less than one - third of @xmath00.3  m@xmath39 stars have jovian - mass companions with semi - major axes in the range 1.5 au@xmath384 au ( fig .\nweaker limits are placed on the existence of jovian planets orbiting in the range 1 au@xmath387 au .\nthese are the first constraints on exoplanets orbiting the most common of galactic stars : m - dwarfs .\nas with all techniques , microlensing has advantages and disadvantages . in the cadre of exoplanet search techniques , it offers the opportunity to _ detect and characterize jovian planets at large orbital radius ( 1 - 10  au ) without waiting for one or more orbital periods_. currently , it also has more _ sensitivity to neptune - mass planets _ than any other ground - based search technique . in the future ,\nthis sensitivity may be enhanced and extended with new facilities on the ground ( peale 1997 , sackett 1997 ) and in space ( rhie , this conference ) .\nchallenges must be overcome to detect and characterize earth - mass planets with reasonable efficiency _\n, including the diluting effect of finite source size on the magnification gradient due to small caustics ( bennett & rhie 1996 , gaudi & sackett 2000 ) .\ncurrently , the mass ratio ( but not the mass ) and the projected separation in units of @xmath17 ( but not in au ) of a lensing planet can be determined from an anomaly .\nmore information may be forthcoming in the future .\n_ large - aperture spectroscopy _ of an event may yield spectroscopic identification of the faint primary lens against the sea of source star light ( mao , reetz & lennon 1998 ) , thereby allowing the mass of the primary and @xmath17 to be estimated .\nmeasurement of the _ photometric centroid motion _ due to the changing position and brightness of the microimages ( astrometric microlensing ) , could yield the mass of the lens ( dominik & sahu 2000 , han 2000 , gould & han 2000 ) , and a more robust determination of planetary parameters ( safizadeh , dalal & griest 1999 ) ."}
{"lay_summary": " masers found in massive star - forming regions can be located precisely in six - dimensional phase space and therefore serve as a tool for studying milky way dynamics . \n the non - random orbital phases at which the masers are found and the sparseness of current samples require modeling . here we model the phase - space distribution function of 18 precisely measured galactic masers , permitting a mean velocity offset and a general velocity dispersion tensor relative to their local standards of rest , and accounting for different pieces of prior information . with priors only on the sun \n s distance from the galactic center and on its motion with respect to the local standard of rest , the maser data provide a weak constraint on the circular velocity at the sun of @xmath0 km s@xmath1 . including prior information on the proper motion of sgr a@xmath2 leads to @xmath3 km s@xmath1 . \n we do not confirm the value of @xmath4 km s@xmath1 found in more restrictive models . \n this analysis shows that there is no conflict between recent determinations of @xmath5 from galactic center analyses , orbital fitting of the gd-1 stellar stream , and the kinematics of galactic masers ; a combined estimate is @xmath6 km s@xmath1 . \n apart from the dynamical parameters , we find that masers tend to occur at post - apocenter , circular - velocity - lagging phases of their orbits . ", "article": "the value of the circular orbital velocity at the sun s radius in the milky way is of considerable interest in galactic and extragalactic astrophysics .\nit is necessary to correct observed velocities of stars and galaxies for the motion of the sun around the galactic center .\nthe circular velocity also plays a large role in characterizing the mass of the milky way in comparison with other spiral galaxies , placing it in a cosmological context , e.g. , when asking whether the milky way matches the tully  fisher relation ( e.g. * ? ? ?\n* ; * ? ? ?\n* ) or what is its total star formation efficiency ( e.g. , * ? ? ?\n* ; * ? ? ?\nthe circular velocity at the sun s radius has typically been established by measuring the sun s motion with respect to an object assumed to be at rest with respect to the galaxy ( sgr a@xmath2 : @xcite ; the stellar halo : @xcite ) , or by using a tracer population assumed to be angle - mixed , i.e. , having a uniform distribution of orbital phases , in a steady - state galaxy ( e.g. , * ? ? ?\nrecently , a competitive estimate has been obtained by a different approach using a narrow stellar stream that is assumed to be tracing out an orbit @xcite .    in this paper\nwe re - analyze a new population of tracers of milky way dynamics : masers associated with star - forming regions ( * ? ? ?\n* r09 ) . using the very long baseline array ( vlba ) and\nthe japanese vlbi  exploration of radio astronomy ( vera ) , precise measurements of the parallaxes , proper motions , and line - of - sight velocities of masers have been made ( see r09  and references therein ) .\nthese give accurate full six - dimensional phase - space information in the disk of the galaxy .\nsince these massive star - forming regions are associated with spiral arms and their shocks , the dense molecular gas regions that produce masers do not lie on exactly circular orbits , nor are they detected at random points on their orbits .\ntherefore , modeling approaches that assume a uniform distribution of the orbital phases of the tracer population can not give accurate determinations of the dynamics of the galaxy .\nfor the existing maser data , the problem of non - random orbital phases is exacerbated by the sparseness of the sample  only 18 masers with accurate six - dimensional phase - space information have been measured at present  and by the spatially non - uniform selection of the current sample of masers .    in this paper\n, we perform an analysis of the r09  maser data that deals simultaneously with the sparseness of the data , the spatial non - uniformity of the sampling , the non - random orbital phase distribution of masers , and prior information . assuming a flat rotation curve , @xmath7 constant\n, we use a simple model for the distribution of the maser velocities with respect to their local standards of rest : a mean offset from circular rotation @xmath8 and a general velocity dispersion tensor fixed in galactocentric cylindrical coordinates . in the probabilistic inference framework that we use  described in @xmath9  [\nsec : data]we can marginalize over the uncertainty in the inferred distribution function of masers , take prior information on the dynamics of the galaxy into account , use the sparse data set as efficiently as possible , and then ask what information on @xmath5 the maser data provide .\nour results presented in @xmath9  [ sec : results ] show that allowing for a finite velocity dispersion tensor in the model for the maser peculiar - velocity distribution function leads to lower values of @xmath5 than the large value reported in r09 , in whose analysis the maser velocity dispersion was ( implicitly ) assumed to vanish . adding in informative prior information about @xmath10 , inferred from monitoring stellar orbits around the black hole at the center of the galaxy @xcite and from the measurement of the proper motion of sgr a@xmath2 @xcite\n, we find that the best circular velocity estimate is @xmath3 km s@xmath1 , but that the current maser data set adds little information .\nwe discuss this measurement and its limitations in the light of other recent determinations in @xmath9  [ sec : discussion ] .\nthroughout the analysis that follows we use the standard cylindrical galactocentric coordinate frame @xmath11 , with associated unit vectors ( @xmath12 ) pointing toward the galactic center , in the direction of galactic rotation , and toward the north galactic pole , respectively .\nthe data we analyze here consist of the galactic coordinates , parallaxes , proper motions , and line - of - sight velocities of 18 galactic masers , as well as their associated uncertainties , presented in table 1 of @xcite .\nfollowing r09 , we add a 7 km s@xmath1 uncertainty in quadrature to the uncertainties in the velocity components of each maser to describe the random , virial motion in the massive star - forming region of the individual massive star associated with each maser .\nthe line - of - sight velocities have been ` corrected ' by the radio observatories pipelines for the motion of the sun with respect to the local standard of rest ( lsr ) .\nthis correction assumed a value of 20 km s@xmath1 toward @xmath13(b1900.0)= 18@xmath14 , @xmath15(b1900.0)=@xmath16 for the solar motion @xmath17 , although it is unclear whether all observatories used this standard value ( m.  reid , private communication ) .\nwe undo this correction , after which the currently accepted correction for @xmath17  can be applied ; however , as we will describe below , this correction will become part of our model and , therefore , the correction for @xmath17  does not occur during the preprocessing of the data .    beyond these two corrections ,\nno processing of the @xcite data has been done .\nparameter estimation in a probabilistic framework _ by necessity\n_ uses bayes s theorem to connect the probability of the model parameters given the data @xmath18 to the probability of the observed data given the model parameters ( e.g. , * ? ? ?\nthis requires us ( 1 ) to identify all the parameters that need to be included in the model , ( 2 ) to write down the likelihood of the model and ( 3 ) to specify suitable priors for the model parameters .\nalthough the model space needs to be exhaustive , the probabilistic framework allows integration over uninteresting parameters .\nhere we put forward a model for the maser kinematics in which the maser velocities are most easily modeled in galactocentric cylindrical coordinates . in order to go from the raw data described in @xmath9  [ sec : datasub ] to the velocity of each maser in galactocentric coordinates , we need to ( 1 ) correct the measured velocity for @xmath17 , ( 2 ) add to this velocity the circular velocity around the galactic center at the sun s radius , and ( 3 ) project this velocity onto the galactocentric coordinate frame ( the details of this transformation are described in the appendix of r09 ) . since the latter procedure includes\ngeometrical projection factors depending on the distance @xmath10  of the sun from the galactic center , the model parameters need to include the three components of @xmath17 , @xmath10 , and @xmath5 . however , it is more practical to assume that sgr a@xmath2 is at rest with respect to the galaxy , and to use the proper motion @xmath19 of sgr a@xmath2 @xcite as a model parameter instead of the circular velocity , as @xmath19 is very tightly constrained independently of @xmath10 .\nthese two parameters are related simply by multiplying the proper motion of sgr a@xmath2 by @xmath10 and correcting this for @xmath17 .\nthe circular velocity then becomes a parameter derived from the actual model parameters , which is no problem in the probabilistic framework , where it is easy to propagate uncertainties correctly . as we will assume that the rotation curve is flat , no extra parameters to model the shape of the rotation curve need to be included in the model .\nif we had uniformly sampled the phase space of masers and full prior knowledge of the phase - space distribution function of massive star - forming regions , this would uniquely specify the likelihood of the model , as the probability of the measured position and velocity of each maser would simply be given by the distribution function of the masers convolved with the observational uncertainty .\nhowever , we have neither a uniform sample of masers nor much prior information about the distribution of masers throughout the galaxy . to account for the spatial non - uniformity of the sample we will focus on the distribution of velocities at the actually observed position of the maser , instead of using the full six - dimensional phase - space distribution function to evaluate the likelihood .\nfor this distribution we will assume that it only depends on the peculiar velocity @xmath20 of the maser in galactocentric cylindrical coordinates .\nwe will assume that this distribution of peculiar velocities is given by a gaussian distribution characterized by a mean , a 3-vector @xmath21 , the offset from circular motion , and a general velocity dispersion tensor , a symmetric @xmath22 tensor @xmath23 with six free parameters .\nsince there have been no measurements of either the mean offset from circular motion of the masers or their velocity dispersion , we will use flat priors on these quantities .\nthis model is essentially a generalization of the model used in @xcite where the velocity dispersion tensor was assumed to vanish ; this was a poor assumption as we will show below .\nthe probability of a single maser is thus given by @xmath24|{\\ensuremath{\\overline{{{\\boldsymbol{{\\mathbf{v}}}}}}}},{\\ensuremath{\\mbox{\\boldmath$\\sigma$}}}\\right)\\otimes p({{\\boldsymbol{{\\mathbf{x}}}}},{{\\boldsymbol{{\\mathbf{v}}}}}|{{\\boldsymbol{{\\mathbf{x}}}}_i}^{\\mathrm{obs}},{{\\boldsymbol{{\\mathbf{v}}}}_i}^{\\mathrm{obs}})\\,,\\ ] ] where we have suppressed the dependence of @xmath25 on the dynamical parameters , and where the convolution with the observational uncertainty distribution @xmath26 has been included .\nthe posterior distribution for the 14 model parameters is then given by @xmath27 where the first factor on the right - hand side is the prior probability distribution for these parameters and the product is the likelihood .\nwe have used flat priors for @xmath21 and @xmath23 , which is why they do not appear explicitly .\nfor @xmath19 we use a gaussian prior with a mean of 30.24 km s@xmath1 kpc @xmath1 and a standard deviation of 0.12 km s@xmath1 kpc@xmath1 @xcite . for @xmath10\nwe combine current state - of - the - art determinations of @xmath10  from galactic center orbits with equal weights : 8.0 @xmath28 0.6 kpc found by @xcite and 8.33 @xmath28 0.35 kpc found by @xcite .\nthis prior is shown as the gray curve in  [ fig : ro ] . for @xmath17\nwe use the value and uncertainties obtained from _ hipparcos _\ndata @xcite , although the clumpiness of the velocity distribution of nearby stars @xcite implies an uncertainty more on the order of a few km s@xmath1 in the value of @xmath17  ( j.  bovy & d.  w.  hogg , in preparation ) .\nthe implied prior for the circular velocity is shown as the thick gray curve in  [ fig : thetao ] . to investigate how informative the maser measurements are about @xmath5 and @xmath10\n, we will consider the effect of dropping ( some combination of ) these priors below .\nthe framework described here can easily be generalized to more general descriptions of the distribution of the peculiar velocities of the masers . in what follows\nwe will use a distribution function that is the sum of two gaussian distributions , the second having half of the weight and twice the dispersion of the first gaussian , to determine the possible effect of outliers .      in order to explore the posterior distribution for all of the model parameters in light of the maser data we use a simple markov chain monte carlo ( mcmc ) method @xcite .\nthis procedure is described in some detail in the appendix .    the practical complication in evaluating the likelihood given in equations  ( [ eq : onelike ] ) and ( [ eq : posterior ] ) for each of the masers comes from the fact that the observational uncertainties are gaussian in the space of observed quantities  more specifically , for the parallax  but are non - gaussian in the space of the peculiar velocities . however , if the relative parallax uncertainty is small ( @xmath29percent ) we can confidently propagate the uncertainties to the space of peculiar velocities , where the convolution of the gaussian velocity distribution model for the peculiar velocities with the observational gaussian uncertainty distribution is simple .\na few of the masers have relative parallax uncertainties larger than 10percent , but we have nonetheless propagated the uncertainties in the gaussian approximation . to check that this does not bias our results\nwe have also run our analysis using a full numerical convolution with the actual observational uncertainties and we find results that are barely distinguishable from the results presented below .\nthe main scientific goal of this paper is to understand what the maser measurements tell us about @xmath5 .\nthe posterior probability distribution for @xmath5 , fully marginalized over all of the parameters of the maser distribution function , the solar motion with respect to the lsr , the distance to the galactic center , and the proper motion of sgr a@xmath2 , is shown in  [ fig : thetao ] .\nthe analogously marginalized posterior distribution for @xmath10  is shown in  [ fig : ro ] .\nalso shown in  [ fig : thetao ] is the posterior we obtained when we drop the informative prior on @xmath19 .\nthe posterior distributions for the proper motion of sgr a@xmath2 and for the components of @xmath17  are not shown here .\nthey are all basically identical to their prior distributions , implying that the masers  not surprisingly  cannot inform us about these quantities .    while the prior on @xmath5 in  [ fig : thetao ] peaks at 244 km s@xmath1 with a 1sigma uncertainty of 16 km s@xmath1 , the posterior for @xmath5 is peaked at a value of 244 km s@xmath1 with a 1sigma uncertainty of about 13 km s@xmath1 .\nthis equal value for @xmath5 after analyzing the masers is in qualitative contrast to the initial analysis of r09 , who found that it raised the peak to 254 km s@xmath1 .\nthis difference arises mainly from our more general model for the distribution function of the masers .\nif we insist within our analysis that the velocity dispersion of the masers is zero , we find a posterior distribution for the circular velocity that is peaked at 255 km s@xmath1 , in rough agreement with the r09  results .\nthe light gray line in  [ fig : thetao ] shows what happens when we drop the informative prior on @xmath19 , while keeping the @xmath10 prior : @xmath0 km s@xmath1 .\nthis and the fact that the posterior probability is barely narrower than the prior , tells us that the current maser measurements have not much power to constrain @xmath5 .\nthe posterior estimate for the distance to the galactic center is @xmath30 kpc ; this shows that the masers lead to a small improvement to our knowledge of the sun s distance to the galactic center . without the informative prior on @xmath19 the posterior estimate for @xmath10\nis the same as the prior estimate : @xmath31 kpc .    at the same time\n, the mcmc procedure provides fully marginalized posterior distributions for the parameters of the conditional velocity distribution function of masers , which are given in  [ fig : dist ] : shown are the posterior distributions for the three components of the mean offset from circular velocity of the masers , i.e. , the mean peculiar velocity , in cylindrical coordinates ( toward the galactic center , in the direction of galactic rotation , and toward the north galactic pole ) as well as for the trace of the velocity dispersion tensor . from this\nwe confirm the mean lag of 15 km s@xmath1we find a lag of @xmath32 km s@xmath1of the masers with respect to their local standards of rest previously found by r09 .\n[ fig : dist ] shows that the masers have a mean velocity toward the galactic center of @xmath33 km s@xmath1 .\ntaken together , these mean peculiar velocities imply that the masers are typically just past the apocenter of their orbits .\nwe also find a mean velocity component of @xmath34 km s@xmath1 in the direction toward the north galactic pole .    from the posterior distribution for the trace of the velocity dispersion tensor\nwe see that the masers have a relative large velocity dispersion@xmath35 km s@xmath1]@xmath37larger than might be expected from a comparison with the velocity dispersion of young stars in the solar neighborhood , whose trace is about [ 14 km s@xmath1]@xmath37 @xcite .\nsince we put no restrictions on the form of @xmath23 we also obtain posterior probability distributions for all of the components of @xmath23 : for the diagonal components we find @xmath38 km s@xmath1 , @xmath39 km s@xmath1 , and @xmath40 km s@xmath1 . as we discuss below\n, the fact that we obtain these large values could be because our model for the conditional velocity distribution is too restrictive .    in order to assess the possible affect of outliers on our inference ,\nwe have performed the same analysis assuming a distribution of the peculiar velocities which consists of a mixture of two gaussian distributions , identical in every aspect except that the second gaussian has half of the weight and twice the dispersion of the first gaussian ( by doubling each component of the velocity dispersion tensor ) .\nwe find the same posterior distributions for the dynamical parameters and the mean offset ; the inferred dispersion of the masers is , predictably , somewhat smaller : the trace of the covariance matrix peaks at [ 22 km s@xmath1]@xmath37 .\ntwo specific candidate outliers , the sources ngc 7538 and g 23.6 - 0.1 , were identified and removed from the sample by r09 , because they displayed large post - fit residuals . to assess whether these two sources affect our results significantly , the same analysis as described above of the r09  basic sample of 16 masers was performed , leaving out the sources ngc 7538 and g  23.6 - 0.1 .\nwe find basically the same result : @xmath41 km s@xmath1 .\nthus , as opposed to r09 , who found that these two sources significantly raise the circular velocity derived from the maser data , our result is robust with respect to their inclusion .\nwe have re - analyzed the recent maser kinematics from r09 , to see what they tell us about @xmath42 and the maser orbits .\nour analysis differs from that of r09  by allowing for a more general model for the distribution of the velocities of the masers with respect to their local standards of rest , by using a proper probabilistic framework that includes proper marginalization over uninteresting parameters , and by the explicit inclusion of suitable prior information . from this\n, we find an estimate of @xmath5 of @xmath43 km s@xmath1 , the same value as the mode of our prior , and substantially lower than the estimate of r09 .\nour analysis has also shown that the current maser measurements have only limited power to constrain @xmath5 beyond the prior ; dropping the prior coming from the measured proper motion of sgr a@xmath2 we find @xmath0 km s@xmath1 ; further dropping the prior information on @xmath10 , the maser data provide no constraint on @xmath5 at all .\nthe value for @xmath5 that we have inferred in this paper from the kinematics of galactic masers compares favorably with other recent measurements of the circular velocity . as is clear from  [ fig : thetao ]\n, the posterior probability distribution for the circular velocity is peaked at about the same value as the prior probability distribution obtained from combining the precise measurements of the distance to the galactic center , the proper motion of sgr a@xmath2 , and the solar motion in the direction of galactic rotation .\nit is also consistent with the value of @xmath44 km s@xmath1 from a recent measurement based on the completely different principle of fitting an orbit to the gd-1 stellar stream @xcite . combining these estimates by inverse variance weighting we find a value for the circular velocity of @xmath45 km s@xmath1 .\nthe results in this paper are unaffected by the uncertainty in the value of the solar motion with respect to the lsr .\nif we use a larger uncertainty in the value of @xmath46 of 3 km s@xmath1 in each component , as suggested by an analysis of the effect of moving groups on @xmath46 ( j.  bovy & d.  w.  hogg , in preparation ) , we retrieve the same estimate @xmath47 km @xmath1 as before .\neven when we use an uncertainty of 15 km s@xmath1 in the value of each component of @xmath46 , we find a slight increase in the uncertainty , but still the same value @xmath48 km s@xmath1 .\nthus , the uncertainty in @xmath46 only affects our conclusions if it is larger than about 10 km s@xmath1 .\nwe also learned that the masers on average lag @xmath5 and are moving toward the galactic center .\nthis fact is illustrated in s  [ fig : dist ] and [ fig : phases ] , where the orbital phases of the masers are shown for a logarithmic potential @xmath49 ( e.g. , equation  ( 3.14 ) in * ? ? ?\n* ) assuming @xmath50 kpc and @xmath51 km s@xmath1 .\nthis will be interesting to analyze in the context of spiral shock models .\nour analysis implies that the present maser data do not lead to a substantive improvement of our knowledge of @xmath10  and @xmath5 , as most of the information in the data is spent on determining the properties of the conditional velocity distribution of the masers .\nit is also remarkable that , given all of the prior information , the masers are much more informative about @xmath10  than they are about the angular rotation speed at the sun s radius , as the posterior distribution for @xmath52 is barely distinguishable from the prior distribution .    despite the fact that most of the information content in the maser data is already being used to infer the distribution function , it is possible that our model for the distribution function is not general enough .\nfor one , it is very likely that the distribution function of the masers depends on the galactocentric radius and , in particular , that the mean velocity offset in the direction toward the galactic center depends on radius .\nindeed , there is some indication of that already in our results , as the large velocity dispersion of the masers is mostly driven by a large velocity dispersion in the direction toward the galactic center ; this could be due to an unmodeled radial dependence of the distribution function .\nthe measurement of the dynamics of the galaxy performed here uses a tracer population that is obviously non - angle mixed but has no unambiguous non - angle - mixed interpretation  such as a stellar stream tracing out an orbit .\nsuch a measurement has the fundamental problem that structure in the distribution function of the tracers is , in a sense , exchangeable with complexity of the potential .\ntherefore , detailed measurements of the potential of the galaxy using larger samples of masers will very likely be fundamentally limited by our lack of knowledge about the distribution function of the masers . as more masers with precise\nkinematic information become available  as many as 400 are possible over the next few years ( m.  reid , private communication)more detailed inferences of the distribution function will have to be made simultaneously with more precise measurements of the potential of the galaxy from these masers .\nthe method described and used in this paper is flexible enough to handle these more general distribution functions and more general models for the potential of the galaxy .\nit is a pleasure to thank dustin lang , mark reid , and scott tremaine for helpful discussions and the anonymous referee for valuable comments .\njb and dwh were partially supported by nasa ( grant nnx08aj48 g ) .\njb was partially supported by new york university s horizon fellowship .\ndwh is a research fellow of the alexander von humboldt foundation of germany .\njb was partially supported by the max - planck - institut fr astronomie , and is grateful for its hospitality during part of the period during which this research was performed .\njb also gratefully acknowledges the hospitality of the lorentz center ( leiden ) where parts of this research were performed .\nwe explore the posterior probability distribution using a metropolis - hastings ( mh ) mcmc algorithm ( e.g. , * ? ? ?\n* ) . the mh algorithm works by proposing new model parameters @xmath53 from a proposal distribution @xmath54 that can only depend on the current values @xmath55 of the parameters .\none then computes the quantity @xmath56 if @xmath57 one accepts the new state ; if @xmath58 , the new state is accepted with probability @xmath59 . if the new state is rejected , the old state is added again as a sample of the posterior .\nthis procedure converges to give samples from the posterior .    as proposal distributions we use :\n( 1 ) the prior for the components of @xmath17 , ( 2 ) a gaussian for @xmath10  and @xmath19 centered on the current values with widths of 0.5 kpc and 0.12 km s@xmath1 kpc@xmath1 , respectively , ( 3 ) a gaussian for the mean offset centered on the current values with a width of @xmath60 km s@xmath1 for each component , and ( 4 ) a wishart distribution for the velocity dispersion tensor with mean equal to the current tensor and shape parameter @xmath61 .\nthe widths of these last three proposal distributions were chosen so as to give an acceptable acceptance rate of about 50percent .\nmonte carlo chains were run with different sets of parameters of the proposal distributions and the resulting posterior probability distributions were found to be independent of the parameters of the proposal distributions .\n, shown as the black curve , and its mean ( top label ) from 10@xmath62 mcmc samples . the prior probability distribution is shown as the thick gray curve ; its mean is @xmath63 km s@xmath1 .\nthe posterior and its mean ( bottom label ) obtained from dropping the informative prior on @xmath19 is shown as the thin gray curve , illustrating that the maser data themselves constrain @xmath5 relatively weakly . the quoted uncertainty in mean value is the standard deviation @xmath64 .\n]       samples : mean motion toward the galactic center ( _ top left panel _ ) ; in the direction of galactic rotation ( _ top right panel _ ) ; toward the north galactic pole ( _ bottom left panel _ ) ; the square root of the trace of the velocity dispersion tensor ( _ bottom right panel_).,title=\"fig : \" ]   samples : mean motion toward the galactic center ( _ top left panel _ ) ; in the direction of galactic rotation ( _ top right panel _ ) ; toward the north galactic pole ( _ bottom left panel _ ) ; the square root of the trace of the velocity dispersion tensor ( _ bottom right panel_).,title=\"fig : \" ] +   samples : mean motion toward the galactic center ( _ top left panel _ ) ; in the direction of galactic rotation ( _ top right panel _ ) ; toward the north galactic pole ( _ bottom left panel _ ) ; the square root of the trace of the velocity dispersion tensor ( _ bottom right panel_).,title=\"fig : \" ]   samples : mean motion toward the galactic center ( _ top left panel _ ) ; in the direction of galactic rotation ( _ top right panel _ ) ; toward the north galactic pole ( _ bottom left panel _ ) ; the square root of the trace of the velocity dispersion tensor ( _ bottom right panel_).,title=\"fig : \" ]    , apocenter radius @xmath66 , and current radius of the masers , normalized by the mean of the pericenter and apocenter radii , as a function of galactocentric radius in a spherically symmetric logarithmic potential for @xmath50 kpc and @xmath51 km s@xmath1 . filled symbols indicate that the maser is moving toward the galactic center . ]"}
{"lay_summary": " we report on a high - statistics measurement of the most basic double pionic fusion reaction @xmath0 over the energy region of the @xmath1 resonance by use of a polarized deuteron beam and observing the double fusion reaction in the quasifree scattering mode . \n the measurements were performed with the wasa detector setup at cosy . \n the data reveal substantial analyzing powers and confirm conclusions about the @xmath2 resonance obtained from unpolarized measurements . \n we also confirm the previous unpolarized data obtained under complementary kinematic conditions . ", "article": "as has been pointed out previously by harney @xcite , finite vector analyzing powers @xmath3 arise in reaction processes only , if at least two different partial waves interfere . hence in case of an isolated @xmath4-channel resonance , which is formed by a single partial wave matching to spin and parity of the resonance , the analyzing powers in the resonance region will be vanishing small , if there is no sizeable interfering background from other reaction processes .    recently , in the reaction @xmath5 a pronounced , narrow resonance structure corresponding to a mass of 2.38 gev and a width of about 70 mev has been observed in the total cross section near @xmath6 2.4 gev ( @xmath7 = 1.2 gev ) @xcite .\nits quantum numbers have been determined to be @xmath8 @xcite .\nthe @xmath4-channel character of this resonance has been established recently by polarized @xmath9 scattering .\ninclusion of these new data into the said partial - wave analysis produces a pole in the coupled @xmath10-@xmath11 partial - waves at ( @xmath12 ) mev @xcite . since then this resonance is denoted by @xmath1 .\nthe @xmath13 channel is the @xmath2 decay channel with the smallest amount of background from other reaction processes @xcite .\nnevertheless it has sizeable contributions from @xmath14-channel @xmath15 and @xmath16 excitations .\nboth of them are very well known from the study of @xmath17-induced two - pion production @xcite .\nhence , due to the finite background amplitudes we may expect sizeable analyzing powers @xmath18 in the region of the @xmath2 resonance .\nalso , they are expected to increase with increasing energy due to the increasing contribution of higher partial waves .\nsince @xmath18 is composed only of interference terms of partial waves , it is sensitive to even small partial - wave contributions and therefore qualifies as a sensitive spectroscopic tool for the investigation of the @xmath2 resonance region .\nin order to investigate this issue in a comprehensive way we measured the basic _ isoscalar _ double - pionic fusion process @xmath0 exclusively and kinematically complete .\nthe experiment was carried out with the wasa detector setup @xcite at cosy via the reaction @xmath19 using a polarized deuteron beam at the lab energy @xmath20 = 2.27 gev . since due to fermi motion of the nucleons in the beam deuteron the quasifree reaction proceeds via a range of effective collision energies , we cover the energy region 2.30 gev @xmath21 2.47 gev .\nthe emerging deuterons as well as the fast , quasifree scattered spectator protons were detected in the forward detector of wasa and identified by the @xmath22e - e technique .\ngammas from the @xmath23 decay were detected in the central detector .    that way the full four - momenta were determined for all particles of an event . since the reaction was measured kinematically overdetermined , kinematic fits with 6 overconstraints\ncould be performed for each event . from the full kinematic information available for each event also the relevant total energy in the @xmath24 system\ncould be reconstructed for each event individually .    by just having a different trigger these measurements\nhave been obtained in parallel to the ones for @xmath24 elastic scattering @xcite .\nthe trigger used for the detection of the @xmath13 events required at least one hit in the forward detector and three neutral hits in the central detector .    for details of the experiment , in particular also with respect to the determination of the beam polarization , checks for quasifree scattering and the procedure for deriving @xmath18 from the data , see ref .\n@xcite .    for convenience\nthe absolute normalization of the cross section data has been obtained just by relative normalization to the datum of the total cross section at @xmath25 = 2.38 gev published in ref .\n= 2.34 gev ( top ) , 2.38 gev ( middle ) and 2.42 gev ( bottom ) .\nthe solid circles denote the experimental results of this work .\nthe dotted lines give a 2-parameter fit to the data by use of eq .\nthe solid lines show the fit results , if a @xmath26 term is added and the dashed lines a fit , if also a @xmath27 term is included , see eq .\n( 2 ) . , title=\"fig : \" ]   = 2.34 gev ( top ) , 2.38 gev ( middle ) and 2.42 gev ( bottom ) .\nthe solid circles denote the experimental results of this work .\nthe dotted lines give a 2-parameter fit to the data by use of eq .\nthe solid lines show the fit results , if a @xmath26 term is added and the dashed lines a fit , if also a @xmath27 term is included , see eq .\n( 2 ) . , title=\"fig : \" ]   = 2.34 gev ( top ) , 2.38 gev ( middle ) and 2.42 gev ( bottom ) .\nthe solid circles denote the experimental results of this work .\nthe dotted lines give a 2-parameter fit to the data by use of eq .\nthe solid lines show the fit results , if a @xmath26 term is added and the dashed lines a fit , if also a @xmath27 term is included , see eq .\n( 2 ) . , title=\"fig : \" ]     scattering angle in the cm system .\nfits are shown for the 2- and 3-parameter options .\n, title=\"fig : \" ]   scattering angle in the cm system .\nfits are shown for the 2- and 3-parameter options .\n, title=\"fig : \" ]   scattering angle in the cm system .\nfits are shown for the 2- and 3-parameter options .\n, title=\"fig : \" ]     scattering angle in the cm system . ,\ntitle=\"fig : \" ]   scattering angle in the cm system .\n, title=\"fig : \" ]   scattering angle in the cm system .\n, title=\"fig : \" ]    the analyzing powers @xmath18 extracted from this experiment are shown in figs .  1 - 3 in dependence of the center - of - mass ( c.m .\n) scattering angles @xmath28 , @xmath29 and @xmath30 of emitted deuteron , @xmath23 and @xmath22 particles , respectively .\nthe intermediate @xmath22 from the process @xmath31 has been reconstructed from the 4-momenta of its decay products @xmath23 and nucleon  the latter by taking half the deuteron momentum , thereby neglecting the small correction due to fermi motion of the nucleons inside the deuteron . since the dalitz plot displayed in fig .  4 of ref .\n@xcite exhibits a @xmath22 excitation band sitting upon no substantial background , no cut on the @xmath22 mass appears to be necessary .\nthe data have been binned into three energy bins as displayed in figs .  1 - 3 : @xmath25  =  2.30  -  2.35  gev with center of gravity at 2.34  gev , @xmath25  =   2.36  -  2.40  gev with centroid at 2.38  gev and @xmath25  =  2.41  -  2.47  gev centered at 2.42  gev .\nthe middle one corresponds to the maximum cross section of the @xmath2 resonance , whereas the other two roughly correspond to its half maximum . at the lowest energy bin\nthe analyzing power in dependence of the deuteron scattering angle is still small .\nhowever , substantial @xmath18 values are obtained at the two higher energy bins .    in the following the description of the data\nis based on the formalism outlined in ref .\n@xcite . based on that work @xmath18 angular dependencies\nhave been derived in ref .\n@xcite , which can be theoretically expected in @xmath17 induced , _\ni.e. _ purely isovector two - pion production , if there are only relative @xmath4- and @xmath32- waves in the final channel :    @xmath33    with the parameters a and b to be adjusted to the data .    for the @xmath5 reaction\nthe situation changes insofar as we deal here with a purely isoscalar channel .\nin addition @xmath34-waves have to be included , in order to allow the formation of @xmath1 . for simplicity\nwe assume the @xmath35 system to be in relative @xmath4-wave .\nat least for the resonance formation this is well justified @xcite . applying the formalism presented in ref .\n@xcite to this situation @xcite we again end up with a formal description in terms of @xmath36 :    @xmath37    due to the involvement of @xmath34-waves the sum runs now over 4 terms ( j = 1 , ... 4 ) from @xmath38 until @xmath39 .\nthe weighting parameters @xmath40 ... @xmath41 to be adjusted to the data have now the following meaning :    @xmath42    here @xmath43 denotes the momentum of the @xmath35 system relative to the deuteron and the strength parameters @xmath44 and @xmath45 stand for the transitions :    @xmath46    where on the left - hand side the @xmath47 partial wave in the entrance channel is given by its spectroscopic nomenclature .\nthe right - hand side denotes the partial wave of the deuteron together with its angular momentum relative to the @xmath35 system .\nthe interference of these partial waves , which are abbreviated by @xmath4 , @xmath32 and @xmath34 , is indicated in brackets at the right - hand side of eq .\nnote that in the entrance channel @xmath48 and @xmath49 as well as @xmath10 and @xmath11 are coupled partial waves . in principle , also the @xmath48 - @xmath49 coupled waves contribute to the @xmath50 configurations .\nhowever , for simplicity we omit this contribution , since it is expected to be small compared to the contribution of the @xmath2 resonance .    in order to see how many terms in the expansion ( 3 )\nare needed by the data , we performed fits with 2 , 3 and 4 terms as given in tables 1 - 3 and shown in figs . 1 - 3 by the dotted , solid and dashed lines , respectively .    for the analyzing power in dependence of the deuteron scattering angle the latter two are very close together in the angular regions , which are well covered by data .\nthis means that a 3-parameter fit is already appropriate for a proper description of the data . for the lowest energy , where the data are very close to zero throughout the measured angular range , already the 2-parameter fit is sufficient with providng a @xmath51 per degree of freedom ( ndf ) of unity\nthe fact that already a 3-parameter fit is sufficient for an appropriate description of the data in the resonance region is in accordance with the new said solution , which exhibits the @xmath2 pole predominantly in the @xmath10 wave and only very weakly in @xmath11 .\nhence @xmath45 got to be small and @xmath41 negligible compared to @xmath52 .\nin fact , the resonance term @xmath52 is highly demanded by the data , as the comparison between dashed and dotted curves demonstrates . since @xmath52 enters also in @xmath40 , the latter\nis also requested by the fit , whereas @xmath53 turns out compatible with zero within uncertainties at resonance .\ntherefore , the leading contribution to the analyzing power of the @xmath28 angular distribution turns out to be the interference of the resonant @xmath34 wave with the non - resonant @xmath32 wave .\n.results of the fits to the analyzing power data in dependence of the deuteron scattering angle by use of eq .\n( 2 ) with two ( 2p ) , three ( 3p ) and four ( 4p ) terms . [ cols= \" < , < , < , < , < , < , < , < \" , ]      +    the @xmath43-dependence of the parameters makes it plausible that the analyzing power is smallest at the lowest energy @xmath25 = 2.34 gev and tends to level off as soon as the resonance maximum is reached . at 2.42 gev the resonance amplitude is already substantially reduced , however , the @xmath43-dependence in @xmath40 and @xmath52 counteracts this reduction .    for the @xmath29 dependence of the analyzing power we may stick with the same ansatz eq .\n( 2 ) , but need to reinterpret the transitions ( 4 ) with respect to the partition @xmath54  -  @xmath23 . with still having\nthe @xmath55 system coupled to zero , this means that the transitions @xmath56 and @xmath57 both represent configurations , where the @xmath23 is in relative @xmath32 wave to the @xmath54 system , _\ni.e. _ contain also resonance contributions .\nif we forget the somewhat erratic data point at small angles at @xmath25 = 2.34 gev , then we observe an approximately constant pattern over the energy region of interest , which can be described sufficiently well by already the first two terms in the expansion eq .\n( 2 ) .    finally ,\nfor the @xmath16 partition we expect relative @xmath4-waves independent of whether this partition originates from @xmath2 or conventional @xmath14-channel excitation , since the considered energies are still below the nominal mass of two @xmath22 excitations .\nthe observed @xmath18 distributions are similar to those for the @xmath54  -  @xmath23 partition and hence characterized dominantly by the @xmath53 contribution .      by using both the unpolarized and polarized runs of this experiment\nwe may extract also ( unpolarized ) differential and total cross sections .\nthis is valuable , since we used in this experiment the quasifree @xmath47 collision in reversed kinematics covering thus the lab system phase space complementary to what has been obtained in regular kinematics used previously @xcite .\n4 shows the @xmath58 angular dependence of the ( unpolarized ) differential cross section over the energy region @xmath25 = 2.33 - 2.43 gev binned into five intervals .\nthe data plotted by the open circles have been obtained in a previous experiment @xcite by use of a proton beam hitting a deuterium target in quasi - free kinematics . due to the experimental conditions\nonly the deuteron back - angles could be measured in good quality .\nnow , with a deuteron beam impinging on a hydrogen target the phase space in the lab system is populated in a complementary way and we may deduce the cross sections preferably at forward angles ( solid circles ) . note that in fig .\n4 the data are plotted at angles mirrored to the way plotted in fig .  5 of ref .\n@xcite . here\n, in this work , the angles are defined relative to the direction of the initial neutron , whereas in ref .\n@xcite they have been defined relative to the direction of the initial proton .\nsince we deal here with a purely isoscalar reaction , the unpolarized angular distributions have to be symmetric about @xmath59 in the cms ( barshay - temmer theorem @xcite ) .\nthe data are in very good agreement with this requirement . to underline this , we show in fig .\n4 fits with an expansion into legendre polynomials of order 0 , 2 , 4 and 6 , _ i.e. _ including @xmath34-waves between d and @xmath55 systems and allowing total angular momenta up to @xmath60 = 3 :    @xmath61    where the coefficients @xmath62 denote the fit parameters .\nin addition to the symmetry about @xmath59 fig .\n4 demonstrates that the anisotropy is largest around the maximum of the @xmath2 resonance flattening off below and above .\nthe fact that the angular distribution tends to flatten out towards lower energies is not unexpected , since close to threshold we expect contributions only from the lowest partial waves .\nthe fact that the angular distribution tends to be flatter also at the high energy end of the investigated energy region , is not as trivial .\nit supports the fact that the high spin @xmath63 = 3 of the @xmath2 resonance requires a unusually large anisotropy of the angular distribution , which is larger than obtained in the conventional @xmath14-channel @xmath16 process , which gets the dominant mechanism at higher energies and where the @xmath16 system may also be in lower angular momentum configurations .\n= 2.33 - 2.43 gev binned into five intervals .\nopen circles denote previous results @xcite , filled circles this work .\nthe dashed curves give legendre fits with @xmath64 6 .\n, title=\"fig : \" ]   = 2.33 - 2.43 gev binned into five intervals .\nopen circles denote previous results @xcite , filled circles this work .\nthe dashed curves give legendre fits with @xmath64 6 .\n, title=\"fig : \" ]   = 2.33 - 2.43 gev binned into five intervals .\nopen circles denote previous results @xcite , filled circles this work .\nthe dashed curves give legendre fits with @xmath64 6 .\n, title=\"fig : \" ]   = 2.33 - 2.43 gev binned into five intervals .\nopen circles denote previous results @xcite , filled circles this work .\nthe dashed curves give legendre fits with @xmath64 6 .\n, title=\"fig : \" ]   = 2.33 - 2.43 gev binned into five intervals .\nopen circles denote previous results @xcite , filled circles this work .\nthe dashed curves give legendre fits with @xmath64 6 .\n, title=\"fig : \" ]    finally we display in fig .  5 the energy dependence of the total cross section as obtained with three independent measurements under different experimental conditions :    * @xmath47 collisions under usual quasifree kinematics with unpolarized beam and without magnetic field in the central part of the wasa detector at three beam energies ( open circles @xcite ) , * @xmath47 collisions under usual quasifree kinematics with unpolarized beam , but with magnetic field in the central part of the wasa detector ( open diamonds @xcite ) and * @xmath9 collisions under reversed quasifree kinematics with polarized beam and without magnetic field in the central part of the wasa detector ( filled circles , this work ) .\nthe data of the first and third measurements have been normalized in absolute height to the value obtained in the second measurement @xcite for @xmath25 = 2.38 gev . within uncertainties\nthe data from all three experiments agree to each other .\nwe have presented the first measurements of the @xmath0 reaction with polarized beam using the quasifree @xmath24 collision process under reversed kinematics .\nthe deduced total cross sections are consistent with previous results .\nthe obtained deuteron angular distributions complement the previous results .\nthey clearly show that at resonance the anisotropy is larger than outside .\nthe measurements exhibit significant analyzing powers in dependence of deuteron and pion angles , which can be understood as being due to the interference of the @xmath2 resonance amplitude with background amplitudes .\nwe acknowledge valuable discussions with ch .\nhanhart on this issue .\nthis work has been supported by forschungszentrum jlich ( cosy - ffe ) , dfg ( cl 214/3 - 1 ) , stfc ( st / l00478x/1 ) , foundation for polish science through the mpd programme and by the polish national science centre through the grants no.2011/01/b / st2/00431 , 2013/11/n / st2/04152 , 2011/03/b / st2/01847 .\nh. l. harney , phys .\nb * 22 * , 249 ( 1968 ) .\nm. bashkanov _\net al . _ ,\nrev . lett . * 102 * , 052301 ( 2009 ) .\np. adlarson _\nlett . * 106 * , 242302 ( 2011 ) .\np. adlarson _ et .\nb * 721 * , 229 ( 2013 ) .\np. adlarson _\net al . _ ,\nlett . * 112 * , 202301 ( 2014 ) .\np. adlarson _\net al . _ ,\nc * 90 * , 035204 ( 2014 ) .\np. adlarson _ et .\nc * 88 * , 055208 ( 2013 ) .\np. adlarson _ et .\nb * 743 * , 325 ( 2015 ) .\nh. clement , m. bashkanov and t. skorodko , phys .\nscr.t * 166 * , 014016 ( 2016 ) .\nm. bashkanov , h. clement and t. skorodko , hyperfine interact * 234 * , 57 ( 2015 ) .\ng. agakishiev _ et .\nb * 750 * , 184 ( 2015 ) .\nl. alvarez - ruso , e. oset and e. hernandez , nucl .\na * 633 * , 519 ( 1998 ) .\nxu cao , bing - song zou and hu - shan xu , phys .\nc * 81 * , 065201 ( 2010 ) .\nj. johanson _\net al . _ ,\nphys . a * 712 * , 75 ( 2002 ) .\nw. brodowski _ et .\nlett . * 88 * , 192301 ( 2002 ) .\nj. ptzold _ et .\nc * 67 * , 052202(r ) ( 2003 ) . s. abd el - bary _ et .\nj. a * 37 * , 267 ( 2008 ) .\nt. skorodko _ et .\nj. a * 35 * , 317 ( 2008 ) .\nt. skorodko _ et .\nb * 679 * , 30 ( 2009 ) .\nt. skorodko _ et .\nb * 695 * , 115 ( 2011 ) .\nt. skorodko _ et .\nj. a * 47 * , 108 ( 2011 ) .\np. adlarson _\net al . _ , phys .\nb * 706 * , 256 ( 2011 ) .\nb * 684 * , 110 ( 2010 ) and b * 702 * , 312 ( 2011 ) ; arxiv:0910.0995v2 [ nucl - ex ] .\nh. h. adam et al . , arxiv : nucl - ex/0411038 .\net al . _ ,\nmeth * a594 * , 339 ( 2008 ) . ch .\nhanhart , phys .\nrept .   * 397 * , 155 ( 2004 ) .\nhanhart , priv .\ns. barshay and g. m. temmer , phys .\n* 12 * , 728 ( 1964 ) ."}
{"lay_summary": " using hst and the wfpc2 we have acquired very deep v- and i - band photometry of stars in ngc 2420 and ngc 2477 to study cluster luminosity functions at approximately solar metallicity . \n we have determined these cluster luminosity functions down to @xmath0 = 10.5 ( 0.2 m@xmath1 ) and find that the luminosity function of ngc 2420 turns over at @xmath0 @xmath2 9.0 , and possibly stops altogether by @xmath0 @xmath2 9.5 . \n the luminosity function of ngc 2477 may flatten at @xmath0 @xmath3 9.5 . \n we compare our open cluster luminosity functions to the solar neighborhood field star luminosity function of kroupa , tout & gilmore ( 1993 ) and the four published hst globular cluster luminosity functions : @xmath4 cen ( elson _ et al . _  \n 1995 ) , 47 tuc ( de marchi & paresce 1995b ) , m 15 ( de marchi & paresce 1995a ) , and ngc 6397 ( paresce , de marchi & romaniello 1995 ) . \n we find a smooth relation between the location of the luminosity function turn - over and the metallicity for all these low mass star samples which matches the expected @xmath0 versus [ fe / h ] trend for a model star of @xmath2 0.27 m@xmath1 ( saumon 1995 ; alexander _ et al . _  \n 1996 ) . \n we interpret this smooth and systematic behavior in the cluster luminosity functions as strong evidence in favor of an invariant initial mass function and a metallicity - dependent mass - luminosity relation . ", "article": "one of the most fundamental aspects of the stellar content of galaxies is the distribution by mass of newly formed stars , the initial mass function ( imf ) .\nevidence supporting or restricting variations in the imf for very low mass stars is of profound importance for an understanding of the mass content of the universe , the dynamical evolution of open and globular clusters , the chemical evolution of galaxies , and the physics of star formation .\nwhile developments in star formation theory ( e.g. shu 1991 ) and observations ( e.g. evans 1991 ) continue to increase our understanding of the complexities and processes involved in star formation , any understanding of how the imf does , or does not , depend on environment and metallicity is still elusive . for low mass stars , which are the subject of this paper , large surveys ( see reid & gilmore 1982 ;\nhawkins & bessell 1988 ; stobie , ishida & peacock 1989 ; bessell & stringfellow 1993 ) have provided a fairly well determined measure of the field star luminosity function near the sun .\nextensive modelling is required to derive the corresponding stellar initial mass function .\nhowever , there is reasonable agreement ( cf .\net al . _\n1993 and tinney 1995 for recent references ) that the luminosity function shows a broad maximum near @xmath5 , while the underlying mass function ( mf ) breaks away from an approximate power - law increase below 0.5 m@xmath1 .\nstar count surveys in the near - ir ( e.g. hu _ et al . _\n1994 ) and in the optical with hst ( bahcall _ et al . _  1994\n; santiago , gilmore & elson 1995 ) , and most recently from the hubble deep field ( elson , santiago & gilmore 1996 ) , suggest that the field stars of the galactic thick disk and halo have a luminosity function which is not significantly distinguishable from that of the solar neighborhood down to masses near the hydrogen burning limit .\nthis is a remarkable result , given that these stellar populations differ considerably in local density , and by a factor of forty in mean chemical abundance .\nfield star analyses are , however , subject to many uncertainties , in particular imprecise distance determination ( kroupa _ et al . _\nthe derivation of an initial mass from a color and apparent magnitude of an object which may be an unresolved binary star of unknown age , distance , and metallicity remains a statistical goal , rather than a precise tool .\nby contrast , in clusters the primary uncertainties of differential ages , abundances and distances are removed .\nhence , extensive surveys of the open clusters near the sun have been undertaken ( e.g. pleiades : hambly & jameson 1991 ; hyades : reid 1993 ; praesepe : williams , rieke & stauffer 1995 ; hambly _ et al . _\nsuch clusters are however primarily young , so that interpretation suffers from the limitation that evolutionary models for pre - main sequence stars of low mass are not yet well tested .\nideally , one wants clusters older than perhaps 1 gyr , covering a wide range of metallicities .    in the past year\nthere has been a vast improvement in the quality and quantity of data on the low mass end of the stellar luminosity function ( lf ) from observations of globular clusters with the refurbished hst ( e.g.  elson _ et al . _  1995\n; de marchi & paresce 1995a , 1995b ; paresce , de marchi & romaniello 1995 ) .\nthese four globular cluster studies have already provided good stellar lfs to @xmath6 ( @xmath2 0.2 m@xmath1 ) , and they will soon be supplemented by at least seven more hst globular cluster studies . in this paper\nwe report deep hst observations of the lfs in two open clusters , which allow us to extend the metallicity range represented by these four globular clusters ( @xmath7 < -0.7 $ ] ) up to solar abundance . thus , for the first time we now have cluster luminosity functions extending to very low stellar masses and covering more than 2 dex in metallicity , and can therefore study the effect of metallicity on stellar luminosity functions . in this paper\nwe search for a systematic dependence of the imf on some parameter to provide clues to the physics of star formation .\nwe observed the open clusters ngc 2477 and ngc 2420 with hst on 1994 march 18 and 1994 may 18/19 , respectively , using the wfpc2 along with the f555w ( approximately v - band ) and f814w ( approximately i - band ) filters .\nour observations were taken 5.2 arc minutes sw of the cluster center ( 7:38:11.2 + 21:33:09.7 , j2000.0 ) for ngc 2420 and 2.7 arc minutes wsw of the cluster center ( 7:52:16.8 -38:35:40.1 , j2000.0 ) for ngc 2477 to avoid the brightest stars in each cluster .\nthese fields still contain many very bright stars so we obtained the cumulative one hour exposures in each filter from nine 400s exposures in ngc 2477 and four 900s exposures in ngc 2420 .\nall data were acquired in the same manner and with the same filters , although the operating temperature of the ccds was @xmath8c during the march observations and @xmath9c during the may observations .\nthe temperature change was made in order to decrease a charge - transfer efficiency ( cte ) problem which manifested itself as a position - dependent non - linearity of the wfpc2 ccds .\nthe effect was found to be @xmath2 10% at @xmath8c and @xmath2 4% at @xmath9c ( holtzman _ et al . _\n1995b ) in a series of 40 second calibration exposures taken of a field in @xmath4 cen .\nelevated sky counts found in longer exposures such as ours are expected to decrease the cte problem ( holtzman _ et al . _\nthe lower operating temperature also resulted in far fewer ` hot pixels ' ; pixels with an elevated dark count lasting for hours or days . finally , an additional difference between our two cluster observations is that the sky level for the may data was five times higher than for the march data , owing to zodiacal light differences .\nthe raw data were reprocessed using the iraf / stsdas software with the updated calibration frames that became available subsequent to the observations .\nthis included the standard statistical corrections to the analogue to digital conversion , bias subtraction , dark count subtraction , flat fielding and geometric distortion correction .\nwe also included the non - standard `` ramp correction '' for the march cte problem .\nthe cte properties of the wfpc2 are still not entirely understood , but applying the correction reduced the significance of the cte effect to @xmath2 1% .\nthe cte effect in the may data is expected to be @xmath10 1% because of the higher sky counts and the cooler ccds , so we did not attempt to apply a correction for these data .\nadditionally we spent great effort trying to identify hot pixels as measured in the dark frames taken shortly before or after our observations , but were largely unsuccessful owing to the short life - times of these hot pixels .\nsince hot pixels have counts which are independent of the filter in use , and thus have color equal to zero on the instrumental system , they appear in the same region of the color - magnitude ( cm ) diagram as the faintest white dwarfs .\nsince the wfpc2 ccds are undersampled , hot pixels may appear like faint stars , especially two adjacent hot pixels or single hot pixels next to positive sky fluctuations .\nhot pixels thus decreased our limiting magnitude for white dwarfs ( von hippel _ et al . _\n1995 , hereafter paper i ) , but did not affect the limiting magnitude for the coolest main sequence stars , the subject of this paper .\nwe performed aperture photometry using 1.5 pixel radius apertures with aperture corrections based on a detailed study of the many bright stars available in our fields .\nafter some experimenting we did not employ point spread function ( psf ) fitting photometry as our fields were uncrowded and the psf was positionally dependent and not well characterized by our stars . unlike paper\ni , the photometry was directly transformed to the standard johnson - cousins vi system using the calibration from holtzman _\net al . _  ( 1995b ) .\nthe photometry we present here is thus slightly different from that presented in paper i , but the differences are so small for the white dwarfs as not to modify the results of that study .\nthe cm diagrams for all the stars in the fields of both our clusters , with galaxies removed , are presented in figures 1 and 2 .      in order to characterize the completeness of our photometry we created synthetic stars using the tinytim hst psf generation package ( krist 1994 ) , added these stars to our data , and then tried to recover them using our standard finding and photometry procedure .\nthe synthetic stars were created for both the f555w and f814w filters and were centered at 16 different sub - pixel positions and laid down in a grid of positions covering the whole of each ccd .\nthis sub - pixel sampling was done since the psf locations affect the number of pixels under the psf , and thus the sky noise and read noise contributions per pixel cause the limiting magnitude to depend on the psf sub - pixel position .\nsince this effect is based on noise changing systematically with psf position , it affects completeness , but not the measured magnitudes of objects bright enough to find .\nthe resulting simulated noise - free stars were scaled and had noise added to them to mimic stars over a range of magnitudes . from this procedure\nwe estimated our completeness levels , which are superimposed on figures 1 and 2 .\nthese completeness levels lead to a limiting magnitude @xmath2 0.5 magnitudes brighter than initially expected for the refurbished hst , but this is now understood as due to the ccds leaking some charge between adjacent pixels ( holtzman _ et al . _\nthese estimates of completeness should be reasonably accurate for the redder stars where hot pixels are not a problem .\nwe outline here the remaining sources of uncertainty in our photometry , although we emphasize that these are all small effects which do not affect our results .\n\\1 ) the cte corrections are almost surely not perfect for the @xmath8c data and they have not been attempted for the @xmath9c data .\nthe resulting uncertainties are @xmath2 1% and do not contribute to any important systematics .\n\\2 ) the hst pipeline flats were taken at the gain=14 setting , whereas our data were taken at the gain=7 setting .\nthe relative gains between these two settings are not identically 2.0 for all ccds .\nthe appropriate gain ratios have been applied , but these are uncertain to @xmath2 1% each .\nthis source of uncertainty should not cause systematic errors since all three wf ccds contain nearly equal portions of the cluster cm diagram .\n\\3 ) the hst pipeline flats are good to a few percent , pixel - to - pixel , over most of the area of the ccds .\n\\4 ) we applied a single aperture correction to all photometry for all wf ccds .\nin fact the relatively large number of bright but isolated stars in our images allowed us to investigate a number of subtle instrumental effects in the photometry .\nwe performed a number of such tests , and compared them with simulations based on tinytim analytical psfs .\nthe results are described in detail in tanvir , robinson & von hippel ( 1995 ) but briefly they found that ( a ) the photometry is essentially unaffected by the position of the center of the star within a pixel , and ( b ) there is a small ( @xmath113% ) variation seen in the ngc 2477 small aperture photometry which correlates with position on the ccd .\nthis latter effect is probably due to small variations in the psf across each ccd .\na similar but not identical effect is seen in the simulations , while ngc 2420 has too few bright stars to show it .\nhowever , given that this effect is small , is uncorrelated with magnitude , and to first order affects v and i in the same way , thus leaving v - i colors unchanged , it makes a negligible difference to the results presented here and so no correction was made .\n\\5 ) the precision of the holtzman _\net al . _  ( 1995b ) transformation is expected to be @xmath2 2% , over the applicable color range .\nthe range of applicability of the holtzman _\net al . _  photometric transformations\nis @xmath12 v - i @xmath13 , whereas our stars continue to v -\ni @xmath2 3.5 .\nthe expected error for the reddest stars is not large ( see section 3 ) , but this is probably our single greatest systematic uncertainty .\n\\6 ) whitmore ( 1995 ) reports that the hst + wfpc2 throughput increased by 4.1% in f555w and by 0.6% in f814w after cooling the wfpc2 ccds to @xmath9c on 24 april 1994 .\net al . _  ( 1995b ) report similar numbers .\nsince the photometric zero points were determined after the ccds were cooled , corrections need to be applied to the earlier data , in our case to ngc 2477 .\nmost of the throughput differences seem to be due to the decrease in the cte problem ( ferguson , private communication ) , however , and since we make a cte correction for our ngc 2477 data , much of this zero point difference probably disappears .\nthe zero point difference between cte corrected data has not yet been determined .\nwe therefore have not applied any throughput correction to the ngc 2477 data .\nthus , our ngc 2477 data may suffer an additional @xmath2 2 - 5% systematic error in v - i .    from items 1 through 5 above\nwe estimate that the additional random error contributed by the instrument , above and beyond that produced by photon counting statistics , is likely to be 4 - 5% , largely independent of magnitude .\nitem number 5 is relevant to the color magnitude diagrams presented in figures 1a , b and 2a , b as well as to any comparison of these data in the transformed johnson - cousins system to models . it does not affect our analysis of cluster luminosity functions as we compare our data to other hst observations taken through the same filters\nalso , these additional noise sources are not included in the cm diagram error bars , which represent only the internal photon - counting errors and read - noise .\nin this section we present the cm diagrams for ngc 2420 and ngc 2477 and derive their main sequence lfs .\nngc 2420 is metal - poor for an open cluster , with @xmath14 \\approx -0.45 $ ] , is only lightly reddened , with a uniform e@xmath15 , and has a distance modulus 11.95 .\nages from isochrone fitting for this cluster range from 2.1 gyrs ( carraro & chiosi 1994 ) to @xmath16 gyrs ( anthony twarog _\net al . _\n1990 ) and 4 gyrs ( vandenberg 1985 ) .\nwe derived ( paper i ) a lower limit for the age of this cluster from the white dwarfs luminosities of 1.3 gyrs .\nngc 2477 is more metal rich , with @xmath14 \\approx 0 $ ] , is heavily and unevenly reddened , with an adopted e@xmath17 ( smith & hesser 1983 ; hartwick , hesser & mcclure 1972 ) , and has a distance modulus of about 10.6 .\nisochrone fitting ages for this cluster range from @xmath18 gyrs ( carraro & chiosi 1994 ) to @xmath19 gyrs ( smith & hesser 1983 ) .\nwe derived ( paper i ) a lower limit on the age of this cluster from the white dwarfs luminosities of 1.3 gyrs .\nthe photometry for ngc 2420 and ngc 2477 is presented in the cm diagrams of figures 1a and 1b , respectively .\nthe photometry has been transformed to the johnson - cousins system and 1 @xmath20 error bars are plotted for all objects .\ncompleteness levels derived from our simulations are indicated at the bottom of these figures by the dotted lines .\nthe completeness levels are labeled and correspond to @xmath2 90 , 50 , and 10% completeness .\nthe v - band completeness levels are nearly horizontal , being curved slightly due to the color term in the photometric transformations .\nlikewise the i - band completeness levels are at a near - constant value in i , and thus inclined in this cm diagram .\nthe saturation limits are indicated by the upper dotted lines , level for v and inclined for i. the reddening vector for each cluster is plotted at v @xmath2 22 and v - i @xmath2 0.6 .\nexamination of these figures shows that the main sequence stars and white dwarfs clearly stand out in both clusters , even in the relatively crowded field of ngc 2477 ( which has galactic latitude @xmath21 = @xmath22 ) .\nit is also evident that the completeness simulations are consistent with the photometric errors and the faint limit of the photometry .\nfigures 2a and 2b present the cluster photometry after the effects of distance and reddening have been removed , and after the removal of the obvious contaminating field stars .\nthe dashed lines are eye - ball fits to the monet _\net al . _  ( 1992 ) trigonometric data for white dwarfs and solar metallicity main sequence stars .\nthey are plotted here to demonstrate that the entire combination of extrapolated photometric transformations , measured distances , and reddenings are reasonable for these clusters .\nfigure 2b presents the fits to the monet _\net al._data placed for e(b - v ) = 0.2 , 0.3 and 0.4 ( left to right ) , since this cluster is known to have variable reddening .\ncontaminating field stars were removed by comparison with nearby fields observed by the hst medium deep survey project .\nthe medium deep survey cm diagrams ( santiago , private communication ) were derived from f606w and f814w photometry , so we used the transformations derived by elson _\net al . _  ( 1995 ) to convert to the johnson - cousins colors .\na detailed comparison was then made of the number of stars as a function of magnitude and color in one nearby field for ngc 2420 and two comparable fields for ngc 2477 .\nthe comparison field for ngc 2420 is at _ l , b _\n= 206 , + 19.6 , whereas ngc 2420 is at _ l , b _ = 198 , + 19.7 .\nthe comparison field has a similar , and nearly negligible , reddening , e(b - v ) = 0.02 ( burstein & heiles 1982 ) .\ntwo comparison fields were used for ngc 2477 since none yet exist which closely match its galactic position and reddening .\none field is at _ l , b _ = 85 ,\n-3.5 and has e(b - v ) @xmath3 0.39 , whereas the other is at _ l , b _\n= 202 , + 9 and has e(b - v ) @xmath3 0.18 ( burstein & heiles 1982 ) .\nngc 2477 is at _ l , b _\n= 254 , -5.8 . using this procedure\nwe found it straightforward to isolate the main sequence cluster stars from the contaminating foreground and background stars , most of which lie well away from the main sequences .\na few stars in the comparison fields do lie on the cluster main sequences , and thus a small proportion of the stars presented in figures 2a and 2b are expected not to be cluster members .\nthese can only be removed statistically , so no corrections were applied to figures 2a and 2b , though the statistical corrections were applied to the cluster main sequence lfs presented below . before moving on to the extracted cluster lfs , it is worth pointing out that the main sequence in ngc 2420 ( figure 2a ) may actually stop at @xmath23 @xmath2 12 ( @xmath0 @xmath2 9.5 ) , as the fainter stars lie somewhat off the expected main sequence locus .\nsince we argue below that this cluster lf peaks at @xmath23 @xmath2 11.5 ( @xmath0 @xmath2 9.0 ) , for the present purposes we make the conservative assumption that these stars are cluster members .\nthe main sequences lfs for ngc 2420 and ngc 2477 are plotted in figures 3a and 3b .\nthe star symbols are the raw lfs , and the open circles are the lfs corrected for field star contamination and incompleteness . also plotted are lines representing the fractional incompleteness based on our synthetic star simulations .\nthe fractional incompleteness rises from @xmath2 0% at @xmath0 = 10 to nearly 100% by @xmath0 = 11.5 . in all subsequent use of the cluster lfs\nwe include only portions of the lf where incompleteness is less than 25% .\nthe ngc 2420 lf ( figure 3a ) turns over at @xmath0 @xmath2 9.0 while the ngc 2477 lf ( figure 3b ) seems to flatten at @xmath0 @xmath3 9.5 .\nthe numbers of stars in these lfs are small , being only 19 and 53 stars in the complete portion of the lfs for ngc 2420 and ngc 2477 , respectively , so these lf shapes are currently only suggestive .\nwe can estimate the likelihood that the ngc 2420 lf does not turn over by evaluating the probability that the value of the lf in the final bin is actually greater than the identified peak . for ngc 2420\na turn - over is a 1.5 @xmath20 result , i.e. there is a 7% chance that this lf continues to rise to its measured limit .\nthe likelihood that the lf continues to rise as rapidly after @xmath0 @xmath2 9.0 as it did before this point is only 1% , however , since the last lf bin lies 2.3 @xmath20 below such an extrapolation . for ngc 2477 a turn - over\nis not seen , and a flattening is only suggestive .\nwe thus locate the peak in this lf at , or after , @xmath0 = 9.5 .\nwe proceed below to consider the implications of these lf shapes , assuming that they have been correctly determined .    in figure 4\nwe plot our open cluster lfs along with the solar neighborhood lf presented in kroupa _\net al . _  ( 1993 ) and the four published hst globular cluster lfs : @xmath4 cen ( elson _ et al . _\n1995 ) , 47 tuc ( de marchi & paresce 1995b ) , m 15 ( de marchi & paresce 1995a ) , and ngc 6397 ( paresce , de marchi & romaniello 1995 ) . the four globular cluster lfs have been shifted down by 1 to 2 units in the log to approximately match the open cluster number counts , for ease of presentation .\nsince all the hst results were obtained using the f814w filter with wfpc2 , we choose to plot the lfs directly in terms of f814w magnitudes , and have therefore transformed the kroupa _\net al . _  ( 1993 ) data first to @xmath0 using the trigonometric parallax data of dahn _ et al . _  ( 1995 ) , and then to @xmath24 .\nerror bars are not plotted here for clarity , but the globular cluster lfs are well determined with typically many hundreds of stars per bin near the lf peak .\nerror bars due to poisson statistics are large for our open cluster data and can be readily determined either in this figure or in figures 3a and 3b by reference to the vertical scale .    in figure 5 we plot the location of the turn - over of all the lfs of figure 4 with respect to their metallicity , measured in [ fe / h ] .\nthe location of a lf turn - over is defined as the location of the peak bin , or for the case of @xmath4 cen , the location of the first bin of the lf flattening .\nthe solar neighborhood value has been placed at [ fe / h ] = @xmath250.2 , representative of this sample ( wyse & gilmore 1996 ) .\nthe abundance distribution of the field stars ( unlike the clusters which each have a single abundance ) blurs any sharp features in its lf , so that the lf maxima discussed here are less precisely defined for the solar neighborhood .\nthe error in the turn - over magnitude for the solar neighborhood is @xmath2 0.25 magnitudes , while the error in the turn - over magnitude for ngc 2420 is larger , @xmath2 0.5 magnitudes .\nthe turn - over magnitude for ngc 2477 is plotted as a lower limit .\nthe internal errors in the turn - over magnitudes for the globular clusters are small because of the large number of stars in each bin .\nthe errors in the turn - over magnitudes are thus likely dominated by the distance uncertainties for these clusters , which are @xmath2 0.2 magnitudes ( e.g. elson _ et al . _\nwe do not plot the location of the turn - over in the very broad halo field star lf as given by dahn _\n_  ( 1995 ) in figure 5 , as the location of this peak is probably more uncertain than the other lf peaks .\nthe essential result which is evident in figure 5 is a smooth and well defined correlation between the location of the turnover of the luminosity function of a stellar sample and the metallicity of that stellar sample . while we discuss explanations of this correlation below , we note here that it bears a close resemblance to a theoretical constant - mass locus .\nsuch loci are plotted in figure 5 as dashed lines from the low mass star models of saumon ( private communication ) , for masses @xmath26 and @xmath27 m@xmath1 , and as solid lines from the low mass star models of alexander _ et al . _  ( 1996 ) , for masses @xmath26 , @xmath28 and @xmath29 m@xmath1 .\nthe saumon models are plotted in @xmath0 , rather than @xmath24 , but the differences are expected to be minor .\nin the preceding sections we have concentrated on the cluster luminosity functions , not the mass functions , since the derivation of the latter requires additional assumptions . indeed ,\net al . _  ( 1995 ) , in their analysis of @xmath4 cen , show that even small uncertainties in the mass - luminosity relation are enough to cause major changes in the derived mass function slope .\ndantona & mazzitelli ( 1996 ) also demonstrate that the faint star lf slope has little to do with the mf slope , or metallicity , as it is driven by the slope of the mass - luminosity relation . while theoretical models for low mass stars are rapidly improving ( see alexander _ et al . _  1996 ; dantona & mazzitelli 1996 ) , a number of difficulties still remain at solar metallicities .\nwe therefore chose not to convert these lfs to mfs , but rather to follow the dominant lf feature , the turn - over , and compare it with stellar models . by following the lf turn - overs we are able to see that all available lfs look essentially the same , especially when corrected for the metallicity of the population .\nall lfs have approximately the same shape , and each has a turn - over at @xmath30 m@xmath1\n. why might all lfs have turn - overs at the same mass value , and what physical phenomena might affect the turn - over ?\nwe look at the effects of dynamics , the mass - luminosity relation , and the imf slope in turn .\nin analyzing their globular cluster luminosity functions , de marchi & paresce ( 1995a , 1995b ) argue that while these three globular clusters have undergone different degrees of core collapse and tidal stripping , their observed lfs are relatively insensitive to the cluster dynamical histories since they were obtained near the cluster half - mass radii .\nour open cluster observations were also made well inside the radii of tidal stripping , 3 pc from the center of ngc 2420 and 1 pc from the center of ngc 2477 .\nthese distances should be compared to the tidal radius for ngc 2420 , which was determined to be @xmath3 18 pc by leonard ( 1988 ) .\nthe tidal radius for ngc 2477 has not been determined to the best of our knowledge , but these clusters are similar in their stellar density and distance from the galactic center . additionally , although ngc 2420 has a relaxation time of only @xmath2 @xmath31 yrs , it shows only marginally significant mass segregation ( leonard 1988 ) .\nfurthermore , since the globular clusters have a mean stellar density a factor @xmath32 to @xmath33 times higher than the open clusters ( compare the densities of leonard 1988 with those of webbink 1985 ) , and are approximately an order of magnitude older , it would require careful tuning of the dynamical histories of these clusters for low mass stellar evaporation to produce , just at the present time , an uncoordinated set of changes which mimic a systematic dependence on metallicity . in any case , several more globular clusters have been observed with hst , so additional information to check the importance of dynamical evolution , and the true scatter in the correlation of figure 5 , will soon be available .\nwe do not argue that these clusters have not undergone possibly very different dynamical histories , only that their dynamical histories are not the primary cause of the lf turn - overs .\nthe slope of the mass - luminosity ( ml ) relation , in both v and i , is rapidly increasing at masses lower than @xmath30 m@xmath1 , independent of metallicity ( alexander _ et al . _  1996 ; dantona & mazzitelli 1996 ) .\nmetallicity does cause an offset in luminosity at a given mass , but it only slightly affects the slope of the ml relation at a given mass ( alexander _ et al . _\nthis increase of slope in the ml relation causes a given mass increment to cover a larger and larger absolute magnitude increment , especially below m@xmath34 @xmath2 9.5 - 10 .\nthus a turn - over in the lf at these magnitudes is naturally explained by the rapidly steepening ml relation .\nthis point was appreciated by kroupa _\net al . _  ( 1993 )\nfor the solar neighborhood lf , and the theoretical models of alexander _ et al .\n_  ( 1996 ) and dantona & mazzitelli ( 1996 ) now support this interpretation for all metallicities .\na test of this hypothesis is whether these ml relations , when applied to our cluster lfs , yield smooth mfs .\nwhen we apply either the observed solar metallicity ml relation of henry & mccarthy ( 1993 ) or the theoretical ml relation of alexander _ et al . _\n( 1996 ) to our lfs , we do indeed find mfs which rise smoothly through the peak and to the completeness limit of the data .\nthis statement can not be made strongly , however , due to the small number of stars in our lfs .\nwe note that our measured mfs rise as n @xmath35 m@xmath36 for both clusters , but that this value for the slope should not be taken too seriously , for the reasons mentioned above with regard to the insensitivity of this procedure to the mf slope , and because of its great dependence on the slope of the ml relation .\nin fact , dantona & mazzitelli ( 1996 ) demonstrate that a change in the imf slope moves the peak of the lf to a different mass value , by approximately 1 magnitude in the i - band for a change of 0.5 in the mf slope , depending somewhat on metallicity .\nthe lf peak is thus a sensitive measure of the mf slope , and any significant changes in this slope from cluster to cluster would have destroyed the match between the data and the single mass locus seen in figure 5 .\nthe increase in the slope of the ml relation below m@xmath34 @xmath2 9.5 makes a smooth mass function a viable explanation for these cluster lfs .\nit is therefore unnecessary to invoke the third possibility , a mf kink at @xmath30 m@xmath1 , as the cause of the lf turn - overs .\nsuch a mf kink is still possible , since the mf is very poorly determined at lower masses , but it is not _\nnecessary_.    a complication we have not addressed here is the effect on the actual mf of undiscovered binaries .\na large number of stars with masses below @xmath30 m@xmath1 could be hiding as unseen companions of brighter main sequence stars .\nfurthermore , globular clusters , open clusters , and the solar neighborhood field could have different relative numbers of such low mass companions .\na detailed analysis of the effect of binarism on luminosity functions was presented by kroupa _\net al . _  ( 1993 ) to which the reader is referred .\nwe conclude that the low mass imf is , to first order , independent of metallicity , with all the systematic changes in luminosity functions with metallicity dominated by the systematic changes in the mass - luminosity relation with metallicity .\nthe implication for star formation is that a large range of initial conditions and environments produce essentially the same distribution by mass of low mass stars .\nadditionally , the low mass mf is not steep enough to provide a large number of essentially invisible main sequence stars ( kroupa _ et al . _\nusing hst and the wfpc2 we have acquired very deep v- and i - band photometry of stars in ngc 2420 and ngc 2477 to study cluster luminosity functions at approximately solar metallicity .\nwe have determined these cluster luminosity functions down to @xmath0 = 10.5 ( 0.2 m@xmath1 ) and find that the lf of ngc 2420 turns over at @xmath0 @xmath2 9.0 , and possibly stops altogether by @xmath0 @xmath2 9.5 .\nthe lf of ngc 2477 may flatten at @xmath0 @xmath3 9.5 .\nwe compare our open cluster luminosity functions to the solar neighborhood field star luminosity function of kroupa _ et al . _  ( 1993 ) and the four published hst globular cluster luminosity functions : @xmath4 cen ( elson _ et al . _\n1995 ) , 47 tuc ( de marchi & paresce 1995b ) , m 15 ( de marchi & paresce 1995a ) , and ngc 6397 ( paresce , de marchi & romaniello 1995 ) .\nwe find a smooth relation between the location of the luminosity function turn - over and the metallicity for all these low mass star samples which matches the expected @xmath0 versus [ fe / h ] trend for a model star of @xmath2 0.27 m@xmath1 ( saumon 1995 ; alexander _ et al . _\nwe interpret this smooth and systematic behavior in the cluster luminosity functions as strong evidence in favor of an invariant initial mass function and a metallicity - dependent mass - luminosity relation .\nwe thank becky elson , basilio santiago , geraint lewis and the hst user support branch for advice and assistance and didier saumon for calculating stellar models for us .\nwe also thank an anonymous referee for her / his careful reading which led to a much improved presentation .\ntvh was supported by a pparc fellowship during this work .\nholtzman , j. a. , hester , j. j. , casertano , s. , trauger , j. t. , bellester , g. e. , burrows , c. j. , clarke , j. t. , crisp , d. , gallagher , j. s. , griffiths , r. e. , hoessel , j. g. , mould , j. r. , scowen , p. a. , staplefeldt , k. r. , watson , a. m. , & westphal , j. a. 1995a , , 107 , 156"}
{"lay_summary": " we describe the design and performance of the medium resolution spectrometer ( mrs ) for the jwst - miri instrument . \n the mrs incorporates four coaxial spectral channels in a compact opto - mechanical layout that generates spectral images over fields of view up to 7.7 x 7.7 arcseconds in extent and at spectral resolving powers ranging from 1,300 to 3,700 . \n each channel includes an all - reflective integral field unit ( ifu ) : an ` image slicer ' that reformats the input field for presentation to a grating spectrometer . \n two 1024 x 1024 focal plane arrays record the output spectral images with an instantaneous spectral coverage of approximately one third of the full wavelength range of each channel . \n the full 5 to 28.5 @xmath0 m spectrum is then obtained by making three exposures using gratings and pass - band - determining filters that are selected using just two three - position mechanisms . \n the expected on - orbit optical performance is presented , based on testing of the miri flight model and including spectral and spatial coverage and resolution . \n the point spread function of the reconstructed images is shown to be diffraction limited and the optical transmission is shown to be consistent with the design expectations . ", "article": "the rationale for , capabilities of , and scientific context of the mid - infrared instrument ( miri ) on jwst are described in rieke et al .\n( 2014 ; hereafter paper i ) and the overall optical , thermal , mechanical / structural electronic and control aspects of the design are summarized in wright et al .\n( 2014 ; hereafter paper ii ) .\nthis paper describes in more detail the miri medium resolution spectrometer ( mrs ) , which is an integral field unit ( ifu ) spectrometer that covers the wavelength range from 5 to 28.5 @xmath0 m at spectral resolving powers of a few thousand .\nthe mrs consists of 4 channels that have co - aligned fields of view , simultaneously observing the wavelength ranges listed in table 1 with individually optimised ifus , collimators and gratings .\nsection [ sec : optical ] of this paper provides a description of the optical design , including the rationale for choosing the ifu concept and its impact on how observations are carried out .\nsection [ sec : measured ] then describes the expected on - orbit optical performance of the mrs as measured during cryogenic testing , and with a description of the procedure used to construct calibrated spectral data cubes from the raw measured images .\nthe impact of particular characteristics of the mrs , including spectral fringing and straylight are also discussed here .\nan ifu based design was preferred to a long - slit design for the miri spectrometer for the following reasons .\nfirstly , for point source observations , the need to centre the source in a narrow slit ( via a peak - up procedure ) is relaxed , simplifying and accelerating the target acquisition procedure .\nthere is an additional benefit that there is no loss of light at the slices ( ` slit losses ' in a conventional long slit spectrometer ) .\nthe mrs slice width is set to be less than or equal to the fwhm of the diffraction limited point spread function at the slicing mirror .\nan equivalent long - slit spectrometer would vignette the light outside this region , losing about 50% of the total .\nthe amount of lost light could be reduced by making the slit wider , but doing so would in turn reduce the spatial and spectral resolution and could also decrease the signal to noise because of increased background radiation .\nsecond , from a scientific perspective , the wavelength range covered by the miri spectrometer is sufficiently broad ( a factor of nearly six ) that different emission mechanisms may dominate in different regions of the spectrum . in cases where these mechanisms do not share a common centre ( e.g. , stellar output compared with infrared re - emission in a starburst galaxy ) , a simple slit spectrograph poses a dilemma in placing the `` source '' on the slit . an ifu implements 3d spectroscopy , which solves this problem by giving accurately registered spatially resolved spectroscopy over the entire field .\nthese considerations , combined with the wavelength coverage and resolving power requirements defined by the jwst mission science goals , and the mass , volume and electrical power limitations set by the jwst spacecraft environment , have resulted in a system with the characteristics summarised below and illustrated in block diagram form in figure 1 .\nas shown in the figure , the full 5 to 28.5 @xmath0 m wavelength range is divided within the spectrometer pre - optics ( spo ) into four simultaneous spectral channels @xcite , each with its own ifu @xcite and using a simple scheme of pass - band separation by dichroic filters whose design is described in hawkins et al .\n( 2007 ) and wells et al .\nwe denote the short and long wavelength limits of each channel as @xmath1 and @xmath2 .\neach channel serves an optimised spectrometer .\nthis separation provides several benefits : ( 1 ) it enables the use of diffraction gratings in first order , allowing each to be used near peak efficiency around the blaze wavelength , and ( 2 ) it also allows the ifu slice widths to be tailored to the wavelength - scaled fwhm in each channel .\nelectrical and thermal constraints limit the mrs to two 1024 x 1024 si : as detectors ( ressler et al . , 2014 , hereafter paper viii ) , resulting in the spectrometer being split into two sets of optics , each with its own detector array , one for the two short - wave channels and one for the two long - wave channels . in each case\n, the spectra of two wavelength channels are imaged simultaneously onto the left and right halves of a detector array .\nthe product of spatial and spectral coverage that can be achieved in a single instantaneous exposure is ultimately set by the number of detector pixels . for the mrs ,\nthis results in a single exposure providing a spectral sub - band that covers only one third of each channel .\nfull wavelength coverage then requires three exposures , with a pair of mechanisms being used to select the gratings and dichroics in each case .\nwe refer to the short and long wavelength limits of each sub - band as @xmath3 and @xmath4 .\nthis design choice allows the grating performance to be optimised over a narrow wavelength range ( @xmath4/@xmath5 @xmath61.2 ) .\nthe gratings only have to work over 20% of the 1@xmath7 order near the blaze wavelength and the dichroics do not have to be used near the cross over between reflection and transmission .\nwe will now step through the optical train as shown in figure 1 : the input optics and calibration ( ioc ) modules pick off the mrs fov from the jwst focal surface and pass it on to the spo .\nthe spo spectrally splits the light into the 4 spectrometer channels and spatially reformats the rectangular fields of view into slits at the entrance of the spectrometer main optics ( smo ) .\nthe smo comprises fixed optics that collimate the light for presentation to diffraction gratings mounted in the spo and then re - images the dispersed spectra onto the two focal plane arrays .\nkey features of this optical system are described individually in the following subsections .\nthe spectral and spatial coverage of the mrs is summarised in table 1 .      the field of view of the mrs is adjacent to the miri imager field and picked off from the jwst focal surface using the miri pickoff mirror ( pom ) , which is common to both ( see paper ii ) .\nthe sky and the jwst pupil are reimaged by the ioc so that there is a pupil image at the spo input and a sky image further on .\na cold stop that is 5% oversized with respect to the jwst pupil is placed at the spo input pupil for straylight control .\nthe light is directed towards the first dichroic filter via a fold mirror placed 10 mm beyond the pupil .\nthe focal plane is formed 535 mm beyond the pupil , providing the long path length and narrow beam waist needed between the pupil and the inputs of the four integral field units ( ifus ) , for mounting a chain of dichroics to divide the light among the four spectral channels .    a hole in the fold mirror , sized to be smaller than the footprint of the telescope central obscuration , acts as an aperture for the injection of light from the on - board spectrometer calibration unit ( scu ) , shown in figure 2 .\nthe scu provides spatially and spectrally uniform blackbody illumination for flux calibration and pixel flat fielding functions , using as its light source a tungsten filament heated to a temperature of @xmath61000 k by the application of an 8 ma drive current .\nthe filament is mounted inside a non - imaging flux concentrator that generates spatially uniform focal plane illumination at the exit port of a 25 mm diameter reflective hemisphere , ( described in glasse et al . , 2006 ) .\ntwo cadmium telluride lenses within the scu then re - image the exit port onto the ifu input focal planes . the lenses provide a pupil image that coincides with the hole in the input fold mirror .\nthis hole is positioned to lie within the footprint of the central obscuration of the jwst primary mirror and so has no impact on the science beam . in this way\n, the scu can provide flood illumination of the full mrs field of view without any need for mechanisms or additional optical elements .\nthe overall layout of the dichroic assembly is shown in figure 3 , with the input fold mirror and scu situated at the left - hand end ( but not shown ) .\nthe three dichroics needed to divide the spectral band among the four spectrometer channels for one of the three sub - bands are indicated as d1 , d2 , and d3 in figures 1 and 3 . taking sub - band a as an example , the required reflective band for dichroic d1 is the wavelength range for sub - band a in channel 1 , while its transmission band needs to extend from the short end of sub - band a in channel 2 to the long end of sub - band a in channel 4 .\nthe bands are listed in table 2 for all nine dichroics . in all cases , the mean\nreflectivity is above 0.95 and the mean transmission is above 0.74 .\nall of the gratings work in first diffractive order so additional blocking is needed to reject second and higher orders . because the dichroics work in series it is possible to use the combined blocking of dichroics 1 and 2 to remove the need for blocking filters in channels 3 and 4 . for channels 1 and 2 ,\ndedicated blocking is provided by the fixed filters shown as bf1 and bf2 in figure 3 , with light traps lt1 and lt2 absorbing unwanted reflections .    the path length required to reach the input of channel 4 is greater than the 535 mm discussed above , so the light transmitted by the final dichroic is re - imaged via an intermediate focal plane to the entrance of the channel 4 ifu .\nthe 21 mm diameter dichroic filters are mounted on two wheels .\nfirst is the nine - sided wheel a containing the three channel 1 dichroic filters and three flat mirrors to direct the light towards channel 1 . the second , six - sided wheel , contains the six dichroics needed to divert the light into channels 2 and 3 .\neach dichroic filter is mounted onto a diamond machined facet on the wheel that provides the required alignment accuracy and reduces the magnitude of any print - through of surface form errors from the wheel to the filter substrate .\nthe filters are held in place with a spring loaded bezel with a clear aperture of 17 mm compared with the coated area of 17.4 mm .\nthe bezel prevents light from reaching the uncoated area of the filter , which might result in un - filtered light entering the optical path .\nthe blocking filters are mounted directly to the spo chassis with a stand and bezel , similar to the mounting arrangement for the wheels .\nthe mechanisms that carry the dichroic wheels also carry the corresponding wheels with diffraction gratings for each sub - band ( three per channel ) , as discussed in section 2.4 . by arranging for the gratings to be mounted on the same mechanisms as their band - selecting dichroics ,\nthe number of moving mechanisms within the mrs is kept to two .      before the light in the four channels reaches the gratings it is sliced and reformatted by the integral field units and\nso we describe these next .\nthe parameters pertaining to the spatial and spectral coverage and sampling of the spectrometer , which are largely determined by the design of the four ifus , are given in table 1 .\nspatially , the image is sampled in the dispersion direction by the ifu slicing mirrors and in the slice direction by the detector pixels .\nspectrally , the width of the slices defines the spectrometer entrance slit and the width of the image ( in pixels ) of the slice at the detector defines the width of the spectral sample .\ninspection of table 1 then shows that channels 1 to 3 are all slightly undersampled spectrally , with slice widths less than 2 pixels at the detector .\nthe bandwidths of the spectral channels listed in table 1 were chosen such that the ratio @xmath8/@xmath1 in all four channels was the same : @xmath2/@xmath9 ( 28.3 / 5)@xmath10 1.54 .\nthis means that , if each channel is assigned the same number of spectral pixels , the resolving power in each will be approximately the same .\neach sub - band then has a width that is slightly larger than one third of the band - width of its parent channel , where the excess provides sufficient overlap of adjacent spectra to allow their concatenation . in practice , the overlap is typically 10 to 15% of the spectral range , depending on the specific sub - bands and position in the field of view .    for full nyquist sampling of the telescope\npsf the four ifu slice widths should ideally be matched to the half width at half maximum intensity of the psf at the shortest wavelength in each channel .\nfor the jwst telescope pupil this would equate to a@xmath11 0.088 ( @xmath12 / 5 @xmath0 m ) arcsec .\nhowever , the large increase in the beam size produced by diffraction at the ifu slicer mirror would then necessitate large apertures for the spectrometer optics to avoid vignetting . to control the size , mass and optical aberrations of the spectrometer , the starting point for determining the slice widths was therefore to set them equal to 2a@xmath13 , with fully sampled psfs to be achieved using two or more pointings of the telescope .\noptimum spatial sampling , which minimises the number of telescope pointings needed to fully sample all four channels simultaneously in the across - slice direction , is achieved by having a single pointing offset equal to n@xmath14 + 1/2 slice widths for all channels where n@xmath14 is a different integer for each channel .\nthis led us to adopt a set of slice widths that follow a scheme where the slices are factors of 1 , 11/7 , 11/5 and 11/3 wider than the narrowest 0.176 arcsec slice .\nthese values closely match the increasing fwhm of the psf in the 4 channels and allow full nyquist sampling to be achieved using a single ` diagonal ' offset whose magnitude in the across slice direction is equal to 11/2 times the width of the narrowest slice ( 0.97 arcseconds ) and ( n + 1/2 ) detector pixels in the along slice direction ( where n is an integer ) . with\nthese slice widths fixed the design was interated to , as far as possible , meet the following criteria : 1 . )\neach channel would occupy half a 1024 x 1024 pixel detector with borders to allow for tolerances in alignment and gaps between slices to avoid crosstalk ; 2 . )\nthe fov of each channel should be as large as possible and approximately square ; and 3 . )\nthe long and short wavelength arms of the spectrometer should be identical ( in practice one is the mirror image of the other ) .\nthis iteration resulted in the parameters in table 1 .\nthe ifu design was developed from the ifu deployed in uist , a 1 - 5 @xmath0 m spectrometer for ukirt @xcite .\nother examples of all - reflecting image slicers are the spectrometer for infrared faintfield imaging ( spiffi ) @xcite , and the slicer in the gemini near - infrared spectrograph ( gnirs ) @xcite .\nthe miri ( and uist ) ifu design allows excellent control over stray light by providing through - apertures for baffling .\nit consists of an entrance pupil , an input fold mirror , an image slicer mirror , a mask carrying exit pupils for the individual sliced images , a mask carrying slitlets for the individual images , and an array of re - imaging mirrors behind the slitlets . these components ( except for the last ) are shown in figure 4 .\nthe design is all - reflecting and constructed entirely of aluminium , and hence is well - suited for operation in the infrared and at cryogenic temperatures , as discussed in paper ii .\n@xcite describe the manufacture of the slicer .\nthe optical path through the ifus begins with the four toroidal mirrors , which comprise the anamorphic pre - optics ( apo ) module , ( not shown in figure 4 ) .\nthe apo re - images an area of up to 8 by 8 arcseconds of the input focal plane onto the image slicer mirror , with anamorphic magnification .\nthe image slicer ( at the relayed image plane ) consists of a stack of thin mirrors angled to divide the image along the dispersion direction of the spectrometer into separate beams . in the across slice ( dispersion ) direction one slice width\nis matched to the fwhm of the airy pattern at the shortest operating wavelength for the ifu . in the along slice direction\nthe magnification is chosen to provide the required plate scale at the detector .\nthese two magnifications are not the same and so the apo exit pupil is elliptical , as illustrated in figure 5 for channel 3 , where the footprint of the jwst pupil is shown in blue .\nthe light exits the ifu through individual pupil masks for each beam , then through individual slitlets ( see figure 4 ) .\nre - imaging mirrors behind the slitlets relay the beam to the input of the appropriate spectrometer .\nthat is , each ifu takes the rectangular fov and transforms it into a pattern of slitlets ( as shown in figure 4 ) that are re - imaged onto the entrance aperture for its corresponding grating spectrometer .\nthe slicing mirror comprises a number of spherical optical surfaces , diamond turned onto a common substrate .\nthis manufacturing approach was used previously for the ifu in gnirs @xcite .\nfigure 6 is a photograph of the image slicer for channel 1 , which has 21 slicer mirrors arranged about the centre of the component with 11 slices on one side and 10 on the other .\neach mirror is offset to direct its output beam towards the corresponding re - imaging mirror .\nthe design for channels 2 to 4 is similar but with correspondingly fewer and larger slices as the wavelength increases , as listed in table 1 .\nthe mirrors are arranged in a staircase - like manner to aid manufacturing .\neach of the slices re - images the ifu entrance pupil at a scale of @xmath151:1 and because the centres of curvature of the mirrors are offset laterally with respect to each other , the pupils that the slices produce are separated , as can be seen in figure 4 .\nthe slicing mirrors truncate the anamorphically magnified image of the sky along the dispersion direction , as shown in figure 7 ( a ) to ( c ) .\nthis truncation results in the pupil image being diffraction broadened in the dispersion direction as shown in figure 7 ( d ) . to reduce vignetting , the baffle at this pupil image and subsequent optical components ( including the diffraction gratings )\nare oversized .\nthis is illustrated in figure 7(d ) where the geometric footprints for 3 field positions are overlaid along a slice to appear as the blurred green patch in the image .\nthe notional , geometric pupil is shown in red and the oversized mask aperture is shown as a green rectangle .\nthe re - imaging mirror array forms images of the slicing mirrors as input slits of the spectrometer and also images the pupils at infinity , making the output telecentric .\nfinally , a roof mirror redirects light from the re - imaging mirrors so that the output consists of the two lines of staggered slitlets relayed from those seen in figure 4 .\na slotted mask at the position of the ifu output slits defines the field of view along the individual slices , while in the spectral direction the slots are oversized to ensure they do not vignette the image , but still act as baffles to reduce scattered light between the slices .\nthe numbers of detector columns covered by the four ifus are approximately 476 , 464 , 485 , 434 for channels 1 to 4 respectively .\nthe size of the gap between individual slits for channel 1 is set to be approximately equal to the diameter of the first dark diffraction ring in the telescope psf , ( about 4 pixels ) . for channels 2\n 4 the size of the gap is slightly greater than the diameter of the first dark ring .\nthe smo ( whose layout is shown in figure 8) , comprises four grating spectrometers in two arms .\nthe development and test of these spectrometers are described by @xcite .\neach of them performs three functions : collimation of the telecentric output beams of one of the four ifus , dispersion of the collimated beam , and imaging of the resulting spectrum onto one half of one of the two focal plane arrays .\none of the two spectrometer arms includes the two short wavelength channels ( 1 and 2 ) , and the other the long wavelength channels ( 3 and 4 ) .\nwe will now step through the optical path from the ifus to the detectors .\nthe ifu output beam for each channel is collimated and its light directed towards the corresponding diffraction gratings as shown in figure 9 .\neach spectrometer arm uses 6 gratings ( two wavelength channels , three sub - band exposures ) .\nfigure 8 then shows the optical paths from the gratings to the detectors .\nthe dispersed beams are imaged by three - mirror - anastigmat ( tma ) camera systems ( m1-m2-m3 ) . in each spectrometer arm\nthe channels have separate , but identical , m1 camera mirrors that provide intermediate images of the spectra between m1 and m2 .\nfolding flats at these intermediate focus positions reflect the channel 1 and channel 4 beams such that the combined ( ch .\n1 + 2 ) and ( ch . 3 + 4 ) beam pairs are imaged onto opposite halves of the detectors by common m2 and m3 mirrors .\nthe symmetry through the centre plane of the camera optics and the positioning of the optics allow for an opto - mechanical design of two mirror - imaged boxes , with identical optics and almost identical structures .\nthe combination of symmetry and an all aluminium design ( optics as well as structures ) allowed the very strict alignment and stability requirements to be met fully with an adjustment - free mounting ( i.e. positional accuracy by manufacturing accuracy only except for the focus shim at the detector interface ) , a major advantage regarding the total design , manufacture and test effort .\nthe mirror substrates are all light - weighted aluminium with diamond turned optical surfaces that are gold coated for maximum reflectivity at the miri operating wavelengths .\nthey are mounted through holes in the housing walls using stress - relieving lugs under light - tight covers to prevent any high temperature radiation from the instrument enclosure ( at @xmath640 k ) reaching the detectors .\nthe two sets of gratings for the a , b and c sub - bands of the two channels are mounted on a single wheel , as shown in figure 10 , that is mounted on a mechanism that also carries the dichroics wheel on a lower level .\nthe mechanisms are located in the spo and each mechanism is rotated by a single actuator to give the correct combination of dichroics and gratings across all channels for each exposure . the gratings are master rulings on aluminium substrates and are gold coated .\ntable 3 lists the design parameters of the gratings .\nall gratings operate in first order .\nthe angular values quoted in figure 1 are calculated for the ( virtual ) nominal input beam , originating from the centre of the ifu output area .\nthe spo is designed to be a well baffled optical system . to intercept stray light from the telescope\nthe first optical element in the mrs is a cold stop placed at the entrance pupil .\na number of features within the mrs help to control stray light : 1 . ) stops at each pupil and sky image in the optical train ; 2 . )\nlight traps where significant stray light occurs ( 0@xmath16 order from the gratings ) ; 3 . )\nlabyrinths at the edges of apertures between modules and tight control of all external apertures , e.g. electrical feed throughs ; 4 . )\nblack coating of all surfaces not in the main optical path , which is an inorganic black anodising applied to a roughened surface of aluminium .\nthe process was carried out by protection des metaux , paris ; and 5 . )\navoidance of surfaces at grazing incidence near the main optical path .\nin addition , for each slice of each ifu there are output pupil and slit masks .\nall the diamond turned aluminium mirrors in miri were specified to have a surface roughness of < 10 nm rms .\nthis results in a total integrated scatter per surface of < 0.06% ; non - sequential optical modelling indicated that this level of scatter should not significantly degrade the psf of the mrs .\nall mirrors have an overcoated gold surface with reflectivity > 98.5% in the miri wavelength range .\nstraylight analysis shows that the extensive baffling combined with the low scattering optical surfaces and blackened structure should reduce unwanted light ( cross talk between channels , degraded psf and out - of - beam light at the output image ) to levels that are estimated to be less than 0.1% of the background radiation included in the science beam .\ndue to the nature of an ifu spectrograph with its slicing and dispersing optics , the resulting detector images are not straightforward to analyze : spatial , spectral , and with it photometric information , are spread over the entire detector array .\nfurther , the gratings are used in an optically fast , non - littrow conguration .\nthe resulting anamorphic magnification varies from the short to long wavelength limit for each sub - band which , when combined with the curved spectral images of the dispersed slices on the detector as shown in figure 11 , makes the optical distortion significant and complex .\nthe anamorphic and slicing optics add other components of distortion that vary the plate scale in the along - slice direction for each slice individually .\nthis leads to a very complicated variation of the spatial plate scales and finally to a dependency of the spatial and spectral axes on each other and on the location on the detector array .    to enable scientific studies\nbased on mrs data , the flux measured in each detector pixel needs to be associated with a wavelength and location on the sky .\nsince the ifu provides two spatial dimensions , each detector pixel corresponds to a position within a three - dimensional cube with two spatial and one spectral dimension .\ndue to the optical distortion , the edges of these cubes are neither orthogonal nor constant in length .\nconsequently , we have developed a process ( called image or cube reconstruction ) , which allows a transformation of the detector pixels onto orthogonal cubes .\ncube reconstruction requires a thorough understanding of the optical distortion .\nit is not possible to just characterize the curved images of the dispersed slices ( as shown in the left plot of figure 11 ) by approximating the curvature with polynomial functions . due to the distortion caused by the slicing optics , the spatial plate scale varies within a slice non - uniformly .\nthe characterization of the plate scale and the association of each detector pixel with its projected location on the sky at any given wavelength is a task for the astrometric and wavelength calibration , described in the next sections .\nonce the sky - coordinates and wavelength are known for each detector pixel , the cube can be reconstructed as discussed by glauser et .\n2010 ) .      to describe the optical distortion on the image plane of the detectors we began from the optical model , using ray - tracing techniques to project each detector pixel through the slicing optics backwards onto the sky .\nwhen the as - built geometry was taken into account , we achieved a high spatial accuracy , as demonstrated for the miri verification model ( glauser , et al . , 2010 ) .\nto verify this approach , a dedicated astrometric calibration campaign was conducted during the instrument test campaign of the miri flight model .    as outlined in glauser et al .\n( 2010 ) , the intra - slice spatial distortion can be approximated with a 2@xmath17 order polynomial to accuracies of a few milli - arcseconds - much better than required for the astrometric accuracy given the minimum plate scale of 0.196 arcseconds in the along - slice direction for channel 1 .\nwe conducted the astrometric calibration by placing a broad - band point source at three field positions for each slice and each channel and recording the dispersed signature on the detector .\nthe central pixel of the spatial profile was determined and correlated with the known position of the point source ( our reference on the sky ) . with this method\nwe were able to determine the spatial plate scale at any location on the detector . due to limitations of the test setup , i.e. , strong field distortion of the steerable point - source ,\nthe achievable relative astrometric accuracy was very limited .\nhowever , within an estimated upper limit of @xmath60.5 pixels ( 0.098  arcsecond for channels 1 and 2 , 0.123  arcsecond for channel 3 , and 0.137  arcsecond for channel 4 ) , the approach of using the optical model for the reconstruction was validated .\na further result from this calibration campaign was the measurement of the fov for each sub - band .\nfigure 12 shows the mrs fov in the jwst coordinate frame and its position relative to the imager field .\nthe fov common to all mrs channels is 3.64  arcsec in the along - slice ( @xmath18 and 3.44  arcsec in the across - slice direction ( @xmath19 .      to determine the absolute wavelengths for the mrs channels we conducted a series of calibration measurements during the instrument test campaign .\nfabry - prot etalon filters were used to create a dense pattern of unresolved spectral lines on the detector .\nmany tens of lines were typically visible at a signal to noise ratio of more than 50 in a single sub - band exposure .\nan example etalon measurement is shown in figure 13 . to provide a reference wavelength to distinguish between adjacent etalon lines , the telescope simulator used in the test\nwas also equipped with a pair of ` edge ' filters , one of which cut - on at around @xmath20 6.6 @xmath0 m ( in sub - band 1c ) and the other which cut off at @xmath21 21.5 @xmath0 m ( in sub - band 4b ) .\nthe absolute wavelengths of the etalon lines and edge filters had previously been measured at ambient and 77 k temperatures using a laboratory standard fourier transform spectrometer with a spectral resolving power of r @xmath22 100,000 .\nthe extrapolation of the wavelength scale to the 34 k operating temperature for the test campaign was based on published measurements ( browder and ballard , 1969 , browder and ballard , 1972 and smith and white , 1975 ) .\nthis extrapolation resulted in a typical wavelength correction of less than 1% of the width of the mrs spectral resolution element .\nthe repeatability of the scale after multiple mechanism reconfigurations has been measured to be 0.02 resolution elements .\nthe wavelength calibration process then involved the assignment of an absolute wavelength to an etalon line by fitting the calibrated spectra of the edge filters to their mrs measured spectra in sub - band 1c and 4b .\nthe known separation of the etalon lines was used to extend the wavelength scale across the full spectral image in each of these sub - bands . to extend the scale to other sub - bands , pairs of measured etalon spectra\nwere co - added and the positions of unique identifying features ( due to spectral beating between the two patterns ) were used .\na set ( 2 per sub - band ) of second order polynomial fits to the positions of the etalon lines was used to generate a wavelength value for the corners of all illuminated pixels .\nthe wavelength calibration derived in this way was encoded for use in the mrs calibration pipeline by forming six images ( one for each mrs detector and all three grating wheel settings ) where the image signal values were set equal to the wavelengths at the corner of each detector pixel .\nwe note that as a result , these wavelength reference images have one more row and column than the detector images .\nthe relative accuracy of this wavelength scale ( within and between sub - bands ) is estimated to be better than 0.02 spectral resolution elements which , for example , corresponds to 0.03 nm at @xmath21 5 @xmath0 m .\nthe absolute accuracy of the wavelength scale is estimated to be comparable to this figure but this will need to be confirmed during on - orbit commissioning using spectral standards .\nthe wavelength calibrated etalon spectra were also used to measure the spectral resolving power of the mrs .\nthe results are shown in figure 14 , where the sub - band averaged values are shown in red and the spread of values seen across the field of view is indicated by the black band .\nwe note that figure 14 does not take account of the intrinsic spectral width of the etalon features , which was determined using the r @xmath22 100,000 calibrated spectra , described above .\ninitial efforts to deconvolve the intrinsic line profiles from the mrs measured spectra suggest that the resolving powers quoted in figure 14 may be underestimated by around 10 % .\nwe have therefore used the band averaged measurements scaled by a factor 1.1 to generate the summary values quoted in table 1 .      as outlined in section [ sec : optical ] , the psf of the mrs is under - sampled by design , with full sampling in both spatial and spectral dimensions requiring that the object be observed in at least two dither positions that include an offset in the across - slice direction of 11/2 times the channel 1 slice width ( which corresponds to 7/2 slices in channel 2 , 5/2 slices in channel 3 , and 3/2 slices in channel 4 ) . due to the curved shape of the distorted spectrum on the detector and the variable plate scale along the individual slices ,\nthe exact dither offset in the along - slice direction is less well determined ( but also less critical ) .\nfigure 15 shows the nominal mrs dither pattern to be used in a single observation to sample point sources fully , as derived during test campaigns , and as proposed for in - flight operations .    to achieve a fully sampled psf\n, these dithered observations must be combined .\nwe anticipate that this could most readily be achieved using the reconstructed cubes .\nto avoid loss of spatial resolving power caused by any shift- and co - adding algorithm due to the re - binning of the data ( for example , fruchter & hook , 2002 ) , we minimize the necessary re - binning steps by incorporating dither offsets parallel to the slice into the reconstruction algorithm itself .\nthis has the advantage that only one re - binning step is required from detector data to reconstructed cubes , while dither offsets in the across slice direction can be corrected and combined afterwards using an interlacing method .\nwe expect more sophisticated techniques than we have developed so far to be incorporated into the data reduction pipeline before launch .\nwe attempted to measure the mrs psf during flight model testing at ral using the miri telescope simulator ( mts ) , described in paper ii .\nhowever , optical aberrations and vignetting in the mts led to the generated point source being elongated and extended at short wavelengths , such that it did not provide a sufficiently point - like image . even at longer wavelengths , where aberrations became less apparent as diffraction started to dominate ,\nthe measured psf was broader than nominal due to vignetting in the telescope simulator .\nwe therefore repeated the psf measurement on the flight model during the first cryo - vacuum test campaign at nasa - goddard ( cv1rr ) , where a compact and well defined point source was available .\ndeep exposures at 17 different locations in the mrs field were combined and reconstructed to form the psf image for channel 1a , shown in figure 16 . for these data ,\nthe spectral coverage was limited to a narrow ( 0.125 @xmath0 m wide ) wavelength range around 5.6  @xmath0 m .\na comparison with the model psf ( pure diffraction limited fourier - transformed jwst pupil ) shows a very good match across the slices . in the along - slice direction , a broadening of approximately 50%\nis observed .\ncurrently , possible causes considered for the broadening include scattering in the detector substrate ( the detector halo effect , which is also observed in the imager and is discussed in rieke et al . , ( 2014 , paper vii ) or a side - effect of the straylight discussed in section [ subsec : mylabel6 ] . in the case of the halo effect ,\nthe larger degree of broadening seen in the mrs may be due to the larger spatial sample per pixel .\nmore detailed modelling is required to confirm the root cause .\nspectral fringes are a common characteristic of infrared spectrometers . they originate from interference at plane - parallel surfaces in the light path of the instrument .\nthese surfaces act as fabry - prot etalons , each of which can absorb light from the source signal with a unique fringe pattern . in the infrared wavelength range , surfaces separated by a fraction of a mm up to a few cm may form very efficient etalons . the most obvious source of fringes in the mrs is the detector itself with a physical thickness of 500 @xmath0 m ( paper vii ) .\nsimilar fringes have also been observed in spectra measured with the miri verification model during testing and with the spitzer - irs instrument , which employs comparable ( though smaller ) si : as bib detectors , lahuis & boogert ( 2003 ) .    for the initial analysis we follow the formalism\nas defined in kester et al . , ( 2003 ) and lahuis & boogert , ( 2003 ) .\nthe sine approximation , @xmath23 _ _ cos(2__@xmath24 _ _ sin(2__@xmath25 , is used with @xmath26 being the wavenumber and @xmath27 the optical thickness of the instrument component .\nof primary interest to help in the identification and first characterization of the fringes is the optical thickness @xmath27 . in the mrs test data three distinct fringe components\nare seen , with key parameters listed in table 4 .    of the three fringe components two\nare directly matched to optical components in the instrument .\nthe main fringe component ( # 1 in table 4 ) has a derived optical thickness of approximately 3.5 mm for all sub - bands .\nthis corresponds to the optical thickness of the detector substrate which has d @xmath6 500 @xmath28 m and n @xmath6 3.42 , giving d @xmath6 0.34 cm .\nfigure 17 gives an illustration of this fringe pattern , showing the main detector and dichroic fringes in more detail for channel 4 .\nthe optical thickness derived for the second , high frequency , component ( d @xmath6 2.7 cm ) is matched to that of the cdte dichroic filters ( section 2.2 ) . for the third set of low frequency components ( d = 0.01 to 0.1 cm ) ,\nno unique surfaces in the instrument are identified ; instead these are likely to originate from beating between primary fringe components .\nthe fringe variations come from the layered structure of the detector substrate and optical thickness differences between individual dichroic filters .\nfigure 18 shows the peak normalized fringes over the entire wavelength range of the mrs .\nthe two curves in figure 18 show predictions for the expected fringe amplitudes based on representative anti - reflection ( ar ) coating profiles as applied to the miri flight detectors .\nthe solid curve assumes a pure two - sided etalon while the dashed - dotted curve simulates a back - illuminated surface with a fully reflective front surface and photon absorption in the active layer ( adopted from woods et al . , 2011 ) .\nthough not a perfect match , this approximate detector model does reproduce the general trend and magnitude of the fringes .\nfringe removal will be achieved using the techniques developed for and applied to iso and spitzer data ( see lahuis & van dishoeck , 2000 ; kester et al . , 2003 ; lahuis & boogert , 2003 ) .\nthis involves dividing the observed spectra by a fringe flat - field followed by the removal of fringe residuals using the sine fitting method .\nthis approach has proven to be reliable and robust for most spectra and the experience with iso and spitzer has shown that it allows the removal of fringe residuals down to the noise level .\nthe main limitations with this technique are the definition of the spectral continuum in the presence of spectral features and isolating the fringe spectrum from broad molecular ( vibration-)rotation bands ( e.g. those of c@xmath29h@xmath29 , hcn , co@xmath29 and h@xmath29o ) .    for the miri ifu\nother effects play a role and may limit the fringe removal for point and compact source measurements .\nthe two major effects are ; i ) the illumination ( and its effective angle ) on the detector depends on the source morphology ( position and extent ) and ii ) the wavelength depends on the spatial location of the point source in the ifu field .\nthis results in i ) changes in the effective optical thickness from source to source and ii ) a wavelength shift with spatial offset .\nboth modify the detailed fringe pattern for individual cases .\nfigure 19 illustrates this with point source measurements from the cv1rr test campaign and using extended source blackbody spectra from flight model testing at ral .\nsmall sub - pixel pointing offsets are seen to have a discernable impact on the fringe pattern .\nthese effects can be mitigated by traditional fringe removal techniques using optimized and iterative reduction algorithms ( e.g. by modifying , shifting and stretching the reference fringe spectrum before applying it ) .\nthis has been used in individual iso and spitzer cases and the miri team will work on developing optimized methods for the mrs . for miri\nan alternative model - based approach is also under study which uses the observed source morphology to define the fringe spectrum .\nthis method will be applicable to both the mrs and the lrs , and will complement the traditional fringe removal techniques .\nthis requires both a well - defined and well - calibrated fringe model ( an ongoing miri team activity ) and a flexible and iterative reduction pipeline ( in development at stsci based on input from the miri team ) .\nwe determined the pixel - to - pixel variation of the response for both short and long wavelength detectors , using measurements taken during testing at ral .\nthe illumination was provided by an external , extended source in the mts .\na number of exposures measured over the period of the whole test run and covering the full mrs wavelength range were included in this calculation .\nwe first de - fringed the data using the prescription described in section [ subsec : spectral ] , with the results illustrated in figure 17 .\nwe then calculated the mean value of each pixel , @xmath30 , by averaging over 5 x 5 pixel boxes centered on pixel ( @xmath31 and accounting for pixels close to the edges of the slices or near bad pixel clusters .\nthe original data were then divided by these averaged values to create a map of the normalized pixel gain .\nwe checked the distribution of the pixel - to - pixel variation for each exposure in all the available data for both detectors and all the sub - bands and found that the distribution is gaussian with a full - width - half - maximum of @xmath62% ( figure 20 ) .\nthe variation among different datasets has a standard deviation of @xmath32 0.2% for 16 different observations .\nthe pixel - to - pixel variation does not appear to be wavelength dependent as both short and long wavelength detectors show the same overall flatness .\nthis uniformity suggests that the correction of pixel response variations on orbit can be achieved using infrequent calibration measurements .\nthe absolute responsivity of the mrs is expressed in terms of the quantity referred to as the photon conversion efficiency ( pce ) , which is equal to the number of electrons detected by the focal plane array for each photon incident at the miri entrance focal plane .\nthe wavelength - dependent pces for the mrs were derived during testing at ral .\nthis was done by configuring the mts to provide extended illumination of the miri entrance pupil with the spectral energy distributions of blackbodies of 400 , 600 and 800 kelvin . for each mts blackbody configuration ,\nmrs spectra were obtained in all 12 spectral bands , together with background measurements using the blank position in the mts filter wheel .\nthe data were processed using the standard dhas tool ( paper ii ) , which converts the raw readouts of the integration ramps to slopes in physical units ( electrons / sec ) .\nthe dhas miricube module , which performs the reconstruction technique described in section [ subsec : mylabel4 ] , was then used to construct spectral cubes from the slope images , re - gridding the focal plane array pixel signals onto an equidistant spectral cube .\nthe spectral cubes of the background measurements ( mts filter blank position ) were subtracted from the flood illumination measurements to correct for the test facility background .\nthe spectral cubes produced with the dhas miricube routine have a fully calibrated wcs with the plate scale and wavelength coverage of every cube pixel . when combined with an estimate for the absolute flux delivered to the entrance focal plane by the mts ( paper ii ) , this allows us to calculate the photon conversion efficiency in every pixel of the spectral cube for all mrs spectral bands .\ntable 5 lists the mean pces for all mrs bands .\nwe estimate the fractional error to be 20 % in these figures , due to systematic effects , primarily in estimating the absolute flux from the mts .\none obvious feature of table 5 is the sharp drop in pce from channel 3 to channel 4 .\nthe pce in channel 4 is roughly a factor of 2.5 lower than was expected from sub - system measurements of the nominal mrs optical train .\nthe extra loss was identified ( m. te plate , esa , private communication ) as being caused by a fault in the groove profiles of the channel 4 gratings , which can not be corrected before launch .\nfollowing the procedure to determine the photon conversion efficiency , we can establish a first spectrophotometric calibration . by comparing the flux conversion factors derived from blackbody measurements of the mts at 400 , 600 and 800k\n, we can assess the achievable spectrophotometric calibration accuracy .\nfigure 21 shows the ratios of the different obtained flux conversion factors as a function of wavelength .\nwe are encouraged by the good agreement ( less than 2 % variation ) over a large swathe of the mrs wave - band .      as described in sections 2.3 and 2.5 ,\ngreat care was taken to minimise sources of straylight and optical cross - talk within the mrs ifus .\nhowever , a source of straylight was detected during ral testing , which was identified as being caused by scattering in optical components within the smo .\nthe stray light is manifested as a signal that extends in the detector row direction .\nits magnitude is proportional to that of bright illuminated regions of the spectral image , at a ratio that falls with increasing wavelength , from about 2 % in channel 1a to undetectably low levels longward of channel 2b .\n[ fig23 ] emphasises the impact of the straylight in channel 1b , using the wavelength - averaged , reconstructed image of a bright source ( seen at the top - left ) .\nthe straylight signature is seen as the two horizontal bands , where the variation in brightness with the ` alpha ' coordinate is well explained by the mapping between alpha and detector row coordinate .\nthe development of algorithms for correction of this straylight is underway .\nthey take advantage of the stray - light being the dominant signal in the inter - slice regions of the detector , thereby making it amenable to accurate characterisation .\ninitial indications ( figure 22 ) suggest that an effective correction algorithm will be available before launch .\ntesting at ral revealed a gap in the performance of the train of dichroics described in section 2.2 .\nthe set of filters that define the pass - band for channel 3 , sub - band a , have an unwanted ( but small ) transmission peak at a wavelength of 6.1 @xmath0 m , which allows light in the second diffraction order to reach the detector at the position where 12.2 @xmath0 m light is detected in the first diffraction order .\nthis leak was confirmed using fabry - prot etalon data and characterised to produce the leak profile plotted in figure 23 .\nthis curve can be interpreted as the transmission profile by which the 6.1 @xmath0 m spectrum of a target object should be multiplied to determine the leakage signal at 12.2 @xmath0 m .\nthere are two options for mitigating the effects of the spectral leak .\nfirst , the channel 3a spectrum can be corrected by multiplying an observation of the 6.1 @xmath0 m ( channel 1b ) spectrum of the target object by the leak profile , resampling the wavelength scale of the resulting spectrum to the wavelength grid of channel 3a and then subtracting it from the contaminated channel 3a spectrum .\nthis requires that a separate channel 1b observation has been taken .\nthe second method would be to make the channel 3a observation with dichroic wheel 1 set to use the sub - band c dichroics ( see section 2.2 to see what this means in terms of the optical train ) .\nthis combination of dichroics reduces the spectral leak by a factor of more than 1000 at @xmath33 = 6.1 @xmath28 m .\nthe unwanted side - effect of this solution is up to a factor of three loss of pce at the short wavelength ends of channel 2a and channel 4a .\nwe have presented the key parameters that describe the performance of the miri mrs spectrometer as designed or measured , in a form that both provides our best estimate of the behaviour of the instrument on - orbit and also that is accessible to the prospective user .\nthe optical design behind the parameters is presented at a level of detail that is intended to provide the astronomer with an understanding of what to expect in terms of operating restrictions and data format when planning observations .\nthe impact of straylight and spectral leaks in contaminating the spectral images has been discussed , along with proposals of operational and analytical techniques that should mitigate their effects . when combined with the latest sensitivity estimates ( glasse et al . , 2014 , paper ix ) , we are confident that the miri mrs will meet all of its scientific objectives as part of the jwst observatory .\nthe work presented is the effort of the entire miri team and the enthusiasm within the miri partnership is a significant factor in its success .\nmiri draws on the scientific and technical expertise many organizations , as summarized in papers i and ii .\na portion of this work was carried out at the jet propulsion laboratory , california institute of technology , under a contract with the national aeronautics and space administration .\nwe would like to thank the following national and international funding agencies for their support of the miri development : nasa ; esa ; belgian science policy office ; centre nationale detudes spatiales ; danish national space centre ; deutsches zentrum fur luft - und raumfahrt ( dlr ) ; enterprise ireland ; ministerio de economi y competividad ; netherlands research school for astronomy ( nova ) ; netherlands organisation for scientific research ( nwo ) ; science and technology facilities council ; swiss space office ; swedish national space board ; uk space agency .\nlccccc slice width & arcsec & 0.176 & 0.277 & 0.387 & 0.645 + number of slices & | & 21 & 17 & 16 & 12 +   @xmath35 & pixels & 1.405 & 1.452 & 1.629 & 2.253 + slice width at detector & & & & & +  @xmath36 & pixels & 1.791 & 1.821 & 2.043 & 2.824 + pixel size along slice & arcsec / pixel & 0.196 & 0.196 & 0.245 & 0.273 + fov ( across @xmath37 along slices ) & arcsec & 3.70 @xmath37 3.70 & 4.71 @xmath37 4.52 & 6.19 @xmath37 6.14 & 7.74 @xmath37 7.95 + & & sub - band a & & & + wavelength range   @xmath38 - @xmath39 & @xmath28 m & 4.87 - 5.82 & 7.45 - 8.90 & 11.47 - 13.67 & 17.54 - 21.10 + resolution & @xmath40 & 3320 - 3710 & 2990 - 3110 & 2530 - 2880 & 1460 - 1930 + & & sub - band b & & & + wavelength range   @xmath41 - @xmath42 & @xmath28 m & 5.62 - 6.73 & 8.61 - 10.28 & 13.25 - 15.80 & 20.44 - 24.72 + resolution & @xmath40 & 3190 - 3750 & 2750 - 3170 & 1790 - 2640 & 1680 - 1770 + & & sub - band c & & & + wavelength range   @xmath41 - @xmath42 & @xmath28 m & 6.49 - 7.76 & 9.91 - 11.87 & 15.30 - 18.24 & 23.84 - 28.82 + resolution & @xmath40 & 3100 - 3610 & 2860 - 3300 & 1980 - 2790 & 1630 - 1330 +    lcc dichroic 1a & 4.84 - 5.83 & 7.40 - 21.22 + dichroic 1b & 5.59 - 6.73 & 8.55 - 24.73 + dichroic 1c & 6.45 - 7.77 & 9.87 - 28.5 + dichroic 2a & 7.40 - 8.91 & 11.39 - 21.22 + dichroic 2b & 8.55 - 10.29 & 13.16 - 24.73 + dichroic 2c & 9.87 - 11.88 & 15.20 - 28.5 + dichroic 3a & 11.39 - 13.68 & 17.45 - 21.22 + dichroic 3b & 13.16 - 15.80 & 20.34 - 24.73 + dichroic 3c & 15.20 - 18.25 & 23,72 - 28.5 +    cccccc & & channel 1 & & & + a & 266.67 & & & & + b & 230.77 & 28 & 44 & 55.46 & 29.2 + c & 200.00 & & & & + & & channel 2 & & & + a & 171.43 & & & & + b & 148.45 & 30 & 63 & 54.46 & 28.5 + c & 128.57 & & & & + & & channel 3 & & & + a & 112.06 & & & & + b & 96.97 & 30 & 63 & 54.46 & 28.5 + c & 83.96 & & & & + & & channel 4 & & & + a & 71.43 & & & & + b & 61.28 & 34 & 64 & 53.46 & 27.2 + c & 52.55 & & & & +                                                                m ( top left ) compared with the fft of the jwst pupil ( top right ) and normalized peak profiles of the measured ( black ) and modelled ( red ) for the along - slice ( bottom left ) and across - slice direction ( bottom right ) .\nthe x - axis is multiplied by two for the lower figures.,width=480 ]"}
{"lay_summary": " we demonstrate that 4-body real space jastrow factors are , with the right type of jastrow basis function , capable of performing successful wave function stenciling to remove unwanted ionic terms from an overabundant fermionic reference without unduly modifying the remaining components . \n in addition to greatly improving size consistency ( restoring it exactly in the case of a geminal power ) , real - space wave function stenciling is , unlike its hilbert space predecessors , immediately compatible with diffusion monte carlo , allowing it to be used in the pursuit of compact , strongly correlated trial functions with reliable nodal surfaces . \n we demonstrate the efficacy of this approach in the context of a double bond dissociation by using it to extract a qualitatively correct nodal surface despite being paired with a restricted slater determinant , that , due to ionic term errors , produces a ground state with a qualitatively incorrect nodal surface when used in the absence of the jastrow . ", "article": "linear wave functions in quantum chemistry are fundamentally limited by their inability to compactly express wave functions in strongly correlated regimes , a difficulty that arises directly from the factorial growth of hilbert space in the quantum many - body problem . in practice , therefore , the field of quantum chemistry has long pursued sophisticated nonlinear forms for its approximate wave function ansatzes .\n@xcite a key challenge arises in this pursuit due to the difficulty of constructing an ansatz that is simultaneously size - consistent ( giving the same energy for independent systems when treated together or individually ) and variational ( giving an upper bound to the true energy ) while maintaining a cost that scales polynomially with system size .\nrecently , wave function stenciling , wich is a generalization of gutzwiller s approach @xcite in which a nonlinear correlation factor removes unsuitable terms from an overabundant fermionic expansion , has been shown to achieve these three properties , @xcite and so appears to be a promising paradigm for future ansatz design .\nwhile the jastrow antisymmetric geminal power ( jagp ) in hilbert space is characteristic of this approach and has proven effective at capturing strong correlation during bond dissociations , @xcite it is much less effective for capturing the full range of dynamic correlation effects .\none way to understand this difficulty is to consider that its number - operator - based jastrow factor , which is central to its stenciling strategy , @xcite can also be written as a very limited coupled cluster doubles operator .\n@xcite although sufficient for stenciling , this incomplete reproduction of the doubles operator only partially recovers dynamic correlation . in short , the hilbert space jastrow factor is effective at making large changes to the wave function through stenciling , but much less so at making the multitude of small changes demanded by dynamic correlation .\nin contrast , more traditional jastrow factors in real space , @xcite especially when working in tandem with diffusion monte carlo ( dmc ) , @xcite are renowned for their ability to capture dynamic correlation .\nindeed , this pairing has been employed as a reliable substitute for the `` gold standard '' coupled cluster with singles , doubles , and perturbative - triples ( ccsd(t ) ) @xcite in cases where the latter s higher cost scaling makes it untenable .\n@xcite    this dichotomy between jastrow factors strengths in real space and hilbert space raises the natural question : what is preventing the development of a jastrow factor that can deliver both the large changes required for stenciling and the small changes for dynamic correlation ?\nfurther : can these obstacles be overcome in a way that maintains both low - order polynomial scaling as well as suitability for use as as a dmc guiding function in strongly correlated regimes , where the best current option is to rely on a factorial - cost determinantal expansion ? in this paper , we will present a real space formulation that answers these questions in the affirmative , explain why previous real space jastrows were not able to live up to this ideal , demonstrate that jastrow - based stenciling can be effective even when the stenciled wave function is a single slater determinant , and offer some thoughts on the requirements that should be satisfied in future by a general - purpose stenciling jastrow .    the essential challenge to performing stenciling in real space\nis that any attempt to delete large portions of the wave function using a multiplicative jastrow factor will require its functional form to contain a high degree of curvature .\nsuch curvature is necessary , as any smooth function that asymptotes to a constant value at infinite distance ( as a jastrow factor should ) and contains little curvature will be similar to a constant , and multiplication by this nearly - constant function will not produce large changes in the wave function .    unless the large curvature needed for stenciling can be hidden in some way , its tendency to raise the kinetic energy will lead the variational principle to eschew jastrow - based deletion of undesirable configurations , even in cases where the functional form could accommodate it . to address this challenge\n, we present a new form of four - body jastrow factor that is better - suited to hiding its curvature in regions of low wave function value ( where it will not affect kinetic energy ) and to counting electrons within local regions of space ( the mechanism by which hilbert space jastrows achieve stenciling ) .\ncombined with traditional two - body jastrows , a slater determinant , and diffusion monte carlo , these real space number counting jastrow factors allow for an effective description of both static and dynamic correlation within a structure whose complexity is explicitly polynomial .\nlet us begin by reviewing hilbert space jastrow factors ( hsjfs ) , which may be written in terms of a matrix @xmath0 and the second quantized number operators @xmath1 within an orthonormal ( and typically local ) one particle basis , @xmath2 note that these can be thought of as four - body e - e - n - n jastrow factors , as the indices @xmath3 and @xmath4 run over orbitals that are localized at or near the nuclei while the results of operating with the number operators tell us about the positions of up to two different electrons .\nas number operators are idempotent and overall constant factors irrelevant , @xmath0 can be chosen such that the hsjf contains any number of gaussian factors @xmath5 for use in wave function stenciling .\napplication of one of these factors to a fermionic wave function effectively reweights each configuration in that wave function s expansion within this particular orbital basis according to a gaussian distribution in the total occupancy of an orbital subset @xmath6 .\nprovided that the `` projection strength '' @xmath7 is sufficiently large , such a gaussian factor acts as a stencil , removing any configuration in which the set of orbitals @xmath6 contains an electron count differing from @xmath8 .\ngiven two or more molecular fragments , this effect can be used to eliminate any configurations in which a fragment possesses an unphysical charge ( an `` ionic configuration '' ) , which turns out to be sufficient for restoring size consistency to a geminal power @xcite . crucially , this factor does nothing to components of the wave function which do not deviate from the prescribed pattern of subsystem electron counts , thus preventing the hsjf from raising the kinetic energy of configurations that survive the stencil .\nunfortunately , a direct translation of the hsjf into real space is problematic for qmc methods due to the nonlocal nature of a number operator s real space form , @xmath9 efficient stochastic interrogations of a wave function in real space hinge on the ability to evaluate local wave function values @xmath10 , which is complicated by the number operators nonlocality .\ninstead , we will seek a local function @xmath11 , associated with a region @xmath6 , enclosed within a jastrow factor of similar gaussian form @xmath12 that permits efficient local evaluation and , thanks to the sum over all the electron positions @xmath13 , maintains the bosonic symmetry required by the jastrow factor to keep the overall wave function correctly antisymmetric .    in order to mimic the effects of a hsjf\n, we therefore desire that each real space gaussian component approximate the effects of its hilbert space counterpart as closely as possible at any sampled position of the electrons ; thus we want @xmath14 where @xmath15 is the fermionic wave function that is to undergo stenciling .\nwhen basis orbitals in @xmath6 are spatially separated from others in the system  an ideal that is often approached in the localized physics of strong correlation  it is sufficient to choose @xmath11 as a step function : @xmath16 in which @xmath17 is a region exclusively supporting the orbitals in @xmath6 . to preserve smooth wave function derivatives and\nallow for a gradual approach to step like behavior in cases where orbital subsets are partially overlapping in space , we relax the step discontinuity at the boundaries of @xmath17 by employing an analytical approximation to the heaviside function ( see section [ sec::ncjf_form ] ) .\nso long as the smoothed form of q rapidly approaches 0 as one moves away from the boundary of @xmath17 , the jastrow factor of eq .\n( [ eqn : gauss_with_c ] ) retains the ability to precisely control the electron count on a subsystem that is spatially well - separated from other subsystems , as there is in this case ample room in between for the 1-to-0 switch to occur .\nthus , as with a hsjf , the real space form presented here can fully eliminate ionic terms between well - separated subsystems , allowing it to restore exact size consistency to geminal powers and to aid in the repair of restricted slater determinants .\nthe key question now becomes whether we can construct functional forms for @xmath11 that permit useful demarcations of spatial regions while also ensuring that the curvature they introduce can be hidden in regions where its contribution to the kinetic energy , through the term @xmath18 is mitigated by small local wave function amplitudes @xmath19 .\nthis is of course trivial when demarcating a region around a well - separated fragment , but becomes less so during dissociation events , where partial stenciling becomes beneficial long before the well - separated limit is reached .      before detailing our proposed form for a stenciling - friendly 4-body jastrow factor , it is instructive to consider why existing 4-body forms are ill - suited for this task .\nbegin by considering a previously used form @xcite for 4-body jastrows that closely mirrors that of a hsjf : @xmath20 by diagonalizing @xmath0 , choosing @xmath21 appropriately , and ignoring changes to wave function normalization , one may convert this jastrow into a product of gaussians , @xmath22 in which @xmath23 is the unitary matrix that diagonalizes @xmath0 .\nwritten this way , we may immediately identify the linear combination @xmath24 as one possible form for the counting function @xmath11 discussed in the previous section .\nwe may evaluate the suitability of 4-body jastrows of the type given in eq .\n( [ eqn:4body_form ] ) for use in hsjf - style stenciling by asking how easily these linear combinations can approximate a step function over a given region , and how much control they have over their curvature . by considering the task of controlling the electron count on a single atom\nwell - separated from the remainder of whatever system is being modeled , the above analysis makes plain that the two common forms for the basis functions @xmath25 , atom - centered gaussians @xcite and symmetric polynomials @xcite , are not effective for wave function stenciling in hilbert space . in the same way that one requires many fourier components to converge to a square wave , small gaussian expansions or low - order polynomial expansions are unable to faithfully approximate the switching behavior required for our jastrow basis functions .\nindeed , gaussian functional forms contain significant curvature at and about the atom s center where the wave function is large in magnitude , and thus can not engage in the curvature hiding necessary to avoid a rise in kinetic energy when @xmath26 is large , i.e.  in the strong stenciling regime .\nalthough it is true that in the infinite basis set limit , a complete set of functions ( such as the gaussian spherical harmonics ) can represent any smooth function , they will converge to the nearly steplike behavior required by @xmath11 only very slowly and so will retain appreciable curvature near the center of the counting region unless the jastrow basis is made extremely large .\nin practice , therefore , the functional forms within previously - studied 4-body jastrows were inappropriate for stenciling , and so , during optimization , the variational principle did not explore their ability to eliminate ionic terms , as doing so would have led to large , curvature - induced increases in the kinetic energy . ultimately , as can be seen in sorella s carbon dimer results @xcite , the price for using a jastrow basis that can not easily represent a step function is , in the context of the jagp , a size consistency error stemming from the inadequate suppression of ionic terms .\nwe investigate the efficacy of real space number - counting jastrow factors ( ncjfs ) that can be written in the same general structure as existing four - body jastrows , @xmath27 as discussed above , the key characteristic of ncjfs will lie in the choice of basis functions @xmath28 , for which we select a form that can , to a certain degree , act as local real space approximations to hilbert space number operators . in the limit of disjoint orbital subspaces , bosonic step functions in real space can exactly reproduce the effects of a sum of hilbert space number operators and can thus serve as a conceptual starting point for our basis functions .\nalthough we will soften this step - function extreme by employing smooth functions , we will retain the spirit of spatially localized curvature so as to facilitate the curvature hiding that ncjfs require in order to effect strong stenciling without unphysically affecting the kinetic energy .\nthis goal in mind , we propose `` counting '' basis functions of the form @xmath29 where the fermi - dirac - like function @xmath30 plays the role of an analytic approximation to the heaviside step function .\nthe value of @xmath31 asymptotically switches from zero to one as its argument traverses the origin , with @xmath32 ( which is _ not _ related to physical temperature ) determining both the slope at the origin as well as the effective width of the switching region in which @xmath31 meaningfully differs from zero or one and displays non - negligible curvature .\nthe interior function @xmath33 is a scalar - valued function of a real - space coordinate whose nodal surface defines the boundary , or switching surface , of the region within which electrons are to be counted . the volume for which @xmath34 takes on positive values ( negative values ) is called the interior ( exterior ) of the counting region , since composition with the switching function @xmath31 ensures that @xmath35 asymptotically evaluates to one ( zero ) inside this region .\nwe will refer to counting functions by the geometry of their switching surface , and in the present study we investigate both planar @xmath36 and elliptical @xmath37 counting regions .\nthe nodal surface of @xmath38 is a plane centered at @xmath39 and normal to the unit vector @xmath40 , while the nodal surface of @xmath41 is an ellipsoid with center @xmath39 and axes defined by the eigenvectors and eigenvalues of @xmath42 . together with @xmath31 , these counting regions provide us with a set of jastrow basis functions whose only curvature appears at the edges of their counting regions , making it more amenable to being hidden in regions of low wave function magnitude .\nthis positioning of curvature should be compared to the more traditional forms given in section [ sec::existing_jastrows ] , which display significant curvature at their centers .\nin addition to this stenciling - friendly curvature , arithmetic operations between these counting basis functions correspond to set operations between their interior volumes , which gives their sums and products a somewhat intuitive meaning .\nfor example , consider the large-@xmath32 limit of these counting functions , @xmath43 in which these functions revert to actual step functions .\nspatial regions complements now occur simply as @xmath44 while intersections @xmath45 and unions @xmath46 arise from products and sums of counting functions . in this way , the quadratic form in eq .\n( [ eqn : jcjf_4body_form ] ) offers the possibility for the full set of first - order topological operations to arise naturally during the variational minimization of a ncjf , raising interesting questions as to whether adjacent regions will merge or produce cutouts from one another in pursuit of optimal stencils .\nwe have prepared a pilot implementation supporting planar and elliptical ncjfs within a development version of qmcpack .\n@xcite ncjfs , as well as spline - based , cusp - correcting @xmath47-@xmath47 and @xmath47-@xmath48 two - body jastrows and the molecular orbital coefficients were optimized with respect to energy using the variational monte carlo ( vmc ) linear method @xcite . the hamiltonian is taken as the non - relativistic electronic hamiltonian under the born - oppenheimer approximation , with effective core potentials @xcite used to replace carbon atoms core electrons .\nrhf solutions are taken as the reference configurations at each geometry in the cc - pvtz basis @xcite and are generated by gamess@xcite .\nmultireference configuration interaction calculations with the davidson correction ( mrcisd+q ) were performed with @xcite also in the cc - pvtz basis .      in our results\n, we will distinguish wave functions based on the types of jastrow factors employed , whether or not the molecular orbitals were re - optimized in the presence of the jastrow , and , where applicable , whether the molecular orbitals are symmetric ( sa ) or have broken symmetry ( sb ) .\nthe presence of counting jastrows will be denoted by c , traditional spline - based @xmath47-@xmath47 and @xmath47-@xmath48 jastrows by t , and orbital re - optimization by the prefix `` oo- '' . in all cases\n, js stands for jastrow - slater .\nfor example , a jastrow - slater wave function with both traditional and counting jastrows whose orbitals were re - optimized starting from a broken symmetry orbital guess would be denoted as oo - ctjs - sb .\nfinally , dmc results will be denoted by adding dmc to the name of the wave function that fixes the nodal surface .      as a minimally correlated wave function ,\na single restricted slater determinant is insufficient to describe electron correlation at stretched molecular geometries , which can lead to large size - consistency errors during molecular fragmentation . to correct this\n, we apply a simple ncjf with a basis consisting of two anti - aligned planar counting functions whose switching surfaces are set to bisect the h - h bond . the ncjf matrix parameters @xmath49 and @xmath50 are initially set to zero ( so that the overall jastrow factor is initially unity ) , after which both the matrix parameters ( @xmath49 , @xmath50 ) and basis function parameters ( @xmath51 ) are optimized .\nfigures 1 and 2 show that ncjfs paired with either cusp - correcting jastrows ( ctjs ) , orbital optimization ( oo - cjs ) , or both ( oo - ctjs ) prove far more effective at recovering size - consistency than when only two - body jastrows ( tjs ) are used , even if assisted by orbital re - optimization ( oo - tjs ) . at a separation of 4  , for example\n, we find that oo - ctjs is size - consistent to within 0.4 me@xmath52 , while the smallest size - consistency error achievable without ncjfs is over 14 me@xmath52 .\na variationally optimized slater - jastrow ansatz is often taken as a guiding function for diffusion monte carlo calculations , but the appearance of symmetry - broken minimum - energy solutions to the rhf equations at stretched geometries  which do not possess the correct nodal structure required by dmc  means that we can not naively take minimum - energy configurations without issue .\nfor instance , when stretching the c = c bond in ethene past 2.5  , an rhf solution with broken - symmetry orbitals sees its rhf energy drop below that of the symmetric - orbital solution .\nhowever , the nodal surface of this broken - symmetry solution is incorrect , and so when used in dmc it gives an energy that is 40 me@xmath52 or more above that of a dmc based on the symmetric - orbital rhf solution ( see figure [ fig : figure3 ] ) .\nin more complicated systems , such effects can be more pronounced , and it would be highly desirable to be able to predict beforehand which nodal surface is most appropriate . given a sufficiently flexible trial function to optimize , vmc can in principle produce the correct nodal surface by selecting the vmc wave function with the lowest energy .     using a cc - pvtz orbital basis .\nthe solid black line is twice the vmc energy of a single h atom in the same cc - pvtz basis . ]     using a cc - pvtz orbital basis , now focusing on stretched geometries .\nthe solid black line is twice the vmc energy of a single h atom in the same cc - pvtz basis .\n]    however , this approach will only be reliable if the trial function is flexible enough , and in the case of ethene , traditional jastrow - slater is not , even under orbital re - optimization , as can be seen in figure [ fig : figure4 ] .\nalthough multiconfigurational expansions can be used in lieu of a single reference fermionic function in order to achieve the flexibility needed to describe the strong correlation responsible for flipping the energy ordering of these two states , the complexity and thus cost of such an expansion must grow exponentially with the number of correlated bonds .\nthe cost of a stenciling approach using ncjfs  assuming a constant number of counting basis functions per fragment  will by comparison scale only quadratically with fragment number , and so it would be quite useful if stenciling were able to capture a sufficient amount of strong correlation to produce the correct energy ordering of states at the vmc level .    using the same planar ncjfs as in the hydrogen case\n( except now the planes bisect the c = c bond ) , we apply ncjfs , orbital optimization , and traditional two - body jastrows to a single slater determinant that is either a symmetry - adapted ( sa ) or symmetry - broken ( sb ) rhf solution .\n( note that sa vs sb orbitals did not interconvert under orbital optimization and appear to represent two separate minima on the optimization surface . ) in the most flexible case , oo - ctjs , vmc is now correctly able to predict that the sa energy lies below that of the sb energy , a prediction that fails to materialize if the ncjf is omitted ( see figure [ fig : figure4 ] ) . upon using the oo - ctjs - sa and oo - ctjs - sb wave functions to fix the dmc nodal surface , we find that the lower - energy vmc state now corresponds to the lower energy dmc result , and that the lower energy dmc result is in close agreement with mrcisd+q ( see figure [ fig : figure5 ] ) .\nthus , in the case of the ethene double bond dissociation at least , the ncjfs ability to suppress spurious ionic terms within a single slater determinant is sufficient to produce a qualitatively correct state ordering and nodal surface without resorting to multi - determinantal expansions .\nfragment , with no jastrow factor ( rhf ) or with a cusp - correcting jastrow ( tjs ) , as indicated , and provide a reference for size - consistency . ]          using elliptical basis functions , we will demonstrate the size - consistency problem encountered with basis functions used previously in four - body jastrow factors .\nas noted earlier , the main problem associated with taking atom - centered gaussian functions as the jastrow basis lies in their inability to effectively hide their curvature in regions where wave function values are small .\nwe reproduce this effect in ethene at a stretched geometry ( 4.5  ) by changing our jastrow basis from c = c bond - bisecting planes to a set of elliptical counting functions in which we scan over an axis scaling parameter @xmath53 while keeping one elliptical edge orthogonally bisecting the c = c bond axis .\nncjf parameters ( @xmath0 , @xmath21 , @xmath32 ) are fixed at values optimal for planar counting functions , which allows us to reproduce the behavior of the planar basis as we increase the axis scale ( at large values of @xmath53 ) .\nthis gives us a suitable baseline to compare the elliptical and planar jastrow basis at different geometries , and , as we expect , vmc energies match reasonably well when each elliptical counting function encompasses an entire ch@xmath54 fragment .\nhowever , as we shrink the elliptical switching surface to only partially encompass each fragment , figure [ fig : figure6 ] shows that the overall energy increases , which can be explained by the fact that the curvature at the edge of the elliptical counting region is now cutting through a region with appreciable wave function magnitude .\nfor jastrow basis functions like these too - small ellipses , the risk of such energetic penalties prevents the variational principle from allowing the elements of the jastrow matrix @xmath0 to become large in magnitude , thus precluding any stenciling - like effects . when instead the basis function allows for curvature hiding , as when the ellipse is large enough so that its edges are outside the boundaries of the ch@xmath54 fragment , the variational principle is free to restore size - consistency by using large - magnitude @xmath0 elements to delete spurious ionic terms .\nwhile we have shown that the combination of suitably chosen jastrow basis functions with a general 4-body jastrow factor form can successfully introduce strong correlation effects through the stenciling of ionic terms , a generally applicable method requires some rule or prescription for how the jastrow counting functions are to be chosen for an arbitrary molecule .\nlet us discuss and discard two options based on the current planes and ellipses before motivating future work with some observations on the properties that a general ncjf basis should satisfy .\nfirst , one might choose to place planar counting functions so as to bisect each bond in a molecule .\nsuch an approach would prepare the ansatz for suppressing unwanted ionic terms in any given bond , but the infinite extent of the planes would clearly not in general satisfy the requirement that the counting function s curvature be hidden in regions of small wave function magnitude .\nwhat if the plane from one bond intersects a far - away atom ?    .\nas @xmath53 is increased , the ellipses grow in size until eventually encompassing an entire ch@xmath54 fragment , with vertical lines showing the values of @xmath53 at which the ellipses outer surfaces cut directly across an atomic nucleus .\nthe horizontal black line indicates the vmc energy of planar counting regions , which should serve as a lower bound for the energy in the @xmath55 limit . ]\nsecond , one could consider using atom - centered ellipsoids for the counting regions , hoping to take advantage of set operations to generate unions of elliptical counting regions where necessary to encompass an overall fragment . while this scheme sounds more promising ,\nthe data presented in figure [ fig : figure7 ] show that in practice , such set operations do not work out cleanly .\nthe trouble in this case is due to the fact that the optimal switching functions are much smoother than sharp step functions ( which would have dire kinetic energy consequences ) , and so clean set operations to create a union of neighboring counting regions are not achievable within the chosen 4-body form of the overall ncjf . while the symmetry of ethene still allows for the eliminate ionic terms via an @xmath0 that suppresses terms in which the left - hand and right - hand fragments not - quite - correctly - unioned counting regions give differing electron counts , the imperfections in the union create residual jastrow curvature in between the c and h atoms where the wave function magnitude is not small .\nthis residual curvature increases the kinetic energy of the neutral terms that survive the stenciling process , and it appears from the results in figure [ fig : figure7 ] that this effect is large enough that the variational principle instead chooses to eschew strong suppression of ionic terms .\nthe difficulties in the above two schemes highlight the properties that should be sought in future for general - purpose ncjf basis functions .\nfirst , the function should be finite in spatial extent , so that when used for stenciling in one region they do not unduly affect the kinetic energy in distant parts of the molecule .\nsecond , the functions must be capable of clean set operations so that they can combine when necessary to form a counting region around a group of atoms .\nfinally , they must remain efficiently evaluable for a randomly chosen configuration of the electrons so as not to disrupt the algorithmic requirements of vmc .\nalthough the presently tested planes and ellipsoids do not meet all of these requirements , the success of fragment - encompassing counting regions in the challenging dissociation of ethene provides strong motivation to search for a formulation that does .\nwe have demonstrated that 4-body real space jastrow factors are , with a suitable choice of jastrow basis functions , capable of performing strong wave function stenciling , in which a multiplicative jastrow factor makes a large change to the wave function by deleting unphysical configurations from a simple but overabundant fermionic reference . in particular , these jastrow factors are capable of eliminating ionic terms between well - separated molecular fragments , which restores exact size consistency to the geminal power and greatly improves the situation for restricted slater determinants , bringing real space jastrows in line with the size - consistency - restoring properties already enjoyed by hilbert space jastrows . unlike their hilbert space brethren , the real space jastrows presented here are compatible with diffusion monte carlo , which creates exciting possibilities for generating qualitatively correct nodal surfaces in strongly correlated regimes with a variational monte carlo approach that is both polynomial cost and size consistent . indeed ,\nour preliminary results show that , when equipped with these stenciling - capable jastrow factors , the variational minimization of a single reference jastrow - slater trial function produces a qualitatively correct nodal surface during the double bond dissociation of ethene , which in turn leads diffusion monte carlo to produce an accurate potential energy curve . as every step in this process has a polynomially scaling cost , it will be very exciting in future to test the efficacy of this combination in larger and more strongly correlated settings .\nthe key development allowing for effective stenciling was the introduction of a new form of 4-body jastrow basis function , in which a smoothed indicator function is used to check whether or not each electron is within a given region of space .\nthese basis functions thereby allow the overall jastrow factor to count and control how many electrons are in a given region , which in turn allows for the suppression of unwanted ionic configurations .\nunlike previously explored basis function forms , these counting functions have no curvature except at the boundary of their spatial region , allowing them to participate in strong stenciling so long as the boundaries are arranged so as to hide their curvature in regions of small wave function magnitude .\nin contrast , gaussian - type basis functions have significant curvature at their centers , leading to kinetic energy changes that prevent effective stenciling .\nthe most pressing priority in the future development of these number counting jastrow factors is to formulate them in a way that permits for black - box treatments of arbitrary molecules in which the variational principle can decide automatically how to demarcate important regions in which to count and control electron number .\nalthough the planar and elliptical forms used in this study do not appear to support this black - box ideal , research into promising alternatives is underway .\nwe acknowledge funding from the office of science , office of basic energy sciences , the us department of energy , contract no .\nde - ac02 - 05ch11231 .\ncalculations were performed using the berkeley research computing savio cluster ."}
{"lay_summary": " we show how one can measure anomalous @xmath0- and @xmath1-couplings with minimal statistical error using integrated observables , without having to assume that the anomalous couplings are small . \n we propose a parametrisation of these couplings which is well suited for the extraction of both single and many parameters , and which leads to a very simple form of the integrated cross section , from which additional information on the couplings can be obtained .    \n hd  \n thep9703 + cpth  \n s4940197    anomalous three gauge boson +   m. diehl + _ department of applied mathematics and theoretical physics + silver street , cambridge cb3 9ew , great britain + present address : + centre de physique thorique + ecole polytechnique , f-91128 palaiseau cedex , france _ + and + o. nachtmann + _ institut fr theoretische physik + philosophenweg 16 , d-69120 heidelberg , germany _ ", "article": "the direct and precise measurement of the self - coupling between the electroweak gauge bosons in @xmath2-pair production will be a crucial step in testing the standard model of electroweak interactions and searching for physics beyond it .\nit will form an important part of the physics programme at lep2 and at a planned linear @xmath3-collider ( lc ) .\nas is well known there are three diagrams at tree level that contribute to the amplitude of @xmath4 in the standard model , one with @xmath5-channel neutrino exchange and the other two with a @xmath6 or @xmath7 in the @xmath8-channel , involving the vertices @xmath1 and @xmath0 .\none can parametrise the corresponding vertex functions in order to quantify the couplings and to compare them with their form in the standard model . in the most general form respecting lorentz covariance\neach vertex involves seven complex form factors @xcite , three of which give couplings that violate @xmath9 symmetry .    without further physical assumptions one\nis thus left with 28 real parameters whose simultaneous extraction in one experiment looks quite hopeless . given the limited event statistics expected at both lep2 and the lc one will only obtain meaningful errors on a reduced number of coupling parameters at one time .\nthis may be achieved by imposing certain constraints on the full set of coupling constants ; various suggestions for such constraints based on symmetry considerations have been made in the literature @xcite .\none must however keep in mind that experimental values or bounds on couplings that have been obtained with particular constraints can not be converted into results without constraints or with different ones ; the information lost by assuming relations between couplings can not be retrieved .\nalthough imposing such constraints is certainly legitimate and can be useful we stress that a data analysis with independent couplings will be valuable , both from the point of view of model independence and the capability to compare results of different experiments .\nwe remark that of course one can also give ( reasonably small ) errors on _ single or few _ couplings in a multi - parameter analysis . in this paper\nwe propose a parametrisation of the couplings which is well adapted to this end , the statistical errors on the different measured parameters being approximately uncorrelated .\nwe will work in the framework of optimal observables , a way to extract unknown coupling parameters introduced for the case of one parameter in @xcite that has since been used for various reactions @xcite .\ngeneral aspects of this method , in particular its extension to an arbitrary number of parameters , as well as its application to @xmath10 production were discussed in @xcite . in this paper\nwe investigate again the reaction @xmath11 .\nwe concentrate here on the decay channels , where one @xmath2 decays hadronically and the other into an electron or muon and its neutrino . calculated with the born level cross section of the standard model the statistics of these channels\nis about 3000 events for a collision energy of @xmath12 and @xmath13 integrated luminosity , which are typical planned lep2 parameters , and about 22000 events with @xmath14 at @xmath15 , which might be achieved at the lc .\na complementary source of information is the integrated cross section , which is a quadratic function of the triple gauge couplings .\nthe combination of information from the total event rate and from observables that make use of the detailed distribution in the final state has for example been used in @xcite , where @xmath9 violation in the decay @xmath16 was investigated .    in sec .\n[ sec : method ] of this paper we will further develop some aspects of the method of optimal observables , in particular we will show how to apply it without the linear approximation in the coupling parameters that was used in @xcite . in sec .  [ sec : diagon ] we then propose a parametrisation of the couplings that simultaneously diagonalises certain matrices connected with our observables and with the integrated cross section .\nthese parameters achieve two goals : their quadratic contribution to the total cross section is a simple sum of squares and the covariance matrix of the corresponding optimal observables is diagonal . the methods which we use for this purpose\nare borrowed from the theory of small oscillations of a system with @xmath17 degrees of freedom ( cf .\ne.g.  @xcite ) .\nour parameters correspond to `` normal coordinates '' and their use in an experimental analysis should in our view present several advantages .\nwe give some numerical examples for @xmath2-pair production at lep2 and the lc in sec .\n[ sec : numeric ] and make some further remarks on how our proposal might be implemented in practice in sec .\n[ sec : practice ] .\nthe last section of this paper gives a summary of our main points .\nthe method of optimal observables has previously been presented in the approximation that the couplings to be extracted are sufficiently small to allow for a leading order taylor expansion of various expressions . here\nwe show how to use it beyond this approximation .\nlet us denote by @xmath18 the real and imaginary parts of the @xmath1 and @xmath0 form factors minus their values in the standard model at tree level .\nas the amplitude of our process is linear in these couplings we can write the differential cross section as @xmath19 where @xmath20 is a positive semidefinite symmetric matrix .\n@xmath21 collectively denotes the set of measured phase space variables .\nthe integrated cross section is @xmath22 with the standard model cross section @xmath23 and coefficients @xmath24 the idea of using integrated observables is to define suitable functions @xmath25 of the phase space variables and to extract the unknown couplings from their measured mean values @xmath26 .\nlet us give the details . from ( [ diffxsection ] ) and ( [ intxsection ] ) we obtain the expectation value @xmath27 $ ] of @xmath28 as @xmath29 - e_0[{{\\cal o}}_i ] = \\frac{\\displaystyle \\sum_{j } c_{ij } \\ , g_j      + \\sum_{jk } q_{ijk } \\ , g_j g_k}{\\displaystyle 1 + \\sum_{j }      { \\hat{\\sigma}_{1,j } } \\ , g_j + \\sum_{jk } { \\hat{\\sigma}_{2,jk } } \\ , g_j g_k}\\ ] ] with the standard model expectation value @xmath30 = ( \\int d\\phi \\ , { { \\cal o}}_i\ns_0 ) / \\sigma_0 $ ] and coefficients @xmath31 \\ , { \\hat{\\sigma}_{1,j } }   { \\hspace{6pt},}\\nonumber \\\\    q_{ijk } & = & \\frac{1}{\\sigma_0 } \\int d\\phi \\ , { { \\cal o}}_i s_{2,jk } -    e_0[{{\\cal o}}_i ] \\ , { \\hat{\\sigma}_{2,jk } } { \\hspace{6pt}.}\\end{aligned}\\ ] ] we remark in passing that the coefficients in ( [ expect ] ) can be written in a compact form as @xmath32 { \\hspace{6pt},}\\hspace{3em }    q_{ijk } { \\hspace{0.4em } = \\hspace{0.4em}}v_0[{{\\cal o}}_i \\ , , \\ ; s_{2,jk } /s_0 ] { \\hspace{6pt},}\\nonumber \\\\    { \\hat{\\sigma}_{1,j } } & = & e_0[s_{1,j } /s_0 ] { \\hspace{6pt},}\\hspace{4.4em }    { \\hat{\\sigma}_{2,jk } } { \\hspace{0.4em } = \\hspace{0.4em}}e_0[s_{2,jk } /s_0 ] { \\hspace{6pt},}\\end{aligned}\\ ] ] where @xmath33 = e_0[f g ] - e_0[f ] \\ , e_0[g]$ ] is the covariance of @xmath34 and @xmath35 in the standard model .\nnote that @xmath36 is symmetric and positive definite , whereas @xmath37 as a matrix in @xmath38 and @xmath39 is symmetric but in general indefinite .\nan estimation of the couplings can now be obtained by solving the system ( [ expect ] ) with @xmath27 $ ] replaced by the mean values @xmath26 , @xmath40 = \\frac{\\displaystyle \\sum_{j } c_{ij } \\\n, g_j      + \\sum_{jk } q_{ijk } \\ , g_j g_k}{\\displaystyle 1 + \\sum_{j }      { \\hat{\\sigma}_{1,j } } \\ , g_j + \\sum_{jk } { \\hat{\\sigma}_{2,jk } } \\ , g_j g_k }   { \\hspace{6pt},}\\ ] ] provided of course one has @xmath41 observables for @xmath41 unknown couplings .\nwhen the system ( [ mean ] ) is linearised in the @xmath18 it is easily solved by inversion of the matrix @xmath42 .\none is however not constrained to do so and can instead solve the exact set of equations ( [ mean ] ) . by multiplication with the denominator\nit can be rearranged to a coupled set of quadratic equations in the @xmath18 and will in general have several solutions .\nsome of these may be complex and thus ruled out , but from the information of the @xmath43 alone one can not tell which of the remaining real ones is the physical solution .\nwe will come back to this point .\nthe measured mean values @xmath43 are of course only equal to the @xmath27 $ ] up to systematic and statistical errors .\nwe only consider the latter here , which are given by the covariance matrix @xmath44 of the observables @xmath28 divided by the number @xmath45 of events in the analysis .\nto convert the errors on the observables into errors on the extracted couplings we use the quantity @xmath46 \\right ) n    v({{\\cal o}})^{-1 } { } _ { ij } \\left ( { \\bar{{{\\cal o}}}}_j - e[{{\\cal o}}_j ] \\right ) { \\hspace{6pt},}\\ ] ] which depends on the @xmath18 through the @xmath27 $ ] given in ( [ expect ] ) .\nsolving ( [ mean ] ) is tantamount to minimising @xmath47 with @xmath48 , and a confidence region on the couplings is as usual given by @xmath49 with the constant determined by the desired confidence level .\nthere are several possible choices for the covariance matrix @xmath50 in ( [ chi ] )\n. it can be    1 .\ndetermined from the measured distribution of the observables @xmath28 , 2 .\ncalculated from the differential cross section ( [ diffxsection ] ) , taking for the @xmath18 the values extracted in the measurement , 3 .\ncalculated for vanishing couplings @xmath18 , 4 .\ncalculated as a function of the couplings .\nchoices 1 .  and 2 .\nshould lead to the same results in the limit of large @xmath45 where the statistical errors on the measured @xmath44 and @xmath18 become small .\ncomparison of the covariance matrices obtained by these two methods might indeed be helpful to rule out unphysical solutions of ( [ mean ] ) .\n.  in turn will be a good approximation of 2 .\nif the couplings are small enough . we consider possibility 4 .  as the least practical one , except maybe for the case of one coupling . for several couplings\nthe expression of @xmath44 as a function of the @xmath18 involves tensors of rank up to four and is even more complicated than the one for the expectation values ( [ expect ] ) , and the inverse matrix is yet more clumsy . for this reason we will discard choice 4 .  in the following .    in @xcite\nwe considered an analysis at leading order in the @xmath18 , where one uses the linearised form of ( [ mean ] ) to estimate the couplings : @xmath51 \\right )   { \\hspace{6pt}.}\\ ] ] correspondingly the linear approximation of ( [ expect ] ) is used in the expression ( [ chi ] ) of @xmath47 which then reads @xmath52 where @xmath53 is the inverse covariance matrix of the estimated couplings @xcite . as one works to leading order in the @xmath18\none can approximate @xmath50 by its value for zero couplings , i.e.  choose possibility 3 .  above .\nthe confidence regions @xmath54 for the measured couplings are then ellipsoids in the space of the @xmath18 with centre at @xmath55 .\nthe optimal observables @xmath56 discussed in @xcite have the property that to leading order the statistical errors on the estimated couplings are the smallest possible ones that can be obtained with _ any _ method , including e.g.  a maximum likelihood fit to the full distribution of @xmath21 given by the differential cross section ( [ diffxsection ] ) .\nnote that one can still use the linearised expressions ( [ linearestim ] ) and ( [ linearchi ] ) in an analysis beyond leading order .\nthe error @xmath57 on the couplings will be given by an ellipsoid with defining matrix ( [ couplingscov ] ) , where @xmath50 is the covariance matrix at the actual values of the couplings .\nthese errors will in general no longer be optimal , so that when the leading order approximation is not good one might obtain better errors with a different choice of observables .\nmore importantly , however , the extracted values of the couplings are biased : averaged over a large number of experiments the measured couplings differ from the actual ones by terms quadratic in the @xmath18 .\nif instead one uses the full expressions ( [ expect ] ) , ( [ mean ] ) and ( [ chi ] ) one has no bias on the extracted coupling parameters , provided the number @xmath45 of events in the analysis is large enough . let us see if we can find optimal observables for this case . to this end\nwe expand the differential cross section around some values @xmath58 of the couplings : @xmath59 the corresponding zeroth order cross sections and mean values are @xmath60 and @xmath61 = ( \\int d\\phi \\ , { { \\cal o}}_i \\widetilde{s}_0 ) / \\widetilde{\\sigma}_0 $ ] , respectively\n. we then can re - express @xmath27 $ ] in ( [ expect ] ) , replacing @xmath18 with @xmath62 , @xmath63 with @xmath64 , and using new coefficients @xmath65 etc .\nconstructed as in ( [ xsectioncoeffs ] ) , ( [ obscoeffs ] ) . making the same replacements in ( [ mean ] ) we have an alternative set of equations to extract the coupling parameters .\nit can be shown that for sufficiently large @xmath45 the confidence regions obtained from ( [ chi ] ) , ( [ confidence ] ) in a nonlinear analysis are again ellipsoids given by @xmath66 one can then write @xmath67 as in ( [ linearchi ] ) , but with @xmath68 of ( [ couplingscov ] ) replaced by @xmath69 where @xmath70 corresponds to an expansion ( [ newdiffxsection ] ) of @xmath71 about the _ actual _ values of the couplings .\nthe main point of the argument is that for large @xmath45 the statistical errors on the @xmath26 become small , so that the extracted couplings will be sufficiently close to the actual ones to allow for a linearisation of ( [ expect ] ) and ( [ mean ] ) , cf .\n@xcite , p.695 , and @xcite .\nfinally one can construct new observables @xmath72 from ( [ newdiffxsection ] ) .\nthey will be optimal , i.e.  have minimum statistical error if the @xmath58 are equal to the actual values of the @xmath18 . in the appendix\nwe show that , up to linear reparametrisations given in ( [ reparam ] ) , this is the only set of @xmath41 integrated observables that measures the @xmath41 couplings with minimum error .\nthere is hence no choice of observables that would be optimal for _ all _ values of the actual coupling parameters . as these\nare unknown one can in practice not write down the truly `` optimal '' observables , but our argument tells us how one can improve on the choice in ( [ optimal ] ) if one has some previous estimates @xmath58 of the couplings ( cf .\nalso @xcite ) .\none may then choose to perform a leading order analysis as described above , linearising about @xmath73 instead of @xmath74 .\na practical way to proceed could be to estimate the parameters @xmath18 at first using the linearised method around @xmath75 .\nsuppose this gives as best estimate some values @xmath76 .\nthen in a second step one could set @xmath77 and use the linearised method around @xmath78 to improve the estimate etc .    at this point\nwe wish to comment on the `` optimal technique '' for determining unknown parameters in the differential cross section that has been proposed in @xcite .\nthe `` weighting functions '' @xmath79 there depend on the actual values of the parameters one wants to extract and are thus not `` observables '' . only if one sets the unknown parameters in the @xmath79 equal to some previous estimates of them can one use these functions to weight individual events ; the better these estimates are the more sensitive the functions will be . if one does this then the set @xmath79 is equivalent to our observables ( [ newoptimal ] ) defined for some estimates @xmath58 of the coupling parameters .\nwe finally remark that if @xmath45 is not large enough the statistical errors on the mean values @xmath26 and thus on the measured couplings might be so large that they lead into a region where a linearisation of ( [ expect ] ) is not a good approximation .\nthe covariance matrix @xmath80 is then no longer given by ( [ newcouplingscov ] ) .\nmoreover the errors on the couplings might be asymmetric and the shape of the confidence region defined by ( [ chi ] ) , ( [ confidence ] ) very different from an ellipsoid , so that knowledge of @xmath80 is not sufficient to estimate the errors on the @xmath18 . in such a case\nwe can not say on general grounds how sensitive our observables are .\nincidentally this also holds for other extraction methods such as maximum likelihood fits , whose optimal properties are realised in the limit @xmath81 .\nif one is rather far from this limit the sensitivity of a method will have to be determined by other means , e.g.  by detailed monte carlo simulations .\nthe method we have outlined can of course also be applied if one chooses to reduce the number of unknown parameters by imposing certain linear constraints on the couplings .\none may still use the observables ( [ optimal ] ) corresponding to the _ full _ set of couplings but minimise @xmath47 in ( [ chi ] ) for the _ reduced _ set ; in this case one can of course not take choice 2.for @xmath50 . in general @xmath82 is then different from zero and its value indicates to which extent the particular constraints on the couplings are compatible with the data .\nif @xmath45 is large enough @xmath82 follows in fact a @xmath47-distribution with @xmath83 degrees of freedom for @xmath41 observables and @xmath84 independent couplings so that its value can be converted into a confidence level @xcite .\nwe conclude with a remark on the use of optimal observables in practice\n. a realistic data analysis will not be good enough if the born approximation of the differential cross section ( [ diffxsection ] ) is used .\nboth higher - order theoretical corrections , such as initial state radiation and the finite @xmath2 width , and experimental effects like detection efficiency and resolution will modify the observed distribution of the phase space parameters @xmath21 .\nif they are taken into account in the determination of the coefficients in ( [ expect ] ) , ( [ mean ] ) and of the covariance matrix @xmath50 they will _ not _ lead to any bias in the extraction of the couplings and their errors . while this will presumably be done with sets of generated events and\nmight be computationally intensive one still has to determine only a rather limited number of `` sensitivity '' constants . on the other hand one needs to know the observables @xmath25 of ( [ optimal ] ) as functions over the entire experimental phase space ,\nso that the expressions of @xmath85 and @xmath86 used to construct them will in practice be taken from a less sophisticated approximation to the actual distribution of @xmath21 in order to keep them manageable .\nthe observables are then no longer optimal , and it will depend on the individual case which approximations of @xmath85 , @xmath86 are good enough to obtain observables with a sensitivity close to the optimal one .      in @xcite it was shown how with a suitable combination of all semileptonic @xmath87 decay channels one can define observables that are either even or odd under the discrete transformations @xmath9 and @xmath88 , where @xmath89 denotes charge conjugation , @xmath90 the parity transformation , and @xmath91 the `` naive '' time reversal operation which flips particle momenta and spins but does not interchange initial and final state . under the conditions on the experimental setup and event selection spelt out in @xcite we have two important symmetry properties :    1 .\na @xmath9 odd observable can only have a nonzero expectation value if @xmath9 symmetry is violated in the reaction .\n2 .   if the expectation value of a @xmath88 odd observable is nonzero the transition amplitude must have an absorptive part whose phase must satisfy certain requirements in order to give an interference with the nonabsorptive part of the amplitude .\nwe assume in this analysis that any nonstandard physics in the reaction is due to the triple gauge vertices . in the standard model one needs at least two loops to violate @xmath9 ; to a good accuracy the triple gauge couplings are therefore the only possible source of @xmath9 violation . for our process ,\ni.e.  @xmath3 annihilation into four fermions , an absorptive part that satisfies the requirements mentioned in point 2 .  will appear in the standard model already at next - to - leading order in the electroweak fine structure constant , either through nonresonant diagrams or through loop corrections . to leading order , however , they are only due to the imaginary parts of triple gauge couplings .    in this approximation the optimal observables ( [ optimal ] ) are @xmath9 even ( odd ) if they correspond to @xmath9 conserving ( violating ) couplings , and @xmath88 even ( odd ) if they correspond to the real ( imaginary ) parts of form factors .\nthe coefficient matrix @xmath92 is then block diagonal in four symmetry classes of observables and three - boson - couplings :    1 .\n@xmath9 and @xmath88 even 2 .\n@xmath9 even and @xmath88 odd 3 .\n@xmath9 odd and @xmath88 even 4 .\n@xmath9 and @xmath88 odd .    in the leading order analysis one\nthus can treat these four classes of couplings separately and benefit from a great reduction of unknown parameters . beyond leading order , however , form factors of any symmetry can contribute to @xmath27 $ ] :    * in the integrated cross section and thus in the denominator of @xmath27 - e_0[{{\\cal o}}_i]$ ] in ( [ expect ] ) couplings of all four classes enter quadratically , couplings of class @xmath93 also appear linearly ; * if @xmath28 belongs to class @xmath93 the numerator of @xmath27 -    e_0[{{\\cal o}}_i]$ ] has terms linear in the couplings of this class but couplings of all four classes enter quadratically through @xmath94 ; * if @xmath28 belongs to a @xmath9 ( @xmath88 ) odd coupling then the numerator in ( [ expect ] ) is only linear in @xmath9 ( @xmath88 ) odd couplings , but it contains also quadratic terms where a @xmath9 ( @xmath88 ) odd coupling is multiplied with a @xmath9 ( @xmath88 ) even one .\nwe remark that this leads to different behaviours of @xmath27 $ ] as one or more couplings @xmath18 become large : whereas for observables in classes @xmath95 , @xmath96 and @xmath97 the expectation value goes to zero when a coupling of the same class goes to plus or minus infinity the corresponding limit of an observable in class @xmath93 can be a positive or negative constant or zero .    in a nonlinear analysis one\nwill therefore in principle have to consider couplings with all symmetries at the same time . in practice one might choose simpler procedures if the linear approximation is expected to be not too bad and if one wants to calculate corrections to it .\none might for instance first analyse the four symmetry classes separately , neglecting in each case the contributions of the three other classes at the r.h.s .\nof ( [ mean ] ) and then refine the analysis of a class by taking the values obtained in the first step for the couplings in the other classes as fixed in ( [ mean ] ) .    we emphasise that even beyond the leading order approximation it is still true that a nonzero mean value of a @xmath9 or a @xmath88 odd observable is an unambiguous sign of @xmath9 violation or the presence of absorptive parts in the process , respectively . the extraction of the values of the couplings , however , becomes more involved than in leading order .\nwe shall now propose a method to analyse the data which presents several advantages in view of the basic problem posed by the large number of unknown three - boson couplings : with limited event statistics significant error bounds can only be obtained for subsets of the coupling parameters , but imposing constraints on the couplings to reduce their number entails a loss of information that can not be retrieved . in view of this\nit should be advantageous to use a parametrisation of the couplings which in a given process and at a given c.m .\nenergy has the following properties :    1 .\nit allows to find observables which are only sensitive to one particular coupling parameter .\n2 .   the induced errors on the couplings determined from these observables are statistically independent .\nwith this we can on the one hand give single errors for each parameter , on the other hand we can recover from the single errors the multidimensional error of the full set of couplings , having avoided the loss of information incurred by imposing constraints . from the single errors we can also directly see which combinations of couplings in more conventional parametrisations can be measured with good accuracy and to which one is rather insensitive .\nlet us remark that in the leading order analysis there is a set of observables satisfying point 1 .  in _ any _ parametrisation of the couplings .\nthe linear combinations @xmath98 of our optimal observables ( [ optimal ] ) are only sensitive to @xmath18 for each @xmath99 ( cf .  also @xcite ) .\nthe errors on the couplings determined from these observables are , however , in general not uncorrelated ; in fact their correlations are the same as those obtained with the original set @xmath28 .\nthis can be seen as follows : going from the @xmath28 to the @xmath100 we must replace @xmath101 so that we have from ( [ couplingscov ] ) @xmath102 in such a case the single errors give an incomplete picture of the situation if correlations are large .\nthis is illustrated in fig .\n[ fig : correlations ] @xmath93 , where the 1@xmath103 ellipsis for two parameters is shown .\ntheir single errors are given by its projection on the coordinate axes and in our example are both rather large .\nsome linear combinations of them are however measurable with much better precision , which one can only recognise if both errors and their correlations are given . in fig .\n[ fig : correlations ] @xmath95 where a set of couplings leading to uncorrelated errors is used the situation is much simpler .\nnote also that the number of correlations , i.e.  off - diagonals in @xmath80 , is yet modest for two couplings but increases rapidly with their number .\n( 0,0 )    ( 5502,3031)(889,-4805 ) ( 1981,-2401)(0,0)[lb ] ( 5131,-2401)(0,0)[lb ] ( 6391,-3706)(0,0)[lb ] ( 3241,-3706)(0,0)[lb ] ( 1116,-2006)(0,0)[lb ] ( 4176,-2006)(0,0)[lb ]    we will now first see that a parametrisation of the couplings satisfying both points 1 .  and 2 .\nabove can be found in idealised circumstances , and then mention the restrictions one will encounter under more realistic assumptions .\nif the leading order analysis is a sufficiently good approximation the solution to our problem is easily found .\nstarting from a set of couplings @xmath18 and the corresponding optimal observables @xmath28 in ( [ optimal ] ) we can go to another set @xmath104 by @xmath105 where we use vector and matrix notation .\nthe coefficients in the expansion of the differential cross section and the optimal observables transform as follows : @xmath106 let now @xmath28 be an arbitrary set of observables related to @xmath18 and define the corresponding @xmath107 related to @xmath104 as in ( [ obstransf ] ) .\nthen we have for the matrices relevant for our analysis the following transformation properties : @xmath108 as shown in @xcite our optimal observables satisfy @xmath109 and @xmath110 so that for them one can choose a transformation @xmath111 which diagonalises all three matrices .\nthis new set @xmath112 of parameters obviously has the properties 1 .  and 2 .\nwe were looking for .    beyond the linear approximation of ( [ expect ] ) the expectation value of @xmath107\nwill still receive contributions from several couplings .\nin fact there is no set of observables for which the full nonlinear expression in ( [ expect ] ) satisfies point 1 .\nexactly , because the denominator involves quadratic terms in _ all _ couplings , and this can not be changed by any linear transformation of the couplings .\nif on the other hand the statistical errors are too large the covariance matrix @xmath80 will not give a good picture of the errors as we discussed in sec .\n[ sec : method ] , and its diagonalisation will not ensure point 2 . in the case\nhowever where nonlinear effects in the determination of the couplings and their errors are not too large , i.e.  where the leading order expressions are a good first approximation both points 1 .  and 2 .\nabove will still be _ approximately _ satisfied in a full nonlinear analysis .\nwe remark that if one has some previous estimates @xmath58 of the couplings that considerably deviate from zero one may reduce nonlinear effects in the determination of the @xmath18 by working with an expansion of @xmath113 around the @xmath58 as shown in sec .\n[ sec : method ] ; in our diagonalisation programme one will then use couplings @xmath114 instead of @xmath18 , the matrix @xmath70 instead of @xmath115 etc .    to the extent that the observables ( [ optimal ] ) are constructed from expressions of @xmath85 and @xmath116 which are only approximations of those that determine the experimentally observed kinematical distribution\nthe matrices @xmath115 , @xmath50 and @xmath117 will not quite be the same and can not be diagonalised at the same time .\none can then diagonalise either @xmath50 or @xmath68 because they are by definition symmetric and positive definite , whereas @xmath115 is not necessarily so . again , unless such effects are large one will end up with a matrix @xmath118 that is not diagonal but has relatively small off - diagonals .    it should also be borne in mind that the covariance matrix @xmath80 only gives the statistical errors on the couplings , so that even if it is exactly diagonal the final errors may be correlated due to systematics .      the choice of transformation in ( [ couplingstransf ] ) to ( [ matrixtransf ] ) is not unique if one does not require @xmath111 to be orthogonal .\nwe see in fact no strong argument in favour of an orthogonal transformation and remark that the various parametrisations of the @xmath1 and @xmath0 couplings in the literature are related by non - orthogonal linear transformations .\nthe freedom to choose @xmath111 can be used to impose additional conditions on the transformation , and the one we propose here is that the transformed quadratic coefficient @xmath119 in the integrated cross section be the unit matrix . in terms of the new couplings one then has @xmath120 where we choose the numbering such that @xmath121 to @xmath122 belong to symmetry class @xmath93 introduced in sec .\n[ sec : symmetries ] , i.e.   they are the @xmath9 and @xmath88 even couplings .\nonly these appear linearly in the cross section , whereas all couplings give a quadratic contribution with coefficient one .\nhaving @xmath123 leads to a convenient simplification of ( [ expect ] ) , ( [ mean ] ) .\nmoreover , the measurement of the total cross section gives complementary information on the unknown couplings . rewriting ( [ xsectransf ] ) as @xmath124 we see that measuring a cross section @xmath125 within an error @xmath126 constrains the couplings to be in a shell between two hyperspheres with centre at @xmath127 in the space of all couplings as shown in fig .\n[ fig : shell ] .\ntheir radii are given by @xmath128 here @xmath129\\ ] ] is the smallest value the cross section can attain ; that such a minimum exists has been pointed out in @xcite .\nif in ( [ radii ] ) @xmath130 is positive but @xmath131 negative the couplings are inside the hypersphere with radius @xmath132 , and if both @xmath130 and @xmath131 are negative the ansatz ( [ diffxsection ] ) for the cross section is inconsistent with the data within the error @xmath126 .\n( 0,0 )    ( 4647,3843)(1339,-5473 ) ( 4231,-3391)(0,0)[lb ] ( 2611,-1726)(0,0)[lb ] ( 5986,-3661)(0,0)[lb ] ( 3401,-3796)(0,0)[lb ] ( 3601,-3166)(0,0)[lb ]    such constraints can be useful to find the physical set of couplings when the solution of ( [ mean ] ) from the measurement of the optimal observables is not unique .\nif they are strong enough they might even restrict the couplings to the region where ( [ mean ] ) can be linearised and thus simplify their extraction .\none can of course use the information from the integrated cross section working with any set of couplings , but again the situation is particularly simple with the form ( [ xsectransf ] ) .\nwe note that the information from the total rate is complementary to what is extracted from the mean values of our observables , which involve normalised kinematical distributions . from an experimental point of view their respective measurements\nwill presumably have quite different systematic errors .\nlet us also recall that the the measurement of the mean values @xmath26 times the number @xmath45 of events obtained with a fixed integrated luminosity combines the information of both @xcite .\na nonlinear data analysis as presented in sec .\n[ sec : method ] can also be done in this case .\nwe draw attention to the fact that unphysical solutions of equation  ( [ mean ] ) for @xmath26 and of its analogue for @xmath133 will in general be different .\nwe shall however not elaborate on this point here .\nanother aspect of the couplings with the property ( [ xsectransf ] ) is the following .\nit is well known that constant coupling parameters deviating from the standard model tree level values lead to amplitudes that violate unitarity @xcite .\nthe coefficients @xmath134 and @xmath135 in the total cross section @xmath103 increase strongly with the @xmath3 c.m .\nenergy @xmath136 and the couplings @xmath18 must vanish as @xmath8 becomes large to ensure a decent high - energy behaviour of @xmath103 . in our new parametrisation the quadratic coefficients in @xmath137 are energy independent , and in this sense the new couplings are at a `` natural scale '' at every energy .    to complete this section\nwe show that a transformation with the properties we require always exists , i.e.  that we can find a matrix @xmath111 that diagonalises @xmath68 in ( [ matrixtransf ] ) and transforms @xmath138 in ( [ quadrattransf ] ) to the unit matrix .\nthe argument is analogous if one replaces @xmath68 with @xmath50 . by construction\nboth @xmath68 and @xmath138 are symmetric and positive definite , so our problem is the same as finding normal coordinates for a multidimensional harmonic oscillator in classical mechanics ( cf .\ne.g.  @xcite ) . to make this analogy transparent\nlet us write @xmath139 and @xmath140 ; we then have to find @xmath111 so that @xmath141 with @xmath142 being diagonal\n. the elements @xmath143 of @xmath142 are generalised eigenvalues of @xmath144 satisfying @xmath145 where @xmath146 is the @xmath99-th column vector of @xmath111 .\nthe solution is well known to be @xmath147 where @xmath148 is the orthogonal matrix that transforms @xmath149 to @xmath142 . of course one\nneed not use ( [ solution ] ) in practice as there are convenient algorithms available to find @xmath111 and @xmath142 . in our numerical calculations\nwe have used the routine ` eigenvals ` of the algebraic package maple .\nwe will now give some numerical examples of our method described in the previous section . in this section\nwe will stay within the framework of a leading order analysis of the observables .\nwe start from the results in @xcite , where the sensitivity of optimal observables for semileptonic @xmath150-decays was calculated .\nwe assume a full kinematical reconstruction of the final state , except for the ambiguity one is left with if the jet charge is not known . for the standard model cross section we use the born approximation and neglect effects of the finite @xmath2 width .\nto describe the triple boson couplings we take the form factors @xmath151 , @xmath152 ( @xmath153 ) of @xcite ; deviations from their standard model tree level values will be referred to as `` anomalous couplings '' .\nlet us first look at a c.m .\nenergy of @xmath12 , which will be attained at lep2 .\nthe coefficient matrix @xmath115 can be found in table  4 of @xcite and in table  [ tab : coeff190 ] here we give the diagonal elements of the transformed matrix @xmath118 , ordered according to the symmetry of the corresponding observables .\nthe one standard deviation ellipsoid is diagonal in the couplings @xmath104 , thus its intersections with the coordinate axes equal its projections on these axes .\nthe errors @xmath154 setting all other @xmath155 to zero are then equal to the errors @xmath156 where all other @xmath155 are arbitrary .\nthey are given by @xmath157 and are listed in table  [ tab : sens190 ] for an integrated luminosity of @xmath13 .\nwe immediately remark that a negative diagonal element occurs in the transformed coefficient matrix , which is not allowed because @xmath158 is a covariance matrix and thus positive definite .\nwe encounter here a problem of numerical instability : small errors in the calculation of the original matrices @xmath115 and @xmath138 can have a large effect on the smallest generalised eigenvalues @xmath159 and their eigenvectors , even to the point that eigenvalues come out with the wrong sign .\nthis is not only a problem of our particular way of diagonalisation , but also occurs if one diagonalises @xmath115 with an orthogonal matrix ; we find that one of the usual eigenvalues of @xmath115 in the subspace of couplings with symmetry @xmath95 is negative .\nsuch instabilities can cause large errors in the matrix inversion of @xmath115 and @xmath50 .\none needs @xmath160 to calculate the error on the extracted couplings as can be seen from ( [ chi ] ) and ( [ couplingscov ] ) , and large errors on @xmath161 can lead to large uncertainties in the extracted couplings , irrespective of whether @xmath161 is explicitly used to solve the system ( [ mean ] ) .\none will of course aim to calculate @xmath115 and @xmath50 with best possible precision , but such an effort has limits , in particular if they are determined from simulated events and include for instance radiative corrections or detector effects . on a more fundamental level any calculation of these matrices will only be an approximation of the `` exact '' ones that correspond to the kinematical distributions seen in experiment . in this sense\nit seems quite inevitable that small eigenvalues ( the usual or our generalised ones ) of @xmath115 and @xmath50 and their eigenvectors are sensitive to imprecisions in the calculation and can lead to large errors or uncertainties in the data analysis .\nthis holds of course even if one does not obtain eigenvalues with the wrong sign .\nwe think that also in view of this a diagonalisation is useful , not because it solves the problem but because it makes it explicit !\nit allows to easily identify those combinations of couplings which have small corresponding eigenvalues in @xmath115 and @xmath50 and will be the most unsafe ones in the analysis . from ( [ onesigma ] )\nwe see that they are those combinations for which the statistical errors will be largest . here\nthe most unsafe coupling parameter is @xmath162 .\none might thus choose to exclude it , and possibly other couplings , from the analysis and work in the remaining subspace of the @xmath104 where the numerics is more stable and where in any case the experiment is most sensitive .\nwe will come back to this in sec .\n[ sec : practice ] .\n.[tab : lr190]diagonal elements @xmath159 of the coefficient matrix restricted to the left or right handed subspace of the couplings as explained in the text .\nthe values in the left handed subspace differ from the corresponding ones in table 1 by at most 3% .\n[ cols=\"^ , > , > , > , > , > , > , > , > \" , ]     crrrrrrrrr & & & + @xmath93 & 1.4 & 1.1 & 0.72 & 0.63 & & 0.50 & 0.17 & 0.062 & 0.044 + @xmath95 & 1.3 & 1.0 & 0.79 & 0.26 & & 0.11 & 0.083 & 0.023 & @xmath163 + @xmath96 & 1.2 & 0.58 & 0.32 & & & 0.076 & 0.031 & 0.013 & + @xmath97 & 1.4 & 1.0 & 0.83 & & & 0.24 & 0.040 & 0.026 & +    finally we remark that like in the case for @xmath12 those couplings @xmath104 which give the largest statistical errors in the optimal observable analysis are predominantly related to right handed combinations of form factors as can be seen from the comparison of tables  [ tab : coeff500 ] and [ tab : lr500 ] .\nlet us sketch how our method of simultaneous diagonalisation might be used in practice .    1 .\none first has to choose which matrix to diagonalise simultaneously with @xmath138 .\nthese matrices need not be the same ones to be used in the data analysis itself but may be calculated under further approximations .\ncovariance matrices for the observables and extracted couplings can be evaluated for zero @xmath18 as our entire procedure will only have its desired properties if nonlinear effects are not too large . if one uses the same approximation of the differential cross section ( [ diffxsection ] ) for the construction of the optimal observables ( [ optimal ] ) and the calculation of @xmath115 , @xmath50 and @xmath117 then the latter are all equal and can be diagonalised at the same time .\notherwise one has to choose a positive definite symmetric matrix for the diagonalisation , i.e.  one of the covariance matrices .\nthe calculation of @xmath80 or of its inverse from ( [ couplingscov ] ) involves however a matrix inversion and might suffer from numerical instabilities , so presumably the best choice will be @xmath50 .\n2 .   in the next step one carries out the simultaneous diagonalisation of the chosen matrix and @xmath138 as described in sec .\n[ sec : simultan ] and determines the transformation matrix @xmath111 in ( [ couplingstransf ] ) to ( [ matrixtransf ] ) . at this point\nit will be useful to test the numerical stability of the transformed matrices , for instance by re - calculating them in the new basis of couplings or by repeating the diagonalisation procedure with slightly modified initial matrices .\none might choose to discard some of the new couplings @xmath104 and the corresponding observables from the analysis if the corresponding matrix elements are found to be instable .\nthis does not mean that one has to set these couplings to zero . from the measurement of the total cross section one will obtain limits on them , which will also allow to control the contribution they can give to the mean values of those observables that are kept in the analysis because the matrix @xmath118 is not exactly diagonal and because of nonlinear terms in ( [ mean ] ) .\n3 .   in the new parametrisation of the couplings\none then carries out the analysis of the data . here\n@xmath164 , @xmath118 , @xmath165 and the other coefficients in ( [ expect ] ) will be determined under the most realistic assumptions and with the best precision one can afford .\nthey will not be exactly diagonal in practice , but should have small off - diagonal elements if the approximations made in step 1 .  and in the construction of the optimal observables are sufficiently good .\n4 .   one can then give both single and multidimensional errors on the measured coupling parameters @xmath104 . at this stage one can also present the results in other , more conventional parametrisations of the couplings and\nin particular compare with the measurements of other experiments , restricting oneself to whatever subspace of couplings might have been chosen there .\nin the first part of this paper we have shown how to extract coupling parameters from the measured mean values @xmath26 of appropriate observables without the approximation that the couplings are small .\nerrors on the couplings can be obtained from a @xmath47-fit of the @xmath26 . if one puts constraints on the couplings in order to reduce their number the method also gives an indication of how compatible these constraints are with the data .\nthe `` optimal observables '' discussed in @xcite have statistical errors equal to the smallest possible ones to leading order in the coupling parameters @xmath18 . beyond the leading order approximation\none can obtain more sensitive observables if one has some previous estimate @xmath58 for the couplings , expanding the differential cross section around @xmath58 instead of zero and constructing observables from the corresponding expansion coefficients . in the appendix\nwe show that up to linear reparametrisations the choice of optimal observables is unique : any other set of observables must give bigger ( statistical ) errors .    in a second part\nwe have proposed to perform the data analysis using a particular parametrisation @xmath104 of the couplings , which is specific to the process and its c.m .  energy .\nit is obtained from the initial set @xmath18 by a linear transformation which diagonalises the covariance matrix @xmath50 of the observables and transforms the matrix @xmath138 of quadratic coefficients in the integrated cross section ( [ intxsection ] ) to unity . in an idealised framework each optimal observable @xmath107 for this parametrisation is only sensitive to one coupling , and the statistical errors on the extracted couplings are uncorrelated . under realistic circumstances both properties can be approximately satisfied provided that the analysis stays in a region of parameter space where the dependence of the mean values @xmath166 on the couplings is not far from linear .\nvarious matrices are then approximately diagonal which should generally facilitate the data analysis . in particular one can directly give errors on single or a small number of couplings , which will be necessary to obtain statistically significant results with a limited number of events . at the same time one can readily present multidimensional errors in parameter space , which is essential to compare with the results of measurements that impose various different constraints on the couplings . having approximately diagonal matrices also allows to easily identify those directions in parameter space which can be measured best and those for which the statistical errors will be large and which are likely to be associated with numerical instabilities , for example in matrix inversions .\none can thus recognise and seek to remedy such problems in an early stage of the analysis .\nthe measurement of the total cross section @xmath103 gives valuable complementary information on the coupling parameters .\nits dependence on the couplings is particularly simple in the parametrisation we propose since the quadratic contributions are @xmath167 times the standard model cross section @xmath168 , i.e.  they have the same form for all couplings\n. a measurement of @xmath103 will then restrict the @xmath104 to a shell between two hyperspheres in parameter space .\nwe have given some numerical examples of our method applied to the semileptonic decay channels in @xmath4 .\nin particular we find that the couplings @xmath104 which can be measured best with unpolarised beams predominantly appear in the amplitude for left handed electrons ( or right handed positrons ) , and that the @xmath104 with the largest statistical errors mainly correspond to the opposite lepton helicity .\ncomparing our results at lep2 and lc energies we see that the coefficients in the linear contributions of the couplings @xmath104 to our observables and to the integrated cross section change much less with energy than in usual parametrisations .\nthis is because in the new parametrisation the quadratic coefficients in the normalised cross section @xmath169 are by construction energy independent .\nwe would like to thank ch .\nhartmann and m.  kocian for their continued interest in optimal observables for triple gauge couplings .\nwe gratefully acknowledge discussions with and remarks by j.  blmlein , p.  overmann , n.  wermes , , and p.  m.  zerwas .\nthis work has in part been financially supported by the eu programme `` human capital and mobility '' , network `` physics at high energy colliders '' , contracts chrx - ct93 - 0357 ( dg 12 coma ) and erbchbi - ct94 - 1342 , and by bmbf , grant .\nit was started while one of us ( md ) was at the university of cambridge , and we acknowledge support by the arc programme of the british council and the german academic exchange service ( daad ) , grant 313-arc - viii - vo / scu , which made mutual visits of the cambridge and heidelberg groups possible .\nin this appendix we show that the set of observables ( [ newoptimal ] ) , obtained from expanding the differential cross section about the actual values of the couplings , is unique in the sense that up to the linear reparametrisations ( [ reparam ] ) it is the only set of @xmath41 integrated observables which in the limit of large @xmath45 leads to the minimum error on the @xmath41 extracted parameters .    to keep our notation simple we give the proof for the case that the actual values of the @xmath18 are zero .\nthe expectation value and covariance of functions @xmath34 and @xmath35 are then given by @xmath170 = \\frac{\\int d\\phi \\ , f(\\phi )   s_0(\\phi)}{\\int d\\phi \\ ,\ns_0(\\phi ) }   { \\hspace{6pt},}\\hspace{3em }    v_0[f , g ] = e_0[f g ] - e_0[f ] \\ , e_0[g ]   { \\hspace{6pt}.}\\ ] ] in the general case one has instead of @xmath85 the zeroth order coefficient @xmath171 ( [ newdiffxsection ] ) from the expansion about the appropriate values @xmath58 .    for large @xmath45 the covariance matrix for the extracted couplings\nis given by ( [ couplingscov ] ) . under a linear reparametrisation of observables , @xmath172 where @xmath173 and @xmath174 are constants and the matrix @xmath173 is nonsingular , the matrices @xmath115 from ( [ obscoeffcompact ] ) and @xmath50 transform according to @xmath175 from ( [ couplingscov ] ) we see that the covariance matrix @xmath80 is unchanged under such a transformation .\nfor our proof we can hence restrict ourselves to observables with mean value @xmath176 = 0\\ ] ] and with a coefficient matrix @xmath177 . from ( [ obscoeffcompact ] )\nwe then have the condition @xmath178 = \\delta_{ij}\\ ] ] and the error on the extracted couplings is given by @xmath179   { \\hspace{6pt}.}\\ ] ]    from @xcite we know that the optimal observables ( [ optimal ] ) lead to the smallest possible error on the @xmath18 , given by the cramr - rao bound . to satisfy our conditions\n( [ centred ] ) and ( [ normalised ] ) we take the linear combinations @xmath180    \\right)\\ ] ] with @xmath181   { \\hspace{6pt}.}\\ ] ] we assume that the functions @xmath86 are linearly independent\n. otherwise some of the parameters @xmath18 are superfluous and can be eliminated ; our assumption is thus that the @xmath18 are an independent set of parameters for the anomalous couplings .\nlinear independence of the @xmath182 guarantees that @xmath183 is nonsingular , which has tacitly been used at several instances in our paper .\nthe set @xmath184 is related to the optimal observables @xmath185 by a linear transformation ( [ reparam ] ) and thus gives the same optimal error matrix @xmath80 .\nthe covariance @xmath186 $ ] defines a scalar product on the hilbert space @xmath187 of sufficiently smooth functions of @xmath21 with the property @xmath188 = 0 $ ] .\nthe functions @xmath184 span a subspace @xmath189 of @xmath187 , and we define @xmath190 as the orthogonal complement of @xmath189 with respect to the scalar product @xmath33 $ ] .\nany set of @xmath41 observables satisfying ( [ centred ] ) can then be written as @xmath191 with @xmath192 , @xmath193 . further decomposing @xmath194 and using the constraint ( [ normalised ] ) we obtain @xmath195 , i.e.@xmath196 finally\n, we have from ( [ simplecov ] ) , ( [ decompose ] ) , ( [ first ] ) @xmath197 +                n^{-1 } v_0[{{\\cal o}}^{\\it ii}_i , { { \\cal o}}^{\\it ii}_j ]   { \\hspace{6pt}.}\\ ] ] the first term gives the error on the couplings for the optimal observables @xmath184 , which is minimal . if the observables @xmath28 have minimal error , too , the second term must be zero , so that for each @xmath99 we have @xmath198 = 0 $ ] and thus @xmath199 which completes our proof .    in sec .\n[ sec : simultan ] we mentioned that instead of @xmath26 one may use the product @xmath200 measured with fixed luminosity to extract the couplings @xcite . by an argument analogous to the one of this appendix one finds that up to linear reparametrisations our observables ( [ newoptimal ] ) are again the only optimal ones .\nin this case linear reparametrisations have to be homogeneous , i.e.  one must have @xmath201 in ( [ reparam ] ) , since adding constants to the observables can change the induced errors on the coupling parameters .\ng. gounaris et al . , `` triple gauge boson couplings '' , report of the `` triple gauge couplings '' working group during the lep2 workshop 19941995 , hep - ph/9601233 , in _ physics at lep2 _ , vol .  1\n, g.  altarelli and f.  zwirner eds .\n, cern report 1996 , and references therein          p. overmann , dortmund preprint do - th 93/24 ; + w. bernreuther , g. w. botz , d. bru , p. haberl and o. nachtmann , z.  phys .\nc68 ( 1995 ) 73 ; + d. bru , o. nachtmann and p. overmann , `` cp violation in radiative @xmath7 decays '' , univ .\nheidelberg report hd  thep9702 ( 1997 )\nr. akers et al .\n( opal coll . ) , z.  phys .\nc66 ( 1995 ) 31 ; + a. stahl , nucl .\nb ( proc .  suppl . ) 40 ( 1995 ) 505 ; + aleph coll .\n, `` search for cp violation in the decay @xmath202 '' , paper contributed to the ichep96 conference , warsaw , 2531 july 1996 , report pa 08 - 030 ; + delphi coll .\n, `` improved test of cp - violation in @xmath203 using optimized observables '' , paper contributed to the ichep96 conference , warsaw , 2531 july 1996 , report pa 07 - 014 ( 1996 ) ; + n. wermes , `` cp tests and dipole moments in @xmath204-pair production experiments '' , talk given at tau96 workshop , estes park , colorado , usa , 1619 september 1996 , report bonn - he-96 - 10"}
{"lay_summary": " we present four - dimensional gauge theories that describe physics on five - dimensional curved ( warped ) backgrounds , which includes bulk fields with various spins ( vectors , spinors , and scalars ) . \n field theory on the ads@xmath0 geometry is examined as a simple example of our formulation . \n various properties of bulk fields on this background , e.g. ,  the mass spectrum and field localization behavior , can be achieved within a fully four - dimensional framework . moreover , that gives a localization mechanism for massless vector fields . \n we also consider supersymmetric cases , and show in particular that the conditions on bulk masses imposed by supersymmetry on warped backgrounds are derived from a four - dimensional supersymmetric theory on the flat background . as a phenomenological application , \n models are shown to generate hierarchical yukawa couplings . \n finally , we discuss possible underlying mechanisms which dynamically realize the required couplings to generate curved geometries .    \n kuns-1790 + hupd-0202 + ut-02 - 35 + tu-658    * field localization in warped gauge theories *    hiroyuki  abe , tatsuo  kobayashi , nobuhito  maru and koichi  yoshioka    @xmath1_department of physics , kyoto university , kyoto 606 - 8502 , japan _ + @xmath2_department of physics , hiroshima university , hiroshima 739 - 8526 , japan _ + @xmath3_department of physics , university of tokyo , tokyo 113 - 0033 , japan _ + @xmath4_department of physics , tohoku university , sendai 980 - 8578 , japan _ ", "article": "the standard model is greatly successful but it still has many free parameters which must be small to describe nature . while its supersymmetric extensions , e.g. ,  the minimal supersymmetric standard model , are attractive scenarios , small couplings are also required to explain observed facts such as the fermion mass hierarchy and mixing angles .    in recent years , extra dimensions have cast a new perspective on physics beyond the standard model .\none of the important aspects of extra dimensional models is that bulk fields can be localized with finite - width wave - function profiles .\nthis fact provides us with a geometrical explanation for small numbers .\nthat is , with a configuration where some fields are separated from each other in the extra dimensional space , the couplings among them are generally suppressed .\nthen how and where fields are localized is an issue to be considered . from this viewpoint , extra dimensional models with a curved background\nare interesting because fields could be localized depending on the shape of the background geometry .\none of the most famous examples of curved geometries is the randall - sundrum ( rs ) model with the ads@xmath0 warped metric  @xcite .\nfield theories of vectors , spinors , and scalars have been studied on this background  @xcite-@xcite .\nthe localization behavior of zero - mode wave functions has interesting applications to phenomenology such as the suppression of unwanted operators .\nfor example , hierarchical forms of yukawa couplings and proton decay were studied in  @xcite .\nthe localization of kaluza - klein ( kk ) excited modes also leads to interesting phenomena .\nfor instance , the localization of higher kk gauge bosons could realize a composite scalar ( higgs ) condensation , which induces dynamical ( electroweak ) symmetry breaking on the brane where the kk gauge bosons localize  @xcite .\nin addition , models on more complicated backgrounds where a warp factor oscillates generate bulk fields which localize at some points in extra dimensions  @xcite . this type of localization might be useful in explaining the observed phenomena .\nhowever extra dimensional theories are generally nonrenormalizable and the calculations depend on the regularization scheme that one adopts . furthermore ,\nextra dimensional theories are constrained by symmetries of higher dimensions .\nfor example , in the supersymmetric case , bulk theories are constrained by @xmath5 supersymmetry in five dimensions .\nmotivated by these facts , recently a four - dimensional ( 4d ) description of extra dimensional models was proposed  @xcite . with this method\n, the phenomena of higher dimensional models are reproduced in terms of 4d theories , and several interesting models have been proposed along this line  @xcite .    in this paper\n, we present 4d gauge theories that describe physics on 5d curved geometries .\nas will be discussed below , taking generic values of gauge couplings and gauge - symmetry - breaking vacuum expectation values ( vevs ) , the models provide vector , spinor , and scalar fields on curved extra dimensions . as a good and simple illustration\n, we compare our 4d model with the rs one .\nwe particularly focus on the `` localization '' behaviors of mass eigenstates in `` index spaces '' of gauge groups .\nit will be shown that the localization profiles and the exponentially suppressed massive spectrum are certainly reproduced .\nin addition , our formulation gives a localization mechanism even for massless vector fields . as a phenomenological application ,\nhierarchical yukawa matrices are derived in our approach ; that is a hierarchy without symmetries in four dimensions .\nthe localization behavior depends on the required conditions for gauge - symmetry - breaking vevs and gauge and other couplings .\nif these values are determined in the underlying theories , it may be said that the physics on warped backgrounds is dynamically generated within a four - dimensional framework .\nwe consider several possibilities to realize the conditions by utilizing , for example , strongly coupled gauge theories .\nthus this could provide a purely 4d dynamical approach for small numbers .\nwe will proceed with the argument as follows . in sec .\n[ sec : dwd ] , we describe our 4d gauge theories , which have generic ( nonuniversal ) values of gauge - symmetry - breaking vevs and couplings .\nthe models provide vector , spinor , and scalar fields in warped extra dimensions .\nit is also shown that supersymmetry multiplets in flat 4d models generate supersymmetry multiplets on warped backgrounds . in sec .\n[ sec : ne ] , we then numerically determine with a finite number of gauge groups that the formulation given in sec .\n2 certainly reproduces various properties of bulk fields on the rs background .\nin addition , a phenomenological application to quark mass matrices is also given . finally , we discuss possibilities of dynamically realizing the conditions required for curved geometries in sec .\n[ sec : ddwd ] .\nwe conclude the discussion in sec .\n[ sec : conclusion ] .\nthe appendix is devoted to a brief review of 5d bulk fields on a rs background .\nfollowing refs .\n@xcite , we introduce @xmath6 gauge theories with gauge couplings @xmath7 ( @xmath8 ) , and scalar fields @xmath9 [ @xmath10 which are in bifundamental representations of @xmath11 .\nthe system is schematized by the segment diagram in fig .\n[ fig : links ] .\nthe gauge invariant kinetic term of the scalars @xmath9 is written by @xmath12 where the covariant derivative is given by @xmath13 .\nwe assume that the scalar fields @xmath9 develop vevs proportional to the unit matrix , @xmath14 , which break the gauge symmetry to a diagonal @xmath15 . from the kinetic term ( [ eq : qkin ] ) , the mass terms for the vector fields @xmath16 are obtained : @xmath17 where the @xmath18 matrix @xmath19 is defined as @xmath20    the consequence of these mass terms is that we have a massless gauge boson corresponding to the unbroken gauge symmetry , which is given by the following linear combination : @xmath21 where @xmath22 and @xmath23 is the gauge coupling of the low - energy gauge theory @xmath15 .\nthe profile of @xmath24 is independent of the values of @xmath25 .\nit is found from this that the massless vector field is `` localized '' at the points with smaller gauge couplings .\nif the gauge couplings take a universal value @xmath26 , the massless mode @xmath27 has a constant `` wave function '' along the `` index space '' of gauge groups . as seen below , this direction labeled by @xmath28\nbecomes the fifth spatial dimension in the continuum limit ( @xmath29 ) .\nthe localization behavior can easily be understood from the fact that , for smaller gauge coupling @xmath7 , the symmetry - breaking scale @xmath30 of @xmath6 becomes lower , and hence the corresponding vector field @xmath16 becomes the more dominant component in the low - energy degree of freedom @xmath27 .\nit is interesting to note that this vector localization mechanism ensures charge universality .\nsuppose that there is a field in a nontrivial representation of @xmath6 only .\nthat is , it couples only to @xmath31 with strength @xmath7 .\nthis corresponds to a four - dimensional field confined on a brane .\nif there are several such fields , they generally have different values of gauge couplings .\nhowever , note that these fields couple to the massless modes @xmath24 with a _\nuniversal _ gauge coupling @xmath23 defined above .\nthis is because , in the presented mechanism , the vector fields are localized depending on the values of the gauge couplings .    as for massless eigenstates ,\nthe mass eigenvalues and wave functions are obtained by diagonalizing the mass matrix ( [ eq : diffop ] ) .\nthe simplest case is the universal couplings @xmath32 in this case , one obtains the mass eigenvalues of @xmath19 as @xmath33 in the limit @xmath29 with @xmath34 fixed ( the limit to continuum 5d theory ) , the eigenvalues become @xmath35 these are the same spectrum as that of the bulk gauge boson in the @xmath36 extra dimension with radius @xmath37 .    with generic values of vevs @xmath25 and gauge couplings\n@xmath7 , the situation is rather complicated . in this case , the mass term ( [ eq : gau - mass ] ) of the vector fields becomes @xmath38(a_\\mu^{i+1})^2    \\nonumber \\\\[1 mm ]    & & + \\frac{1}{2}v_n^2g_n(g_{n+1}-g_n)(a_\\mu^n)^2    -\\frac{1}{2 } v_1 ^ 2g_1(g_2-g_1)(a_\\mu^1)^2 .\n\\label{eq : gbbm}\\end{aligned}\\ ] ] the first term becomes the kinetic energy transverse to the four dimensions in the continuum limit . on the other hand ,\nthe second and third terms are bulk and brane mass terms , respectively .\nit should be noted that these mass terms vanish in the case of universal gauge coupling , which corresponds to a flat massless vector field in 5d theory as discussed above . in other words ,\nnonuniversal gauge couplings generate bulk / brane mass terms and cause a localization of the wave function .\nfirst we consider the series of vevs @xmath25 and couplings @xmath7 that generates a vector field on the rs warped background , namely , the ads@xmath0 background .\nthis model can be obtained by choosing a universal @xmath7 and by varying @xmath25 as @xmath39 substituting this and taking the continuum limit , eq .\n( [ gkt ] ) becomes @xmath40 ^ 2 , \\label{eq : contlimrs}\\end{aligned}\\ ] ] where @xmath41 represents the coordinate of the extra dimension : @xmath42 ( @xmath8 ) and @xmath43 , etc .\nit is found that eq .\n( [ eq : contlimrs ] ) successfully induces the kinetic energy term along the extra dimension and mass terms for the vector field on the warped background metric @xmath44 where @xmath45 with @xmath46 .\nwe here conclude that we can obtain the vector field on a rs warped background by varying only the vevs @xmath25 . in the following\nwe will see that nonuniversal gauge couplings @xmath7 induce other interesting results beyond the effects from the background metric .\nnow let us compare the 4d model with generic couplings ( [ eq : gbbm ] ) to extra dimensional ones .\nwe define the dimensionless parameters @xmath47 and @xmath48 as @xmath49 first we restrict ourselves to the case that the gauge group is @xmath50 , namely , abelian theory with _ no vector self - couplings_. similarly substituting eq .\n( [ eq : deffh ] ) and taking the continuum limit , eq .\n( [ gkt ] ) becomes @xmath51\\bigr]^2 .\n\\label{eq : contlim}\\end{aligned}\\ ] ] equation ( [ eq : contlim ] ) induces the kinetic energy term along the extra dimension and mass terms for the vector field on the warped background metric : @xmath52 ^ 2 \\eta_{\\mu\\nu}dx^\\mu dx^\\nu - dy^2 .\n\\label{eq : generalbkg}\\ ] ] the bulk and boundary mass terms are @xmath41 dependent and proportional to the derivatives of @xmath53 .\nthis is also seen from the 4d model [ the second and third terms in eq .\n( [ eq : gbbm ] ) ] .\nthe above is a generic correspondence between our 4d case and continuum 5d theory . as an example , consider the following forms of the parameters : @xmath54 where @xmath55 is a positive constant with mass dimension @xmath56 .\nequation ( [ eq : contlim ] ) leads to @xmath57    -\\frac{1}{2}\\biggl[\\zeta ke^{-2(\\zeta+\\eta)ky }    ( a_\\mu)^2\\biggr]_0^{l/2}.   \\label{eq : wgmbbm}\\end{aligned}\\ ] ] the first term on the right hand side is the kinetic term of the gauge boson along the extra dimension with the warped background @xmath58 the second and third terms correspond to the bulk and boundary masses announced before .\nas easily seen , the above equation includes the expression for vector fields on the rs background . in the 5d rs model\n, the lagrangian for vector fields is written as ( see the appendix ) @xmath59 where the @xmath60 gauge fixing condition is chosen . by comparing eq .\n( [ eq : wgmbbm ] ) with eq .\n( [ rsgauge ] ) , we find that the case with @xmath61 realizes vector fields on the rs background .\nalso , a special limit , @xmath62 , produces the flat zero - mode solution .\nthat corresponds to the form of the parameters ( [ eq : rsparaf ] ) in the previous special argument .\nthe other solutions which satisfy @xmath63 correspond to nonflat wave functions of the zero - mode vector field on the rs background .\nit is clearly understood in our formulation that such nonflat wave functions are caused by introducing bulk and/or boundary mass terms in the rs model .\nfor example , in the case of @xmath64 , the vector field has bulk and boundary mass terms , and is localized with a peak at the @xmath65 point .\nit should be noticed that with these bare mass terms the zero mode is still massless .\nthis is understood from our formulation where the gauge symmetry @xmath66 is left unbroken in the low - energy effective theory .      in the above abelian case we discussed interpretation of the nonuniversal @xmath47 as @xmath41-dependent bulk or boundary masses in the warped extra dimension .\nnext we treat the non - abelian theory with vector self - couplings .\nsince in this case we also have @xmath41-dependent vector self - couplings in addition to the @xmath41-dependent bulk or boundary masses , it may be convenient and instructive to see @xmath47 as a @xmath41-dependent coefficient of the vector kinetic term .\nto this end , we define the four - dimensional field @xmath67 , @xmath68 where @xmath69 is the lattice spacing , which goes to zero in the continuum limit . rescaling the gauge fields @xmath70 , the kinetic term @xmath71 and eq .\n( [ eq : qkin ] ) become @xmath72   \\nonumber \\\\ & & \\qquad \\qquad \\qquad \\qquad   \\qquad \\qquad               + i \\hat{g } a_5^{i+1/2 } ( a^{i+1}_\\mu - a^i_\\mu )              + { \\cal o}(a^{1/2 } ) \\bigg|^2 ,   \\label{eq : gqkin2}\\end{aligned}\\ ] ] where @xmath73 and @xmath74 . in the continuum limit @xmath75 with @xmath76 and @xmath77 fixed , eq .\n( [ eq : gqkin2 ] ) results in @xmath78 ^ 2 \\eta^{\\mu \\nu } f_{\\mu 5 } f_{\\nu 5 }         \\big\\},\\end{aligned}\\ ] ] where @xmath79 $ ] .\nthis completely reproduces the 5d yang - mills kinetic term with a @xmath41-dependent coefficient @xmath80 on the warped - background metric ( [ eq : generalbkg ] ) , provided that @xmath81 .\nthis is the generic correspondence between the present 4d model and continuum 5d theory . from eq .\n( [ eq:5dym ] ) , we thus find the @xmath41-dependent factor @xmath82 in front of the canonical yang - mills term , which corresponds to a 5d dilaton vev .\nthe factor does carry the origin of the massless vector localization shown in eq .\n( [ zero - a ] ) . with the constant gauge coupling @xmath83 ( @xmath47 = 1 )\n, one obtains a bulk vector field with a constant zero mode on the warped metric ( [ eq : generalbkg ] ) .\na field redefinition @xmath84 in eq .\n( [ eq:5dym ] ) gives the previous bulk and boundary mass terms but one then has @xmath41-dependent vector self - couplings in non - abelian cases .\nwe next consider spinor fields by arranging fermions of fundamental or antifundamental representation in each gauge theory @xmath6 .\nwe introduce two weyl ( one dirac ) spinors to construct a 5d bulk fermion .\nthe orbifold compactification in continuum theory requires that one spinor obeys the neumann boundary condition and the other the dirichlet one . in the present 4d model ,\nthis can be achieved by having asymmetrical numbers of fundamental and antifundamental spinors , resulting in chiral fermions in the low - energy gauge theory . here\nwe consider the fundamental weyl spinors @xmath85 ( @xmath8 ) in the @xmath6 theory and the antifundamental @xmath86 ( @xmath87 ) .\nas seen below , @xmath88 corresponds to the bulk fermion with the neumann boundary condition and @xmath89 to that with the dirichlet one .\nthe generic gauge - invariant mass and the mixing terms of @xmath85 and @xmath86 are written as @xmath90 where @xmath91 and @xmath92 are dimensionless coupling constants .\nwe assume that @xmath9 develop vevs @xmath93 . the mass matrix for spinors\nis then given by @xmath94 the spinor mass eigenvalues and eigenvectors ( wave functions ) are read from this matrix .\none easily sees that the massless mode is contained in @xmath88 and given by the following linear combination : @xmath95 therefore the localization profile of zero mode depends on the ratio of dimensionless couplings @xmath91 and @xmath92 .\na simple case is @xmath96 for all @xmath28 . in this case\n, @xmath97 corresponds to a chiral zero mode obtained from a 5d bulk fermion on the flat background . if @xmath98 , the system describes a fermion with a curved wave - function profile .\nfor example , if @xmath99 ( @xmath100 ) , @xmath97 has a monotonically increasing ( decreasing ) wave - function profile . as another interesting example\n, taking @xmath101 ( @xmath102 , @xmath103 are constants and @xmath104 ) , @xmath97 has a gaussian profile with a peak at @xmath105 .\nother profiles of massless chiral fermions could also be realized in our approach .\nlet us discuss the 5d continuum limit .\nthe relevant choice of couplings @xmath91 and @xmath92 is @xmath106 the parameters @xmath107 give rise to a bulk bare mass in the continuum limit as will be seen below .\nthe only difference between the vector and spinor cases is the existence of possible bulk mass parameters [ see eqs .\n( [ eq : diffop ] ) and ( [ eq : mass - spi ] ) ] .\nthe mass and mixing terms  ( [ eq : fermionmoose ] ) then become @xmath108 + \\textrm{h.c.},\\end{aligned}\\ ] ] where @xmath109 and @xmath110 are the same as defined in the case of vector fields  ( [ eq : deffh ] ) .\nsimilar to the vector case , this form is compared with the bulk spinor lagrangian in the rs space - time ( see the appendix ) @xmath111 .\n\\label{eq : rsspinor}\\end{aligned}\\ ] ] here the kinetic terms have been canonically normalized in order to compare them to the 4d model . in eq .\n( [ eq : rsspinor ] ) , @xmath102 is a possible 5d dirac mass , and the `` 1/2 '' contribution in the mass terms comes from the spin connection with the rs metric .\nit is interesting that the 5d spinor lagrangian ( [ eq : rsspinor ] ) is reproduced by taking the exact same limit of parameters as that in the vector case , defined by eq .\n( [ eq : rsparaf ] ) .\nfurthermore , the relation between the mass parameters @xmath102 should be taken as @xmath112 that is , the @xmath107 s take a universal value .\nnow the localization behavior of the spinors is easily understood . in the present 4d model ,\nthe spinor mass matrix ( [ eq : mass - spi ] ) becomes with eq .\n( [ eq : spinorcond ] ) @xmath113 a vanishing bulk mass parameter @xmath114 corresponds to @xmath115 , that is , @xmath116 in our model .\nthen the mass matrix @xmath117 is exactly the same as @xmath19 , and their mass eigenvalues and eigenstates are the same . in particular\n, the massless mode @xmath97 has a flat wave function with universal gauge couplings as considered here .\nthis is consistent with the expression ( [ zero - eta ] ) , where the ratio @xmath118 determines the wave - function profile . on the other hand , in the case of @xmath119 ( @xmath120 )\n, the rs zero - mode spinor is localized at @xmath121 ( @xmath65 )  @xcite , which in turn corresponds to @xmath122 ( @xmath123 ) in our model .\none can see from the spinor mass matrix ( [ eq : mass - rsspi ] ) that the zero - mode wave function is monotonically increasing ( decreasing ) with respect to the index @xmath28 .    in this way\n, we have a 4d localization mechanism for the spinor fields .\nnonuniversal gauge couplings or nonuniversal masses give rise to a nonflat wave function for a chiral massless fermion .\nthe latter option is not realized for vector fields .\nnotice that the charge universality still holds in the low - energy effective theory .\nthat is , with any complicated wave - function profiles , zero modes interact with a universal value of the gauge coupling .\nthis is because curved profiles of vector fields depend only on the gauge couplings .\nfinally we consider scalar fields .\nwe may introduce two types of scalar field @xmath124 and @xmath125 in the fundamental and antifundamental representations of @xmath6 , respectively .\nin addition , for each type of scalar , there are two choices of the @xmath126 parity assignment in the continuum limit .\nthis orbifolding procedure is incorporated by removing @xmath127 or @xmath128 .\nthe gauge invariant mass and mixing terms for @xmath129 and @xmath130 are written as @xmath131 where @xmath132 , @xmath133 , and @xmath134 are the dimensionless coupling constants .\nit is implicitly assumed that nonintroduced fields are appropriately removed in the sums .\nwe have included the mixing mass terms up to the nearest - neighbor interactions .\nother invariant terms such as @xmath135 or terms containing @xmath9 correspond to nonlocal interactions in 5d theories , and we do not consider these in this paper .\nnotice , however , that for a supersymmetric case , these terms may be suppressed due to renormalizability and holomorphy of the superpotential .\nthe zero - mode eigenstates are given in the same form as that of the spinor shown in the previous section , replacing @xmath132 and @xmath133 by @xmath136 and @xmath137 ( @xmath138 and @xmath139 ) .\ntherefore the ratio @xmath140 ( @xmath141 ) determines the zero - mode wave function .\nlet us consider the continuum 5d limit .\nin what follows , we remove @xmath128 , which corresponds to the @xmath126 assignment @xmath142 and @xmath143 .\nthe 5d limit can be achieved by taking the following choices of couplings : @xmath144 & & \\bar\\alpha'_i \\,=\\ , g_{i+1 } , \\qquad \\bar\\beta'_i \\,=\\ , g_{i+1}(1-\\bar c'_{i+1}),\\end{aligned}\\ ] ] where @xmath145 and @xmath146 correspond to the bulk mass parameters , as in the spinor case\n. then the mass terms ( [ eq : nsp ] ) and ( [ eq : dsp ] ) for the scalars take the following forms with the parametrization ( [ eq : deffh ] ) : @xmath147\\{f(y)\\phi(x , y)\\}\\bigr|^2 + [ gv\\gamma(y)]^2|f(y)\\phi(x , y)|^2 \\biggr],\\ ] ] @xmath148\\{h(y)\\varphi(x , y)\\ } \\bigr|^2 + [ gv\\bar\\gamma(y)]^2|h(y)\\varphi(x , y)|^2 \\biggr].\\ ] ]    as a special case , we compare @xmath129 and @xmath130 with the scalar fields in the rs space - time .\nthe scalar lagrangian on the rs background is ( see also the appendix ) @xmath149\\end{aligned}\\ ] ] where the 4d kinetic term is canonically normalized , and @xmath150 and @xmath151 are the bulk and boundary mass parameters , respectively , defined in the appendix [ eq .\n( [ eq : smass ] ) ] . by substituting the rs limit in our model given by eq .\n( [ eq : rsparaf ] ) , we find the relations between the mass parameters in 4d and 5d : @xmath152      in this subsection , we discuss 5d supersymmetry on warped backgrounds .\ngenerally a supersymmetric theory may be obtained by relevant choices of couplings from a nonsupersymmetric theory .\nwe here examine whether it is possible to construct supersymmetric 4d models which describe 5d supersymmetric ones on warped backgrounds .\nthis is a nontrivial check for the ability of our formalism to properly describe 5d nature . in ref .\n@xcite , the 5d theory on the ads@xmath0 rs background was studied . there\n, supersymmetry on ads@xmath0 geometry was identified and then the conditions on the mass parameters imposed by this type of supersymmetry were derived ( also given in the appendix here ) . as seen below\n, these relations among mass parameters for ads@xmath0 supersymmetry are indeed satisfied in our _\n4d formalism_. this fact seems remarkable in the sense that the present analyses do not include gravity .\nfirst consider vector supermultiplets in 5d .\nthe scalar fields @xmath9 and the gauge bosons @xmath31 are extended to chiral and vector superfields in 4d , respectively . notice that the vevs that were discussed above , @xmath153 are in the ( baryonic ) @xmath154-flat direction .\nwe start with the following 4d supersymmetric lagrangian @xmath155 the bilinear terms of the component fields are written in the unitary gauge ( we follow the conventions of @xcite ) : @xmath156 where we have rescaled @xmath157 for canonical normalization of the kinetic terms . the mass matrix @xmath158 is defined in eq .\n( [ gkt ] ) .\nthe first term is nothing but eq .\n( [ gkt ] ) , that is , the mass terms for vector fields . by\nalso canonically normalizing @xmath159 and @xmath160 and integrating out the auxiliary fields , we find the mass terms for the adjoint spinors and scalar @xmath161 these masses have the same forms as that of the vector field because we started from a supersymmetric theory .\nwe thus have a model with @xmath162 for the spinors and @xmath163 for the scalar .\n( note that @xmath164 , which originate from @xmath9 , have @xmath126 odd parity . )\nit is a nontrivial check to see whether the above mass terms satisfy the conditions for 5d ads@xmath0 supersymmetry .\nwe find from the relations ( [ eq : ci - spi ] ) and ( [ eq : massd ] ) that the mass terms for @xmath165 and @xmath166 imply @xmath167 indeed , these relations are just those required by ads@xmath0 supersymmetry  @xcite . in this way , _\n5d vector supermultiplets on a rs warped background are automatically derived from a 4d supersymmetric model on a flat background_.    we also construct a 5d hypermultiplet in the warped extra dimension starting from a 4d supersymmetric theory . in order to have a hypermultiplet we introduce the chiral superfields @xmath124 and @xmath125 in the fundamental and antifundamental representations of the @xmath6 gauge theory . in the following , @xmath128 is removed to implement @xmath126 orbifolding which leaves a chiral zero mode of the fundamental representation .\nthe fermionic components of @xmath124 and @xmath125 , then correspond to @xmath85 and @xmath168 , respectively , in sec .\n[ sec : spinor ] .\nthe generic renormalizable superpotential is written as @xmath169 this superpotential just leads to a spinor mass term of the form ( [ eq : fermionmoose ] ) .\nin addition , the mass and mixing terms of the scalars @xmath129 and @xmath130 also have the same form as those of the spinors : @xmath170 supersymmetry induces equivalence between the boson and fermion mass matrices . in turn , this implies in our formulation given in the previous sections that the mass parameters are equal , @xmath171 and also @xmath172 .\nthus , there is only one parameter @xmath102 left .\nit is found from eqs .\n( [ eq : ci - spi ] ) , ( [ eq : massn ] ) , and ( [ eq : massd ] ) that if one take the continuum limit the relations @xmath173 are generated .\nthese mass relations are exactly those imposed by supersymmetry on the ads@xmath0 geometry  @xcite .\nthus hypermultiplets on the rs background are properly incorporated in our formalism with a flat background .\nit may be interesting that the mass relation for vector multiplets is the one for chiral multiplets with dirichlet boundary conditions ( [ eq : abchypd ] ) with @xmath114 .\nthis value of @xmath102 is the limit of vanishing bulk mass parameters .\nit should be noticed that our analyses have been performed for generic warped backgrounds , including the rs case as a special limit .\nwe thus found that even in generic warped backgrounds the conditions on the bulk mass parameters required for 5d warped supersymmetry should be the same as for the rs case .\nhere we perform a numerical study to confirm our formulation of the curved extra dimension discussed in the previous sections . we will also give a phenomenological application to the hierarchy among yukawa couplings .\nin the following , we consider the case that corresponds to the rs model in the continuum limit , as a good and simple application . the gauge couplings and vevs are specified as given in sec .\n[ sec : dwd ] ; @xmath174 the universal gauge coupling @xmath26 implies that vector zero modes have flat wave functions as shown in eq .\n( [ zero - a ] ) .\nthe following is a summary of the mass terms for various spin fields , which were derived in the previous sections : @xmath175 { \\cal l}_{fm } & = & -\\psi d_c \\eta + \\textrm{h.c . } , \\\\[2 mm ] { \\cal l}_{sm}^\\phi & = & -\\bigl|d_{3/2-b } \\phi\\bigr|^2 -|m \\phi|^2 , \\\\[1 mm ] { \\cal l}_{sm}^\\varphi & = & -\\bigl|d_{-(3/2-b)}^\\dagger \\varphi\\bigr|^2 -|m^\\dagger \\varphi|^2.\\end{aligned}\\ ] ] the parameters @xmath151 and @xmath102 represent the bulk mass parameters for scalars and spinors , respectively .\nthe @xmath18 mass matrices @xmath176 and @xmath177 are defined as follows : @xmath178    m & = & \\sqrt{a+4b - b^2}\\,\\frac{k}{v }    \\pmatrix { v_1 & & \\cr & \\ddots & \\cr & & v_{n-1 } }    \\pmatrix { 1 &     0    &          &    \\cr      & \\ddots & \\ddots   &    \\cr      &         & 1 & 0 } , \\end{aligned}\\ ] ] where @xmath179 for supersymmetric cases , the mass matrices @xmath176 for bosons and fermions take the same form and , moreover , @xmath180 , as discussed previously .\nwe define the matrices @xmath181 that diagonalize the mass matrices for gauge , fermion , and scalar fields , respectively . for example\n, @xmath182 satisfies @xmath183 where @xmath184 are the mass eigenvalues which should correspond to the kk spectrum of vector fields . in the following , we use the notation @xmath185 that is , the coefficients of @xmath31 in the @xmath186th massive eigenstates @xmath187 . in the continuum limit\n, this corresponds to the value of the wave function at @xmath188 for the @xmath186th kk excited vector field .\nsimilar definitions are made for spinors and scalars .    for vector fields ,\nwe illustrate the resultant eigenvalues @xmath189 and eigenvectors @xmath190 in figs .\n[ fig : bulkgaugesys](a)[fig : bulkgaugesys](f ) . for comparison\n, we also show in the figures the wave functions and kk mass eigenvalues of vector fields on the rs background .\nit is found from the figures that our 4d model completely reproduces the mode function profiles [ figs .\n[ fig : bulkgaugesys](b ) , [ fig : bulkgaugesys](d ) , and [ fig : bulkgaugesys](f ) ] . localization becomes sharp as @xmath191 increases ; this situation is similar to the continuum case .\nthe warp - suppressed spectra of kk excited modes are also realized [ figs .\n[ fig : bulkgaugesys](a ) , [ fig : bulkgaugesys](c ) , and [ fig : bulkgaugesys](e ) ] . for a larger @xmath192 ( the number of gauge groups )\n, the model leads to a spectrum more in agreement with the continuous rs case .\nnote , however , that the localization profiles of wave functions can be seen even with a rather small @xmath192 .\nit is interesting that even with a finite number of gauge groups the massive modes have warp - suppressed spectra and localization profiles in the index space of gauge theory .    for fermion fields\n, there is another interesting issue to be examined .\nit is the localization behavior via dependence on the mass parameters @xmath102 , which was discussed in sec.[sec : spinor ] .\nwe show the @xmath102 dependence of the zero - mode wave function @xmath193 in fig .\n[ fig : cdepwf ] .\nthe figure indicates that the zero - mode wave functions surely give the expected localization nature of the continuum rs limit [ eq .  ( [ eq : hzero ] ) in the appendix ] .\nwe find that the values of the wave functions are exponentially suppressed at the tail of localization profile even with a finite number of gauge groups .\nthe profiles of massive modes can also be reproduced .\nnow we apply our formulation to phenomenological problems in four dimensions .\nlet us use the localization behavior , which has been shown above , to obtain the yukawa hierarchy .\nthis issue has been studied in the 5d rs framework  @xcite .\nwe consider a model corresponding to the ( supersymmetric ) standard model in the bulk .\nthe yukawa couplings for quarks are given by @xmath194 where @xmath195 , @xmath196 , and @xmath197 denote the left - handed quarks and the right - handed up and down quarks , respectively , and @xmath198 are the family indices .\nfor simplicity , we study a supersymmetric case and introduce two types of higgs scalars @xmath199 and @xmath200 .\nthen the mass parameters of the higgs scalars satisfy eq .\n( [ eq : abchypn ] ) and they are denoted by @xmath201 in the following .\nsimilarly , the quark behaviors are described by their mass parameters @xmath202 .\nwe assume @xmath203 . generally , in supersymmetric 5d models , yukawa couplings such as eq .\n( [ eq : yukawaorg ] ) are prohibited by 5d supersymmetry . however , since the present model is 4d , one may apply 5d - like results to yukawa couplings without respecting 5d consistency .\nthis is one of the benefits of our scheme .\nwe are now interested in the zero - mode part of eq .\n( [ eq : yukawaorg ] ) , which generates the following mass terms @xmath204 where the fields with tildes @xmath205 stand for the @xmath186th mass eigenstate given by @xmath206 ( similarly for @xmath196 , @xmath197 , and @xmath207 ) .\nthe effective yukawa couplings are @xmath208 and similarly for @xmath209 . a typical behavior of @xmath210 is shown in fig .  [ fig : cdepwf ] for several values of the bulk mass parameter @xmath102 . in fig .\n[ fig : cdepy ] , we show the behaviors of the zero - mode yukawa couplings @xmath211 against the quark mass parameters .\ntwo limiting cases with @xmath212 and 1 are shown .\nthe former corresponds to a bulk higgs scalar localized at @xmath65 and the latter to one at @xmath121 in the continuum rs limit . from the figures\n, we see that if there is a @xmath213 difference of mass ratio among the generations , it generates a large hierarchy between yukawa couplings .\ncombined with the mechanisms that control mass parameters discussed in the next section , one obtains a hierarchy without symmetries within the four - dimensional framework .\n\\(a ) @xmath212    \\(b ) @xmath214    \\(c ) @xmath212\n\\(d ) @xmath214    in the case of @xmath214 , the yukawa coupling depends exponentially on the quark bulk mass parameters @xmath202 when @xmath215 .. for @xmath216 , the higgs scalars have a peak at @xmath217 ( @xmath121 ) .\nthis situation is different from the one discussed in ref .\n@xcite where the higgs field is localized at @xmath218 ( @xmath65 ) . ]\nthis implies that if @xmath202 exist in this region one obtains the following form of the yukawa matrices : @xmath219 where their exponents satisfy @xmath220 this form is similar to that obtained by the froggatt - nielsen mechanism  @xcite with a @xmath50 symmetry . as an illustration ,\nlet us take the following mass parameters @xmath221 and @xmath222 and @xmath223 , which generates the low - energy yukawa matrices @xmath224 where @xmath225 .\nthis pattern of quark mass textures leads to realistic quark masses and mixing angles  @xcite with a large value of the ratio @xmath226 . if the above analysis were extended to su(5 )\ngrand unified theory , realistic lepton masses and mixing may be derived .\nother forms of yukawa matrices that may be realized by the froggatt - nielsen mechanism are easily incorporated in our formulation .    for more complicated patterns of mass parameters , we could realize yukawa matrices that are different from those derived from the froggatt - nielsen mechanism . in general ,\noff - diagonal entries tend to be rather suppressed , that is , we have @xmath227 for the yukawa matrix ( [ yij ] )\n. such a form may lead to realistic fermion masses and mixing angles .\nfor example , one could derive the yukawa matrix @xmath228 if initial values of @xmath229 are sufficiently suppressed . in this case\n, the @xmath230 submatrix for the second and third generations does not satisfy eq .\n( [ fntype ] ) . the yukawa matrix ( [ eq : compli ] )\nmay be relevant to the down - quark sector , indeed studied in ref .\nwe do not pursue further systematic studies on these types of yukawa matrices in this paper .\nwe have shown that 4d models with nonuniversal vevs and gauge and other couplings can describe 5d physics on curved backgrounds , including the rs model with an exponential warp factor . in the continuum 5d\ntheory , this factor is derived as a solution of the equation of motion for gravity . on the other hand , in the 4d viewpoint ,\nwarped geometries are generated by taking the couplings and vevs as appropriate forms . in the previous sections ,\nwe have just assumed their typical forms and examined its consequences .\nif one could identify how to control these couplings by the underlying _ dynamics _ , the resultant 4d theories turn out to provide attractive schemes to discuss low - energy physics such as tiny coupling constants .\nfirst we consider the scalar vevs @xmath231 . a simple way to dynamically control them is to introduce additional strongly coupled gauge theories  @xcite .\nconsider the following set of asymptotically free gauge theories : @xmath232 where @xmath233 and @xmath234 denote the dynamical scales .\nwe have , for simplicity , assumed common values of @xmath235 and @xmath233 for all @xmath6 .\nin addition , two types of fermions are introduced : @xmath236 where their representations under @xmath237 gauge groups are shown in parentheses . if @xmath238 , the @xmath239 theories are confined at a higher scale than @xmath6 , and the fermion bilinear composite scalars @xmath240 appear .\ntheir vevs @xmath25 are given by the dynamical scales @xmath234 of the @xmath239 gauge theories through a dimensional transmutation as @xmath241 where @xmath242 is a universal one - loop gauge beta function for @xmath239 ( @xmath243 ) .\nthe gauge couplings @xmath244 generally take different values and thus lead to different values of @xmath25 .\nfor example , a linear dependence of @xmath245 on the index @xmath28 is amplified to an exponential behavior of @xmath25 .\nthat is , @xmath246 which reproduces the bulk fields on the rs background as shown before .\nthe index dependences of the gauge couplings are actually generic situations , and may also be controlled , for example , by some mechanism fixing dilatons or the radiatively induced kinetic terms discussed below .\na supersymmetric extension of the above scenario is achieved with quantum - deformed moduli spaces  @xcite .\nanother mechanism that dynamically induces nonuniversal vevs is obtained in supersymmetric cases .\nconsider the gauge group @xmath247 and the chiral superfields @xmath9 with charges @xmath248 under @xmath249 .\nit is assumed that the scalar components @xmath250 of @xmath9 develop their vevs @xmath251 .\nthe @xmath154 term of each @xmath252 is given by @xmath253 where @xmath254 is the coefficient of the fayet - iliopoulos ( fi ) term , and the ellipsis denotes contributions from other fields charged under @xmath252 , which are assumed not to have vevs .\ngiven nonvanishing fi terms , @xmath255 , the @xmath154-flatness conditions mean @xmath256 and nonuniversal vevs @xmath25 are indeed realized . in this case\n, the dynamical origin of nonuniversal vevs is the nonvanishing fi terms .\nthese may be generated at the loop level .\nfurthermore , if the matter content is different for each gauge theory , the @xmath254 themselves have complicated forms .\nabove , we supposed that the charges of @xmath9 are @xmath248 under @xmath257 .\nalternatively , if @xmath9 have charges @xmath258 under @xmath257 and other matter fields have integer charges , the gauge symmetry @xmath247 is broken to the product of a diagonal @xmath50 gauge symmetry and the discrete gauge symmetry @xmath259\n. such discrete gauge symmetry would be useful for phenomenology  @xcite .\nmodels with nonuniversal gauge couplings @xmath7 are also interesting in the sense that they can describe the localization of massless vector fields .\na nonuniversality of gauge couplings is generated , e.g. ,  in the case that the @xmath6 gauge theories have different matter content from each other .\nthen radiative corrections to gauge couplings and their renormalization - group running become nonuniversal , even if their initial values are equal .\nthis fact is also applicable to the above - mentioned mechanism for nonuniversal @xmath25 .\nsuppose that the @xmath239 theory contains ( @xmath260 ) vectorlike quarks which decouple at @xmath261 .\nthe gauge couplings @xmath262 are then determined by @xmath263 where we have assumed that the @xmath239 theories are strongly coupled at a high - energy scale @xmath264  ( @xmath265 ) .\ntuning of the relevant matter content thus generates the desired linear dependence of @xmath245 . with these radiatively induced couplings ( [ eq : nonuni - g ] ) at hand , the vevs are determined from eq .\n( [ eq : dtvev ] ) : @xmath266\nwe have formulated 4d models that provide 5d field theories on generic warped backgrounds .\nthe warped geometries are achieved with generic values of symmetry - breaking vevs , gauge couplings , and other couplings in the models .\nwe focused on field localization behaviors along the index space of gauge theory ( the fifth dimension in the continuum limit ) , which is realized by taking relevant choices of the mass parameters .\nas a good and simple application , we constructed 4d models corresponding to bulk field theories on the ads@xmath0 randall - sundrum background .\nthe localized wave functions of massless modes are completely reproduced with a finite number of gauge groups .\nin addition , the exponentially suppressed spectrum of the kk modes is also generated .\nthese results imply that most properties of brane world models can be obtained within 4d gauge theories .\nsupersymmetric extensions were also investigated . in 5d warped models ,\nthe bulk and boundary mass terms of spinors and scalars satisfy complicated forms imposed by supersymmetry on the rs background .\nhowever , we show in our formalism that these forms of the mass terms are derived from a 4d _ global _ supersymmetric model on a _\nflat _ background .    as an application of our 4d formulation\n, we derived hierarchical forms of yukawa couplings .\nthe zero modes of scalars and spinors with different masses have different wave - function profiles as in the 5d rs cases .\ntherefore by varying the @xmath213 mass parameters for each generation , one can obtain realistic yukawa matrices with a large hierarchy from the overlaps of the wave functions in a purely 4d framework .\nother phenomenological issues such as proton stability , grand unified theory ( gut ) symmetry breaking , and supersymmetry breaking can also be discussed .\nthe conditions on the model parameters should be explained by some dynamical mechanisms if one considers the models from a fully 4d viewpoint .\none interesting way is to include additional strongly coupled gauge theories . in this case , a small @xmath213 difference between gauge couplings is converted to exponential profiles of symmetry - breaking vevs via dimensional transmutation , and indeed generates a warp factor of the rs model . a difference of gauge couplings\nis achieved by , for example , the dynamics controlling dilatons , or radiative corrections to gauge couplings .\nsupersymmetrizing models provide a mechanism for dynamically realizing nonuniversal vevs with @xmath154-flatness conditions .\nour formulation makes sense not only from the 4d points of view but also as a lattice - regularized 5d theory . in this sense , effects such as the ads / conformal field theory ( cft ) correspondence might be clearly seen with our formalism . as another application , it can be applied to construct various types of curved backgrounds and bulk or boundary masses .\nfor example , we discussed massless vector localization by varying the gauge couplings @xmath7 .\nfurthermore , one might consider models in which some fields are charged under only some of the gauge groups .\nthese seem not like bulk or brane fields , but `` quasi - bulk '' fields .\napplications including these phenomena will be studied elsewhere .\nthis work is supported in part by the japan society for the promotion of science under the postdoctoral research program ( grants no .  @xmath267 and no .\n@xmath268 ) and a grant - in - aid for scientific research from the ministry of education , science , sports and culture of japan ( no .  @xmath269 ) .\nhere we briefly review the field theory on a rs background , following ref .\none of the original motivations for introducing a warped extra dimension by randall and sundrum is to provide the weak planck mass hierarchy via the exponential factor in the space - time metric .\nthis factor is called `` warp factor , '' and the bulk space a `` warped extra dimension '' .\nsuch a nonfactorizable geometry with a warp factor distinguishes the rs brane world from others .\nconsider the fifth dimension @xmath41 compactified on an orbifold @xmath270 with radius @xmath271 and two three - branes at the orbifold fixed points @xmath121 and @xmath272 .\nthe einstein equation for this five - dimensional setup leads to the solution  @xcite @xmath273 where @xmath55 is a constant with mass dimension @xmath56 .\nlet us study a vector field @xmath274 , a dirac fermion @xmath275 , and a complex scalar @xmath129 in the bulk specified by the background metric ( [ metric ] ) .\nthe 5d action is given by @xmath276 , \\label{kin}\\ ] ] where @xmath277 and the covariant derivative is @xmath278 where @xmath279 is the spin connection given by @xmath280 and @xmath281 . from the transformation properties under @xmath282 parity , the mass parameters of scalar and fermion fields are parametrized as is taken as @xmath283 .\nhere we adopt @xmath284 , and then the boundary mass parameter @xmath151 in eq .\n( [ eq : smass ] ) is different from that in ref .\n@xcite by the factor @xmath285 . ] @xmath286 where @xmath150 , @xmath151 , and @xmath102 are dimensionless parameters .\nreferring to @xcite , the vector , scalar and spinor fields are cited together using the single notation @xmath287 .\nthe kk mode expansion is performed as @xmath288 by solving the equations of motion , the eigenfunction @xmath289 is given by @xmath290 ,    \\label{eq : modefunction}\\end{aligned}\\ ] ] where @xmath291 , @xmath292 , and @xmath293 for each component in @xmath294 .\n@xmath295 is the normalization factor and @xmath296 and @xmath297 are the bessel functions .\nthe corresponding kk spectrum @xmath298 is obtained by solving @xmath299    a supersymmetric extension of this scenario was discussed in  @xcite .\nthe on - shell field content of a vector supermultiplet is @xmath300 where @xmath274 , @xmath301 , and @xmath302 are the vector , two majorana spinors , and a real scalar in the adjoint representation , respectively .\nalso a hypermultiplet consists of @xmath303 , where @xmath304 @xmath305 are two complex scalars and @xmath275 is a dirac fermion . by requiring the action ( [ kin ] ) to be invariant under supersymmetric transformation on the warped background ,\none finds that the five - dimensional masses of the scalar and spinor fields have to satisfy @xmath306 where @xmath102 remains as an arbitrary dimensionless parameter .\nthat is , @xmath307 , @xmath308 , and @xmath114 for vector multiplets and @xmath309 and @xmath310 for hypermultiplets .\nthere is no freedom to choose the bulk masses for vector supermultiplets and only one freedom parametrized by @xmath102 for the bulk hypermultiplets .\nit should be noted that in warped 5d models fields contained in the same supermultiplet have different bulk and boundary masses .\nthat is in contrast with the flat case .\nthe @xmath126 even components in supermultiplets have massless modes with the following wave functions : @xmath311 \\frac{e^{(1/2- c)\\sigma}}{n_0\\sqrt{2\\pi r } } & & \\textrm { for } \\;h^{1\\ , ( 0 ) } \\ , \\textrm { and } \\,\\psi^{(0)}_l .\n\\label{eq : hzero}\\end{aligned}\\ ] ] the subscript @xmath76 means the left - handed ( @xmath126 even ) component .\nthe massless vector multiplet has a flat wave function in the extra dimension .\non the other hand , the wave function for massless chiral multiplets involves a @xmath41-dependent contribution from the space - time metric , which induces a localization of the zero modes . the zero modes with masses @xmath119 and @xmath120 localize at @xmath121 and @xmath312 , respectively .\nthe case with @xmath114 corresponds to the conformal limit where the kinetic terms of the zero modes are independent of @xmath41 .\nl.  randall and r.  sundrum , phys .\nlett . * 83 * , 3370 ( 1999 ) [ hep - ph/9905221 ] ; phys .\n* 83 * , 4690 ( 1999 ) [ hep - th/9906064 ] .\nw.  d.  goldberger and m.  b.  wise , phys .\nd * 60 * , 107505 ( 1999 ) [ hep - ph/9907218 ] ; phys .\nlett . * 83 * , 4922 ( 1999 ) [ hep - ph/9907447 ] ; h.  davoudiasl , j.  l.  hewett and t.  g.  rizzo , phys .\nb * 473 * , 43 ( 2000 ) [ hep - ph/9911262 ] ; a.  pomarol , phys .\nb * 486 * , 153 ( 2000 ) [ hep - ph/9911294 ] ; s.  chang , j.  hisano , h.  nakano , n.  okada and m.  yamaguchi , phys .  rev .\nd * 62 * , 084025 ( 2000 ) [ hep - ph/9912498 ] ; b.  bajc and g.  gabadadze , phys .\nb * 474 * , 282 ( 2000 ) [ hep - th/9912232 ] ; e.  shuster , nucl .\nb * 554 * , 198 ( 1999 ) [ hep - th/9902129 ] .\nt.  gherghetta and a.  pomarol , nucl .\nb * 586 * , 141 ( 2000 ) [ hep - ph/0003129 ] .\nt.  gherghetta and a.  pomarol , nucl .\nb * 602 * , 3 ( 2001 ) [ hep - ph/0012378 ] .\ns.  j.  huber and q.  shafi , phys .\nb * 498 * , 256 ( 2001 ) [ hep - ph/0010195 ] .\nh.  abe and t.  inagaki , phys .\nd * 66 * , 085001 ( 2002 ) [ hep - ph/0206282 ] .\nh.  abe , k.  fukazawa and t.  inagaki , prog .\n* 107 * , 1047 ( 2002 ) [ hep - ph/0107125 ] ; h.  abe , t.  inagaki and t.  muta , in _ fluctuating paths and fields _ , edited by w.  janke , a.  pelster , h .- j .\nschmidt , and m.  bachmann ( world scientific , singapore , 2001 ) [ hep - ph/0104002 ] .\ni.  i.  kogan , s.  mouslopoulos , a.  papazoglou and g.  g.  ross , nucl .\nb * 615 * , 191 ( 2001 ) [ hep - ph/0107307 ] .\ns.  dimopoulos , s.  kachru , n.  kaloper , a.  e.  lawrence and e.  silverstein , phys .\nd * 64 * , 121702 ( 2001 ) [ hep - th/0104239 ] .\nn.  arkani - hamed , a.  g.  cohen and h.  georgi , phys .\n* 86 * , 4757 ( 2001 ) [ hep - th/0104005 ] .\nc.  t.  hill , s.  pokorski and j.  wang , phys .\nd * 64 * , 105005 ( 2001 ) [ hep - th/0104035 ] .\nh.  c.  cheng , c.  t.  hill , s.  pokorski and j.  wang , phys .\nd * 64 * , 065007 ( 2001 ) [ hep - th/0104179 ] ; a.  sugamoto , prog .\ntheor .  phys . *\n107 * , 793 ( 2002 ) [ hep - th/0104241 ] ; h.  c.  cheng , c.  t.  hill and j.  wang , phys .\nd * 64 * , 095003 ( 2001 ) [ hep - ph/0105323 ] ; n.  arkani - hamed , a.  g.  cohen and h.  georgi , phys .\nb * 513 * , 232 ( 2001 ) [ hep - ph/0105239 ] ; h.  c.  cheng , d.  e.  kaplan , m.  schmaltz and w.  skiba , phys .\nb * 515 * , 395 ( 2001 ) [ hep - ph/0106098 ] ; m.  bander , phys .  rev .\nd * 64 * , 105021 ( 2001 ) [ hep - th/0107130 ] ; c.  csaki , g.  d.  kribs and j.  terning , phys .  rev .\nd * 65 * , 015004 ( 2002 ) [ hep - ph/0107266 ] ; h.  c.  cheng , k.  t.  matchev and j.  wang , phys .\nb * 521 * , 308 ( 2001 ) [ hep - ph/0107268 ] ; n.  arkani - hamed , a.  g.  cohen and h.  georgi , hep - th/0108089 ; c.  t.  hill , phys .\nrev .  lett . * 88 * , 041601 ( 2002 ) [ hep - th/0109068 ] ; n.  arkani - hamed , a.  g.  cohen and h.  georgi , jhep * 0207 * , 020 ( 2002 ) [ hep - th/0109082 ] ; i.  rothstein and w.  skiba , phys .  rev .\nd * 65 * , 065002 ( 2002 ) [ hep - th/0109175 ] ; t.  kobayashi , n.  maru and k.  yoshioka , hep - ph/0110117 ; n.  arkani - hamed , a.  g.  cohen , d.  b.  kaplan , a.  karch and l.  motl , hep - th/0110146 ; c.  csaki , j.  erlich , v.  v.  khoze , e.  poppitz , y.  shadmi and y.  shirman , phys .\nd * 65 * , 085033 ( 2002 ) [ arxiv : hep - th/0110188 ] ; g.  c.  cho , e.  izumi and a.  sugamoto , hep - ph/0112336 ; e.  witten , hep - ph/0201018 ; w.  skiba and d.  smith , phys .\nd * 65 * , 095002 ( 2002 ) [ hep - ph/0201056 ] ; r.  s.  chivukula and h.  j.\nhe , phys .\nb * 532 * , 121 ( 2002 ) [ hep - ph/0201164 ] ; n.  arkani - hamed , a.  g.  cohen , t.  gregoire and j.  g.  wacker , jhep * 0208 * , 020 ( 2002 ) [ hep - ph/0202089 ] ; k.  lane , phys .\nd * 65 * , 115001 ( 2002 ) [ hep - ph/0202093 ] ; z.  berezhiani , a.  gorsky and i.  i.  kogan , jetp  lett .\n* 75 * , 530 ( 2002 ) ; pisma  zh .\n.  fiz . * 75 * , 646 ( 2002 ) [ hep - th/0203016 ] ; a.  falkowski , c.  grojean and s.  pokorski , phys .\nb * 535 * , 258 ( 2002 ) [ hep - ph/0203033 ] ; c.  t.  hill and a.  k.  leibovich , phys .\nd * 66 * , 016006 ( 2002 ) [ hep - ph/0205057 ] . c.  csaki , j.  erlich , c.  grojean and g.  d.  kribs , phys .\nd * 65 * , 015003 ( 2002 ) [ hep - ph/0106044 ] .\nk.  sfetsos , nucl .\nb * 612 * , 191 ( 2001 ) [ hep - th/0106126 ] .\na.  kehagias and k.  tamvakis , phys .\nb * 504 * , 38 ( 2001 ) [ hep - th/0010112 ] . c.  d.  froggatt and h.  b.  nielsen , nucl .\nb * 147 * , 277 ( 1979 ) .\ng.  altarelli and f.  feruglio , phys .\nb * 451 * , 388 ( 1999 ) [ hep - ph/9812475 ] .\np.  ramond , r.  g.  roberts and g.  g.  ross , nucl .\nb * 406 * , 19 ( 1993 ) [ hep - ph/9303320 ] .\nl.  e.  ibanez and g.  g.  ross , nucl .\nb * 368 * , 3 ( 1992 ) ; phys .  lett .\nb * 260 * , 291 ( 1991 ) .\nj.  wess and j.  bagger , _ supersymmetry and supergravity _\n( princeton university press , princeton , nj , 1992 )"}
{"lay_summary": " recent observations show that the number of stars with very low metallicities in the dwarf spheroidal satellites of the milky way is low , despite the low average metallicities of stars in these systems . \n we undertake numerical simulations of star formation and metal enrichment of dwarf galaxies in order to verify whether this result can be reproduced with `` standard '' assumptions . \n the answer is likely to be negative , unless some selection bias against very low metallicity stars is present in the observations . ", "article": "the study of the formation and evolution of galaxies is one of the most important issues of present - day astronomy .\nthe currently favoured models suggest that large galaxies such as the milky way formed through the hierarchical accretion of a number of smaller objects .    one possible way to test this scenario is to focus on dwarf galaxies :\nin fact , it is reasonable to expect that their assembly was considerably less complicated than that of the milky way , and easier to understand .\nthe nine dwarf spheroidal ( dsph ) satellites of the milky way are ideal targets in this respect : theoretically , they might be the `` fossil '' remnants of the `` building blocks '' which ended up inside the milky way ; observationally , they can be studied in much greater detail than more distant objects .\nfor example , it has been possible to study their stellar populations , extracting informations about their star formation ( sf ) and chemical evolution histories ( see e.g. the review by mateo 1998 ) , which turned out to be quite varied . however , all of them contain a population of very old stars , and all of them exhibit low mean metallicities ( grebel & gallagher 2004 ) .\nlarge observational programs ( such as dart , i.e. dwarf abundances and radial - velocities team ) are measuring , for the first time , the stellar metallicity distribution in dsph galaxies ( tolstoy 2004 ; koch 2006 ; battaglia 2006 ) . despite the low average metallicities ( consistent with previous estimates ) , out of about 2000 stars which were observed in four different galaxies ( carina , fornax , sculptor , and sextans ) , none of them turned out to have a metallicity lower than [ fe / h]=-3 , which is quite surprising ( helmi 2006 ) .    here\n, we use numerical simulations of chemical enrichment of dwarf galaxies in order to investigate whether this dearth of very metal poor stars ( vmpss , i.e. stars with @xmath0}\\leq-3 $ ] ) is consistent with the simple hypothesis that the gas in the dwarf galaxies was completely self - enriched in metals ( i.e. that the gas metallicity when sf started in these galaxies was essentially 0 ) , and that the imf of these galaxies was always given by a salpeter power law extending from 0.1 to 100 @xmath1 .\nwe modified the public sph code gadget ( springel 2001 ; springel 2005 ) in order to include the treatment of gas cooling , sf , supernova ( sn ) and stellar wind feedback , and metal enrichment of the inter - stellar medium .\na complete description will be given in ripamonti 2006 .\nhere it is sufficient to say that the gas cooling rate was taken from sutherland & dopita ( 1993 ) ( if @xmath2 ; otherwise it was assumed to be 0 ) , the sf recipe assumes a schmidt law ( see e.g. thacker & couchman 2000 ) , the stellar lifetimes are taken from the geneva evolutionary tracks ( e.g. schaller 1992 ) , and that sn energies and yields are from woosley & weaver ( 1995 ) .\nour simulations were aimed at reproducing the chemical properties of the sculptor dsph ( hereafter , scl ) , rather than those of the full sample of helmi ( 2006 ) .\nthe reason for this choice is that the low metallicity tail of scl extends to slightly lower metallicities than those of the other three dsphs ( a fact which will strengthen our conclusions ) .\nfurthermore , the sf history of scl appears to have lasted only a few gyr , and after this initial period it appears to have stopped , as no stellar population younger than about 10 gyr has been detected : such a simple history should be relatively easy to reproduce .\nthe total mass of scl was quoted to amount to a few @xmath3 ( queloz 1995 ) , but more recent estimates ( battaglia 2006 ) have put it at a much higher value ( @xmath4 ) . here\nwe report the results of simulations where its total mass was assumed to be @xmath5 : such a value is low when compared to recent measurements , but this should have only a small effect on the metallicity distribution of the stars in the galaxy .    }\n\\leq-3 $ ] ( thin solid ) , sf rate of stars with @xmath6}\\leq-2.5 $ ] ( dashed ) , sf rate of stars with @xmath7}\\leq-2 $ ] ( dotted ) .\ncentral panel : total mass of stars , and mass of stars in metallicity ranges ( symbols as in the top panel ) .\nbottom panel : maximum ( dotted ) , average ( solid ) , and median ( dashed ) of stellar metallicities . ]      at the beginning of our simulations we assume that all the baryons are in gaseous form , and that both the gas and dm follow a nfw profile ( navarro 1997 ) with concentration @xmath8 and virial radius @xmath9 ( approximately coincident with the present - day tidal radius of scl ) .\nwe place 20000 dm particles and 100000 gaseous particles within twice the virial radius .\nsince we assume that a mass @xmath10 is entirely enclosed within @xmath11 , the total mass included in each simulation is about @xmath12 , of which a fraction @xmath13 is in the dm component , and a fraction @xmath14 is in the baryonic component ( @xmath15 , and @xmath16 are the cosmological density parameters of dm and baryons ; see spergel 2006 ) .\nthe initial velocities were assigned according to the recipe for a spherical halo described in hernquist ( 1993 ) , and the gas particles were assumed to be cold .\nthe main parameters of our simulations were related to sf and feedback .\nthey include the typical mass of stellar particles ( @xmath17 ) , the sf efficiency @xmath18 ( which was varied in the range @xmath19 ; see e.g. thacker & couchman 2000 ) , the typical energy of a sn explosion which is transferred to neighbouring gas particles  ( @xmath20  erg ) erg , the feedback completely stopped the sf after much less than one gyr , preventing the formation of more than a few @xmath21 of stars .\n] , and the fraction @xmath22 of the metals ejected in a sn explosion which is retained by the galaxy ( we tested @xmath23 and @xmath24 ; this second value is justified by the results of mac low & ferrara 1999 , which found that metals from the sn ejecta can escape from the galaxy far more easily than the rest of the gas ) .\nand @xmath18 indicated in each panel .\nthe dots ( whose size is comparable to the error bars ) show the metallicity distribution of 496 stars in scl . the leftmost point ( at @xmath0}=-3.5 $ ] ) actually groups together all the vmpss .\nvalues are normalized to the total number of stars . ]\nwe ran a grid of simulations with different combinations of the above parameters ; each one was run for just 1 gyr , because in all of them we found that the formation of very low metallicity stars had essentially stopped before that time ( see fig .\nthe mass of the stellar component was always much smaller ( typically , by a factor 3 - 10 ) than the stellar mass in scl , but sf in the simulated galaxy was still active , even if only for stars with @xmath0}\\gtrsim-2.3 $ ] .\nthis fact must be kept into account when comparing the observed scl metallicity distribution with those produced by the simulations , because the average stellar metallicity from the simulations is still growing . in fig .\n2 we show such a comparison in four typical cases .\nit is apparent that the fraction of vmpss is always very high ; it is higher in models where a low value of @xmath22 and an high value of @xmath18 are assumed ( which is unsurprising because such assumptions correspond to a longer timescale for the metal enrichment of the gas ) . in all the cases\nthe fraction of vmpss is difficult to reconcile with the observations , even when a `` dilution '' by a factor 3 - 10 ( due to the future formation of a large number of stars ) is introduced .\nfurthermore , the models with @xmath23 , where this discrepancy is lower , suffer from another problem at the high metallicity end , since they produce an average metallicity which is too high , at least if @xmath25 .    in fig .\n3 we try to limit the effects of the unknown sf after the first gyr of evolution by looking just at the metallicity distribution of stars with @xmath0}\\leq-2.3 $ ] , because in such metallicity range sf is essentially complete by the time the simulations are stopped . here\nthe excess of vmpss appears less dramatic ; but this is mostly an artifact of the large error bars due to the low number ( 23 ) of observed stars in this metallicity range .\nfurthermore , the _ shape _ of the distributions appear to be different : the models fail to reproduce the observed increase in the number of stars at @xmath0}\\gtrsim-2.5 $ ] , and predict a very large number of essentially metal - free stars ( when @xmath23 is assumed , most of the vmpss have @xmath0}\\leq-4 $ ] ) .\nand @xmath18 indicated in each panel .\ndots with error bars show the metallicity distribution of stars in scl .\nthe two leftmost bins refer to stars with @xmath0}\\leq-4 $ ] , and with @xmath26}\\leq-3.5 $ ] .\nall the values are normalized to the number of stars with @xmath27/h\\leq-2.3 $ ] . ]\nthe metallicity distribution obtained in our simulations is quite different from the predictions of lanfranchi & matteucci ( 2004 ) , as they predict a quite sharp drop at low metallicity ( @xmath28}\\lesssim-2.5 $ ] ) , in agreement with observations ( however , there is significant disagreement at @xmath0}\\gtrsim-1.5 $ ] ) .\nthis is probably due to their assumptions about the `` infall '' history of gas inside the galaxy ( which implies a very low sf rate at early times , when the vmpss should form ) , and about the complete mixing of gas ( so that there is no spread in the age - metallicity relation ) .\ninstead , we have a large spread ( of the order of 1 dex ) in the metallicities of stars which form after the very early stages of our simulations ; furthermore , we do not need to assume an infall history for the gas , even if it can be argued that our initial conditions are not completely realistic because of the assumption that no star ever formed before the halo density profile reached a nfw shape .\nour simulations indicate that the dearth of observed vmpss in dsphs is problematic . apart from the hypothesis that observations are biased in some unidentified way against the detection of vmpss\n, possible solutions might involve a pre - enrichment of the gas up to the @xmath0}\\sim-3 $ ] level ( see e.g. helmi 2006 ) , or a difference between the present and the primordial ( metal - free ) imf , such as a suppression of the sf rate of stars below @xmath29 in environments of very low metallicity ( see e.g. omukai 2005 ) .\nbattaglia , g. , 2006 , a&a 459 , 423 grebel , e.k .\n, & gallagher , j.s . , 2004 apj , 610 , l89 helmi , a. , 2006 , apj 651l , 121 hernquist , l. 1993 , apjs , 86 , 389 koch , a. , grebel , e.k . ,\nwyse , r.f.g . ,\nkleyna , j.t . , wilkinson , m.i .\n, harbeck , d.r . ,\ngilmore , g.f .\n, & evans , n.w . 2006 , aj , 131 , 895 lanfranchi , g.a . , & matteucci , f. 2004 , mnras , 351 , 1338 mac low , m .- m . , & ferrara , a. 1999 , apj , 513 , 142 mateo , m.l .\n1998 , ara&a , 36 , 435 navarro , j.f . ,\nfrenk , c.s .\n, & white , s.d.m .\n1997 , apj , 490 , 493 omukai , k. , tsuribe , t. , schneider , r. , & ferrara , a. 2005 , apj , 626 , 627 queloz , d. , dubath , p. , & pasquini , l. 1995 , a&a , 300 , 31 ripamonti , e. , tolstoy , e. , helmi , a. , & abel , t. 2006 , in preparation schaller , g. , schaerer , d. , meynet , g. , & maeder , a. 1992 , a&as , 96 , 269 spergel , d.n . , 2006 , preprint [ astro - ph/0603449 ] springel , v. , yoshida , n. , & white , s.d.m . 2001 , new astronomy , 6 , 51 springel , v. 2005 , mnras , 364 , 1105 sutherland , r.s . , & dopita , m.a .\n1993 , apjs , 88 , 253 thacker , r.j . , & couchman , h.m.p .\n2000 , apj , 545 , 728 tolstoy , e. , 2004 , apj , 617 , l119 woosley , s.e . , &\nweaver t.a .\n1995 , apjs , 101 , 181"}
{"lay_summary": " we present a numerical method for calculating piecewise smooth spectral functions of correlated quantum systems in the thermodynamic limit from the spectra of finite systems computed using the dynamical or correction - vector density - matrix renormalization group method . \n the key idea is to consider this problem as a blind deconvolution with an unknown kernel which causes both a broadening and finite - size corrections of the spectrum . in practice \n , the method reduces to a least - square optimization under non - linear constraints which enforce the positivity and piecewise smoothness of spectral functions . \n the method is demonstrated on the single - particle density of states of one - dimensional paramagnetic mott insulators represented by the half - filled hubbard model on an open chain . \n our results confirm that the density of states has a step - like shape but no square - root singularity at the spectrum onset . ", "article": "the dynamical density  matrix renormalization group ( dmrg )  @xcite and the closely related correction  vector dmrg  @xcite have been widely used in the last decade to compute the dynamical correlation functions and spectral functions of low - dimensional strongly correlated quantum systems .\n@xcite although more powerful dmrg approaches have been developed recently ,  @xcite dynamical dmrg ( ddmrg ) often remains the method of choice because it offers two practical advantages over the other approaches : it is simpler and it can be easily parallelized .\nfor instance , it has been recently shown that ddmrg allows us to investigate features with small spectral weights such as power - law pseudo - gaps in luttinger liquids .\n@xcite the main drawback of ddmrg is that it always yields the convolution of the desired spectrum with a lorentzian distribution of finite width .\ntherefore , the true spectrum can only be obtained through a deconvolution of the ddmrg spectrum .\n( in principle , there are some methods to get around this problem  @xcite but they are rarely used in practice . )    deconvolution is a typical ill - conditioned inverse problem , however .\n@xcite a direct solution of the deconvolution equation usually yields a very noisy and thus useless spectrum . nevertheless , various regularization methods have been successfully used to deconvolve ddmrg spectra for one - dimensional systems and quantum impurity problems .\n@xcite astonishingly , some of these deconvolution methods even allow us to bypass the finite - size scaling analysis and to obtain the piecewise smooth spectrum of an infinite systems directly from a broadened finite - system ddmrg spectrum .\nunfortunately , regularization also smooths out the sharp features of the true spectrum .\nthis is a serious issue as the spectra of one - dimensional systems and quantum impurities often exhibit very interesting ( power - law ) singularities .    in this paper\nwe present a method , which allows us to determine sharp spectral features in the thermodynamic limit starting from a broadened finite - system ddmrg spectrum . for this purpose\nwe consider the extrapolation to the thermodynamic limit and the deconvolution for the lorentzian kernel to be a single blind deconvolution ,  @xcite i.e.  an inverse problem with an unknown kernel including both the lorentzian broadening and the finite - size effects . the key idea to preserve sharp spectral features in a piecewise smooth spectrum is to impose a minimal distance @xmath0 between extrema of the deconvolved spectrum . to illustrate our method we investigate the single - particle density of states ( dos ) of one - dimensional paramagnetic mott insulators represented by the half - filled hubbard model .\n@xcite we confirm that this dos has the step - like onset predicted by field - theoretical studies  @xcite at least at weak to intermediate coupling up to @xmath1 .\nthe hubbard model  @xcite with on - site interaction @xmath2 and nearest - neighbor hopping @xmath3 is a basic lattice model for the physics of strongly interacting electrons , in particular the mott metal - insulator transition .\n@xcite at half filling ( i.e. , the number of electrons equals the number of sites @xmath4 ) the ground state is a mott insulator for strong interaction @xmath5 , while it is a fermi gas in the non - interacting limit @xmath6 .\nthe hamiltonian of the hubbard model is defined by @xmath7 where the operator @xmath8 ( @xmath9 ) creates ( annihilates ) an electron with spin @xmath10 on the site @xmath11 , @xmath12 , and @xmath13 .\nthe first sum runs over all pairs @xmath14 of nearest - neighbor sites while the other two sums run over all sites @xmath15 .\nhere we will only consider half - filled systems and thus set the chemical potential @xmath16 to have electron - hole - symmetric spectra and a fermi energy @xmath17 .\nthe bulk single - particle dos @xmath18 can be measured experimentally using photoemission spectroscopy or scanning tunneling spectroscopy .\ntheoretically , it can be defined as the average of the local dos @xmath19 where the sum runs over both spins and all sites @xmath15 in the lattice , while @xmath20 is the local single - particle dos at site @xmath15 for spin @xmath10 and can be calculated using @xmath21 for @xmath22 and @xmath23 for @xmath24 . here\n@xmath25 denotes the eigenstates of the hamiltonian @xmath26 and @xmath27 their eigenenergies in the fock space .\nthe ground state for the chosen number of particles corresponds to @xmath28 . the total spectral weight is @xmath29 we will consider only lattice geometry for which the hamiltonian  ( [ eq : hamiltonian ] ) is invariant under the electron - hole transformation @xmath30 .\ntherefore , for half filling the density of states is symmetric , @xmath31 . if the system is translation invariant , the bulk dos and the local dos are identical . for dmrg simulations , however , open boundary conditions are preferred to periodic boundary conditions . in this case\n, the bulk dos can be identified with the local dos on one of the two equivalent middle sites of the system , i.e.  as far as possible from the system boundaries .\ninverse problems such as ( blind ) deconvolutions  @xcite occur in many scientific fields and are among the most challenging numerical computations .\nexperimental measurements and computer simulations often yield approximations of the true quantities which are measured or computed , respectively .\nit is often assumed that the deviations from exact results can be modelled by a convolution with a smoothing function and an additive noise due to the finite accuracy and resolution of the measurement or simulation process .\na typical example of a blind deconvolution is the reconstruction of an original signal from a degraded copy using incomplete information about the degradation process .\n@xcite here we want to compute sharp spectral features in the piecewise smooth spectrum of an infinite system from a broadened finite - system spectrum calculated with ddmrg . in this section\nwe first show that this task can be formulated as a blind deconvolution problem , then present an algorithm for solving it .\nlet @xmath32 be a spectrum of a finite lattice model with @xmath4 sites .\nthis spectrum is a dirac - comb ( a finite sum of dirac - peaks ) @xmath33 where the sum runs over all hamiltonian eigenstates @xmath25 which contributes to the spectrum , i.e.  with a nonzero spectral weight @xmath34 . here\n@xmath35 denotes the corresponding excitation energies .\nthis spectrum can be broadened with a lorentzian distribution of width @xmath36 @xmath37 to obtain a smooth spectral function @xmath38 with the ddmrg method we can calculate this spectrum for a discrete set of excitation energies @xmath39 . as numerical calculations are always affected by errors , ddmrg actually yields values @xmath40 which are related to the true spectral function by @xmath41 for @xmath42 , where @xmath43 represents the unknown errors .\n( it should be noted that ddmrg errors @xmath43 include significant systematic contributions , for instance due to the variational nature of the procedure .\n@xcite ) in principle , one could determine the true spectrum , i.e. , the excitation energies @xmath35 and the corresponding weights @xmath44 , through this system of equations . in practice\n, however , this is an ill - conditioned problem except for simple discrete spectra .\nmoreover , we are not interested in resolving the discrete peaks of small systems but in calculating the piecewise smooth spectra of macroscopic systems .\nthe spectrum in the thermodynamic limit is given by @xmath45 note that , generally , the order of the two limits can not be exchanged .\ntypically , the spectral function @xmath46 is piecewise smooth , i.e. , it exhibits one or more continua as well as isolated sharp features such as steps , power - law singularities or cusps . in principle\n, one should carry out several ddmrg simulations with varying system size @xmath4 and broadening @xmath36 and then extrapolate the numerical data to obtain @xmath46 . in most cases ,\na simultaneous extrapolation for @xmath47 and @xmath48 is possible  @xcite using a constant value of @xmath49 .\nnevertheless , the computational cost of ddmrg simulations increases very rapidly with smaller @xmath36 and the overall cost of this approach is prohibitive for a full spectrum .\nindeed , this approach has been mostly used to study isolated spectral features in the thermodynamic limit such as power - law singularities and steps .\n@xcite    as all operations used to define @xmath46 from @xmath50 are linear , the broadened spectrum of the finite system can also be written explicitly as a function of the infinite system spectrum @xmath51 the kernel @xmath52 includes both the finite - size effects and the lorentzian smoothing .\nits form is not known but it is clear that we must recover a pure lorentzian smoothing in the thermodynamic limit @xmath53 combining eqs .\n( [ eq : deconv ] ) and  ( [ eq : spec - inf ] ) we obtain a system of equations @xmath54 for @xmath55 , relating the ddmrg data set @xmath56 to the infinite system spectrum @xmath46 .\ndetermining @xmath46 from these equations is a so - called inverse problem .\n@xcite this kind of problem is also called blind deconvolution since our knowledge of the kernel is incomplete .\n[ strictly speaking , it is not a deconvolution because eq .\n( [ eq : inverse - problem ] ) is not a convolution .\nhowever , as the kernel approaches the form @xmath57 in the thermodynamic limit , we will use the terminology of deconvolution problems . ]\nit should be obvious that this is an ill - posed problem .\nfirst , the errors @xmath43 and the kernel @xmath52 are not known .\nsecond , the problem is sorely underdetermined as we try to reconstruct the function of a continuous variable from a finite number @xmath58 of data points .\nfinally , a convolution with a lorentzian is a smoothing operation and thus the corresponding deconvolution is an extremely ill - conditioned inverse problem : the solution will be extremely sensitive to small changes or errors in the input .\nvarious deconvolution methods have been used successfully to deduce piecewise smooth spectra from the broadened finite - system spectra calculated with ddmrg .\nthey include , direct inversion at low resolution ,  @xcite linear regularization methods ,  @xcite fourier transform with low - pass filtering ,  @xcite nonlinear regularization methods such as the maximum entropy method ,  @xcite parametrization with piecewise polynomial functions ,  @xcite and a deconvolution ansatz for the self energy .\n@xcite however , this task has not been viewed as a blind deconvolution so far .\ninstead , it has been considered as the deconvolution of a perfectly known kernel .\nthe need for regularization or filtering techniques has been viewed as the consequence ill - conditioning and under - determination of the problem  ( [ eq : inverse - problem ] ) with a lorentzian kernel .\nall of these methods offer some advantages for particular spectral forms . however , their common drawback is that they are ill - suited for sharp spectral features , such as steps or power - law singularities , within or at the edge of a continuum .\neither the regularization procedure smooths out true sharp features excessively or it allows the occurrence of deconvolution artifacts ( artificial sharp structures , rapid oscillations or negative spectral weight ) , especially in the vicinity of the true spectrum singularities .\nnaturally , better results can be obtained if we can use _ a priori _ knowledge about the properties of the spectrum  @xcite but , in practice , this is a rare occurrence .\ntherefore , we need a better method for solving the inverse problem  ( [ eq : inverse - problem ] ) which allows us to determine isolated sharp spectral features accurately while preserving the positivity and the piecewise smoothness of @xmath46\n.    let the ddmrg data ( [ eq : dmrg - data ] ) be evenly distributed in the energy interval @xmath59 $ ] .\nthe difference between two consecutive energies is @xmath60 .\nadditionally , consider a set of equidistant energies @xmath61 in the interval @xmath62 \\subset [ \\epsilon_a,\\epsilon_b]$ ] .\nthe distance between these energies is @xmath63 . as we will always use @xmath64 , we have @xmath65 .\n( typical values are @xmath66 and @xmath67 . ) as in a least - square approach we define a cost function @xmath68 as the sum of the squares of the differences between the ddmrg data and an approximate representation parametrized by a discrete set of variables @xmath69 @xmath70 the absolute minimum of @xmath68 is zero and the corresponding parameters @xmath71 are determined by a linear system of @xmath58 equations @xmath72 using this equation system to determine the parameters @xmath71 would be an unconstrained least - square fit .    in the limit @xmath73 ( followed by @xmath74 and @xmath75 )\nthis equation system becomes equivalent to the inverse problem  ( [ eq : inverse - problem ] ) with vanishing errors @xmath76 .\nthus the absolute minimum of @xmath68 yields the spectrum @xmath46 through @xmath77    if we substitute a lorentz kernel @xmath78 for the unknown kernel , @xmath79 in  ( [ eq : linear - system ] ) , we recover the finite - system deconvolution problem defined by equations  ( [ eq : spec - finite ] ) and  ( [ eq : deconv ] ) for vanishing errors @xmath43 .\nthus the absolute minimum of the cost function corresponds to the discrete finite - system spectrum @xmath32 through @xmath80 if @xmath81 and @xmath82 otherwise .\nphysically , the solution of the deconvolution problem is unique for vanishing errors @xmath43 and thus the cost function should have a unique absolute minimum . from a mathematical point of view , however , the equation system  ( [ eq : linear - system ] ) could have no solution or infinitely many solutions . then any small error @xmath43 can generate wildly different ( and mostly unphysical ) solutions .    therefore , as  ( [ eq : kernel - limit ] ) holds in the thermodynamic limit , it is possible and preferable to obtain a reasonable approximation of the infinite - system spectrum @xmath46 from the minimization of the cost function  ( [ eq : cost - function ] ) with a lorentz kernel under the constraint that the spectral function @xmath46 is physically allowed .\nfor instance , @xmath46 should be positive semidefinite and piecewise smooth .\ngenerally , this solution does not correspond to the absolute minimum or even a local minimum of @xmath68 .\nindeed , the solution of the inverse problem  ( [ eq : inverse - problem ] ) corresponds to the value @xmath83 if we assume that the relation  ( [ eq : solution ] ) holds .\nof course , it could be possible to lower the cost function with other configurations @xmath84 but in that case the relation  ( [ eq : solution ] ) would no longer hold .\nnote that , this idea has been implicitly assumed in all previous deconvolution schemes of ddmrg data aiming at piecewise smooth spectra so far .\nhowever , in these approaches the agreement between solution @xmath84 and numerical data @xmath85 in eq .\n( [ eq : linear - system ] ) with a lorentzian kernel is considered essential while the regularization of the solution and the errors @xmath43 are seen as perturbations which should deteriorate the agreement as little as possible .    yet a blind deconvolution requires equal balancing of the agreement between solution and numerical data and of the smoothness and stability of the solution .\n@xcite hence we must take a different point of view : the lorentzian kernel  ( [ eq : kernel - limit ] ) is only an approximation of the true kernel @xmath52 and the physical constraints on the deconvolved spectrum @xmath46 are essential in the minimization of the cost function . thus we accept significant deviations of @xmath84 from the conditions  ( [ eq : linear - system ] ) yielding the absolute minimum of the cost function , or , equivalently , we assume that the errors @xmath43 can be substantial .      therefore , the blind deconvolution problem can be formulated as a least - square optimization under non - linear constraints .\nwe want to minimize the cost function  ( [ eq : cost - function ] ) with the lorentz kernel under the constraints that the spectrum @xmath46 has the following properties :    1 .\nfinite band width , i.e @xmath86 for all @xmath87 and all @xmath88 for some finite @xmath89 , 2 .\npositive semi - definite , @xmath90 , and 3 .\npiecewise smooth .\nthe first two conditions are easily expressed for the parameters @xmath91 .\nthe somewhat fuzzy concept of a piecewise smooth spectrum must now be formulated more precisely . in principle\n, we wish that @xmath46 is piecewise continuous and that the distance between discontinuities is larger than a minimal energy difference @xmath0 .\nas we must work with a finite number @xmath92 of points @xmath93 , we only have a discrete representation of @xmath46 and we have to formulate a `` continuity '' condition for the discrete set of variables as well .\ntherefore , we require that the distance between two significant extrema is larger than a parameter @xmath94\n. two neighboring extrema at energy @xmath95 and @xmath96 are significant if there relative height difference is larger than a parameter @xmath97 , @xmath98 this condition can easily be formulated for the parameters @xmath91 .\nthe minimal extremum distance @xmath0 must be chosen carefully .\nit should be smaller than the distance between actual singularities in the spectrum @xmath46 but a too small value allows many artificial peaks in a deconvolved spectrum . in practice , we have found that we can obtain reasonable solutions to the blind deconvolution problem which look piecewise smooth using @xmath99 . in all examples discussed in this paper\nevery local extremum is considered to be significant ( i.e. , we have used the precision of floating - point arithmetic @xmath100 ) .\nthe cost function is minimized iteratively .\niterations are repeated until the procedure converges .\neach iteration consists in two steps . in the first step\nthe cost function @xmath101 is minimized with respect to each variable @xmath102 successively .\nthis minimization under constraint does not present any difficulty as @xmath101 is a second - order polynomial in each variable @xmath103 . in the second step , we first find the positions @xmath104 of all significant extrema pairs in @xmath105 which are separated by less than a distance @xmath0\n. then we interpolate the data @xmath105 linearly from @xmath106 to @xmath107 to smooth out the spectrum around the extrema . in doing\nso we take care to preserve the total spectral weight @xmath108 the search for extrema and their smoothing is repeated until there is no more close significant extrema in @xmath109 .\nthen we start the next iteration . by design the first step results in a decrease of @xmath101 .\nthe second step nearly always results in an increase of @xmath101 . without the second step , however , we would perform an under - determined ( @xmath110 ) deconvolution devoid of any regularization mechanism and thus obtain a completely useless result .\ntypically , we observe a rapid and monotonic decrease of @xmath101 in the initial iterations followed by a saturation or oscillations in further iterations .\ntherefore , we monitor the changes in the parameters @xmath103 and the normalized cost function @xmath111 to determine converged configurations @xmath71 .\nconvergence requires typically @xmath112 to @xmath113 iterations depending on the quality of the ddmrg data and the complexity of the spectrum .\nfinally , the solution @xmath91 can be smoothened using a narrow lorentzian distribution to obtain a continuous function @xmath114 with @xmath115 .\nalternatively , we can use a gaussian distribution  @xcite of width @xmath116 .\nthe second approach yields sharper ( real or artificial ) features because the tail of a gaussian distribution decreases faster than that of the lorentz distribution . as our minimization problem possesses many local minima , the final results @xmath71 depend somewhat on the criteria for convergence . however , if the final smoothening function is broad enough , the differences are canceled out .\nif the ddmrg data  ( [ eq : dmrg - data ] ) are not evenly distributed in the interval @xmath59 $ ] or if they already exhibit numerous close extrema , it is useful to regularize them before starting the deconvolution iterations using an interpolation and the smoothening procedure described above .\nthe computational effort required by this procedure is negligible compared to the computational cost of the ddmrg simulations yielding the original data .\n( our code in the programming language c contains less than 400 lines of instructions and the deconvolution of one spectrum takes less than 30 minutes on a single cpu . )\ntherefore , we have not bothered to optimize the algorithm .\nnevertheless , it should be implemented in such a way that it only requires @xmath117 operations rather than the @xmath118 operations of a straightforward implementation .\nthe method described here can be generalized in several ways .\nfor instance , it is possible to use a variable spacing @xmath119 of the ddmrg data points , such as a finer mesh close to sharp spectrum features .\nhowever , this does not seem to improve the results in practice because the broadening parameter @xmath36 , not @xmath119 , is the limiting scale .\na generalization to variable @xmath36 and @xmath119 , as proposed in ref .   for quantum impurity problems , should also be possible but we have not tested it yet . to introduce information about the variation of the spectrum with @xmath36 one could combine ddmrg data obtained for different values of @xmath36 by defining an overall cost function as the sum of the cost functions for each @xmath36 .\nthese generalizations will be tested in future works .\nas an illustration of our deconvolution procedure we discuss its application to the dos of one - dimensional paramagnetic mott insulators .\nthe nature of mott insulators is a long - standing open problem in the theory of strongly correlated quantum systems .\n@xcite in a paramagnetic mott insulator quantum fluctuations or frustration of the antiferromagnetic spin exchange coupling prevents the formation of a long - range magnetic order .\nexperimentally , non - magnetic mott insulators have been found in layered organic insulators  @xcite as well as in quasi - one - dimensional cuprate chains  @xcite and ladders  @xcite . despite decades of extensive research the properties of mott insulators , in particular their single - particle dos , are still poorly understood and thus actively investigated .\nthe half - filled hubbard model  @xcite with repulsive on - site interaction @xmath2 is a basic lattice model for describing mott insulators and the mott metal - insulator transition .\nhere we consider the case of the one - dimensional hubbard model , which is exactly solvable by bethe ansatz .\n@xcite at half- filling it describes a paramagnetic mott insulator with a charge gap ( mott - hubbard gap ) @xmath120 for @xmath121 .\nhowever , the dos can not be calculated directly from the bethe ansatz .\nall ddmrg spectra used here have been calculated with a variable number of density - matrix eigenstates kept ( up to 512 ) to reach a discarded weight lower than @xmath122 and to check dmrg truncation errors .\ntypically , convergence was reached after three sweeps for each frequency interval of size @xmath36 .\nthe ddmrg method is presented in detail in ref .  .\nfor @xmath6 the exact dos of the tight - binding chain in the thermodynamic limit is @xmath123 for @xmath124 while @xmath125 vanishes for larger @xmath126 . for finite coupling @xmath127\nthe spectrum consists in two symmetric hubbard bands separated by the gap @xmath128 .\nlow - order strong - coupling perturbation theory  @xcite predicts a square - root divergence at the dos threshold for @xmath129 , namely @xmath130 for @xmath131 and @xmath132 otherwise with @xmath133 . because of this strong - coupling result and the result of the hartree - fock ( hf ) approximation it has often been assumed that the dos of one - dimensional mott insulators exhibits a square - root divergence at the spectrum onset @xmath134 like in a one - dimensional band insulator .\nindeed , in the unrestricted hf approximation the one - dimensional half - filled hubbard model is an antiferromagnetic mott insulator for @xmath121 .\nits dos is given by @xmath135 for @xmath136 and vanishes otherwise . here\n@xmath137 is the hf gap . for @xmath6 , @xmath138 and\nthis dos reduces to the dos of the tight - biding chain  ( [ eq : dos - tb ] ) . for @xmath139 , @xmath140 and the hf dos shows a square - root divergence at the onset of the spectrum .\nhowever , in the weak - coupling limit @xmath141 a field - theoretical analysis  @xcite predicts that the dos of one - dimensional mott insulators is constant above the threshold energy @xmath142 , @xmath143 at least for @xmath144 .\nthus there is a discrepancy between the field - theoretical and strong - coupling predictions for the behavior of @xmath18 just above the threshold energy @xmath142 .\n( color online ) dos of a tight - binding chain : ( a ) ddmrg spectrum for a @xmath145-site chain with a lorentzian broadening @xmath146 ( red dashed line ) and result of our deconvolution method with a gaussian broadening @xmath147 ( black line ) .\n( b ) enlarged view close to the singularity at @xmath148 on a double logarithmic scale : exact results ( black long - dashed line ) , ddmrg data ( red short - dashed line ) , and the deconvolved spectra @xmath109 for @xmath149 ( black solid line ) and @xmath150 ( blue dash - dot line).,title=\"fig:\",scaledwidth=48.0% ]   ( color online ) dos of a tight - binding chain : ( a ) ddmrg spectrum for a @xmath145-site chain with a lorentzian broadening @xmath146 ( red dashed line ) and result of our deconvolution method with a gaussian broadening @xmath147 ( black line ) .\n( b ) enlarged view close to the singularity at @xmath148 on a double logarithmic scale : exact results ( black long - dashed line ) , ddmrg data ( red short - dashed line ) , and the deconvolved spectra @xmath109 for @xmath149 ( black solid line ) and @xmath150 ( blue dash - dot line).,title=\"fig:\",scaledwidth=48.0% ]    figure  [ fig : tb](a ) shows the dos of a tight - binding chain calculated with ddmrg and the result of our deconvolution procedure .\nthe ddmrg spectrum has been calculated in the middle of an open chain with @xmath151 sites using a broadening @xmath146 , which is just broad enough to hide its discreteness .\nwe see that the square - root divergences at @xmath152 have been smoothed into two broad peaks and that there is substantial spectral weight at energies @xmath153 .\nthe deconvolved dos has been determined from these same ddmrg data using a minimal extremum distance @xmath154 and a final gaussian broadening with @xmath155 .\nwe see now that the singularities at @xmath152 are clearly visible as sharp peaks and that there is not any spectral weight at @xmath153 .\noverall the deconvolved dos is in excellent agreement with the exact spectrum in the thermodynamic limit  ( [ eq : dos - tb ] ) . in particular\n, we do not observe any unphysical artefact such as negative spectral weight .\nhowever , in fig .  [ fig : tb](a ) we observe two shoulders in the deconvolved dos at energies @xmath156 , which are not present in the exact solution  ( [ eq : dos - tb ] ) .\nan enlarged view close to the singularity at @xmath157 is shown in fig .  [\nfig : tb](b ) on a double logarithmic scale .\nwe see that the ddmrg data agree with the exact result only at some distance from the singularity . in this figure\nwe also show deconvolved spectra @xmath109 for two different values of the normalized cost function @xmath158 . clearly , they reproduce the square - root divergence at @xmath157 much better than the original ddmrg data .\nthe overall divergent behavior is visible on a broader energy scale for the smaller value of @xmath158 but we see that the reduction of the cost function is also accompanied by stronger oscillations around the exact result .\nthese oscillations correspond to the shoulder seen in fig .\n[ fig : tb](a ) .\nthe occurrence of artificial shoulder - like structures is the main drawback of our deconvolution procedure .\nany deconvolution method magnifies the noise ( numerical errors ) which is present in the original data .\nthis the main issue that existing methods try to solve in different ways .\n@xcite we have systematically tested our deconvolution procedure using exact results for non - interacting systems and purposely adding random numerical errors .\nwe have found that by preventing the formation of local maxima in the deconvolved spectrum our procedure allows us to control the noise magnification only partially .\nunfortunately , it can not handle extrema ( @xmath159 oscillations ) in the spectrum derivative .\nthus the magnified noise shows up as shoulder - like structures ( but not as local maxima , discontinuities , or sharp angles ) on an energy scale @xmath0 and gives a rough appearance to some deconvoled spectra presented here . in principle , we should be able to correct this deficiency with a higher - order interpolation procedure in the smoothening step or with a smoothening of the derivative of @xmath46 ( i.e. , the finite differences between the parameters @xmath103 ) .\nhowever , we have not yet succeeded in developing a practical algorithm based on these ideas .\n( color online ) ( a ) dos of the one - dimensional half - filled hubbard model at @xmath160 calculated with ddmrg in a 128-site chain using a broadening @xmath146 ( red dashed line ) and the result of our deconvolution procedure ( black line ) with a minimal extremum distance @xmath161 and a gaussian broadening @xmath162 .\nthe vertical dashed lines show the exact position of the dos threshold calculated from the bethe ansatz solution .\n( b ) enlarged view of the same data around the dos threshold for @xmath163 .\nadditionally , the result of our procedure with @xmath164 ( blue dot - dash line ) and of a deconvolution with linear regularization  @xcite ( green dots ) are also shown.,title=\"fig:\",scaledwidth=48.0% ]   ( color online ) ( a ) dos of the one - dimensional half - filled hubbard model at @xmath160 calculated with ddmrg in a 128-site chain using a broadening @xmath146 ( red dashed line ) and the result of our deconvolution procedure ( black line ) with a minimal extremum distance @xmath161 and a gaussian broadening @xmath162 . the vertical dashed lines show the exact position of the dos threshold calculated from the bethe ansatz solution .\n( b ) enlarged view of the same data around the dos threshold for @xmath163 .\nadditionally , the result of our procedure with @xmath164 ( blue dot - dash line ) and of a deconvolution with linear regularization  @xcite ( green dots ) are also shown.,title=\"fig:\",scaledwidth=48.0% ]    figure  [ fig : onedim4](a ) shows the single - particle dos of the half - filled one - dimensional hubbard model at @xmath160 calculated with ddmrg and the result of our deconvolution procedure .\nthe ddmrg spectrum has been computed  @xcite in the middle of an open chain with @xmath151 sites and a broadening @xmath146 .\nthe deconvolved spectrum has been obtained from these ddmrg data using a minimal extremum distance @xmath165 and a final gaussian broadening @xmath166 .\nthe effects of the broadening are clearly visible in the ddmrg data .\nfor instance , although one can recognize the opening of the mott - hubbard gap @xmath128 , spectral weight is clearly visible inside the gap .\na point - wise analysis  @xcite of the scaling for @xmath47 with @xmath167 is required to confirm that the spectral weight jumps from @xmath168 to a finite value at the onset @xmath169 and that the gap width agrees with the exact results @xmath170 calculated with the bethe ansatz .\n@xcite however , the behavior for @xmath171 remains uncertain because of the relatively large broadening used in the ddmrg calculation . on the contrary\nthe deconvolved dos clearly shows a gap with the step - like onset  ( [ eq : dos - ft ] ) predicted by field theory  @xcite at the position @xmath172 given by the bethe ansatz solution .\nwe obtain similarly unambiguous results for @xmath127 up to @xmath173 ( see below ) .\ntherefore , our numerical investigation confirms the field - theoretical prediction  @xcite for the onset of the dos in one - dimensional mott insulators .\nthe superiority of the deconvolved spectrum over the original ddmrg data is even more obvious in fig .\n[ fig : onedim4](b ) which shows an enlarged view of the dos around @xmath172 . in this figure\nwe also show the result of a deconvolution of the ddmrg data with a standard linear regularization method  @xcite .\n( note that this method yields negative spectral weights for some energies @xmath174 but we show the positive parts only . )\nwe see that the result of the deconvolution procedure proposed in this work is much superior to that of the standard one , which is too blurred to allow us to determine the true form of the dos at the onset @xmath172 .\nin addition , fig .\n[ fig : onedim4](b ) shows the result of our deconvolution procedure for a minimal extremum distance @xmath175 which is deliberately too small . in that case ,\nartificial oscillations on energy scales @xmath176 are clearly visible in the deconvolved spectrum .\n( color online ) upper hubbard band in the dos of the one - dimensional half - filled hubbard model at @xmath177 calculated with ddmrg in a 64-site chain using a broadening @xmath178 ( red dashed line ) and the result of our deconvolution procedure ( black line ) with a gaussian broadening @xmath179 .\n, scaledwidth=48.0% ]    in the strong - coupling limit @xmath180 our results are less conclusive .\nfor instance , we show the ddmrg and deconvolved upper hubbard and for a very strong coupling @xmath177 in fig .\n[ fig : onedim40 ] .\nthe ddmrg spectrum has been calculated in the middle of an open chain with @xmath181 sites using a broadening @xmath178 .\nthe deconvolved spectrum has been obtained from these ddmrg data using a minimal extremum distance @xmath182 and a final a gaussian broadening @xmath179 .\ntwo broad peaks are clearly visible at energies @xmath183 as predicted for the strong - coupling limit .\nhowever , the widths and heights of these peaks after deconvolution are not compatible with the square - root divergences  ( [ eq : dos - scpt ] ) predicted by the low - order strong - coupling expansion .\nactually , higher - order corrections indicate  @xcite that some spectral weight is present below the peak at @xmath184 on a scale set by the effective spin exchange coupling @xmath185 .\nthis width is compatible with our deconvolved spectra for @xmath186 .\nthus our numerical results agree at least qualitatively with strong - coupling perturbation theory and suggest that the square - root divergences in the dos  ( [ eq : dos - scpt ] ) is an artifact of a truncated strong - coupling expansion .\nnevertheless , for strong coupling such as @xmath177 we are not able to determine the shape of the dos at the onset @xmath172 . in particular\n, it is not clear if the field - theoretical prediction  ( [ eq : dos - ft ] ) is still valid . indeed ,\nif the distance @xmath187 between onset at @xmath169 and peak at @xmath188 becomes smaller than the minimal extremum distance @xmath0 , we can no longer distinguish both structures in the deconvolved spectrum . in practice ,\nthe distance @xmath0 must be comparable to the broadening @xmath36 of the ddmrg data to obtain piecewise smooth spectra .\ntherefore , although we can reduce the broadening of isolated spectral structures by several orders of magnitude , we can not resolve distinct spectral features on a scale lower than the original broadening of the ddmrg data .\nthis is a limitation of our deconvolution method that one has to keep in mind .\n( color online ) deconvolved dos of the half - filled hubbard model for energies @xmath189 for @xmath6 ( dashed line ) , and from left to right @xmath190 ( red line ) , @xmath191 ( blue line ) and @xmath192 ( green line ) .\nthe result for @xmath177 is shifted to the left by @xmath193 .\n, scaledwidth=48.0% ]    finally , fig .\n[ fig : onedim ] recapitulates the evolution of the dos as a function of the interaction strength @xmath5 . as the spectrum is symmetric @xmath194 ,\nwe show only the deconvolved spectra for positive energies ( i.e. , the upper hubbard band ) . at @xmath6\nthe spectrum consists in a single band with two clearly visible square - root singularities at the band edges @xmath195 . for weak coupling @xmath127\nthe band splits into two symmetric hubbard bands separated by a gap @xmath128 , which agrees perfectly with the charge gap calculated from the bethe ansatz solution . at the dos onsets\n@xmath196 the spectrum exhibits the step - like behavior  ( [ eq : dos - ft ] ) predicted by field theory .\n@xcite there is an apparent plateau between the onset and a strong first peak , which evolves from the square - root singularities at @xmath195 for @xmath6 .\nadditionally , we observe substantial spectral weight and a small second peak at higher excitation energy .\nhowever , for weak enough @xmath127 most of the spectral weight lies between the spectrum onset and the first peak .    as @xmath127 increases ( compare the spectra for @xmath160 and @xmath1 in fig .\n[ fig : onedim ] ) , the spectrum and all its features shift to higher excitation energy and the spectral weight becomes more concentrated between the visible peaks . in addition , we note that the separation between onset energy @xmath142 and the strong first peak becomes systematically smaller until it is no longer resolvable with our method , the peak separation increases monotonically from about @xmath197 for @xmath198 to approximately @xmath199 for @xmath200 , and the strength of both peaks become more equal .    comparing the dos with the momentum - resolved spectral function and the bethe ansatz dispersion ( see figs . 4 and 5 in ref .  )\nwe note that the strong first peak corresponds to the edge of the spinon branch at momentum @xmath201 , the weak second peak corresponds to the edge of the holon branch at @xmath202 , and the upper edge of the dos spectrum coincide with the edge of the single spinon - holon continuum .\nfinally , we do not observe any spectral weight outside the first lower and upper hubbard bands and these two bands account for the full spectral weight  ( [ eq : sum ] ) .\nthus we conclude that higher - energy hubbard bands do not carry any spectral weight in the bulk single - particle dos .\nwe have presented a blind deconvolution procedure which allows us to obtain piecewise smooth spectral functions for infinite - size systems from the ddmrg spectra of finite systems .\nit involves a trade - off between the agreement of the deconvolved spectrum to the original ddmrg data and the piecewise smoothness and positivity of spectral functions . in practice\n, the method reduces to a least - square optimization under non - linear constraints which enforce the positivity and piecewise smoothness .\nwe have tested this deconvolution method on many spectra which are known exactly in the thermodynamic limit , such as the single - particle density of states and the optical conductivity of correlated one - dimensional insulators .\n@xcite we have found that our method works well for several kinds of singularities ( e.g.  power - law band edges , steps , excitonic peaks ) in piecewise smooth spectra . in particular , it allows us to reduce the broadening by orders of magnitude and even to substitute the lorentzian broadening by a gaussian one .\nits main drawback is the frequent appearance of artificial shoulder - like structures on energy scales @xmath203 .\nwe have demonstrated the deconvolution procedure on the single - particle dos in the one - dimensional hubbard model at half filling .\nour results show that the dos has a step - like shape but no square - root singularity at the spectrum onset in agreement with a field - theoretical prediction for one - dimensional paramagnetic mott insulators .\n@xcite in addition , the deconvolution procedure has allowed us to detail the evolution of the dos from the non - interacting limit @xmath6 to the strong - coupling limit @xmath180 .\nwe thank karlo penc and fabian eler for helpful discussions .\nthe gotoblas library developed by kazushige goto was used to perform the ddmrg calculations .\nsome of these calculations were carried out on the rrzn cluster system of the leibniz universitt hannover .\ne. jeckelmann , f. gebhard , and f.h.l .\nessler , phys .\nlett . * 85 * , 3910 ( 2000 ) .\ne. jeckelmann , phys .\nb * 66 * , 045114 ( 2002 ) . t.d .\nkhner and s.r .\nwhite , phys . rev .\nb * 60 * , 335 ( 1999 ) .\npati , s. ramasesha , z. shuai , and j.l .\nbrdas , phys .\nb * 59 * , 14827 ( 1999 )\n. e. jeckelmann , prog .\n. suppl . * 176 * , 143 ( 2008 ) .\ne. jeckelmann and h. benthien , in _ computational many particle physics _\n( lecture notes in physics * 739 * ) , edited by h. fehske , r. schneider , and a. weie ( springer - verlag , berlin , heidelberg , 2008 ) , p. 621 .\nwhite and i. affleck , phys .\nb * 77 * , 134437 ( 2008 ) .\na. weichselbaum , f. verstraete , u. schollwck , j.i .\ncirac , and j. von delft , phys .\nb * 80 * , 165117 ( 2009 ) .\na. holzner , a. weichselbaum , i.p .\nmcculloch , u.  schollwck , and j. von delft , phys .\nb * 83 * , 195115 ( 2011 )\ndargel , a. honecker , r. peters , r.m .\nnoack , and t.  pruschke , phys .\nb * 83 * , 161104 ( 2011 ) .\ne. jeckelmann , j. phys . : condens .\nmatter * 25 * , 014002 ( 2013 ) .\nr. peters , phys .\nb * 84 * , 075139 ( 2011 ) . w.h . press , s.a .\nteukolsky , w.t .\nvetterling , and b.p .\nflannery , _ numerical recipes in c++  the art of scientific computing _\n, second edition ( cambridge university press , cambridge , 2002 ) , chap .\noleary , _ scientific computing with case studies _\n( siam , philadelphia , 2009 ) , chap . 6 and 14 .\nf. gebhard , e. jeckelmann , s. mahlert , s. nishimoto , and r.m .\nnoack , eur .\nj. b * 36 * , 491 ( 2003 ) .\ns. nishimoto and e. jeckelmann , j. phys . : condens .\nmatter * 16 * , 613 ( 2004 ) .\ns. nishimoto , f. gebhard , and e. jeckelmann , j. phys . : condens .\nmatter * 16 * , 7063 ( 2004 ) . c. raas , g.s .\nuhrig , and f.b .\nanders , phys .\nb * 69 * , 041102(r ) ( 2004 ) . c. raas and g.s .\nuhrig , eur .\nj. b * 45 * , 293 ( 2005 ) .\ne. jeckelmann and h. fehske , rivista del nuovo cimento * 30 * , 259 ( 2007 ) .\np. schmitteckert , journal of physics : conferences series * 220 * , 012022 ( 2010 ) . t. ulbricht and p. schmitteckert , euro .\n* 89 * , 47001 ( 2010 ) .\np. campisi and k. egiazarian , _ blind image deconvolution  theory and applications _\n( crc press , boca raton , 2007 ) . j. hubbard , proc .\nlondon a * 276 * , 238 ( 1963 ) .\nf.h.l . essler and a.m. tsvelik , phys .\nb * 65 * , 115117 ( 2002 ) .\nmott , _ metal - insulator transitions _ ( taylor and francis , london , 1990 ) .\nf. gebhard , _ the mott metal - insulator transition _\n( springer , berlin , 1997 ) .\ny. kurosaki , y. shimizu , k. miyagawa , k. kanoda , and g. saito , phys .\nlett * 95 * , 177001 ( 2005 ) .\nkim , j.p .\nhill , h. benthien , f.h.l .\nessler , e. jeckelmann , h.s .\nchoi , t.w .\nnoh , n. motoyama , k.m .\nkojima , s. uchida , d. casa , and t. gog , phys .\nlett . * 92 * , 137402 ( 2004 ) .\nm. azuma , z. hiroi , m. takano , k. ishida , and y. kitaoka , phys . rev\n73 * , 3463 ( 1994 ) .\ne. h. lieb and f. y. wu , phys .\n20 * , 1445 ( 1968 ) .\nessler , h. frahm , f. ghmann , a. klmper , and v. korepin , _ the one - dimensional hubbard model _\n( cambridge university press , cambridge , 2005 ) .\na. parola and s. sorella , phys .\nb * 45 * , 13  156 ( 1992 ) .\nk. penc , k. hallberg , f. mila , and h.  shiba , phys .\nb * 55 * , 15  475 ( 1997 ) . k. penc ( private communication ) .\nessler , f. gebhard , and e. jeckelmann , phys .\nb * 64 * , 125119 ( 2001 ) ."}
{"lay_summary": " complex potential and non - hermitian hopping amplitude are building blocks of a non - hermitian quantum network . \n appropriate configuration , such as @xmath0-symmetric distribution , can lead to a full real spectrum . to investigate the underlying mechanism of this phenomenon , we study the phase diagrams of a semi - infinite non - hermitian systems . \n they consist of finite non - hermitian clusters and semi - infinite leads . based on the analysis of the solutions of the concrete systems \n , it is shown that they can have full real spectra without any requirements on the symmetry and the wave function within the leads becomes unidirectional plane waves at the exceptional point . \n this universal dynamical behavior is demonstrated as the persistent emission and reflectionless absorption of wave packets in the typical non - hermitian systems containing the complex on - site potentials and non - hermitian hopping amplitudes . ", "article": "non - hermitian hamiltonians are often employed to describe the open systems due to their features of complex - valued energy and non - preserved particle probability .\nrecent observations show that a large families of non - hermitian hamiltonians can have all eigenvalues real , if the loss and gain are set in a balanced manner , being invariant under the combination of the parity ( @xmath1 ) and the time - reversal ( @xmath2 ) symmetry . a parity - time ( @xmath3 ) symmetric non - hermitian quantum theory has been well developed as the complex extension of conventional quantum mechanics @xcite .\nalthough the condition of the @xmath3 symmetry for a complete real spectrum is weaker @xcite , it still implies the underlying mechanism can be based on the balance of the loss and gain .\nhowever , such an intuitive consideration of the balance needs to be investigated precisely .\nthe concept of the balance should not be simply understood as the conjugate relation of two non - hermitian subsystems arising from the @xmath3 symmetry .\nit can not provide physical explanation to the following features about exceptional point : ( i ) the @xmath3 symmetry of the system can not guarantee the balance of the loss and the gain , or the reality of the energy levels .\n( ii ) the spontaneous symmetry broken states always appear in pairs .\nfurthermore , this consideration is also related to the precise physical significance of the complex potential and non - hermitian coupling , which are basic elements for a discrete non - hermitian system . on the other hand ,\nthe purpose of this investigation is not only for the fundamental physics , but also for the application in practice due to the formal equivalence between the quantum schrdinger equation and the optical wave equation @xcite .\nfurthermore , the @xmath3 symmetry breaking has been observed in experiments @xcite .    in this paper\n, we investigate semi - infinite non - hermitian system without @xmath0 symmetry . based on this , we try to clarify the concept of balance in the non - hermitian discrete system in the framework of the quantum mechanics rather than a phenomenological description .\nwe show an entirely real spectrum and study the exceptional point of a semi - infinite non - hermitian system from the dynamical point of view .\nwe show that the wave function within the lead becomes a unidirectional plane wave at the exceptional point .\nthis universal dynamical behavior is demonstrated as the self - sustained emission and reflectionless absorption of wave packets by two typical non - hermitian clusters containing the complex on - site potential and non - hermitian hopping amplitude .\nthis paper is organized as follows . in section [ semi - infinite system ]\nwe analyze the classification of possible solutions and solve two examples to illustrate our main idea .\nsection [ relation with pt ]  presents the connection between the semi - infinite systems and @xmath3-symmetric systems .\nsection [ wavepacket ] is devoted to the numerical simulation of the wave packet dynamics to demonstrate the phenomena of the persistent emission and reflectionless absorption .\nsection [ sec_summary ] is the summary and discussion .\nthe discrete non - hermitian model , with the non - hermiticity arising from the on - site complex potentials as well as the non - hermitian hopping amplitude , is a nice testing ground to study the basic features of the non - hermitian system not only because of its analytical and numerical tractability but also the experimental accessibility . in recent years ,\nfundamental aspects of non - hermitian continuum systems are studies by using discretization znojil , as well as the studies on quantum square wells @xcite . on the other hand ,\nnon - hermitian quantum models are also investigated , such as tight - binding systems @xcite , spin systems @xcite , and strongly correlated systems @xcite . besides the fundamental features of discrete @xmath3-symmetric quantum systems , theoretical research on the quantum dynamics and scattering behaviors in discrete non - hermitian networks are investigated in a series of papers @xcite . in experiment , light transport in large - scale temporal lattices\nis studied in @xmath4-symmetric fiber networks , it is also demonstrated that the @xmath3-symmetric network can act as a unidirectional invisible media @xcite .\nalthough many surprising features and possible applications of @xmath3-symmetric are revealed , they are mostly based on the finite systems . in this paper\n, we intend to study the infinite system .      here\nwe consider a semi - infinite lead coupled to a non - hermitian finite cluster .\nthe hamiltonian is written as @xmath5it is noted that @xmath6  is non - hermitian , possessing the complex - valued eigen energy , while @xmath7  is hermitian , having complete spectrum @xmath8 , @xmath9 and the eigen state @xmath10 .  to investigate the role of the lead in the non - hermitian @xmath11 , we will consider the whole solution of the hamiltonian @xmath12 and analyze its properties .\nthe eigen state can be expressed as @xmath13 .\nthe explicit form of the wave function @xmath14 depends on the structure of @xmath6 . generally speaking\n, the solution of @xmath15 can not be obtained exactly even the explicit form of @xmath6  is given . however , within the lead the wave function is always in the form @xmath16due to the semi - infinite boundary condition .\nthe schrdinger equation has the explicit form@xmath17 \\right ) &   \\notag\\end{aligned}\\]]within all the regions .\nthe solutions of @xmath18 and @xmath15 depend on the structure of the system @xmath6 .\nnevertheless , the exclusive geometry of the lead will give some clues to the characteristics of the eigenvalues and eigenfunctions .\nin the framework of bethe ansatz method , all possible solutions within the lead  can be classified into three types :    \\(1 ) scattering state wave , the wave function and energy are in the form @xmath19\n\\(2 ) monotonic damping wave , the wave function and energy are in the form@xmath20    \\(3 ) oscillation damping wave , the wave function and energy are in the form @xmath21 .\\end{aligned}\\ ] ]    in fig .\n[ fig1 ] , the concerned system and three types of possible solutions within the lead  are illustrated schematically .\nfor the case of a hermitian @xmath6 , the solutions are the form of @xmath22  and @xmath23  with @xmath24 or @xmath25  definitely . in the case of non - hermitian @xmath6\n, @xmath26 may appear associated with the complex energy level . in case of absence of the solution @xmath27\n, full real spectrum achieves , which shows the existence of the stationary states .\nit indicates that the lead acts as a channel to balance the gain or loss in the system @xmath6 .    at certain points\n@xmath28 , the system makes transitions between wavefunctions @xmath29 and @xmath30 ,  as well as between @xmath31 and @xmath27 .\nthe former transition is actually a switch between real and imaginary @xmath32 , preserving the reality of the eigen energy .\nthen the transition point locates at @xmath33 ,  i.e.,@xmath34which usually occurs in the case of hermitian @xmath6 .\nthe later transition only occurs in a non - hermitian system , eigen energy switching between real and complex values .\nin contrast to the above case , the transition point ( referred as exceptional point ) depends on the structure of the non - hermitian @xmath6 , i.e. , @xmath35it indicates that a unidirectional plane wave exists in the lead when an appropriate  non - hermitian @xmath6 is connected .\nit has both fundamental as well as practical implications .\nthis result reveals the exceptional point from an alternative way : it is the threshold of the balance between the non - hermitian  subcluster and the lead . from a practical perspective\n, the unidirectional - plane - wave solution at the exceptional point can be used to realize the reflectionless absorption and persistent emission in the experiment . to characterize the probability generation ( negative in the case of the dissipation ) of the non - hermitian cluster , we introduce the current operator @xcite@xmath36where @xmath37 $ ] .    for three types of wave functions @xmath38 , @xmath39  and @xmath40 , the corresponding currents can be obtained as @xmath41 } .\n\\notag\\end{aligned}\\]]we can see that @xmath42  is time - independent and is conservative along the lead , representing a steady flow or the dynamic balance , while @xmath43  is non - periodically time - dependent , indicating the unbalance of the state .\nin other word , the mechanism of the reality of the spectrum is the balance between the source ( or drain ) and the channel of the probability flow .\nthen the exceptional point is the threshold of such dynamic balance , corresponding to the unidirectional - plane - wave , i.e. , @xmath44  or @xmath45 .\nthen the probability generation for the exceptional point is@xmath46which the sign indicates that the cluster is a source or drain , then it is referred as critical current in this paper .\nunlike the situation in traditional quantum mechanics , the magnitude of the current @xmath47  does not represent the absolute current in traditional quantum mechanics because the corresponding eigenstate is not normalized under the dirac inner product .\nwe will demonstrate and explain these points through the following illustrative example .\nwe would like to point out that , there is another type of the exceptional point , arising from the transition of two types of wave functions @xmath27 and @xmath48 , which is beyond our interest .      in this subsection\n, we investigate two simple exactly solvable systems to illustrate the main idea of this paper . in order to exemplify the above mentioned analysis of relating the wavefunction within the lead and the eigenvalue\n, we take @xmath6  to be the simplest non - hermitian networks to construct two types of exemplified systems .\ntype i is a uniform chain with a complex potential at one end and type ii is a uniform chain with a complex hopping at one end . in the following , we present the analytical results in the framework of above mentioned for the two models in order to perform a comprehensive study .\nthe type i hamiltonian has the form @xmath49where @xmath50  is a complex number .\naccording to bethe ansatz method , the wavefunction @xmath15  can be expressed as    @xmath51    and the schrdinger equations for @xmath52 is    @xmath53 f^{k}\\left ( 1\\right ) .\n\\notag\\end{aligned}\\ ] ]    submitting @xmath15  into the schrdinger equation , we have@xmath54which is the reflection amplitude for the scattering state .\nnow we are interested in the wavefunction with complex eigen energy .\nthe existence of the solution @xmath27  requires@xmath55which lead to @xmath56 with im@xmath57 .\nthen we conclude that there is a unique complex solution within the region im@xmath58 and the system has full real spectrum if the potential is in the rest region . at the boundary\n, we have @xmath59which indicates a circle of radius @xmath60 in the complex plane .\nthe phase diagram is sketched in fig .\n[ fig3 ] ( a ) .\nthen the corresponding wavefunction has the form@xmath61which represents a unidirectional plane wave with energy@xmath62accordingly , the critical current is @xmath63which accords with the intuition that a positive imaginary potential can be a source and a negative imaginary potential can be a drain .\nhowever , unlike the situation in traditional quantum mechanics , the magnitude of the current @xmath47  does not represent the absolute current in traditional quantum mechanics because the eigenstate is not normalized under the dirac inner product .\n-symmetric networks : ( a ) two separable semi - infinite chains with the complex potential and ( b ) with the complex hopping at the end .\n( c ) when an arbitrary semi - infinite system and its conjugate counterpart are connected at infinity , a @xmath3-symmetric system are constructed.,scaledwidth=40.0% ]    before further discussion of the implication of the obtained result , two distinguishing features need to be mentioned .\nfirstly , the non - hermitian system can have full real spectrum even though there is no symmetry required .\nsecondly , there is only one possible complex energy level rather than complex conjugate pairs .\nthus there is no level coalescing occurring at the exceptional point .\nboth of these differ from that of a finite @xmath64-symmetric system . in the following example\n, it will be shown that such features are not exclusive to the complex potential .\nthe type ii hamiltonian has the form@xmath65which is a different type of the non - hermitian model in contrast to the type i. here @xmath66  is a complex number . in the following , we will perform a parallel investigation with the current hamiltonian .\nthe bethe ansatz wave function has the form@xmath67substituting @xmath15  to the schrdinger equation,@xmath68we obtain the reflection amplitude@xmath69the existence of the solution @xmath27requires@xmath70similarly , we conclude that there are two complex solutions within the region @xmath71re@xmath72 , and the system has full real spectrum if @xmath66  is in the region @xmath73re@xmath74 .\nthe phase diagram is sketched in fig .\n[ fig2 ] ( b ) . the boundary can be expressed as@xmath75\n^{2}+% \\left [ \\text{im}\\left ( \\kappa _ { c}\\right ) \\right ] ^{2}\\right\\ } ^{2}=\\left [ \\text{re}\\left ( \\kappa _ { c}\\right ) \\right ] ^{2}-\\left [ \\text{im}\\left ( \\kappa _ { c}\\right ) \\right ] ^{2 } ,   \\label{boundary_cc}\\]]which is a lemniscate of bernoulli in the complex plane .\nthen the corresponding eigen wave functions at the boundary have the form@xmath76where @xmath77is real .\nthe wave functions @xmath78  represent unidirectional plane waves with energy @xmath79 , respectively .\nthis indicates that a complex - coupling dimer is a different type of basic element for a discrete non - hermitian system in comparison with complex potential .\nthere are two eigenstates corresponding to a single exceptional point . in virtue of the critical current @xmath80\n, one can see that the complex - coupling dimer  acts as a source for @xmath81  but a drain for @xmath82 .\nit is noted that both above two examples are not symmetric , which show that the symmetry is not the necessary condition for the occurrence of full real spectrum .\nthe underlying mechanism can be explained as the balance between the source ( or drain ) and the channel . in this sense ,\na semi - infinite chain can act as a source ( or drain ) to balance the original drain ( or source ) .\nthe exceptional point is the threshold of such balance .\nthis point will be elucidated in details in the section [ relation with pt ] .\nso far we have shown that there exist a class of semi - infinite non - hermitian non-@xmath3  symmetric systems possessing fully real spectra .\nthe occurrence of complex levels in such systems , or quantum transition , is not accompanied by the spontaneous symmetry breaking , but the delocalization - localization transition of wave functions .\nso it is interesting to consider the connection between the obtained results and the well developed non - hermitian @xmath3-symmetric quantum mechanics .\nwe start the analysis with the simple configuration , which can constructed from @xmath52 ( @xmath83 ) and its @xmath3  counterpart @xmath84 ( @xmath85 ) , as sketched in figs .\n[ fig3 ] ( a ) and ( b ) . here\nthe action of the parity operator @xmath1 is defined as @xmath86 and the time - reversal operator @xmath87 as @xmath88 .\nthe hamiltonians are written as@xmath89and@xmath90obviously , they are @xmath3-symmetric and have all features of typical pseudo - hermitian systems : ( i ) they have the same phase diagrams in fig .\n( [ fig2 ] ) as their corresponding sub - systems @xmath52  and @xmath91 . at the exceptional points ,\ntwo eigen functions coalesce an entire plane wave within the whole space except the @xmath92th site .\n( ii ) the complex levels come in conjugate pairs .\n@xmath3-symmetry of the eigen functions break .\nthis toy model shows us the essence of symmetry breaking : the delocalization - localization transition of wave functions in each sub - system .\nat this point we are ready to move to a more complete description , considering an inseparable system .\nwe start from the corresponding solutions of the hamiltonians @xmath93  and @xmath94 , which actually can be obtained by applying time - reversal operation , i.e. , taking complex conjugation for the obtained solutions of the hamiltonians @xmath52  and @xmath83 .\nit is interesting to find that the real eigen - valued solutions between @xmath95  and @xmath96  ( @xmath83  and @xmath97 ) can match with each other due to the fact that@xmath98for both examples in the eqs .\n( [ r_cp ] ) and ( [ r_cc ] ) . in other words ,\nall the real eigen - valued solutions will not change if two systems @xmath99  and @xmath96  ( @xmath83  and @xmath97 ) are connected at the infinity , as sketched in fig .\n[ fig3 ] ( c ) .\nit is presumable that the similar situation could occur in finite system , i.e. , a semi - infinite non-@xmath3 symmetric system can be regarded as the rudiment of the corresponding finite @xmath3-symmetric system .\nwe will demonstrate this point through the following illustrative examples , which are finite versions of combined @xmath52  and @xmath96  ( @xmath83  and @xmath94 ) .\na sketch of such systems are given in figs .\n[ fig4 ] ( a ) and [ fig4 ] ( b ) .\nthe potential example * *  * * is a @xmath3 symmetric  non - hermitian @xmath100-site chain with complex on - site potential at two ends , which has the hamiltonian @xmath101it is a @xmath3 symmetric model , i.e. , @xmath102=0 $ ] , where the action of the parity operator @xmath1 is defined as @xmath103 and the time - reversal operator @xmath87 as @xmath88 .  for infinite @xmath100\n, it becomes the combination of the systems @xmath52  and @xmath96 . for finite @xmath100\n, it is an extension version of the model proposed in the previous paper ref .\n@xcite . by using the standard bethe ansatz method ,\nthe solution is determined by the critical equation @xmath104where@xmath105   \\\\ & & + \\sin \\left [ k(n+1)\\right ] + 2\\text{re}\\left ( e^{i\\theta } \\right ) \\sin \\left ( kn\\right ) .\n\\notag\\end{aligned}\\]]accordingly , the exceptional point can be obtained by the equations liang jin , l .\njin@xmath106it is difficult to get the explicit solutions of the eq .\n( critical_condition ) for finite @xmath100 .\nnevertheless , the equation about d@xmath107d@xmath32  can be reduced to@xmath108 + \\cos \\left [ k_{c}(n+1)\\right ]   & & \\\\ + 2\\text{re}\\left ( e^{i\\theta }\n\\right ) \\cos \\left ( k_{c}n\\right ) \\approx 0 & & \\notag\\end{aligned}\\]]by taking the approximation @xmath109 in the large @xmath100  limit .\nit is easy to find that the existence of real @xmath28 solution  requires im@xmath110 and @xmath111 .\nit is in accordance with result in the corresponding semi - infinite system .\nthe dimer example * *  * * can be described by the hamiltonian@xmath112which corresponds to the combination of two systems @xmath83  and @xmath113 . by the same procedure as that for @xmath114\n, we find that the critical equation for finite @xmath100 is @xmath115 + \\chi _ { 1}\\sin \\left [ k\\left ( n-1\\right ) \\right ]   & & \\\\\n-\\sin \\left [ k\\left ( n+1\\right ) \\right ] = 0 & &   \\notag\\end{aligned}\\]]where@xmath116 in addition , the exceptional point for large @xmath100 is determined by the equations @xmath117and@xmath118which leads to the same results as the eqs .\n( [ boundary_cc ] ) and ( cc1 ) .\nit has been shown by the * *  * * @xmath3-symmetric quantum theory , beyond the exceptional points the complex levels in both above two models come in conjugate pairs @xcite and the @xmath3  symmetry of * *  * * the corresponding eigen functions break . nevertheless according to our above analysis\n, the occurrence of the complex level should be accompanied by the delocalization - localization transition of the corresponding wave function .\nwe perform numerical simulation of eigen functions for finite size system to demonstrate this connection . in fig .\nfig5 , we plot the eigenfuctions with complex eigen values including real and imaginary parts for the models @xmath114  and @xmath119 , respectively . * *  * * it shows that the * *  * * @xmath3 * *  * * symmetry  of all the eigen functions break and are local , which accords with our analysis .\nthe above results are helpful to understand the mechanism of the hermiticity of a non - hermitian system .\nit is well known that the existence of the full real spectra of two above @xmath3  systems is attributed to  the balance between the source and drain .\nnevertheless , this description can not provide an explanation for the exceptional point and symmetry breaking since the @xmath3 symmetry of the hamiltonian seems to maintain such a balance always .\nbased on the investigations of above two subsections , we can reach the following picture : a finite non - hermitian cluster can act as a source ( or drain ) , while a semi - infinite lead can act as a tunnel to release the current caused by the source ( drain ) .\na semi - infinite lead has its own threshold to carry the current , which is characterized by the onset of complex energy level , or unsteady current .\nthen the  exceptional point in this sense is the threshold of the balance between source ( or drain ) and the lead .\nit leads to another signature of the point , delocalization - localization transition of the corresponding wave function .    as for a finite @xmath3-symmetric system in the form @xmath114and @xmath119 ,\nthe source and drain is always in balance within the unbroken region .\nthe consistency of the phase diagrams between the finite @xmath0-symmetric system with large @xmath100  and the corresponding semi - infinite systems shows that the exceptional points are caused by the same mechanism .\nthen the essence of the symmetry breaking is the unbalance between the source ( drain ) and the uniform chain , rather than that between source and drain . loosely speaking ,\nthe symmetry breaking is due to that the uniform chain blocks the current from the source and drain . on the other hand , the accordance between the results of these @xmath3  systems with large @xmath100  and that of semi - infinite systems implies that a lead can act as a multifunctional  source ( or drain ) to match a drain ( or source ) .\nwe would like to emphasize the difference between two types of non - hermitian elements , complex on - site potential and non - hermitian hopping amplitude , by means of the current @xmath120  for the eigenstate @xmath121  of the hamiltonian @xmath114  and @xmath122 . in fig .\n[ fig6 ] , we plot the current @xmath123  for all the eigenstates @xmath124  of finite - size systems for @xmath114  and @xmath119 .\nit shows that the signs of the currents are independent of @xmath32 for @xmath114 , but dependent of @xmath32 for @xmath119 .\na certain non - hermitian dimer can be a source or drain for two different eigenstates , which is different from a complex potential .\nin this section we will apply the above theoretical results to simple accessible examples to investigate the dynamic behavior for local initial states .\nthis may provide some insights into the application in practice .\nfirstly , we focus on the phenomenon of the persistent emission .  consider an arbitrary local initial state on the lead in the system at the exceptional point .\nthe initial state can always be written in the form @xmath125where @xmath126  represents the superposition of the scattering states with different @xmath32.it is presumable that the probability of all the scattering states transfers to infinity  after a sufficient long time , and then only the unidirectional plane wave survives . to demonstrate and verify this analysis ,\nnumerical simulations are performed for two typical initial states : an incoming gaussion wavepacket and a delta - pulse at the scattering center . a gaussian wavepacket with momentum @xmath127 and initial center @xmath128 has the form\n@xmath129where @xmath130 is the normalization factor and the half - width of the wavepacket is @xmath131 .\nhere we take @xmath132 , @xmath133  and @xmath134 .\nthe concerned system is described by the hamiltonian in the eq .\n( [ h_1 ] ) with @xmath135 , which corresponds to the persistent emission of the plane wave with momentum @xmath136 .\nthe profiles of the evolved wave functions are plotted in figs .\n[ fig7 ] ( a ) and [ fig7 ] ( b ) .\none can see the profile of the wave and the corresponding phase velocity from the figures ,  and after a little long time the evolved wave functions accord with the plane wave of    @xmath137 , \\\\\n\\text{im}\\left ( \\left\\langle j\\right\n. \\left\\vert \\phi \\left ( t\\right ) \\right\\rangle \\right )   & \\sim & \\sin \\left [ \\left ( \\pi /4\\right ) j+2jt\\cos \\left ( \\pi /4\\right ) \\right ] , \\end{aligned}\\ ] ]    within the finite region along the lead , approximately .\nthis result has implications in two aspects : * *  * * firstly , we achieve a better understanding of the imaginary potential .\nwe found that a complex potential always corresponds to the wave vector of the unidirectional plane wave , which is determined by eq .\n( [ potentialk ] ) . * *  * * secondly , it provides a way * *  * * to measure the complex potential in the experiment .    on the other hand ,\nit is presumable that the reflectionless absorbtion should naturally be reflected in the dynamics of the wavepacket with the momenta around @xmath28 due to the continuity of the reflection coefficient in the vicinity of the exceptional point @xmath28 .\nconsider an incoming gaussian wavepacket with momentum @xmath138 and initial center @xmath128 , which can always be written as @xmath139where @xmath140 denotes the plane wave with momentum @xmath32 , and  @xmath141d@xmath32 is the normalization factor .\nit is a superposition of the plane waves with momenta around @xmath28 , which have small reflection coefficients .\ntherefore there is small probability being reflected for the wavepacket .\nthe optimal situations to achieve the reflectionless absorbtion of a wavpacket are determined by the conditions@xmath142which minimizes the reflectional probability .\nstraightforward derivation indicates that the optimal complex - potential ( hopping ) scattering center system requires @xmath143  ( @xmath144 ) and the momentum of the corresponding reflectionless wave is @xmath145 ( @xmath146 ) .    to demonstrate and verify this analysis ,\nnumerical simulations are performed for two initial wavepackets with @xmath132 , @xmath133 , @xmath134 and @xmath147 , respectively .\nthe concerned system is described by the hamiltonian in the eq .\n( [ h_1 ] ) with @xmath143 , which corresponds to the reflectionless plane wave with momentum @xmath145 .\nthe profiles of the evolved wave functions are plotted in figs .\n[ fig8 ] ( a ) and fig8 ( b ) .\nthe reflection coefficients of the two wavepackets are @xmath148 and @xmath149 , respectively .\nit shows that wider wavepacket leading to lower reflection rate , which accords with the previous theoretical analysis .\nin summary , the mechanism of the non - hermiticity of a discrete non - hermitian system has been investigated in an alternative way .\nit is shown that the symmetry is not the necessary condition for the occurrence of full real spectrum .\nthe underlying mechanism can be explained as the balance between a non - hermitian cluster and a semi - infinite chain : the semi - infinite lead can play a complete role to balance a finite non - hermitian cluster , resulting in a full real spectrum .\nit is also shown that the threshold of such balance is the exceptional point of the semi - infinite non - hermitian systems , the occurrence of the corresponding complex eigenstates experienced the delocalization - localization transition .\nfurthermore , at the exceptional point , the eigen wave function is shown to be a unidirectional plane wave .\npractical application of this feature to the dynamics of the wave packet demonstrates the phenomena of the self - sustained emission and reflectionless absorbtion ,  which could be very useful for the design of quantum devices .\ny. n. joglekar and a. saxena , phys .\na * 83 * , 050101(r ) ( 2011 ) ; d. d. scott and y. n. joglekar , phys .\na * 83 * , 050102(r ) ( 2011 ) ; y. n. joglekar and j. l. barnett , phy .\na * 84 * , 024103 ( 2011 ) .\na. regensburger , c. bersch , m .- a .\nmiri , g. onishchukov , d. n. christodoulides and u. peschel , nature * 488 * , 167 ( 2012 ) ; m .- a .\nmiri , a. regensburger , u. peschel , d. n. christodoulides , phys . rev . a * 86 * , 023807 ( 2012 ) ."}
{"lay_summary": " a derivation is given for the vogel - fulcher - tammann thermal activation law for the glassy state of a bulk polymer . \n our microscopic considerations involve the entropy of closed polymer molecular chains ( i.e. polymer closed strings ) . for thin film polymer glasses , \n one obtains open polymer strings in that the boundary surfaces serve as possible string endpoint locations . \n the vogel - fulcher - tammann thermal activation law thereby holds true for a bulk polymer glass but is modified in the neighborhood of the boundaries of thin film polymers . ", "article": "there has been considerable recent interest on the general dynamics of the glass transitions in bulk polymer systems@xcite .\na central experimental law which controls the rate of transition was long ago formulated by vogel , fulcher and tammann@xcite ; the empirical vft law of transition rates reads @xmath0 \\right\\ } , \\label{intro1}\\ ] ] wherein @xmath1 is the free energy of thermal activation .\nthe vft thermal activation law is quite similar to the well known arrhenius@xcite thermal activation law except for the temperature singularity in the denominator on the right hand side of eq.([intro1 ] ) .\nthe singularity occurs at a dynamical temperature @xmath2 which is somewhat lower than the thermodynamic glass transition temperature @xmath3 .\nthe singularity is thereby never quite attained .\nnevertheless , the critical slowing down of the vft eq.([intro1 ] ) is experimentally well obeyed in bulk polymer glasses . there\nexist somewhat different physical views@xcite as to why the vft law might theoretically be true .\nnevertheless there is presently no agreed upon theory of eq.([intro1 ] ) .\nour purpose is to derive the vft thermal law through the following quite simple quantum mechanical considerations .\nthe transition rate per unit time for an activated process involves an absolute squared transition amplitude ( matrix element ) times a density of final states .\nthe logarithm of the density of final states represents the final entropy .\nthus , the quantum mechanical rule for computing transition rates is that @xmath4 , \\label{intro2}\\ ] ] wherein @xmath5 is the entropy of activation to a state with energy @xmath6 .\nthe theoretical problem is to deduce the nature of the excitations@xcite and compute the entropy of activation from the the logarithm of the final state phase space magnitude @xmath7    the polymer glass excitation configurations@xcite pictured in fig.[fig1 ] are of two types : ( i ) there are - in the bulk of the polymer - closed chains of atoms referred to as _ closed _ strings .\n( ii ) also , there are open polymer chains which begin and end on the boundary surfaces of the bulk polymer and are referred to as _ open _ strings .\nit will be shown below that the closed strings have an entropy obeying the vft thermal activation eq.([intro1 ] ) .\non the other hand , the open string configurations with end points in the neighbourhood of surface boundaries obey shifted thermal activation laws .\nthe distinction between the thermal activation properties of open and closed strings is crucial for an understanding of surface effects which are of importance for thin films@xcite .\nthe vft thermal activation law holds only for the bulk polymer . by contrast\n, the dynamical sinularity temperature @xmath2 decreases as the ratio of boundary surface are to the bulk volume , @xmath8 , increases .\nconsequently , the singularity temperature is sharply lowered@xcite when @xmath9 is decreased to a few nanometers .\nclosed polymer chains in the form of `` polygons '' are treated as a self avoiding random polygons . the number of _ closed self avoiding polygon _\npolymer chains containing @xmath10 links is thought to obey@xcite @xmath11 wherein @xmath12 denotes the connectivity .\nthe de gennes scaling law@xcitein @xmath13 dimensions for the exponent @xmath14 is given by @xmath15 wherein @xmath16 is the fractal dimension of the complete closed chain configuration . in mean field theory@xcite\nwe have @xmath17 if @xmath18 denotes the activation energy per link for a mobile closed chain ( closed string ) , then the energy @xmath19 determines the entropy via eqs.([intro3 ] ) , ( [ closed1 ] ) and ( [ closed4 ] ) according to @xmath20 wherein @xmath21 the activation entropy as a function of energy exhibits a minimum as shown in fig .\n[ fig2 ] . for stable entropy functions ,\nthe maximum entropy principle dictates upward convexity while metastable entropy functions exhibit downward convexity . since the density of final states @xmath22 ,\nrates become slower as the minimum activation entropy is approached .    in terms of the temperature @xmath23 ,\n@xmath24 we have at @xmath2 the activated energy singularity @xmath25 . \\label{closed8}\\ ] ] eqs.([closed3 ] ) , ( [ closed5 ] ) and ( [ closed8 ] ) imply @xmath26   \\nonumber \\\\   & \\ &\n\\ -(3-\\alpha)k_b\\ln \\left[\\frac{(t}{(t - t_0)}\\right ] .\n\\label{closed9}\\end{aligned}\\ ] ]    using eqs.([intro2 ] ) , ( [ closed3 ] ) and ( [ closed9 ] ) , we may now complete the proof that the closed chain activation law has the vft form given by eq.([intro1 ] ) .\nexplicitly , we have @xmath27^{2.8 }   \\nu_\\infty e^{s_\\infty /k_b}\\ . \\label{closed10}\\end{aligned}\\ ] ] in practice , the vft activation process is often observed by measuring viscosity , @xmath28 wherein @xmath29 is the mass density and @xmath30 is the length scale of the polymer links . in this regard , the prediction for the activation free energy @xmath31 is subject to an experimental test of the scaling critical index in eq.([closed2 ] ) .\nconsider the problem of how much activation energy would be required to remove a given section of chain from the condensed matter piece of polymer .\nif the given section of chain were deep within the polymer , the removal would be quite difficult .\nfor example , if one exerted a force on the given chain section , then it would become knotted with other polymer chain sections and would be rendered immobile .\non the other hand , if the given section of chain was entirely located in the neighborhood of the surface boundary of the polymer , then it would be relatively easier to peel the chain off the surface .\nlet us consider , in more detail , the activation energy to slide a section of polymer chain along a given path .\nsuch an activation energy has been denoted above as @xmath32 per link of the chain section .\nfurthermore , let @xmath33 denote the distance from a chain link to the boundary surface . by the above physical arguments\nwe expect @xmath34 to sharply decrease as @xmath35 . from eq.([closed6 ] ) we expect , for uniform connectivity ( @xmath36 ) , the dynamical singularity temperature to be a decreasing function of @xmath33 varying as @xmath37 in a local density theory@xcite , @xmath38 may be parameterized by @xmath39 in which the coherence length is related to the density @xmath40 the @xmath41 relation invalidates the vft eq.([intro1 ] ) for the case of very thin polymer films .\na derivation has been provided for vft activated transition rates in bulk polymer glasses .\nour derivation depends on the micro - canonical counting of the number of closed polymer chain configurations within the bulk glassy system .\nthe configuration counting is mapped into the self avoiding polygon problem .\nthe activation energy @xmath18 per link determining the chain mobility also determines the dynamical glass transition temperature in the empirical vft law .\nthe critical indices employed are calculated as in flory s theory .\nthe chain movements also lend strong support to `` co - operative '' motion inside the bulk .\nit is also to be stressed that the dynamical glass transition temperature , @xmath42 , varies with the distance from the surface boundary through that a coherence length scale of about a few nanometers .\nthis surface effect is due to the fact polymer strings localized near the surface boundary are more mobile than the polymer chains embedded in the bulk . for sufficiently thin films ,\nthe vft activation law thereby becomes modified as in eqs .\n( [ se1 ] - [ se3 ] ) ."}
{"lay_summary": " we present a theoretical study of an ensemble of x - like 4-level atoms placed in an optical cavity driven by a linearly polarized field . \n we show that the self - rotation ( sr ) process leads to polarization switching ( ps ) . below the ps threshold , both the mean field mode and the orthogonal vacuum mode \n are squeezed . \n we provide a simple analysis of the phenomena responsible for the squeezing and trace the origin of vacuum squeezing not to sr , but to crossed kerr effect induced by the mean field . \n last , we show that this vacuum squeezing can be interpreted as _ polarization squeezing_. ", "article": "the principal limit in high precision measurements and optics communication is given by the quantum fluctuations of light . for several years , in order to beat the standard quantum limit , a number of methods consisting in generating squeezed states of light have been developed @xcite . in connection with quantum information technology the quantum features of the polarization of light\nhas raised a lot of attention .\nthe generation of polarization squeezing has been achieved experimentally by mixing an opo - produced squeezed vacuum with a coherent field @xcite , or more recently by mixing two independent opa - originated squeezed beams on a polarizing beamsplitter @xcite .\nseveral schemes using kerr - like media have also been proposed @xcite , and very recently , matsko et al .\nproposed to propagate a linearly polarized field through a self - rotative atomic medium to produce vacuum squeezing on the orthogonal polarization @xcite .\nthe kerr - like interaction between cold cesium atoms placed in a high finesse optical cavity and a circularly polarized field has been studied in our group and a field noise reduction of 40% has been obtained @xcite .\nwe recently observed experimental evidence of polarization squeezing when the incoming polarization is linear @xcite . in this paper , we present a theoretical investigation of polarization squeezing generated by an ensemble of x - like 4-level atoms illuminated by a linearly polarized field . to be as realistic as possible ,\nthe experimental parameters values of ref @xcite are taken as references .\nin the first part of the paper , we give a detailed study of the steady state and show that self - rotation is responsible for polarization switching and saturation leads to tristability .\nwe derive simple analytical criteria for the existence of elliptically polarized solutions and the stability of the linearly polarized solution .\nthis steady state study is essential to figure out the interesting working points for squeezing . in the second part , we focus on the case\nin which the polarization remains linear ( below the ps threshold ) and show that both the linearly polarized field mode and the orthogonal vacuum mode are squeezed .\nanalytical spectra are derived in the low saturation limit and enable a clear discussion of the physical effects responsible for polarization squeezing ; in particular , we demonstrate that self - rotation is associated to strong atomic noise terms preventing vacuum squeezing at low frequency . on the other hand , saturation accounts for the squeezing on the mean field and crossed - kerr effect\nenables to retrieve vacuum squeezing at high frequency .\nthe analytical results are compared with a full quantum calculation .\nfinally , we derive the stokes parameters @xcite and relate their fluctuations to those of the vacuum field .\nthe vacuum squeezing obtained is then equivalent to the squeezing of one stokes parameter , the so - called _ polarization squeezing _ @xcite .\nthe system considered in this paper is a set of n 4-level cold atoms interacting in an optical cavity driven by a linearly polarized field as represented in fig [ fig1 ] .\nwe denote @xmath0 the slowly - varying envelope operators associated with the @xmath1 components of the light @xcite .\nthey are defined from the standard linear polarization components    @xmath2    the atomic frequencies are both equal to @xmath3 .\nthe field frequency is @xmath4 and the detunings from atomic resonance are equal on both transitions to @xmath5 .\nthe 4-level system is described using collective operators for the n atoms of the ensemble , the optical dipoles being defined in the rotating frame associated to the laser frequency ( e.g. @xmath6 ) .\nthe coupling constant between the atoms and the field is defined by @xmath7 , where @xmath8 is the atomic dipole and @xmath9 . with this definition ,\nthe mean square value of the field is expressed in number of photons per second . as in fig\n[ fig1 ] , the population of level 3 decays with rate @xmath10 on level 1 and with rate @xmath11 on level 2 , the dipole decay rate being @xmath12 .\nwe consider the case of saturated optical pumping and neglect the relaxation rate of the ground states populations .\nthis approximation is well verified for alkali cold atoms @xcite . with these conventions ,\nthe atom - field hamiltonian is    @xmath13\\ ] ]    the atomic evolution is then governed by a set of quantum heisenberg - langevin equations    @xmath14    note that we have not reproduced all the atomic equations , but only those of interest for the following .\nthe langevin operators @xmath15 are @xmath16-correlated and their correlation functions are calculated via the quantum regression theorem @xcite .\nwe consider a ring cavity with @xmath17 the transmission of the cavity coupling mirror , @xmath18 the cavity resonance frequency closest to @xmath4 and @xmath19 the cavity round - trip time .\nthe cavity dephasing is @xmath20 .\nthe incoming quantum fields are @xmath21 and the field equations read    @xmath22\nthe atomic steady state is readily obtained by setting the time derivatives to zero and using the fact that a langevin operator mean value is zero . defining saturation parameters @xmath23 for both polarizations ,    @xmath24    the atomic steady state is given by    @xmath25    @xmath26 are the rabi frequencies and @xmath27 is the coupling saturation parameter which plays a symmetrical role with respect to both polarization components . for an x - polarized field , @xmath28 is directly related to the intracavity field intensity .\nit is well known that such a coupled system may exhibit polarization switching when driven by a linearly polarized field @xcite .\nin fact , the intracavity field intensities depend on the atomic dephasings @xmath29 and absorptions @xmath30    @xmath31    with @xmath32 and @xmath33 the linear dephasing and absorption in the absence of saturation . these quantities depend in turn on the intensities to yield a complex coupled system . in order to derive analytical criteria for polarization switching ,\nwe follow the method given in @xcite and decompose dephasings and losses into their linear and non - linear parts ,    @xmath34    where @xmath35 and @xmath36 are the non - linear circular birefringence and dichroism , related to the ellipticity @xmath37 @xcite    @xmath38    thus , as pointed out in the literature @xcite , the optical pumping induces non - linear self - rotation ( sr ) of elliptically polarized light .\nit will be shown in the next section that this effect is responsible for ps in a cavity configuration .\nlet us first focus on the solution for the @xmath1 components .\nnormalizing all the dephasings and absorptions by @xmath39 ( @xmath40 and @xmath41 ) , eqs ( [ aplus]),([amoins ] ) read in steady state    @xmath42    with @xmath43 the maximal intracavity intensity in the absence of absorption . replacing ( [ spm ] ) in ( [ epsilon ] ) , we derive the equation for @xmath44 : non zero solutions correspond to elliptically polarized states .\nafter straightforward calculations , we obtain    @xmath45    the first trivial solution corresponds to the linearly polarized field .\nit follows from the second equation and ( [ phil]),([al ] ) that elliptically polarized states may exist as soon as the existence criterion @xmath46 is satisfied    @xmath47    note that the absorption brings a positive contribution to the existence of asymmetrical solutions : this is due to the fact that non - linear circular dichroism produces `` self - elliptization '' of the field\n. however , this criterion gives no information on the stability of the solutions . in order to get some physical insight into this complicated problem\nit is useful to look at the evolution of the linearly polarized solution .      in this section ,\nwe give a simple interpretation of ps as the threshold for laser oscillations .\nlet us consider the linearly polarized solution along the x axis .\nthe adiabatic elimination of the atomic variables leads to    @xmath48    where @xmath49 is the intracavity field decay rate . in ( [ equationay2 ] )\nall terms have zero mean value and are of order 1 in fluctuations ( @xmath50 ) . using @xmath51 ,\none obtains    @xmath52    owing to sr the fluctuations of the orthogonal mode undergo a phase dependent gain .\na similar equation has already been derived in previous theoretical works in a single pass scheme @xcite . in our configuration\nthe presence of the cavity will lead to oscillations of this mode as soon as the phase sensitive gain is larger than the losses .\nthis condition may be expressed as follows    @xmath53    obviously , the linearly polarized solution is not stable when @xmath54 .\nhowever , the adiabatical elimination of the atomic variables does not _ a priori _ take all causes for instability into account .\nyet , we checked that this threshold analysis was consistent with a numerical calculation of the atom - field stability matrix . in the following we use @xmath55 as a stability criterion for the linearly polarized solution\nnevertheless , it does not yield information on the stability of the elliptically polarized solutions , which has been evaluated numerically . + besides , the ability of a system to produce squeezing being closely related to its static properties , the fluctuations of the vacuum field are expected to be strongly modified in the vicinity of the ps threshold . since eq ( [ equationay3 ] )\nis similar to that of a degenerate optical parametric oscillator ( opo ) below the threshold @xcite , perfect squeezing could be obtained via sr .\nhowever , the atomic noise is not included in ( [ equationay3 ] ) and is to be carefully evaluated .      ,\nthe cavity dephasing corresponding to ps is @xmath57 , close to @xmath58 as given by the ps criterion .\nwhen the cavity detuning is scanned from the right , the linear solution is stable until @xmath59 and unstable afterwards .\nthen the elliptically polarized solutions , @xmath60 and @xmath61 , become stable for @xmath62 .\nwe plot also the resonance peaks ( dashed line ) for the cavity with @xmath63 or @xmath64 atoms , in the absence of sr phenomenon.,width=377 ]    ps is caused by a competition between the two @xmath1 optical pumping processes .\nwe can understand the main features of this effect by restraining ourselves to the case where absorption and saturation are negligible : @xmath65 and @xmath66 . neglecting the excited state populations , the optical pumping equations for the ground state populations are    @xmath67    so that the @xmath68 component tends to pump the atoms into level 2 , the @xmath69 into 1 , and , in steady state , @xmath70 and @xmath71 .\nthe circular birefringence @xmath72 is proportional to the ground state population difference , and consequently , to the intensity difference @xmath73 [ see ( [ epsilon ] ) ] .\nthis simple analysis allows for relating self - rotation to competitive optical pumping and will help us interpret the resonance curves .\n+ under the previous conditions both criteria ( [ critereexistence ] ) and ( [ criterestabilite ] ) are equivalent and it follows that the linearly polarized solution bifurcates into an elliptically polarized state for @xmath74 .\nconsequently , ps is observed as soon as the linear dephasing is greater than half the cavity bandwidth ( @xmath75 ) .\nthis represents an easily accessible condition from an experimental point of view : in our cesium experiment using a magneto - optical trap @xcite , the number of atoms interacting with the light is @xmath76 . to find realistic experimental parameters , we assimilate each one of our x - model transitions to the transition @xmath77 of the @xmath78 line of @xmath79 , for which @xmath80 mhz .\nthe square of the coupling constant @xmath81 is proportional to the ratio of the diffusion section at resonance to the transversal surface @xmath82 mm@xmath83 of the beam , @xmath84 hz .\nthe cavity transmission is 10% . to obtain a sufficiently high non - linearity , keeping the absorption low , a good detuning is @xmath85 , so that an approximate value for the linear detuning is @xmath86 .\nnote that the saturation parameters of ( [ s ] ) are simply    @xmath87    the saturation intensity being @xmath88 mw / cm@xmath83 @xcite , typical values for @xmath23 are 0.1 - 1 .\n+ in fig [ fig2 ] are represented the admissible intensities for the @xmath68 and @xmath69 components versus the cavity detuning for typical experimental values of the parameters .\nthe peak centered on @xmath90 corresponds to the symmetrical solution . when the cavity is scanned from right to left\n, the linearly polarized field ( @xmath91 ) intensity increases until the ps threshold is reached ( @xmath92 ) .\nthen one elliptically polarized state becomes stable .\nthe predominant circular component , say @xmath68 , creates , via the optical pumping process ( [ op1]-[op2 ] ) , a positive orientation of the medium @xmath93 , @xmath94 . since the atomic dephasing decreases to zero for the @xmath68 component ( @xmath95 ) , as if it were propagating in an empty cavity .\nhence , the solution draws close to the zero - dephasing peak , that is , close to resonance in the range @xmath62 . on the other hand\nthe @xmath69 component `` sees '' all the atoms ( @xmath96 ) and breaks down to fit the peak centered on @xmath97 , which is far from resonance . in order to illustrate this interpretation of the resonance curves ,\nthe two airy peaks centered on @xmath98 and @xmath97 are represented in fig [ fig2 ] . as the cavity detuning\nis decreased both asymmetrical solutions reunite when the criterion ( [ criterestabilite ] ) is no longer satisfied and the linear solution becomes stable again .\nthese simple interpretations will help us understand the much more complex general case , when absorption and saturation come into play .\n+ as discussed in ref @xcite , taking into account the ground state relaxation rate @xmath99 yields tristability in the unsaturated optical pumping regime ( @xmath100 ) .\nwe will now show that the optical saturation also leads to tristability .      ,\n@xmath101 and @xmath102 .\nthe linear absorption is @xmath103 .\ndashed parts indicate unstable solutions .\nthe switching occurs for @xmath104 and @xmath105 .\n@xmath106 for @xmath107 , so that the tristability range is @xmath108 .\nthe arrows on the hysteresis cycle correspond to increasing and decreasing cavity detuning scan .\nbelow are plotted the two criteria : @xmath55 giving the stability of the linear solution ( plain ) and @xmath46 giving the existence of asymmetrical solutions ( dashed).,width=491 ]    it is well - known that saturation may induce multistability for the linearly polarized field @xcite in our configuration and substantially modify the steady state .\nwhen the non - linearity is sufficient , there may be three possible values for the x - polarized field intensity .\ntherefore , saturation is an additional cause of instability for the symmetrical solution . in fig [ fig3 ]\n, we plotted the same curves as in fig [ fig2 ] , but for higher values of @xmath109 and @xmath58 .\nas expected , the linearly polarized state solution is distorted as a consequence of the non - linear effect .\nthe effect of absorption is also clear : whereas the symmetrical peak height is reduced , the @xmath68 dominant peak height is not .\nindeed , the @xmath68 component `` sees '' no atoms after the switching .\n+ besides , the system now exhibits tristability for a certain range of the cavity detuning . as mentioned previously the existence of asymmetrical solutions\nis related to the positivity of @xmath46 , whereas the stability of the symmetrical solution is given by @xmath55 .\nfor instance , on fig [ fig3 ] , @xmath106 for @xmath110 and the threshold @xmath111 is reached for a dephasing @xmath112 .\nthus , in the range @xmath113 , two different sets of asymmetrical solutions exist , in addition to the linear polarization state .\nthis phenomenon is due to the saturation experienced by the @xmath68 and @xmath69 components .\nas expected , we checked that only the lower branch of each asymmetrical curve is stable , leading to tristability for the polarization state : linear , @xmath68-dominant or @xmath69-dominant .\nthe system switches for a different value of the cavity detuning if the cavity is scanned from left to right , or from right to left ( see fig [ fig3 ] ) .\nhence , unlike the unsaturated case , saturation induces a multistable behavior and a hysteresis cycle now appears in the resonance curve . +\nthis brief study of the resonance curve for typical parameters leads to an essential observation : the lower branch of the bistability curve for the linear polarized field is not stable .\nwe may wonder if there is a domain of the parameter space for which it is not the case .\nsince the quantum fluctuations are expected to be most reduced in the vicinity of the lower turning point @xcite , the answer is of crucial importance for squeezing and will be treated in the next section .       as a function of @xmath109 .\nps is the switching threshold , @xmath114 and @xmath115 the higher and lower turning points . for certain incident intensities\n@xmath109 three solutions ( 1,2,3 ) exist for the intracavity intensity @xmath116 , of which only one ( 3 ) is stable , instead of the usual two ( 1,3 ) in the absence of ps phenomenon .\n, width=377 ]    to complete the analysis of the steady state , we would like to emphasize that , when the cavity is scanned , ps always happens before reaching the higher turning point of the bistability curve .\nin order to get some insight into this complicated problem , it is worth looking at fig [ fig4 ] .\nwe plotted the typical s - shaped variation of the linearly polarized field intensity @xmath117 versus the incoming intensity @xmath109 , for a fixed value of the cavity detuning @xmath118 .\nwe choose the parameters so that there is bistability for this state of polarization and report the position of the lower ( @xmath115 ) and the higher ( @xmath114 ) turning points . in the absence of the ps phenomenon ,\nthe solutions between @xmath114 and @xmath115 are unstable ( like 2 on fig [ fig4 ] ) , whereas solutions on the lower ( 1 ) and higher ( 3 ) branches are stable\n. however the stability of the linear polarization is modified by the ps effects . to a fixed value of\nthe dephasing corresponds the ps intensity @xmath119 cancelling @xmath55 in ( [ criterestabilite ] ) ; if @xmath120 , then the linear polarization is unstable .\nhence , if @xmath121 is satisfied in the whole parameter space , then ps occurs before reaching @xmath114 , and , consequently , the lower branch is never stable .\n+ this general feature is shown on fig [ fig5 ] , in which we represented different bistability curves as in fig [ fig4 ] .\nthe upper branch of ab is the @xmath114 curve ( the ensemble of the higher turning points when @xmath118 is varied ) , the lower branch is the @xmath115 curve . the dashed curve shows the ensemble of the intensities @xmath119 for which the polarization switches .\nthis curve is always above the @xmath114 curve , confirming that the linear polarization always becomes unstable on account of ps first .\nwhat is more , we see that ps is closer to @xmath114 for low values of @xmath117 .\nwe thus expect this situation to be the most favorable to achieve squeezing via optical bistability .\nwe checked that varying the parameters @xmath58 and @xmath122 does not change the conclusion .\nas a function of @xmath109 for field @xmath123 .\nthe three s - shaped curves correspond to different values of the cavity dephasing ( @xmath124 from left to right ) , @xmath58 and @xmath122 having the same value as in fig [ fig3 ] .\nthe ab segments represent the @xmath114 ( higher ) and @xmath115 ( lower ) curves .\nthe dashed curve is the ensemble of the intensities @xmath119 for which polarization switching occurs .\nthe system exhibits bistability for @xmath125.,width=415 ]    to conclude this section , we would like to point out that bistability , as well as ps , may disappear when the saturation is too high , as can be seen from fig [ fig4 ] .\nhowever , we will focus on the low saturation case in the large detuning limit which is the most favorable case for squeezing , and provides analytical results , as well as a clear physical understanding .\nsince we are interested in the quantum fluctuations , we linearize the quantum operators around their steady state values following the standard linear input - output method @xcite .\nthe elliptically polarized solutions are not of great interest for squeezing since the predominant circular component sees no atom and the other has negligible intensity . therefore , in all the following , we focus on the linearly polarized state and study how both the mean field @xmath123 and the orthogonal vacuum field @xmath126 may be squeezed .\nwe have calculated the outgoing fields noise spectra via a full quantum treatment ( see e.g. @xcite ) involving the four - level system .\nthe outgoing fields are standardly defined from the input - output relation @xcite :    @xmath127    yet , to provide clear interpretations as well as analytical results , we derive simplified equations , first for the mean field mode @xmath123 , then for the vacuum mode @xmath126 . + a similar equation to ( [ equationay2 ] ) can be derived for the field @xmath123 with a term arising from sr in @xmath128 . in the linearization , this product of zero mean value operators vanishes , so that we only have to take saturation into account to derive the spectra of @xmath123 .\nfield squeezing owing to optical bistability has been widely studied @xcite and is known to occur on a frequency range given by the cavity bandwidth @xmath129 .\nthe most favorable configuration is the bad cavity limit : @xmath129 is greater than @xmath130 ( in our experiment , @xmath131 ) . in the large detuning limit , @xmath132 ,\nthe equation for @xmath123 reads at order 3 in @xmath133 ,    @xmath134+\\frac{2}{\\sqrt{t}}a_x^{in } \\label{ax1}\\ ] ]    where @xmath123 is short for @xmath135 .\nthis simplified equation yields the classical kerr terms in @xmath136 producing squeezing .\nnote that absorption , dispersion and the associated atomic noise are not included in ( [ ax1 ] ) .\nthe spectra taking absorption and dispersion into account can be easily derived and are shown on fig [ fig7 ] . the associated susceptibility and correlation matrices , @xmath137_{kerr}$ ] and @xmath138_{kerr}$ ] , of the linear input - output theory\nare reproduced in appendix , and the comparison with a kerr medium is discussed in @xcite . the situation is more complex for the orthogonal mode on account of sr .\nas mentioned in sec [ opo ] , sr seems to be a very promising candidate for generating vacuum squeezing .\nhowever , a careful analysis of the atomic noise , which can not be neglected , is necessary in the squeezing calculations . in the optical pumping regime\nthe circular birefringence , @xmath139 , is proportional to the ground state population difference @xmath140 ( see sec [ opticalpumping ] ) .\nthe sr effect is thus closely related to the fluctuations of @xmath141 , and consequently to the fluctuations of @xmath126 via the coupling term in @xmath142 [ eq ( [ equationay2 ] ) ] .\ntherefore , we derive general equations for @xmath143 and @xmath144 in the fourier domain , and examine their low and high frequency limits . for the sake of simplicity , absorption and linear dispersion , again , are not shown ; however , the additional terms are included in the appendix .\nas previously we place ourselves in the large detuning limit with @xmath66 and obtain , discarding terms of order greater than @xmath145 ,    @xmath146\\\\ & & + \\beta(\\omega)\\frac{2\\delta_0}{n}a_x\\delta j_z+\\frac{2}{\\sqrt{t}}\\delta a_y^{in}+f_{a_y}\\label{ay1}\\\\ -i\\omega\\delta j_z & = & -\\gamma_p\\alpha(\\omega)\\left[\\delta j_z-\\lambda(\\omega)\\left(1-\\frac{s_x}{2}\\right)\\frac{n}{2}\\frac{\\delta s_z}{|a_x|^2}\\right]+f_z\\label{jz1}\\end{aligned}\\ ] ]    where @xmath147 is the usual stokes parameter ( see sec [ polarizationsqueezing ] ) and    @xmath148\\frac{\\beta(\\omega)}{\\lambda(\\omega ) } \\;\\;,\\;\\;\\;\\beta(\\omega)=1-\\frac{s_x}{4\\lambda(\\omega)}\\;\\;,\\;\\;\\ ; \\lambda(\\omega)=\\frac{2\\gamma - i\\omega}{2(\\gamma - i\\omega)}\\ ] ]    with @xmath149 and @xmath150 the langevin operators associated to @xmath126 and @xmath141 after the adiabatical eliminations , @xmath151 the optical pumping rate . in ( [ ay1 ] ) , the last term of the first line is a crossed kerr term and clearly contributes to squeezing .\nwe also see that the coupling with @xmath141 is strongly frequency - dependant and requires a careful investigation . in the next sections\n, we discuss the low and high frequency limits to further simplify the previous equations and give simple interpretations for the squeezing .      ,\n@xmath152 , @xmath153 , @xmath154 , @xmath155 , @xmath156.,width=529 ]    again , to stress the effects on the fluctuations only due to sr , we neglect the terms in @xmath117 responsible for the kerr effect , which will be studied in the next section , and place ourselves in the optical pumping regime , keeping only terms of order 1 in @xmath133 .\nnote that this approximation consists in adiabatically eliminating the optical dipoles and neglecting the excited state populations and thus limits the analysis to the range of frequencies @xmath157 . under these conditions\n, one has @xmath158 , @xmath159 , @xmath160 and eq ( [ jz1 ] ) reduces to the linearized optical pumping equation    @xmath161+f_z \\label{jz2}\\ ] ]    it is clear that the fluctuations of @xmath141 are governed by the time constant @xmath162 , consistently with the optical pumping approximation @xmath163 .\nsr is effective only at low frequency .\nplugging ( [ jz2 ] ) back into ( [ ay1 ] ) , one gets    @xmath164\\delta a_y\\\\ & & + i\\delta_0\\frac{\\gamma_p}{\\gamma_p - i\\omega}\\frac{a_x^2}{|a_x|^2}\\delta a_y^{\\dagger}+\\frac{2}{\\sqrt{t}}\\delta a_y^{in}+\\tilde{f}_{a_y } \\label{ay2}\\end{aligned}\\ ] ]    the sr term comes with an amplitude @xmath58 ( @xmath165 ) around zero frequency , which is much greater than the usual third order saturation non - linearity . very good squeezing could be expected if it were not for the noise coming from the atoms @xmath166 , which we now study .\nthe fluctuation operator arising from atomic and field fluctuations reads    @xmath167    the second term @xmath149 is responsible for the noise due to absorption .\nthe first term includes the optical pumping noise .\none calculates the correlation function of @xmath150 via the quantum regression theorem @xcite    @xmath168    so that    @xmath169    in which we introduced @xmath170 the cooperativity parameter quantifying the strength of the atom - field coupling via the cavity ( @xmath171 in our cs experiment ) .\nfor @xmath172 the noise is thus much more important than the losses due to absorption and therefore has a dramatic influence on the squeezing that could have been produced by the sr term .\nfollowing the method given in @xcite , we derive the susceptibility and correlation matrices which are given in appendix .\nwe can then calculate the outgoing vacuum field spectrum for all the quadratures .\nminimal and maximal spectra are plotted on fig [ fig6 ] in the `` close - to - bad '' cavity limit ( @xmath154 ) corresponding to our experimental configuration . whereas the first is close to the shot - noise level , the second is extremely noisy . in the good cavity limit\n, the noise is even more important .\nthe conclusion is that the optical pumping process adds too much noise at zero frequency for sr to generate vacuum squeezing .\nhowever , this low frequency noise does not prevent squeezing at higher frequencies .\nif one repeats the previous calculation keeping the first order saturation terms in @xmath117 and considers frequencies @xmath173 , one finds    @xmath174    this is not surprising , since the evolution times considered are small with respect to the atomic relaxation time .\nthe system behaves as if @xmath68 and @xmath69 were independent .\nin fact , let us consider two independent two - level systems , 1 - 4 and 2 - 3 , each with @xmath175 atoms . in the large detuning limit , one has @xmath176 and @xmath177 , and the atomic fluctuations follow the field fluctuations @xcite ( still at order 3 in @xmath178 )    @xmath179    so that , using @xmath180 , we retrieve ( [ jzkerr ] ) .\nthis equation shows that the fluctuations of @xmath141 are only caused by saturation and their contribution adds to the crossed kerr terms already mentioned in ( [ ay1 ] ) to retrieve a similar `` kerr '' equation for @xmath126 to that of @xmath123 at high frequency    @xmath181+\\frac{2}{\\sqrt{t}}\\delta a_y^{in}+f_{a_y } \\label{aykerr}\\end{aligned}\\ ] ]    this high frequency behavior is thus characterized by the same kerr - induced optimal squeezing on both polarization modes , consistently with the previous analysis for two independent two - level systems .\nmore precisely , the optimal squeezing spectra are the same for each mode , but involve orthogonal quadratures [ because of the sign difference in the kerr terms between ( [ ax1 ] ) and ( [ aykerr ] ) ] .\nwe now plot the outgoing fields @xmath182 squeezing spectra and discuss the squeezing optimization .\nto derive spectra for the whole frequency range , we combine both effects by adding the matrices obtained in the two asymptotical regimes studied previously . we write the complete susceptibility and correlation matrix under the form @xmath183_y=[\\chi(\\omega)]_{kerr}+[\\chi(\\omega)]_{sr}$ ] and @xmath184_y=[\\sigma(\\omega)]_{kerr}+[\\sigma(\\omega)]_{sr}$ ] , where the kerr matrices are those obtained in the high frequency limit , and the sr matrices those obtained at low frequency ( see appendix for analytical expressions ) .\nthis approximation is good since kerr effect is negligible at low frequency compared to sr , while sr breaks down at high frequency .\n+ in fig [ fig7 ] , typical spectra for a working point close to the ps threshold are represented .\nthe parameters are chosen to be as close to the experimental situation as possible @xcite .\nwe compared these approximate spectra ( a ) with those obtained with a full 4-level calculations based on the linear input - output theory ( b ) .\nthe analytical spectra combining kerr and sr effects show indeed an excellent agreement with the exact calculations , as long as the saturation is low .\nas shown previously , the sr spectrum is close to the shot - noise level .\nthe kerr spectrum is accurate for @xmath126 only for @xmath173 and extends on a range of several @xmath129 as expected @xcite . the combined spectrum ( a ) confirms that sr destroys completely the squeezing at low frequency and reproduces well the exact behavior ( b ) .\nthe best squeezing for @xmath126 , obtained at intermediate frequencies , is about 25% .\n+ note that the kerr spectrum in ( a ) is also valid for field @xmath123 for all frequencies and 45% of squeezing is obtained at zero frequency .\nthe situation for the mean field @xmath123 is identical to that of a circularly polarized field with intensity @xmath116 interacting with @xmath175 two - level atoms as in @xcite , for which the kerr spectrum shows good agreement with the exact spectrum .     given by the sr effect ( dashed ) , by the kerr effect ( light ) and by both effects ( dark ) .\n( b ) exact spectra for the mean field mode @xmath185 ( light ) and the orthogonal vacuum mode @xmath186 ( dark ) .\nparameters values : @xmath187 , @xmath101 , @xmath153 , @xmath154 , @xmath188 , @xmath189.,width=377 ]    as mentioned in sec [ competition ] , we expect squeezing to improve in the vicinity of the ps threshold .\nwe verified this behavior by plotting on fig [ fig8 ] the evolution of the spectra when the cavity is scanned while keeping the incident intensity ( @xmath190 ) constant .\nit appears clearly that the best squeezing is obtained at the peak of the resonance curve , right before the switching .\nthis is due to the fact that , in the low saturation regime , the ps threshold is close to the point where saturation process is the most efficient .    ,\n@xmath101 , @xmath191 , @xmath188 .\nthe working points coordinates are : a ( @xmath192 , @xmath193 ) , b ( @xmath194 , @xmath195 ) , c ( @xmath196 , @xmath197 ) . the inset shows the working points positions on the resonance curve.,width=377 ]    we then study the effect of saturation and plot on fig [ fig9 ] various spectra corresponding to working points close to ps with increasing saturation .\nthe conclusion is that , for given values of the detuning @xmath122 and linear dephasing @xmath58 , there is an optimal value of @xmath117 for squeezing .\nthis is due to the fact that the range for which sr adds noise increases with the saturation and eventually destroys kerr - induced squeezing .\nthe optimal saturation value thus corresponds to a compromise between added noise and kerr squeezing in the intermediate frequency range .\ntherefore , a bad cavity is preferable ( @xmath198 ) , since kerr - induced squeezing occurs on a frequency range given by @xmath129 and sr destroys squeezing for frequencies smaller than @xmath130 .\nspectra for different cavities are represented in fig [ fig10 ] .\nthe case @xmath154 corresponds to the experimental situation , `` close - to - bad cavity '' , the other curves to increasingly bad cavities .\nsince sr is effective on a range smaller and smaller compared to the cavity bandwidth , its effect becomes negligible , and 75% of squeezing can be obtained .\n+ the conclusion is that very interesting squeezing values can be reached in the bad cavity limit for both the mean field mode and the orthogonal field mode . in the next section ,\nwe establish the link between polarization squeezing and the vacuum squeezing obtained in our system .    .\nfor each value of @xmath109 , the working point is chosen close to ps .\nparameters : @xmath187 , @xmath101 , @xmath199.,width=377 ]     ( short dash : @xmath200 , long dash : @xmath201 , plain : @xmath202 ) . for each value of @xmath203 ,\nthe saturation is optimized .\nparameters : @xmath187 , @xmath101 , @xmath153 . ,\nthe noise of the mode with orthogonal polarization with respect to the mean field is commonly referred to as polarization noise .\nhowever , the study of the polarization state fluctuations requires the introduction of the quantum stokes operators @xcite    @xmath204    to be consistent with the definition of our slowly - varying envelope operators @xmath123 , @xmath126 , these stokes operators are time - dependent and expressed in number of photons per second @xcite .\nthey obey the following commutation relationships    @xmath205=0\\hspace{0.7cm}and\\hspace{0.7 cm } \\left[s_{i}(t),s_{j}(t')\\right]= 2i\\epsilon_{ijk}s_{k}\\delta(t - t')\\end{aligned}\\ ] ]    with @xmath206 and then the spectral noise densities of these operators , defined by @xmath207 , satisfy uncertainty relations    @xmath208    the coherent polarization state correspond to the case where both modes @xmath123 and @xmath126 are coherent states .\nthen the noise densities of the stokes parameters are constant and all equal to @xmath209 for @xmath210 .\nthe so called polarization squeezing is achieved if one or more of these quantities ( except @xmath211 ) is reduced below the coherent state value    @xmath212    if the mean field is x - polarized , then @xmath213 and @xmath214 . at first order in noise fluctuations , @xmath215 and @xmath216 read    @xmath217    where @xmath218 is the phase of the mean field and @xmath219 is the quadrature with angle @xmath220 of the orthogonal mode .\ntherefore the fluctuations of these two stokes parameters are proportional to the quadrature noise of @xmath126 and the polarization squeezing of @xmath221 and @xmath222 is simply related to the vacuum squeezing that we have studied in the previous sections .\nthe physical meaning of this result is clear : let us choose @xmath223 , then geometric jitter on the polarization is due to the intensity fluctuations of @xmath126 ( @xmath224 ) , whereas the fluctuations of the ellipticity are caused by the phase fluctuations ( @xmath225 ) . in the general case ,\nthe squeezed and antisqueezed stokes parameters are found to be    @xmath226    note that , unlike @xcite , there is no need to lock the phase - shift difference @xmath227 , since it is automatically done in this system ; this property appears clearly in eq ( [ aykerr ] ) where @xmath228 .\nsince the new set of the stokes parameters @xmath229 , @xmath230 , @xmath231 and @xmath232 still satisfy the relationships ( [ heisenberg ] ) , we obtain polarization squeezing in our system as soon as any quadrature of the vacuum field @xmath126 is squeezed , and the results of the previous sections can be applied to the squeezed stokes component .\nwe have presented a study of polarization switching in an x - like 4-level atoms ensemble illuminated by a linearly polarized light in an optical cavity .\nps has been traced to self - rotation and simple criteria allow for a clear understanding of the switching effects and the multistable behavior of the system .\nthe steady state analysis enables one to figure out the interesting working points for squeezing .\n+ in terms of squeezing the respective contributions of sr and saturation have been investigated and compared to a full quantum calculation . since the propensity for squeezing of sr is cancelled by atomic noise at low frequency\n, the squeezing originates from kerr effect .\nthe mean field mode is squeezed via the usual saturation effects , whereas the vacuum mode squeezing is induced by the mean field via crossed kerr effect .\nboth sr and crossed kerr effects can be dissociated in a bad cavity configuration , thus allowing for high squeezing values .\nlast , this vacuum squeezing is shown to be equivalent to squeezing one stokes operator .      using the input - output theory notations @xcite,@xcite ,\nwe give here the expressions of the susceptibility matrix @xmath183 $ ] and the correlation matrix @xmath184 $ ] for field @xmath126 . in the high frequency limit , they resume to those derived in @xcite in the large detuning limit    @xmath233_{kerr}=\\frac{1}{2\\delta } \\left(\\begin{array}{cc }    1 & 0 \\\\    0 & 1 \\end{array}\\right )    & + \\frac{1}{2\\delta^2}\\left (    \\begin{array}{cc }    i\\gamma+\\omega & 0 \\\\    0 & -i\\gamma-\\omega\\end{array}\\right)\\\\    & -\\frac{g^2}{2\\delta^3}\\left (    \\begin{array}{cc }    2|a_x|^2 & \\varepsilon a_x^2 \\\\\n\\varepsilon a_x^{*2 } & 2|a_x|^2\\end{array}\\right)\\end{aligned}\\ ] ]    @xmath234 yields the susceptibility matrix for the vacuum mode . to retrieve the matrix for @xmath123\n, @xmath235 should be taken equal to @xmath236 .\nthis matrix corresponds to approximating the atoms ensemble with a kerr medium : the term of order 1 in @xmath237 is the linear dephasing , the second order matrix represents dispersion and absorption and the third order term is the non - linear dephasing corresponding to the kerr effect .\nthe associated correlation matrix is      in the kerr limit , the atomic noise comes only from the frequency independent linear losses of the kerr medium , which acts as a beamsplitter for the field .\nsimilar matrices can be derived for field @xmath123 in agreement with ( [ ax1 ] ) . at low frequency , however , the previous matrices have to be completed by      @xmath240_{sr } & = & \\frac{\\gamma_p^2}{4\\gamma_{\\perp}(\\gamma_p^2+\\omega^2)}\\left(\\begin{array}{cc }    1 & -a_x^2/|a_x|^2 \\\\\n-a_x^{*2}/|a_x|^2 &    1\\end{array}\\right)\\\\    & &    + \\frac{\\gamma_p}{2\\delta(\\gamma_p^2+\\omega^2)}\\left(\\begin{array}{cc }    -2\\omega & \\omega+i\\gamma_p\\\\    \\omega - i\\gamma_p & 0\\label{sigmay}\\end{array}\\right)\\end{aligned}\\ ] ]        so that a lot of noise is reported on all the quadratures of @xmath126 for frequencies of the order of @xmath162 , as pointed out in sec [ faradaysection ] . for frequencies\n@xmath173 , the sr noise terms vanish , allowing for crossed kerr effect to produce squeezing ."}
{"lay_summary": " this paper gives a summary of the author s works concerning the emergent general relativity in a particular class of tensor models , which possess gaussian classical solutions . \n in general , a classical solution in a tensor model may be physically regarded as a background space , and small fluctuations about the solution as emergent fields on the space . \n the numerical analyses of the tensor models possessing gaussian classical background solutions have shown that the low - lying long - wavelength fluctuations around the backgrounds are in one - to - one correspondence with the geometric fluctuations on flat spaces in the general relativity . \n it has also been shown that part of the orthogonal symmetry of the tensor model spontaneously broken by the backgrounds can be identified with the local translation symmetry of the general relativity . \n thus the tensor model provides an interesting model of simultaneous emergence of space , the general relativity , and its local gauge symmetry of translation .    \n = 17.5pt plus 0.2pt minus 0.1pt    # 1([#1 ] ) ", "article": "the tensor model was originally considered in @xcite to generalize the matrix model , which describes the two - dimensional simplicial quantum gravity , to higher dimensional cases .\nwhile the matrix model is a successful tool to analyze the two - dimensional simplicial gravity , the tensor model has not been successful in this direction , partly because of the absence of analytical methods to solve it and of physically appropriate interpretations of its partition function .    in ref .\n@xcite , a new interpretation of the rank - three tensor model was proposed .\nnamely , theory of a dynamical rank - three tensor may be regarded as that of dynamical fuzzy spaces .\nthis proposal is based on the fact that a fuzzy space is described by an algebra of functions , which can be characterized by a rank - three tensor that defines multiplication , @xmath0 .\nthis reinterpretation of the tensor model provides a new practical manner of extracting physics from the tensor model . in the original interpretation ,\nit is necessary to compute the tensor model non - perturbatively , since the large volume limit of spaces corresponds to the large loop - number limit of the feynman diagrams of the tensor model . on the contrary , under the new interpretation ,\nthe semiclassical treatment of the tensor model is physically meaningful ; its classical solutions can be regarded as background fuzzy spaces , and small fluctuations around solutions as field fluctuations on fuzzy spaces .\nanother key difference from the original proposal is that rank - three is enough as the rank of tensor to describe fuzzy spaces with arbitrary dimensions .\nthis property drastically simplifies the structures of the tensor model , since various dimensional cases can be treated in a common framework .\nthe rank - three tensor model has mainly been analyzed in numerical manners by the present author @xcite .\nin particular , for the tensor models that possess a certain gaussian type of classical solutions , it has numerically been shown that the properties of low - lying long - wavelength modes of small fluctuations around such gaussian backgrounds are in remarkable agreement with the general relativity in all the dimensional cases having been studied so far ( @xmath1 ) @xcite .\nnamely , the general relativity was found to emerge in the tensor model as an effective long - wavelength description of the tensor model around a particular class of classical background solutions .\nthis is also expected to be true in any other dimensions , since the framework and the procedure of analysis are common .\nthis paper gives a summary of the results obtained so far concerning the emergence of the general relativity in the tensor model .\nthere exist various versions of the rank - three tensor model @xcite .\nthe simplest is the one that has a real symmetric rank - three tensor as its only dynamical variable , and has the invariance under the orthogonal group . in this paper , this simplest one is considered .\nthe dynamical variable is a real - valued rank - three tensor @xmath2 , each index of which takes integers , @xmath3 .\nthe number @xmath4 is the total number of linearly independent functions on a fuzzy space , or can more physically be interpreted as the number of `` points '' forming a fuzzy space .\nthe variable @xmath2 is assumed to be totally symmetric , @xmath5 the algebra of products defined by @xmath6 is commutative but nonassociative in general .\ntherefore the tensor model in this paper is a theory of dynamical commutative _ nonassociative _ fuzzy spaces .\nthe basis of functions @xmath7 can be changed by linear transformations .\na simple choice of equivalence of the basis functions is to assume that bases related by the orthogonal transformations represent equivalent fuzzy spaces .\ncorrespondingly , the tensor model must be invariant under the orthogonal transformation @xmath8 where @xmath9 is an arbitrary element of the orthogonal group @xmath10 .\nthe definition of the system is given by a partition function , @xmath11 where @xmath12 is an action with the variable @xmath2 , and must be invariant under the orthogonal group transformation ( [ eq : trans ] ) . the integration measure @xmath13 must also be invariant under ( [ eq : trans ] ) , and is defined from the invariant metric in the space of @xmath2 given by @xmath14\nso far , the emergence of the general relativity in the tensor model has only been shown around a particular class of backgrounds in the tensor model .\nthese backgrounds have certain gaussian forms , and the algebras defined by them represent certain simple kinds of commutative _ nonassociative _ fuzzy flat spaces with arbitrary dimensions @xcite . in this section , to describe such genuine gaussian backgrounds , the indices of @xmath2 are assumed to take continuous values , while they will take finite discrete values in the actual analyses of the following sections .\nthe gaussian backgrounds have the form , @xmath15 , \\label{eq : cx}\\ ] ] where @xmath16 and @xmath17 are positive numerical constants , @xmath18 are @xmath19-dimensional continuous coordinates , @xmath20 , and @xmath21 .\nthe algebra of functions @xmath22 defines a commutative _ nonassociative _ fuzzy @xmath19-dimensional flat space considered in @xcite . because of the translational symmetry of ( [ eq : cx ] )\n, it is generally more convenient to describe it in the momentum basis . by applying fourier transformation to the coordinate indices , one obtains the expression in the momentum basis because of the reality condition of the tensor in the coordinate basis , and one needs also an additional symmetric tensor @xmath23 for contracting the indices .\nthese details are essentially important in the mode analysis of the following sections .\n] as @xmath24,\\ ] ] where @xmath25 and @xmath26 are positive numerical constants .\none of the motivations for considering such particular solutions is the ( partial ) computability due to the gaussian forms .\nanother is that the fuzzy spaces are physically well - behaved , because the fuzziness is well localized and the spaces are invariant under the poincare transformation , representing fuzzy @xmath19-dimensional flat spaces .\nmoreover , as shown in the next section , there exists a natural correspondence between the metric field in the general relativity and the tensor around the gaussian backgrounds in the tensor model .\nin fact , there exist infinitely many actions that have such gaussian backgrounds as their classical solutions .\ntwo explicit examples have been studied so far @xcite .\nunfortunately , the explicit forms of the actions are very complicated and unnatural .\nthis is a serious problem , which must be investigated in future study .\nhowever , what is interesting and remarkable in these actions in common is that each of them contains all the dimensional gaussian fuzzy flat spaces as its classical solutions , as illustrated in figure  [ fig : potential ] .\nthis means that all the dimensional spaces can be treated with one action in a unified manner .\nthus , for example , it is in principle possible to study transitions between spaces with distinct dimensions in the tensor model .\nin the physical interpretation of the tensor model , a classical solution should be regarded as a background space , and fluctuations of tensor around such a classical solution as field fluctuations on a background space .\nthe main interest of the present study is whether such fluctuations can be identified with the general relativity or not . to check this ,\nthe procedure carried out so far in @xcite assumes a correspondence between the tensor model around the gaussian backgrounds and the metric tensor field in the general relativity .\nthis correspondence enables one to compute the expectations about the tensor model from the general relativity .\nif the expectations successfully agree with the numerical analysis of the tensor model , one may conclude that the general relativity is emergent around the gaussian backgrounds in the tensor model .    generalizing the gaussian backgrounds ( [ eq : cx ] ) in a coordinate invariant manner\n, one can derive a natural correspondence between the metric tensor field in the general relativity and the tensor around the gaussian backgrounds as @xmath27,\\end{aligned}\\ ] ] where @xmath28 , and @xmath29 denotes the geometric distance between @xmath30 and @xmath31 .\nthe main assumption in this correspondence is that the low - lying long - wavelength fluctuations of the tensor around the gaussian backgrounds in the tensor model are exhausted by the metric field in the general relativity in the manner given in ( [ eq : correspondence ] ) .\nit should be noted that this correspondence could be modified in higher orders of the fuzziness @xmath32 .\nfor example , there could exist corrections such as @xmath33 in ( [ eq : correspondence ] ) .\nalthough it is certainly possible to directly use the correspondence ( [ eq : correspondence ] ) in the comparison between the tensor model and the general relativity , it is much more convenient to use a tensor with a smaller rank .\nlet me define @xmath34 small fluctuations @xmath35 around a classical solution @xmath36 induces fluctuations of @xmath37 as @xmath38    on the other hand , if one assumes a gaussian background and puts the assumed correspondence ( [ eq : correspondence ] ) into ( [ eq : tensordk ] ) , one obtains in the lowest order @xcite @xmath39 where the momentum basis is used , and @xmath40 is the fourier transform of @xmath41 , which describes the fluctuations of the metric tensor field around a flat background .    in later sections ,\nthe analysis of eigenvectors gives @xmath35 of each fluctuation mode in the tensor model .\nthen one can compute @xmath42 of each mode by putting this @xmath35 and the background @xmath36 into ( [ eq : tensordk ] ) .\nthis @xmath42 obtained from the numerical analysis of the tensor model can be compared with the fluctuation modes of the metric tensor field in the general relativity through ( [ eq : metricdk ] ) .\nanother important fact which can be derived from ( [ eq : correspondence ] ) is that the measure which must be used in the analysis of the general relativity is uniquely determined from the measure ( [ eq : cmeasure ] ) in the tensor model . by putting the correspondence ( [ eq : correspondence ] ) into ( [ eq : cmeasure ] ) , one obtains the dewitt supermetric @xcite , @xmath43,\\ ] ] in the lowest order @xcite .\nin this section , i will study the small geometric fluctuations on @xmath19-dimensional flat tori in the general relativity to prepare for the comparison with the tensor model .\nthe important point in the analysis is that not all of the fluctuations of the metric tensor field are the fluctuations of geometry , because of the gauge symmetry ( local translation symmetry ) in the general relativity .\nthe relevant modes are only those which are normal to the gauge symmetry @xcite .\nthe measure to be used to define this normality condition is the dewitt supermetric given in ( [ eq : supermetric ] ) , since the numerical analysis of the tensor model uses the corresponding measure ( [ eq : cmeasure ] ) as shown in the following section .    for small fluctuations around a flat metric @xmath44 , the supermetric ( [ eq : supermetric ] ) is given by @xmath45.\\ ] ] on the other hand , the infinitesimal gauge transformation on a flat background\nis given in the momentum basis by @xmath46 where @xmath47 is the fourier transform of local translation vector .    at the vanishing momentum sector @xmath48 , as can be seen in ( [ eq : gaugemom ] ) , the gauge transformation is vacant , and all the components of the metric tensor are geometric degrees of freedom . by diagonalizing the supermetric ( [ eq : explicit ] ) ,\nthe modes can be shown to be classified into the following three orthogonal classes : + ( i ) 1 conformal mode : @xmath49 .\n+ ( ii ) @xmath50 traceless diagonal modes : @xmath51 .\n+ ( iii ) @xmath52 off - diagonal modes .    at the nonvanishing momentum sector\n, one may take the momentum to be in the direction @xmath53 with obvious generalization to the other directions .\nthen one can show that the modes normal to the gauge directions ( [ eq : gaugemom ] ) in the sense of the supermetric ( [ eq : explicit ] ) can be classified into the following three orthogonal classes : + ( i ) 1 diagonal mode : @xmath54 , @xmath55 for @xmath56 .\n+ ( ii ) @xmath57 traceless diagonal modes : @xmath58 , @xmath59 . + ( iii ) @xmath60 off - diagonal modes : @xmath61 for @xmath62 , @xmath63 .\n@xmath42 for the geometric fluctuations of each mode in the general relativity can be computed by putting these results into ( [ eq : metricdk ] ) , and can be compared with the numerical analysis of the tensor model .\nin this section , i will give a brief summary of the numerical analyses having been done so far on the small fluctuations around the gaussian backgrounds in the tensor model @xcite .    to unambiguously determine the spectra , the fluctuations must be normalized in a manner respecting the symmetries of the tensor model .\nthe tensor @xmath2 is symmetric under the exchanges of the indices as in ( [ eq : csym ] ) , and the tensor model has the orthogonal group symmetry ( [ eq : trans ] ) .\nthus the independent components of fluctuations are normalized through ( [ eq : cmeasure ] ) as @xmath64\\ ,   d c_{abc}\\ , d c^{abc}=\\sum_{(abc ) } d \\tilde c_{(abc ) } \\ , d \\tilde c^{(abc)},\\ ] ] where @xmath65 denotes an order - independent set of three indices , @xmath66}\\,c_{abc}$ ] are the independent normalized components , and @xmath67 $ ] is the multiplicity defined by @xmath68=\\left\\ {   \\begin{array}{ll } 1 & \\hbox{for } a = b = c,\\\\ 3 & \\hbox{for } a = b\\neq c,\\ b = c\\neq a,\\ c = a\\neq b,\\\\ 6 & \\hbox{all different}. \\end{array } \\right.\\ ] ] then the coefficient matrix for the normalized fluctuations in the quadratic order around a background @xmath69 is given by @xmath70    the numerical analysis is carried out to obtain the eigenvalues and eigenvectors of the matrix ( [ eq : m ] ) , and then the results are compared with the general relativity through the procedure explained in the previous sections .\nthe genuine gaussian backgrounds presented in section [ sec : gauss ] can not be used as a background @xmath69 , because of their infinite number of degrees of freedom .\nthus the actual numerical analyses have been done around the backgrounds of @xmath19-dimensional fuzzy flat tori . to describe such backgrounds of fuzzy flat tori in terms of @xmath2 ,\nthe indices are assumed to take integer momenta bounded by a cut off , and the momentum conservation , @xmath71 , is assumed on account of the translational symmetry of such flat tori .\nin fact , under these assumptions , one can numerically find classical solutions that resemble the genuine gaussian backgrounds @xcite .\nusing these numerical classical solutions as backgrounds , the coefficient matrices ( [ eq : m ] ) have been analyzed for dimensions @xmath72 in @xcite , and also for @xmath1 with an approximate method explained below @xcite .\nthe numerical analyses have shown that the spectra of the modes with long - wavelengths can roughly be classified into the following three classes .\n+ ( i ) the `` heavy '' modes with spectra of order 1 or larger .\n+ ( ii ) in @xmath73 , there exist low - lying modes with non - vanishing spectra of order much smaller than 1 .\n+ ( iii ) the zero modes with vanishing spectra .\n+ it is observed that the two classes ( i ) and ( ii ) are rather clearly separated so that they are located hierarchically .\nthe spectra in the class ( ii ) have been shown to form trajectories of the fourth power of momenta . moreover ,\nthe spectral patterns and the mode profiles have been shown to be in good agreement with the geometric degrees of freedom in the general relativity discussed in section [ sec : gr ] , by comparing ( [ eq : tensordk ] ) computed numerically from the tensor model and ( [ eq : metricdk ] ) from the general relativity .\nthis shows that the general relativity is emergent around such backgrounds , and that the lowest effective actions are composed of curvature quadratic terms .    as for the class ( iii ) , by counting their numbers , these modes have been identified with the modes of the @xmath10 symmetry transformations in the tensor model spontaneously broken to the remaining symmetry @xmath74 of the torus backgrounds .\ntherefore these zero spectra are just the gauge modes of the tensor model .\nthe relation between these zero modes and the local gauge symmetry ( local translation symmetry ) of the general relativity has been studied in @xcite , which will be summarized in the following section .    in the approximate method used in @xcite ,\nthe backgrounds @xmath69 in ( [ eq : m ] ) are not taken to be the classical solutions , but to be approximate ones , the gaussian backgrounds ( [ eq : cp ] ) with the modifications that the continuum @xmath75-functions are replaced with kronecker deltas , and that @xmath76 is taken in the range @xmath77 for the approximation to be good . in this approximation , it is easier to numerically analyze the cases with larger @xmath78 , and the agreement between the spectra in the class ( ii ) and the geometric degrees of freedom in the general relativity has been observed more clearly than without approximations .\npart of the results for @xmath79 are shown in figures [ fig : dim2l10spec ] and [ fig : dim2l10 ] . especially , figure [ fig : dim2l10 ] shows very clearly the agreement of the mode profiles between the tensor model and the general relativity .\nfuzzy flat torus for cut - off @xmath80 and @xmath81 .\nthe horizontal axis is the size of momentum @xmath82 of fluctuation modes , and the vertical axis is the spectral value .\nthe solid line is @xmath83 . ]     for the low - lying mode at @xmath84 sector for @xmath79 .\nthe left and right figures are ( [ eq : tensordk ] ) from the numerical analysis of the tensor model and ( [ eq : metricdk ] ) for the diagonal mode in the general relativity , respectively .\nthe axes are @xmath85.,title=\"fig:\",width=226 ]   for the low - lying mode at @xmath84 sector for @xmath79 .\nthe left and right figures are ( [ eq : tensordk ] ) from the numerical analysis of the tensor model and ( [ eq : metricdk ] ) for the diagonal mode in the general relativity , respectively\n. the axes are @xmath85.,title=\"fig:\",width=226 ]\nthe connection between the spontaneously broken @xmath10 symmetry and the local gauge symmetry ( local translation symmetry ) in the general relativity has been discussed in @xcite . in the paper ,\nthe brst gauge fixing procedure has been applied to the @xmath86 symmetry of the tensor model , and the spectra of the ghost quadratic term have been studied numerically .\nthen the appearance of emergent massless ghost fields has been observed , and they have been identified with the reparametrization ghost fields coming from the brst gauge fixing of the general relativity .\nlet me start with the gauge fixing in the tensor model .\nthe off - shell nilpotent brst transformation in the tensor model is defined by @xmath87 where @xmath88 and @xmath89 are the ghosts ( anti - ghosts ) , and the bosonic auxiliary variables @xcite , respectively . here\n@xmath90 is the infinitesimal orthogonal transformation defined by @xmath91 where @xmath92 are the elements of the lie algebra @xmath93 in the vector representation , and @xmath94 is the structure constant defined by @xmath95=f^{ij}{}_k t^k$ ] .\nnow let me define a new dynamical variable @xmath25 by shifting the original variable @xmath96 by a background @xmath69 , @xmath97 then a natural gauge fixing plus faddeev - popov action is given by @xmath98 where @xmath99 is the inner product associated with the measure ( [ eq : cmeasure ] ) .\nthe reason why this is natural is that the gauge fixing conditions ( @xmath100 ) only allow @xmath25 to be normal to the symmetry directions around the background @xmath69 .\nthis action contains the ghost quadratic term as @xmath101 figure [ fig : ghostspec ] shows the spectra of this ghost quadratic term and the ratio of the two trajectories obtained numerically for a gaussian background of @xmath79 flat torus .    , @xmath102 , @xmath103 .\nthe right figure shows the ratios of the two trajectories .\nthe horizontal axis is the momentum size @xmath104.,title=\"fig:\",width=302 ] , @xmath102 , @xmath103 .\nthe right figure shows the ratios of the two trajectories .\nthe horizontal axis is the momentum size @xmath104.,title=\"fig:\",width=302 ]    on the other hand , the off - shell nilpotent brst gauge transformation in the general relativity is given by @xmath105 corresponding to ( [ eq : shiftca ] ) , let me define a new dynamical field @xmath106 by shifting the metric by a flat background , @xmath107 . then ,\nan action naturally corresponding to ( [ eq : sgftensor ] ) is given by @xmath108 where @xmath109 is the inner product associated with the dewitt supermetric ( [ eq : supermetric ] ) .\nin fact , the gauge fixing conditions in only allows @xmath106 to be normal to the infinitesimal gauge transformations of the flat background .\nthis action contains the ghost kinetic term as @xmath110+\\cdots.\\ ] ] this kinetic term contains the longitudinal ( @xmath111 ) and normal ( @xmath112 ) modes with spectra @xmath113 and @xmath114 , respectively .\nin fact , the ratio of spectra @xmath115 agrees well with the numerical analysis of the tensor model as plotted in figure [ fig : ghostspec ] .\nthe mode profiles have also been checked as shown in figure [ fig : ghostprofile ] for @xmath79 .\nthe comparison of ghosts between the numerical analysis of the tensor model and the general relativity has also been done for @xmath116 , and clear agreement has been obtained .    , through @xmath42 in ( [ eq : tensordk ] ) and ( [ eq : metricdk ] ) .\nthe left couple of figures show the profiles of the modes in the lower and upper trajectories in the tensor model .\nthe right couple of figures show the profiles of the normal ( @xmath117 ) and the longitudinal ( @xmath118 ) modes in the general relativity .\n, title=\"fig:\",width=147 ] , through @xmath42 in ( [ eq : tensordk ] ) and ( [ eq : metricdk ] ) .\nthe left couple of figures show the profiles of the modes in the lower and upper trajectories in the tensor model .\nthe right couple of figures show the profiles of the normal ( @xmath117 ) and the longitudinal ( @xmath118 ) modes in the general relativity .\n, title=\"fig:\",width=147 ] , through @xmath42 in ( [ eq : tensordk ] ) and ( [ eq : metricdk ] ) .\nthe left couple of figures show the profiles of the modes in the lower and upper trajectories in the tensor model .\nthe right couple of figures show the profiles of the normal ( @xmath117 ) and the longitudinal ( @xmath118 ) modes in the general relativity .\n, title=\"fig:\",width=147 ] , through @xmath42 in ( [ eq : tensordk ] ) and ( [ eq : metricdk ] ) .\nthe left couple of figures show the profiles of the modes in the lower and upper trajectories in the tensor model .\nthe right couple of figures show the profiles of the normal ( @xmath117 ) and the longitudinal ( @xmath118 ) modes in the general relativity .\n, title=\"fig:\",width=147 ]\nin a series of papers , i have studied the tensor model with actions which possess the gaussian backgrounds as their classical solutions .\nthese backgrounds represent fuzzy flat spaces with arbitrary dimensions , and the small fluctuations around them have been compared with the general relativity on flat backgrounds through numerical analyses . the numerical analyses for dimensions @xmath1 have shown that the long - wavelength low - lying fluctuation spectra are in one - to - one correspondence with the geometric fluctuations in the general relativity .\nthe analyses have also shown that part of the orthogonal symmetry of the tensor model spontaneously broken by the backgrounds corresponds to the local gauge symmetry ( local translational symmetry ) of the general relativity .\nthese results should be valid in all dimensions , because of the dimensional independence of the framework and of the way of analysis .\nthus , the tensor model provides an interesting model of simultaneous emergence of space , the general relativity and its gauge symmetry of translation in general dimensions .\nthere seem to exist various questions about the results .\nfor example , the agreement between the modes in the tensor model and in the general relativity should be checked also for higher orders of fluctuations , although such higher order agreement is expected , because the general relativity ( possibly with modified actions ) is the only theory of symmetric rank - two tensor field with the gauge symmetry .\nthis will require more efficient numerical facility and/or technical developments .\nanother important question is the range of generality of the results , which have only been shown so far around the gaussian backgrounds in a few actions of examples . for the tensor model to be really interesting\n, such emergence should be shown to be common phenomena in more general settings .\nj.  ambjorn , b.  durhuus and t.  jonsson , `` three - dimensional simplicial quantum gravity and generalized matrix models , '' mod .\na * 6 * , 1133 ( 1991 ) . n.  sasakura , `` tensor model for gravity and orientability of manifold , '' mod .\nlett .  a * 6 * , 2613 ( 1991 ) .\nn.  godfrey and m.  gross , `` simplicial quantum gravity in more than two - dimensions , '' phys .\nd * 43 * , 1749 ( 1991 ) .\nn.  sasakura , `` an invariant approach to dynamical fuzzy spaces with a three - index variable , '' mod\n.  phys .\na * 21 * , 1017 ( 2006 ) [ arxiv : hep - th/0506192 ] .\ny.  sasai and n.  sasakura , `` one - loop unitarity of scalar field theories on poincare invariant commutative nonassociative spacetimes , '' jhep * 0609 * , 046 ( 2006 ) [ arxiv : hep - th/0604194 ] .\na.  connes , `` noncommutative geometry , '' _ academic press ( 1994 ) 661 p_. + j.  madore , `` an introduction to noncommutative differential geometry and its physical applications , '' lond .  math .\nnote ser .\n* 257 * , 1 ( 2000 ) .\n+ a.  p.  balachandran , s.  kurkcuoglu and s.  vaidya , `` lectures on fuzzy and fuzzy susy physics , '' arxiv : hep - th/0511114\n. + r.  j.  szabo , `` quantum field theory on noncommutative spaces , '' phys .\n* 378 * , 207 ( 2003 ) [ arxiv : hep - th/0109162 ] .\nn.  sasakura , `` an invariant approach to dynamical fuzzy spaces with a three - index variable - euclidean models , '' in the proceedings of 4th international symposium on quantum theory and symmetries ( qts-4 ) , varna , bulgaria , 15 - 21 aug 2005 [ arxiv : hep - th/0511154 ] .\nn.  sasakura , `` tensor model and dynamical generation of commutative nonassociative fuzzy spaces , '' class .\n* 23 * , 5397 ( 2006 ) [ arxiv : hep - th/0606066 ] .\nn.  sasakura , `` the fluctuation spectra around a gaussian classical solution of a tensor model and the general relativity , '' int .\nj.  mod .\na * 23 * , 693 ( 2008 ) [ arxiv:0706.1618 [ hep - th ] ] .\nn.  sasakura , `` the lowest modes around gaussian solutions of tensor models and the general relativity , '' int .\nj.  mod .\na * 23 * , 3863 ( 2008 ) [ arxiv:0710.0696 [ hep - th ] ] .\nn.  sasakura , `` gauge fixing in the tensor model and emergence of local gauge symmetries , '' prog .\n.  phys .   * 122 * , 309 ( 2009 ) [ arxiv:0904.0046 [ hep - th ] ] .\nb.  s.  dewitt , `` quantization of fields with infinite - dimensional invariance groups .\ngeneralized schwinger - feynman theory , '' j.  math .\nphys .   * 3 * , 1073 ( 1962 ) .\nr.  ferrari and l.  e.  picasso , `` spontaneous breakdown in quantum electrodynamics , '' nucl .\nb * 31 * , 316 ( 1971 ) .\nr.  a.  brandt and w.  c.  ng , `` gauge invariance and mass , '' phys .\nd * 10 * , 4198 ( 1974 ) .\na.  b.  borisov and v.  i.  ogievetsky , `` theory of dynamical affine and conformal symmetries as gravity theory of the gravitational field , '' theor .  math .\n* 21 * , 1179 ( 1975 ) [ teor .  mat .\n* 21 * , 329 ( 1974 ) ] .\nt.  kugo and s.  uehara , `` general procedure of gauge fixing based on brs invariance principle , '' nucl .\nb * 197 * , 378 ( 1982 ) ."}
{"lay_summary": " it is a known fact that a quintessence model with @xmath0 fits the publicly available super nova ( sn ) type ia data better than a model with cosmological constant or @xmath1 . \n two types of models have this property : scalar fields with unconventional kinetic term and models with cosmological constant and a slowly decaying cold dark matter ( cdm ) . in this work \n we investigate the possibility of replacing the cosmological constant in the latter models with gradual condensation of a scalar field produced during the decay of the cdm and present some preliminary results . \n the advantage of this class of models to the ordinary quintessence is that the evolution of the dark energy and cdm are correlated and cosmological coincidence problem is solved or at least reduced to the fine tuning of the coupling between decaying cdm and quintessence field i.e the hierarchy problem . \n here we show that for part of the parameter space these models are consistent with present estimation of cosmological parameters .    * \n quintessence from a decaying dark matter + *    _ houri ziaeepour + mullard space science laboratory , + holmbury st . \n mary , dorking , surrey rh5 6nt , uk . + \n email : hz@mssl.ucl.ac.uk_ ", "article": "the mystery of the dark energy / cosmological constant persists despite great efforts of particle physicists and cosmologists to find a convincing solution . since the famous article by s. weinberg\n, it is well known that candidate models should not only explain the smallness of the cosmological constant , if it is somehow related to quantum gravity , but also what is called the coincidence problem i.e. why does dark energy become dominant quite late in the history of the universe ?\nmodels inspired by string theory like 4-form gauge models can describe the smallness of the dark energy but not the coincidence problem .\nanthropical models explain the latter problem but it is very difficult to find a natural and convincing particle physics model for them .\nthe same problem somehow exists for the alternative to a cosmological constant i.e. for quintessence models .\neven if tracker solutions make the model not very sensitive to the initial conditions , some fine tuning of the slope of the potential is necessary .\nit is also an open question if both inflation and quintessence behavior can be explained by the same field and if not , what is their relation and which type of particle physics can provide both of them specially in a natural way .\n+ here we suggest an alternative to a primordial quintessence field\n. there are at least two motivations for the existence of a decaying dark matter ( ddm ) .\nif r - parity in susy models is not strictly conserved , the lsp which is one of the best candidates of dm can decay to standard model particles .\nviolation of this symmetry is one of the many ways for providing neutrinos with very small mass and large mixing angle .\nanother motivation is the search for sources of ultra high energy cosmic rays ( uhecrs ) . in this case\n, ddm must be composed of ultra heavy particles with @xmath2 . in a recent work\nwe have shown that the lifetime of uhdm ( ultra heavy dark matter ) can be relatively short , i.e. @xmath3 where @xmath4 is the age of the universe ( astro - ph/0001137 ) .\n+ if a very small fraction of the mass of primary ddm particles changes to a scalar field with proper self interaction potential , the gradual condensation of this field at late time behaves like a quintessential matter .\nthe advantage of this model to others is that late time yield of this type of energy and its correlation with the amount of dark matter comes up naturally and the dominance of one with respect to the other at each epoch is automatically explained .\n+ in the present work we only study the plausibility of this model .\nwe postpone a more detailed study to elsewhere .\nthe natural choice of cosmological parameters for this model is an initial @xmath5 where @xmath6 is an early time in the history of the universe . for the result presented here\nwe consider it to be the time of decoupling of cmb photons ; @xmath7 .\nthe remnants of the decay else than quintessence field mainly consist of very energetic particles which will contribute to the yield of hot dark matter .\nthere is strict constraint on the amount of the latter from cosmological observations and the model must be consistent with observations .\nhowever , one should not forget that massive particles like proton / ant - proton and even electrons become colder with the expansion of the universe and at some point they are not any more considered as hot .\nin fact it can be shown that the whole effect on the equation of state of the universe is the reduction of the effective @xmath8 of the cosmological constant or a quintessence matter ( astro - ph/0002400 ) .\n+ we summarize our preliminary results in two following figures .\nthe first figure shows @xmath9 of the fit of quintessence models on the publicly available super - novae ia data .\nmodels with @xmath0 fit the data better than @xmath10 .\n+    the second figure shows the evolution of density of various types of matter from decoupling of cmb photons to today for a typical selection of parameters .\nin one hand it shows that it is possible to obtain the present `` equivalent '' value of cosmological parameters without fine tuning of the suggested model .\nanother conclusion is that the appearance of cosmological parameters as measured in the local universe is very recent i.e. the measurement of cosmological parameters at high redshift permits to distinguish between this model and other quintessence models .\nit is evident that the model presented here can not be believed before investigating many issues .\nthe first and one of the most important ones is the condensation of the scalar field .\none should determine the mass and the form of the potential and find the region of the parameter space that in a natural way can lead to a late condensation .\nthe other issue is that the value of @xmath8 for this type of matter can not be constant .\nthis can affect the evolution of halos , star formation rate , ionization of igm etc . and can be used to verify the model ."}
{"lay_summary": " in this work , we have used an effective field theory ( eft ) framework based on heavy quark spin ( hqss ) , heavy flavour ( hfs ) and heavy antiquark - diquark symmetries ( hads ) . using a standard lagrangian for the heavy meson - heavy antimeson system , we fit the counter - terms of the model to predict some promising experimental data that can be interpreted as heavy meson - heavy antimeson molecules , that is , the @xmath0 and the @xmath1 . \n next , and , taking advantage of hads , we use the same lagrangian to explore the consequences for heavy meson - doubly heavy baryon molecules , which can also be interpreted as triply heavy pentaquarks . ", "article": "since the mid 1970 s the existence of heavy hadronic molecules ( composed by a pair of heavy hadrons instead of a pair of heavy quarks ) has been theorized@xcite .\nthis assumption was made based on the similarities between the heavy meson - heavy antimeson system and the deuteron .\nhowever , it was not until the discovery of the @xmath0@xcite by the belle collaboration , in 2003 , that the first experimental data that could fit into that molecular scheme was found .\nsince then , many other xyz states have been found , being the @xmath1 also natural candidates to have a molecular structure ..    besides , the @xmath2 limit of qcd simplifies the theory so a set of symmetries are induced .\nprobably , the most important symmetries induced in this limit are hqss , hfs , and hads .\nwe make use of them , along with the assumptions of the @xmath0 and the @xmath1 to be heavy hadronic molecules , to obtain a family of heavy meson - doubly heavy baryons that could also be interpreted as triply heavy pentaquarks .\nthis proceeding is organized as follows .\nfirst we briefly introduced our eft based on hqss and hfs that we will use in the analysis of the @xmath0 and the @xmath1 .\nsecond , we will discuss hads and its implications .\nfinally , our results will be shown in table [ tab : predictions ] .\nin this work we are following the scheme described in @xcite where all sort of details can be found . at lowest order , hqss and hfs\nimpose that the dynamics of the model does not depend on either the mass or the spin of the heavy quark . taking this into account , the most general potential that describes the dynamics of the heavy meson - antimeson pair depends only in four low energy constants or counter - terms ( lecs ) , up to corrections of the order @xmath3 : @xmath4 tr\\left[{h}^{(\\bar{q } ) } \\bar{h}^{(\\bar{q } ) } \\gamma^{\\mu } \\right ] + \\\\ \\nonumber { } & & + \\frac{c_{a}^{\\lambda}}{4}~ tr\\left[\\bar{h}^{(q)}_{a } \\lambda^{i}_{ab } { h}^{(q)}_{b } \\gamma_{\\mu } \\right ] tr\\left[{h}^{(\\bar{q})}_{c } \\lambda^{i}_{cd}\\bar{h}^{(\\bar{q})}_{d }\n\\gamma^{\\mu } \\right ]   + \\\\\n\\nonumber { } & & + \\frac { c_{b}}{4}~ tr\\left[\\bar{h}^{(q)}{h}^{(q ) } \\gamma_{\\mu } \\gamma_{5 } \\right ] tr\\left[{h}^{(\\bar{q } ) } \\bar{h}^{(\\bar{q } ) } \\gamma^{\\mu } \\gamma_{5}\\right ] + \\\\ & & +   \\frac{c_{b}^{\\lambda}}{4}~ tr\\left[\\bar{h}^{(q)}_{a } \\lambda_{ab}^{j}{h}^{(q)}_{b } \\gamma_{\\mu } \\gamma_{5 } \\right ] tr\\left[{h}^{(\\bar{q})}_{c } \\lambda^{j}_{cd } \\bar{h}^{(\\bar{q})}_{d } \\gamma^{\\mu } \\gamma_{5}\\right]\\end{aligned}\\ ] ] being @xmath5 the gell - mann matrices and @xmath6 the meson ( antimeson ) field in the charm sector ( and viceversa in the bottom sector ) .\nmoreover , the four lecs will be rewritten through a linear combination into @xmath7 , @xmath8 , @xmath9 and @xmath10 for notation .\nthese four lecs will be fitted to reproduce some experimental data in our scheme . in this framework\n, bound states will be found by solving the lippmann - schwinger equation as they will appear as poles in the t - matrix : @xmath11 , and the ultraviolet divergences of the loop function are treated introducing a gaussian regulator in the propagator and in the potential such as :    @xmath12    these assumptions determine three linear combinations of the lecs , that is : @xmath13 and @xmath14 which in turn are determined by the @xmath0 ( for more details , see @xcite ) and @xmath15 by the @xmath16 resonances [ @xcite ] .\nup to now , we have only established an eft that analyzes heavy meson - heavy antimeson molecules . in order to use this approach to different systems we will take advantage of the heavy antiquark - diquark symmetry ( hads ) .\nthis @xmath17 limit symmetry , first introduced by savage and wise , states that a heavy diquark behaves as a heavy antiquark up to corrections of the order @xmath18 , , being v the velocity of the heavy quarks .    furthermore ,\nsince the dynamics of our eft only depends on the light degrees of freedom , that are the same than in the heavy meson - heavy antimeson system , we can make use of some racah algebra ( similar to @xcite ) to obtain the potentials in every possible channels , which are displayed in table [ tab : potentials ] .\nthe @xmath19 states are those where heavy quarks in the baryon are coupled to @xmath20 ( which is forbidden if the two quarks are the same because of the pauli s principle of exclusion )\n.    then we just have to solve the lippmann - schwinger equation in each channel using the lecs we have previously fitted to obtain the results of table [ tab : predictions ] .\nthe isoscalar states are related to the @xmath0 .\nthe isovector states are determined by the @xmath21 and the isovector component of the @xmath0 .\nthe sources of error in the analysis are : the masses of the @xmath0 and @xmath22 resonances , the ratio of the @xmath0 amplitude decays ( calculated in @xcite ) and the two eft expansions used in this work . the errors for hqss are taken to be @xmath23 in the charm ( bottom ) sector and @xmath24 $ ] in the charm ( charm - bottom ) [ bottom ] sector for hads .\nthen , an unique error is obtained by adding in quadratures all different sources .\nas a summary , we can conclude that our analysis based on several qcd symmetries in the @xmath17 limit predicts the existence of several heavy meson - doubly heavy baryon molecular partners of the @xmath0 and the @xmath1 .\nthis same effective field theory approach could also be extended to study doubly heavy baryon - double heavy antibaryon molecular systems in the future .\nf .- k.g . acknowledges the theory division of ihep in beijing , where part of the work was done , for the hospitality . c. h .- d .\nthanks the jae - csic program .\nthis work is supported in part by the dfg and the nsfc through funds provided to the sino - german crc 110 `` symmetries and the emergence of structure in qcd '' , by the nsfc ( grant no .\n11165005 ) , by the spanish ministerio de economa y competitividad and european feder funds under the contract fis2011 - 28853-c02 - 02 and the spanish consolider - ingenio 2010 programme cpan ( csd2007 - 00042 ) , by generalitat valenciana under contract prometeo/2009/0090 and by the eu hadronphysics2 project , grant agreement no ."}
{"lay_summary": " we introduce new methods for robust high - precision photometry from well - sampled images of a non - crowded field with a strongly varying point - spread function . for this work , we used archival imaging data of the open cluster m37 taken by mmt 6.5 m telescope . \n we find that the archival light curves from the original image subtraction procedure exhibit many unusual outliers , and more than 20% of data get rejected by the simple filtering algorithm adopted by early analysis . in order to achieve better photometric precisions and also to utilize all available data , the entire imaging database was re - analyzed with our time - series photometry technique ( multi - aperture indexing photometry ) and a set of sophisticated calibration procedures . \n the merit of this approach is as follows : we find an optimal aperture for each star with a maximum signal - to - noise ratio , and also treat peculiar situations where photometry returns misleading information with more optimal photometric index . \n we also adopt photometric de - trending based on a hierarchical clustering method , which is a very useful tool in removing systematics from light curves . \n our method removes systematic variations that are shared by light curves of nearby stars , while true variabilities are preserved . \n consequently , our method utilizes nearly 100% of available data and reduce the rms scatter several times smaller than archival light curves for brighter stars . \n this new data set gives a rare opportunity to explore different types of variability of short ( @xmath0minutes ) and long ( @xmath01 month ) time scales in open cluster stars . ", "article": "we are poised on the threshold of unprecedented technical growth in wide - field time domain astronomy , where ground - based observations yield very precise measurements of stellar brightness from high - volume data streams .\nso far , wide - field time - series surveys has been spearheaded by relatively small telescopes since they are supported by large field of view ( fov ) instruments operating with high duty cycle ( see @xcite for a summary of optical variability surveys ) . within the last decade ,\nthe advent of large mosaic ccds has facilitated the coverage of large sky area even for large - aperture telescopes ( e.g. , mmt megacam : @xcite ; eso very large telescope omegacam : @xcite ; subaru suprime - cam : @xcite ; chft megacam : @xcite ; iptf : @xcite ) .\nalthough these facilities are generally devoted to imaging surveys , researchers are attempting to utilize them for short- and long - term variability surveys with short - cadence exposures ( e.g. , @xcite ) .\nsuch wide - field imaging systems have enabled us to observe hundred of thousands of target stars simultaneously and also to detect various variability phenomena .\na remarkable thing about these surveys is that the fraction of variable sources increases as the photometric precision of the survey improves .\nfor this reason , it is important to improve the accuracy in photometry .\nanother key issue in wide - field time - series photometry is the removal of temporal systematics from a single image frame or several consecutive image frames .\nit has recently become known that systematic trends in time - series data can be different and localized within the image frame when the fov is large . such spatially localized patterns may be related to subtle point spread function ( psf ) differences and sky condition within the detector fov ( e.g. , @xcite ) .\nas these patterns change in time , we can see how the temporal variations of systematic trends affect the brightness and shape of light curves directly .\nthe time - scale of systematic variation is sometimes comparable to short - term variability , such as transits or eclipses , and in some cases even long - term variability .\nthus , it is often difficult to identify and characterize true variabilities .    in this paper\n, we introduce a new photometry procedure , called multi - aperture indexing , which is suited to analyzing well - sampled wide - field images of non - crowded fields with a highly varying psf , such as those produced by wide - field mosaic imagers on large telescopes .\nwe apply this procedure to archival imaging data from the mmt / megacam transit survey of the open cluster m37 ( hartman et al .\n2008a ) , demonstrating a substantial improvement over the existing photometry .\nsection 2 describes the mmt imaging database and identifies problems in the existing photometry which motivated the development of our new methods .\nsection 3 describes the multi - aperture photometry that utilize newly defined contamination index and carefully tuned calibration procedures , including the results of the basic tests to validate our approach .\nsection 4 gives an in - depth discussion about systematic trends in time - series data and suggests an efficient way for identifying , measuring , and removing spatio - temporal trends .\nsection 5 describes the effects of new calibration on period search , and we summarize our main results in the last section .\n@xcite have conducted a study to find neptune - sized planets transiting solar - like stars in the rich open cluster m37 .\nthe observing strategy was carefully designed for a transiting planet search by several considerations ( e.g. , the reliability of exposure time per frame , the effects of pixel - to - pixel sensitivity variations , and sensitivity of filter ) .\ntheir work did not reveal any transiting planets , but it did provide a rare opportunity to explore photometric variability at relatively high temporal resolution with 3090 s. @xcite discovered 1430 new variable stars , including very short - period eclipsing binaries ( e.g. , v37 , v706 , v1160 ) and @xmath1 sct - type pulsating stars ( e.g. , v397 , v744 , v1412 ) .\nwe used the same data set on the open cluster m37 .\na detailed discussion of the observations , original data reduction , and light curve production is described in @xcite .\nthe data archive consists of approximately 5000 @xmath2-filter images taken over 24 nights with the wide - field mosaic imager ( megacam ) mounted at the @xmath3 cassegrain focus of the 6.5 m mmt telescope .\nnote that megacam is made up of 36 2048 @xmath4 4608 pixel ccd chips in a @xmath5 pattern , covering a 24@xmath6@xmath424@xmath6 fov @xcite .\nthis instrument has an unbinned pixel scale of @xmath7 , but it was used in @xmath8 binning mode for readout .\nthe observation logs are summarized in table 1 of @xcite . in brief , the @xmath9-band time - series observations were undertaken between 2005 december 21 and 2006 january 21 , with a median fwhm of @xmath10 arcsec .\nexposure times are chosen to keep an @xmath11 mag star as close to the saturation limit , which is expressed as a function of seeing conditions . with an average seeing @xmath00@xmath12.89 on images ,\nthe quality of the images is good to achieve high - precision light curves ( less than 1% rms value ) down to 20 .\nin addition to the imaging data set , this database includes light curve data sets for a total of 23,790 sources detected in a co - added reference image .\ntheses light curves are obtained by the image subtraction technique using a modified version of isis software ( @xcite ; @xcite ) .    as shown in figure [ fig : fig1 ] , however , the raw light curves from the original image subtraction procedures exhibit many unusual outliers , and more than @xmath015% of data get rejected by a simple filtering algorithm after cleaning procedures . in practice , brutal filtering that is often applied to remove outlying data points can result in the loss of vital data , with seriously negative impact to short - term variations such as flares and deep eclipses .\nwe also find that the image subtraction technique often resulted in measurement failures from several frames due to poor seeing or tracking problem . after removing these bad frames\n, it leads to loss of additional @xmath05% data points from most light curves . in order to overcome this problem ,\nwe have re - processed the entire image database with new photometric reduction procedures .\n3-@xmath13 control limits ( dotted lines ) .\nthese light curves contain outlier points that significantly increase the rms scatter of the raw light curves . ]\nwe followed the standard ccd reduction procedures of the bias correction , overscan trimming , dark correction , and flat - fielding as described in @xcite .\nthe individual ccd frames were calibrated in iraf , using the mosaic data reduction package megared .\nthe first step is to correct the pixel - to - pixel zero - point differences that are usually described by the sum of a mean bias level and a bias structure .\nas the bias frames were not separately taken during the time of the observations , the mean bias level was subtracted from each image extension using an overscan correction and so we can not remove any remaining bias structure from all overscan - subtracted data frames . according to description in matt ashby s megacam reduction guide , the bias structure can be very significant in some small regions such as the portions of the arrays close to the readout leads .\nthe dark currents are normally insignificant for megacam so that corrections are not needed even for long exposures .\nthe next step is to correct pixel - to - pixel variations in the sensitivity of the ccd ; we used the program ` domegacamflat2 ` .\nthis program determines the scaling factors to correct the gain difference between the two amplifiers of each chip by finding the mode in the quotient of pixels to the left and right of the amplifier boundary , and then flattens each of the frames with a master flat field frame .\nit is worth mentioning that the sky conditions were rarely photometric during the observing run , with persistent light cirrus for most of the nights .\ntherefore it was only possible to obtain twilight sky flats on a handful of nights ( dome flats were not possible ) .\nwe removed bad pixels using the megacam bad pixel masks distributed with the megared package .\nthe values of bad pixels are replaced with interpolated value of the surrounding pixels using the iraf task ` fixpix ` .\nthe numerous single pixel events ( cosmic - rays ) were identified and removed using the lacosmic package @xcite .\nthe megacam data already have a rough world coordinates system ( wcs ) solution that is based on a single value of the telescope pointing .\nto update these with a more precise solution , we applied astrometric correction to each ccd in the mosaic using the wcstools imwcs program @xcite .\nthe new solution is derived by minimizing the differences between the r.a . and decl .\npositions of sources in a single ccd chip and their positions listed in the 2mass point source catalog @xcite .\nthe resulting astrometric accuracy is typically better than 0@xmath14.1 rms in both r.a . and decl .\ntypically , a point or extended source detection algorithm is applied to each frame independently and it always requires criteria for what should be regarded as a true detection . in obtaining the pixel coordinates for all objects in the m37 fields , this procedure often misses some objects when the detection threshold approaches the noise level .\nalso it needs a substantial effort to match the objects that are detected in only some of the frames .\nour approach is as follows : a complete list of all objects is obtained from a co - added reference frame , and then the photometry is performed for each frame using the fixed positions of the sources detected on the reference . since the relative centroid positions of all objects are the same for all frames in the time series , we can easily place an aperture on each target and measure the flux even for the stars at the faint magnitude end .\nwe constructed the reference frame for each chip from the best seeing frames using the swarp software .\nbenefiting from a highly accurate astrometric calibration of input frames , we were able to improve the quality of co - added images . in the swarp implementation\n, the pixels of each frame were resampled using the lanczos3 convolution kernel , then combined into the reference frame by taking a median or average .\nafter this was done , sources were detected and extracted on the reference frame using the sextractor software @xcite .\nwhen configured with a lower detection threshold , sextractor extracts the number of spurious detections ( e.g. , diffraction spikes around bright stars , or outer features of bright galaxies ) .\nthese false detections were removed by careful visual inspection for each chip .\nthe final catalog contains a total of 30,294 objects including both point and extended sources .\nprior to the photometry , the initial centroid coordinates of the target objects for each frame were computed by using the wcstools sky2xy routine @xcite .\nthe stored world coordinate system for each frame is used to convert the ( r.a .\n, decl . ) coordinates from the master source catalog to the @xmath15 pixel locations .\nhowever , actual positions of objects for each frame can be slightly moved from its original locations depending on the focus condition of instrument , seeing condition , and the signal - to - noise ratio ( s / n ) in the individual observations .\nthese types of positioning errors ( i.e. , centroid noise ) will lead to the internal error for a photometric measurement that results from placement of the measuring aperture on the object being measured .\nthe situation gets worse for faint stars because the centroid position of them is itself subject to some uncertainty . the fractional error in the measured flux as a result of mis - centering\nis given by:@xmath16 where @xmath17 is the positioning error , @xmath18 is the radius of aperture , @xmath13 is the profile width for a source with a gaussian psf , and total flux @xmath19 ( see appendix a in irwin et al . , 2007 for details ) .\nthis expression shows that if we set the aperture radius equal to the fwhm ( @xmath18=2.35-@xmath13 ) , even small differences in placement of the aperture ( e.g. , @xmath17=0.1-@xmath13 ) may increase the uncertainty in the flux measurements ( @xmath20 1 mmag ) .\nthus , accurate centroid determination is important to achieve the high - precision photometry .    following the windowed centroid procedure in the sextractor\n, a refined centroid of each object is calculated iteratively .\non average , the rms uncertainty in the coordinate transformation using the wcs information was @xmath21 pixels for the bright reference stars .\nafter the coordinate transformation from sky to @xmath22 , however , the centroid coordinates ( @xmath23 , @xmath24 ) are slightly misaligned from their actual ones ( @xmath25 , @xmath26 ) .\nthe refined centroid values ( @xmath27 , @xmath28 ) are used only if the maximum displacement is at least less than 1.5 pixels .\nthis condition prevents arbitrary shifting of a source centroid , especially for faint stars .\nwe estimated a local sky background by measuring the mode of the histogram of pixel values within a local annulus around each object , which is suitable choice for our uncrowded field ( less than @xmath01000 stars per chip ) .\nthis process is a combination of @xmath29-@xmath13 clipping and mode estimation .\nthe background histogram is clipped iteratively at @xmath303-@xmath13 around its median , and then the mode value is taken as : @xmath31 it represents the most probable sky value of a randomly chosen pixel in the sample of sky pixels @xcite .\nfor relatively crowded regions , we utilized a background map created by sextractor package using a mesh of @xmath32 pixels and a median filter box of @xmath33 pixels .\nthis map is used to confirm the properness of individual sky values from annulus estimates .\nmodern data reduction techniques aim to reach photon noise limit and minimize systematic effects .\nfor example , differential photometry technique can be achieved better than 1% precision for brighter stars ( e.g. , @xcite ) , and the deconvolution - based photometry algorithm leads to the minimization of systematic effects in very crowded fields ( e.g. , @xcite ) . however\n, conventional data reduction methods often fail to handle various artifacts in wide - field survey data .\nwe present below a new photometric reduction method for precise time - series photometry of non - crowded fields , without the need to involve complicated and cpu intensive process ( e.g. , psf fitting or difference image analysis ) .\nour photometry is similar to standard aperture photometry , except in that we compute the flux in a sequence of several apertures and then determine the optimum aperture individually to each object at each epoch .\nthis multi - aperture photometry is an efficient way to determine the optimum aperture size that gives the maximum s / n for a flux measurement . the maximum s / n is not necessarily at the same aperture for all objects , and it can be obtained from a relatively small aperture @xcite .\nthis _ photometric _\naperture is to achieve the optimal balance between flux loss and noises based on a relationship derived from the ccd equation ( see @xcite ) .\nfigure [ fig : fig2 ] shows how the optimum apertures vary with the stellar magnitude .\nthere is an obvious trend of decreasing aperture sizes with increasing magnitudes down to the faint magnitude limit in the example frame .\nonce we measure the flux of each object with the optimum aperture , we need to apply the aperture correction for small apertures .\nthe aperture correction terms are estimated from the growth curve analysis of selected isolated bright stars ( i.e. , reference stars ) .\nthe average curve - of - growth for each frame is calculated by measuring the difference in magnitude between different pairs of apertures ( up to 10 pixels aperture radius ) and then an automatic correction is applied to all objects for each photometric aperture .\nthe use of a common aperture correction for each ccd assumes that there is no variation in the correction across the ccd .\nthis flux correction method gives nearly the same brightness within the measurement uncertainties for all apertures .\nany psf variation across the ccd causes systematic errors , however , and we deal with this in section 3.4 and section 4 .    100 thumbnail images of the target star . _\nmiddle panels _ : normalized s / n as a function of aperture size . _ bottom panels _ : aperture corrected magnitude as a function of aperture size .\nthe arrows represent the peak locations in the aperture - s / n diagram ( see text for details ) . ]\nwe performed the multi - aperture photometry based on the concentric aperture photometry algorithm in daophot package @xcite , using several circular apertures ( up to 10 pixels aperture radius ) with a fixed sky annulus from 35 to 45 pixels .\nthe initial results of multi - aperture photometry are stored in ascii - format photometry tables , including the date of the observations ( mjd ) , the pixel @xmath15 coordinates , the aperture - corrected magnitudes with errors for each aperture , the sky values and its errors .\nfigure [ fig : fig3 ] shows the details of the multi - aperture photometry for one star at different epochs . in the former two epochs , the photometric apertures can be properly selected by the s / n cuts , while in the latter two epochs , s / n increases for lager apertures .\nthis unusual behavior is due to contamination by a moving object .\nwe automatically identifies similar unusual cases by the method of aperture indexing .\n-filter light curve of same star ( id=10213 ) as shown in figure [ fig : fig3 ] .\nbottom panels show the multi - aperture indexing scheme .\nthe @xmath34-axis is the aperture size and @xmath35 @xmath36-axis is the differential magnitude between pairs of apertures @xmath37(=@xmath38 ) .\nwe can see whether and at what aperture the differential magnitude ( solid lines ) begins to deviate from the model curve ( dashed lines ) for each epoch . ]\nour multi - aperture indexing method is similar to the basic concept of the discrete curve - of - growth method @xcite .\neach object is indexed based on the difference in aperture - corrected magnitude between pairs of apertures @xmath37(=@xmath38 ) with mean trend for stars of similar brightness ( see solid and dotted lines in bottom panels of figure [ fig : fig4 ] , respectively ) .\nthe aperture with a 10 pixel radius is used as the fixed reference aperture .\nthe mean trend is determined by computing the rms curve of the aperture correction values for all measured apertures , and used to evaluate whether magnitude at a given aperture significantly differs from the mean trend .\nsince the rms value depends on the chosen magnitude interval , all stars are divided into groups according to their brightness in the individual frames .\nwe determine the rms curve for each magnitude group using an iterative @xmath13-clipping until convergence is reached .\nobjects lying within @xmath303-@xmath13 of the model curve are indexed as contamination - free , and those above @xmath303-@xmath13 as a contaminated source .\nfigure [ fig : fig4 ] shows that multi - aperture indexing guides us to throw out some photometric measurements if they are discrepant from the mean trend .\nthis approach also gives us a chance to recover a measurement that would be otherwise thrown out .\nthe problematic aperture can be simply replaced by one of the smaller apertures if it is indexed as contamination - free .\nthis help us make a full use of the information offered by the data .\nwe present a new photometric calibration to convert the instrumental magnitudes onto the standard system , including a relative flux correction of the left and right half - region of each ccd chip .\nas mentioned in the section 3.1 , mmt / megacam shows the temporal variations in the gain between two amplifiers on each ccd , as well as between ccds that are part of the same mosaic .\nit may have been caused by unstable bias voltage of the ccd output drain which has a profound impact on the gain of the output amplifier .\nthe level of readout noise is also unstable between two amplifiers . to correct for this effect\n, the photometric calibration needs to be performed individually for each amplifier region .\nwe use a sufficient number of ( pre - selected ) bright isolated stars as standard stars and compute the relative flux correction terms .\nthese terms were derived for each frame using the mean magnitude offset ( @xmath39 ) of standard stars ( @xmath40 ) with respect to corresponding magnitudes ( @xmath41 ) in the master frame chosen as an internal photometric reference    @xmath42    where @xmath43 is the aperture - corrected instrumental magnitudes in other frames and @xmath44 is the photometric zero - points for the left- and right - side of each chip , respectively . to calculate the zero - points , we solve\na linear calibration relation of the form : @xmath45 where @xmath46 and @xmath47 are standard magnitudes from the photometric catalog of m37 @xcite and @xmath48 is an airmass term .\nthe fit is performed iteratively using a sigma - clipping method .\nfigure [ fig : fig5 ] shows the difference in the magnitude offsets between the left- and right - side of each chip ( @xmath49 ) for the whole data set , which is within @xmath50 magnitude level for all 36 ccd chips .\nthe histograms are normalized by the total number of data frames @xmath51 and are described by a gaussian function with slightly different mean values and shapes ( dashed line ) .\nwe clearly see a significant variation in difference between a pair of magnitude offsets for all ccds .      the photometric calibration for wide - field imaging systems is also affected by position - dependent systematic errors due to a psf variation across the fov ( e.g. , @xcite ) .\nwe derive psf variations across the fov with the sextractor package .\nthe change of the psf shapes in the image plane is represented by spatial distribution of psf fwhm values for several bright stars , with parameters of ` class\\_star ` @xmath52 0.9 , ` magerr\\_auto ` @xmath53 0.01 mag , and ` flags ` = 0 ( i.e. , isolated point sources with no contamination ) .\nnote that the psf fwhm values are defined as the diameter of the disk that contains half of the object flux based on a circular gaussian kernel .\nfigure [ fig : fig6 ] presents the variation of the psf fwhm as a function of distance from the image center for various seeing conditions . for each quadrant ,\nthe dashed lines represent the weighted spline approximation of the median value of each distance bin ( 1 arcmin ) .\nthe result shows that the psf fwhm varies significantly as a function of position on the single - epoch image frames and variations are at the level of @xmath010% to 20% ( @xmath54 ) across the fov . as the field distortion is not negligible from the center of field to its edges ,\nsuch variations limit the accuracy of stellar photometry .        to address this issue , we perform a 2d polynomial fitting technique . for each frame , the correction terms are described by a linear or quadratic polynomial depending on the position @xmath55 only .\n@xmath56    where @xmath57 are the pixel coordinates of @xmath58 bright isolated stars , @xmath59 is the statistical weight in the fitting procedure , @xmath60 are the sets of polynomial coefficients for each aperture size , and @xmath61 are the difference in magnitude between the reference aperture and @xmath62 aperture , @xmath63 , at the position @xmath55 for each chip @xmath64 .\nwe derived the optimal parameter values from a nonlinear least - squares fit using the levenberg \nmarquardt algorithm and automatic differentiation , and choose between two models that best fit the data .\nfigure [ fig : fig7 ] shows the field - dependent magnitude offsets and the distortion correction by 2d polynomial fitting method for one example mosaic ccd . for the outer and the central region of the mosaic , we compare the magnitude offsets between the reference aperture and the relatively smaller apertures as a function of @xmath55 coordinates . here\n@xmath34-axis is in the declination direction and @xmath36-axis is opposite to the right ascension direction .\nwe find that the magnitude difference depends on position @xmath15 and is most discrepant in the outer part of the fov .\nthis effect is usually more significant in the @xmath36-direction than in the @xmath34-direction , especially for the case of aperture photometry performed with small apertures .\nthe correction for field - dependent psf variation reduces the initial @xmath010% variation ( gray lines ) to less than @xmath01% ( black lines ) .    .\n]        we compare the photometric performance of the re - calibrated light curves with the non - de - trended archival light curves by means of the two representative measures : ( i ) the rms photometric precision @xmath65 , and ( ii ) the data recovery rate @xmath66 .\nthe former is defined as the standard deviation of light curves around the mean value as a function of @xmath46 magnitude : @xmath67 where @xmath68 is the number of data points in each light curve , @xmath69 is the observed magnitude , and @xmath70 is the mean magnitude of the object @xmath71 , and the latter refers to the number of _ analyzed _ data frames normalized by the total number of observed data frames @xmath58 for each object . in typical cases , the data recovery rate should be near unity in the bright magnitude regime and decreases with magnitude for fainter objects . for comparison , we decided to select light curve samples which show either no significant variability or seeing - correlated variations induced by image blending .\nwe remove all known variable stars from the sample list based on a new catalog of variable stars in m37 field ( s .- w .\nchang et al .\n2015 , hereafter paper ii ) . to remove the light curves of blended objects\n, we use an empirical statistical technique to quantify the level of blending by looking for seeing - correlated shifts of the object from its median magnitude @xcite .\n@xmath72 where @xmath73 for light curve points @xmath69 with uncertainties @xmath74 , and @xmath75 is the same statistic measured with respect to a fourth order polynomial in fwhm fitted to the data .\nwe adopt the value @xmath76 for the selecting light curves with no blending .\nthe last selection criterion is that the light curves must exit both in the archive and our database .    in the bottom panels of figure [ fig : fig8 ] and figure [ fig : fig9 ] , we plot the rms photometric precision of light curves for the two megacam ccd chips in the outer ( ccd 1 ) and central ( ccd 21 ) part of the fov , respectively .\nthe black points show the rms values of the re - calibrated light curves , while the gray points are for the raw and filtered light curves in archive .\nthe first impression from this comparison is that the typical rms scatter is overestimated from the raw light curves because of many outliers in the photometric data ( bottom left panels ) . for the better results ,\nthese light curves were filtered out in two steps : ( i ) clipping 5-@xmath13 outliers from each light curve and ( ii ) removing every data points that are outliers in a large number of light curves @xcite . in the second step ,\nthe outlier candidates are estimated by choosing a cutoff value for each ccd chip .\nthe cutoff value is defined as the fraction of light curves for which a given image is a 3-@xmath13 outlier .\nthis filtering was applied to remove bad measurements due to image artifacts or poor conditions , which were previously thought to be unrecoverable , but resulting data loss is up to 20% of the total number of data points ( bottom right panels ) . as shown in the top panels of the two figures ,\nthe data recovery rate for the re - calibrated light curves is close to 100@xmath77 over a wide range of magnitude and it appears to be more complete compared with the raw ( top left panels ) and filtered ( top right panels ) light curves . at bright magnitudes ( @xmath78 )\nthe data recovery rate does not reach 100@xmath77 because the exposure time was chosen to be saturated at a magnitude of @xmath11 .\nthis comparison proves that our approach is a powerful strategy for improving overall photometric accuracy without the need to throw out many outlier data points .\nfinally , we compare the light curves themselves for selected variable stars between the archive and our own .\nthis comparison serves to illustrate how the photometric precision and data recovery rate of the time - series data affect the ability to address a variety of variability characteristics .\nfigure [ fig : fig10 ] shows a direct comparison with the filtered light curves ( top panels ) and our re - calibrated light curves ( bottom panels ) for four variable stars .\nit is shown that our method recovers more data points ( black ) from the same data set of images .\nand @xmath36 coordinates , respectively , for selected ccd chips .\nthe filled squares are relatively bright stars with @xmath79 mag , while the open squares are stars with @xmath80 mag . ]      in order to further investigate possible systematics in our approach , we conducted psf - fitting photometry with daophot ii and allstar @xcite .\nfor each mosaic frame , we select bright , isolated , and unsaturated stars to make the psf model varying quadratically with @xmath55 coordinates .\nafter psf modeling , we run allstar to perform iterative psf photometry of all detected sources in the frame with initial centroids set to the same values used for our own photometry .\nwe then calculated aperture corrections using the package daogrow @xcite after subtraction of all but psf stars , which creates aperture growth curves for each frame and then integrates them out to infinity to obtain a total magnitude for each psf star .\nthe final step is to convert the instrumental magnitudes into the standard photometric system . for each frame , the initial zero - point correction is applied by correcting the magnitude offset with respect to the master frame .\nthis places photometry for all frames on a common instrumental system .\nfollowing the same procedure in section 3.3 , the photometric calibration is performed individually for each amplifier region .\nfigure [ fig : fig11 ] shows the residual magnitudes and sky values between our multi - aperture photometry and the psf - fitting photometry as a function of position in the selected ccd chips .\nthere are no position - dependent trends in the magnitude residuals . for the brighter stars with @xmath79 mag ,\nthe rms magnitude difference between the two methods is very small ( @xmath81 = @xmath82 and @xmath83 = @xmath84 , respectively ) , while for the relatively faint stars the rms difference is somewhat larger ( @xmath81 = @xmath85 and @xmath83 = @xmath86 , respectively ) .\nthe results of this example indicate that we can reliably correct for the psf variations by our calibration procedures\n. meanwhile , our sky values are slightly higher than the allstar sky values , but not to the degree that can seriously affect photometric measurements .\nmagnitude in the central region of the open cluster m37 ( left panel ) .\nthe arrows indicate the three different magnitude levels from bright to faint in our sample shown in the right panels .\nnote that the variable object ids are taken from the new variable catalog of the m37 ( see paper ii ) . ]\nfigure [ fig : fig12 ] shows a comparison of the rms dispersion of the light curves obtained with our photometry with respect to the that of the psf - fitting photometry in the central region of the open cluster m37 .\nwe only compare the light curves of non - blended objects as described in section 3.5 .\nour multi - aperture photometry does not reach the same level of precision as psf - fitting photometry for the faintest stars , while the psf - fitting approach results in poorer photometry for bright stars .\nas shown in the right panels of figure [ fig : fig12 ] , it is clear that our photometry tend to have smaller measurement errors with respect to the psf photometry for the bright stars .\n-axis indicate the corresponding timestamps in each frame .\nthe deviations from the mean value , @xmath87 , are less than @xmath300.01 mag level ( with a rms values of 0.0021 , 0.0025 , and 0.0033 mag from the top panel down ) .\nthese stars show a similar pattern of light variations over the observation span . ]\nfrom a visual inspection of the re - calibrated light curves in the same ccd chip , we found that some light curves tend to have the same pattern of variations over the observation span ( figure [ fig : fig13 ] ) .\nthis kind of systematic variation ( i.e. , _ trend _ ) is often noticed in other studies .\nfor example , the importance of minimizing known ( or unknown ) systematics have been recognized by several exo - planet surveys because planet detection performance can be easily damaged by them ( e.g.,@xcite ) .\nalso space - based time - series data ( e.g. , corot and kepler ) are no exception to this behavior although it is completely free from systematics caused by the turbulent atmosphere .\nmost of the raw light curves are affected by a secular ( or a sudden ) variation of flux without any obvious physical reason @xcite .    in order to check the properties of temporal systematics\n, we examined the correlation coefficients as measure of similarity between two light curves @xmath47 and @xmath71 obtained from a single ccd chip ( ccd 1 ) .\n@xmath88 where @xmath89 is the flux of each star at time @xmath90 , @xmath58 is the total number of measurements , @xmath91 is the mean flux of each star , and @xmath13 is the standard deviation of @xmath89 .\nthis comparison is a point - by - point comparison and is done for every pair of light curves in the data set .\nthe resultant similarity matrix can be used to identify correlated pairs of light curves and to determine which light curve is least like all other light curves ( e.g. , @xcite ) .\nafter that , we selected stars showing most systematics based on a hierarchical clustering method with the correlation coefficients ( see @xcite , for more details ) .\nfigure [ fig : fig14 ] represents spatial distribution of the most prominent trend groups on the ccd plane ( top panel ) and its strongly correlated features determined by the weighted sum of normalized light curves ( bottom panel ) .\nthere are two interesting features in this figure : the first one is that each trend covers only a certain part of the sky area and the second one is that some portions of neighboring trends show different variation patterns even at the same moment in time ( shaded gray region in the figure ) . in particular , we found an anti - correlated variation for the trends between the group 1 ( @xmath92 ) and the group 2 ( @xmath93 ) , so we might expect to find possible noise sources that are responsible for these discrepancies .\nwhy the trends are different and localized within a single ccd frame is a subject of further study , but it is probably related to subtle changes in point spread function and sky condition within the detector fov .     and @xmath94 ) of stars .\nthe numbers on the @xmath34-axis indicate the corresponding timestamps between the frame 1 and the frame 400 . from the top to bottom , the panels show the average difference of trend , flux concentrations in which we applied a @xmath95 mag shift to the @xmath96 value , sky level , and psf fwhm value between the two groups . ]    , for the original multi - aperture magnitude measurements as a function of aperture size , which is marked with a gray dots in all panels .\na positive @xmath97 indicates that the photometric measurements with the corresponding aperture size , @xmath98 , are brighter than those of reference aperture @xmath99 , while a negative @xmath97 indicates vise versa .\nthe dashed lines are the rms model profiles introduced in section 3.2.2 .\nthere is a noticeable distinction between the group 1 ( _ top panels _ ) and group 2 ( _ bottom panels _ ) when looked at different concentration levels .\nbut the trends are not fully explained by the difference patterns in @xmath97 because those correlated variations become small after the correction for the psf variation ( black dots ) . ]    for these two groups , we consider a possible causal relationship between the systematic trends and average object / image properties .\nfigure [ fig : fig15 ] shows the differences in trend , differential magnitudes , sky level , and psf fwhm between the two groups , respectively . in the top panel , we plot the magnitude difference in trends , which shows variations in the range of @xmath50 mag .\nwe suspect that this may be due to the different concentration of star light between these two groups\n. it can be checked by using the magnitude difference @xmath100 , where @xmath99 and @xmath98 are the reference aperture and the relatively small aperture , respectively .\nin fact , we already know that there is a magnitude variation in @xmath37 depend on the aperture size due to the field - dependent psf variation ( see section 3.4 ) . for example , figure [ fig : fig16 ] shows the response of multi - aperture photometry for the two groups of stars at one epoch ( mjd = 53726.14817 ) before and after applying the distortion corrections .\nalthough the magnitude variation between the group 1 and the group 2 seems to have different behavior as a function of aperture size ( gray points ) , it is negligible after the removal of the psf variation ( black points ) .\nwe also check that the possible contribution of sky level ( @xmath101 ) and psf fwhm differences ( @xmath102 ) to the systematic trends on the re - calibrated light curves . as mentioned by @xcite , sky over - subtraction\nmay lead to the systematic trends as a function of the psf fwhm , the amplitude of which increase for fainter stars .\nthe third and forth panels of figure [ fig : fig15 ] show the variation of the mean @xmath101 and @xmath102 , respectively . in our case , however , the form and amplitude of trends seem independent of sky level and psf fwhm .\nsome other possible sources that may contribute to the observed systematic trends include : higher order variations in the psf shape beyond just the fwhm ; cross - talk from other amplifiers , or ghosts from bright stars undergoing multiple reflections within the optics ; non - uniform variations in the gain ; and unmodeled temporal atmospheric variations that are dominated by rayleigh scattering , molecular absorption by ozone and water vapor , and aerosol scattering @xcite .\nwhile we find a clear presence of trends that should be removed , we are not able to identify their exact cause .      in order to reduce systematic effects in photometric time - series data , several methods were introduced ( e.g. , tfa : @xcite ; sys - rem : @xcite ; pdt : @xcite ; cda : @xcite ; pdc : @xcite ) .\nall of these algorithms share a common advantage that they work without any prior knowledge of the systematic effects .\nwe use the pdt algorithm , which has been designed to detect and remove spatially localized patterns . by default\n, this algorithm works with a set of light curves that contain the same number of data points distributed in the same series of epoch . in many cases , however ,\nmissing data occur when no photometric measurements are available for some stars in a given observed frame .\nthese missing data can be simply replaced by means , medians , or the values from the interpolation of adjacent data points in each light curve ( e.g. , @xcite ) .\nalthough using the replaced value is the easiest way to reconstruct the light curve to be analyzed , it is not appropriate if the time separation between two subsequent observations is too large .\ninstead we use more straightforward approach by applying the pdt algorithm in two separate steps : ( i ) we construct the master trends from the subset of bright stars , and ( ii ) de - trend light curves of all stars with most similar master trend and matching time line .    -axis indicate the corresponding timestamps between the frame 1 and the frame 2000 .\nthe @xmath36-axis is @xmath46-filter magnitude ( normalized by its mean value ) .\nwhile the morphology of the two light curves in the left panels appear to be variable stars of some kind , these turn out to be non - variable after applying the photometric de - trending method . in the case of the right panels ,\nall true variabilities are preserved from the raw light curves . from upper left\nto lower right : id=10032 , id=10039 , id=170088 , and id=170108 . ]\nwe briefly describe the main procedure of our de - trending process following the algorithm derived by @xcite .\nwe first select the template light curves from bright stars that show the highest correlation in the light - curve features .\nthe total length of template light curves should be long enough to cover the whole time span of observations . in this step , we take a sequence of data points , @xmath103 as the reference time line . using the correlation matrix calculated from equation ( 7 ) , we extract all subset of light curves that show spatio - temporally correlated features ( i.e. , clusters ) .\neach cluster is determined by hierarchical tree clustering algorithm based on the degree of similarity .\nnext , we obtain master trends @xmath104 for each cluster by weighted average of the normalized differential light curves , @xmath105 : @xmath106 @xmath107 @xmath108 where @xmath109 is the total number of light curves in each cluster @xmath64 , @xmath110 is mean value of _ i light curve , and @xmath111 is the standard deviation of @xmath105 . after determining the master trends , we de - trend the light curves of all stars with matching master trend and time line .\nwe adjust the temporal sequence of measurements for the master trends @xmath112 by that of individual light curves to be de - trended @xmath113 . because each light curve is assumed as a linear combination of master trends and noise\n, we can determine the optimal solution by minimizing the residual between the master trends and the light curve : @xmath114 @xmath115 where @xmath116 is the total number of master trends and @xmath117 are free parameters to be determined by means of minimization of noise term @xmath118 .\n_    figure [ fig : fig17 ] shows examples of our light curves before and after removing the systematic trends .\nthe algorithm we used for de - trending removes only the systematic variations that are shared by light curves of stars in the adjacent sky regions ( left panels ) , while all kinds of true variabilities are preserved ( right panels ) .\n( indicated by arrow ) .\nthe phased diagram of this candidate frequency is shown in the low - right panel .\nwe see that the model fits well the overall pulsating variability ( red line ) . ]    , but the subfigure of low - right panel is 200@xmath4200 thumbnail image of the target star .\nthere is no potential sources of contamination to hamper the interpretation of the power spectrum . ]\nthe usefulness of our photometry is tested for a set of variable stars .\nwe immediately find abundant cases of improvements in the following three aspects : ( i ) refinement of the derived period , ( ii ) detection of a new significant peak in the periodogram , and ( iii ) separation of non - variable candidates where systematics in the light curves were mistaken for true variability .\nfor each case , we compare light curves and power spectra for archival data and our data .\nfor the first example , we show that a new photometric measurement and calibration allowed us to derive a much improved refinement of the light curves and of the derived periods ( figure [ fig : fig18 ] ) . we performed a lomb - scargle ( l - s : @xcite ) search of both archival and new light curves for periodic variable star ( v427 ) .\nthe light curves are folded by the best - fit period of 5.4615 and 4.4158 days , respectively .\nwe also calculated the false - alarm probability ( @xmath119 fap ) for each peak and its signal to noise ratio ( s / n ) : @xmath119 fap@xmath120 = @xmath121 , s / n@xmath120 = 43.2 for the archival data and @xmath119 fap@xmath122 = @xmath123 , s / n@xmath122 = 84.5 for the new data .\nsince we can get better estimation with much lowered minimum fap value , our new period is the most likely result . in the bottom panels ,\nthe resulting amplitude spectrum was calculated with ` period04 ` package .\nsince the archival data is more noisy than the new one , it is rather complicated to interpret the peaks of its power spectrum .    for the second example , we show the newly discovered low - amplitude pulsating variable star ( figure [ fig : fig19 ] ) .\nwe used the ` period04 ` package to find multiple pulsation periods .\nthe whole process of identifying , fitting , and pre - whitening successive frequencies was repeated until no significant frequencies were found .\nwe adopt a conservative approach in selecting the statistical significant peaks from the amplitude spectrum\n. a s / n amplitude ratio of 4.0 is a good criterion for independent frequencies , equivalent to 99.9% certainty of variability @xcite .\nwhile no clear periodicity was found in the archive data , our amplitude spectrum shows a clear excess of power centered at 22.3979 days@xmath124 with peak amplitudes of about 1 mmag ( s / n@xmath122 = 9.02 ) .\nthe last example is the opposite case of the second .\nfigure [ fig : fig20 ] shows that this object is unlikely to be a variable source because there is no evidence for any significant peaks , which indicates that the variations are mostly noise .\nextensive study on variabilities will be presented in paper ii .\nin this paper , we introduce a new time - series photometry with multi - aperture indexing and spatio - temporal de - trending techniques , together with complex corrections to minimize instrumental biases .\nwe used the archival , high - temporal time - series data from one - month long mmt / megacam transit survey program .\nthe re - calibration of the archival data has made several improvements as follows : ( i ) the photometric information derived from the multi - aperture indexing measurements is useful to obtain the best s / n measurement , but also to diagnose whether or not the targets are contaminated ; ( ii ) the resulting light curves utilize nearly 100% of available data and reach precisions down to sub mmag level at the bright magnitude end without the need to throw out many outlier data points , which makes it possible to preserve data points that show intrinsic sudden variations such as flare events ; ( iii ) corrections for position - dependent psf variations and de - trending of spatio - temporal systematic trends improve the quality of light curves ; and ( iv ) new photometry enables us to determine the variability nature and period estimate more accurately .    while this study deals with a particular set of data from mmt\n, we find our approach has a potential for other wide - field time - series observations .\nmulti - aperture indexing measurement is a powerful tool in isolating and even correcting various contaminations .\nspatio - temporal de - trending is also very useful in removing systematics caused by psf variation and even non - uniform extinction of thin clouds across the fov .\n@xcite proved this for different sets of archival survey data .\nthis research was supported by basic science research program of the national research foundation of korea ( 2011 - 0030875 ) .\ni.b . is grateful for support from kasi - yonsei drc program of korea research council of fundamental science and technology ( drc-12 - 2-kasi ) .\nwe thank the mmt / m37 survey team for the kind provision of raw image data .\nkim , d .- w . helped us to test the modified photometric de - trending algorithm .\nadditionally , we would like to thank the anonymous referee for many helpful comments , including the suggestion to use psf photometry to further justify the successful removal of systematics ( section 3.5.2 ) .\nalard , c. 2000 , , 144 , 363 alard , c. & lupton , r. h. 1998 , , 503 , 325 becker , a. c. , wittman , d. m. , boeshaar , p. c. , et al .\n2004 , , 611 , 418 bertin , e. & arnouts , s. 1996 , , 117 , 393 bianco , f. b. , protopapas , o. , mcleod , b. a. , et al .\n2009 , , 138 , 568 boulade , o. , charlot , x. , abbon , p. , et al .\n2003 , , 4841 , 72 bramich , d. m. & freudling , w. 2012 , , 424 , 1584 breger , m. , stich , j. , garrido , r. , et al .\n1993 , , 271 , 482 chang , s .- w . & byun , y .- i .\n2013 , in astronomical society of the pacific conference series , vol .\n475 , astronomical data analysis software and systems xxii , ed .\nd. n. freidel , 41 everett , m. e. & howell , s. b. 2001 , , 113 , 1428 gillon , m. , pont , f. , moutou , c. , et al .\n2007 , , 466 , 743 hartman , j. d. , stanek , k. z. , gaudi , b. s. , holman , m. j. , & mcleod , b. a. 2005 , , 130 , 2241 hartman , j. d. , gaudi , b. s. , holman , m. j. , et al . 2008a , , 675 , 1233 hartman , j. d. , gaudi , b. s. , holman , m. j. , et al . 2008b , , 675 , 1254 hartman , j. d. , gaudi , b. s. , holman , m. j. , et al .\n2009 , , 695 , 336 hodgkin , s. t. , irwin , m. j. , hewett , p. c. , & warren , s. j. 2009 , , 394 , 675 howell , s. b. 1989 , , 101 , 616 irwin , j. , irwin , m. , aigrain , s. , et al .\n2007 , , 375 , 1449 ivezi , z. , smith , j. a. , miknaitis , g. , et al .\n2007 , , 134 , 973 jenkins , j. m. , caldwell , douglas a. , chandrasekaran , h. , et al .\n2010 , , 713 , l87 kim , d .- w . ,\nprotopapas , p. , alcock , c. , byun , y .-\ni . , & bianco , f. 2009 , , 397 , 558 kim , d .- w . , protopapas , p. , alcock , c. , byun , y .- i .\n, et al . 2010 , , 139 , 757 kovcs , g. , bakos , g. , & noyes , r. w. 2005 , , 356 , 557 kuijken , k. , bender , r. , cappellaro , e. , et al .\n2002 , the eso messenger , 110 , 15 kulkarni , s. r. 2013 , the astron .\ntelegram , 4807 , 1 magain , p. , courbin , f. , gillon , m. , et al .\n2007 , , 461 , 373 mazeh , t. , guterman , p. , aigrain , s. , et al .\n2009 , , 506 , 431 mcleod , b. a. , conroy , m. , gauron , t. m. , geary , j. c. , & ordway , m. p. 2000 , in further developments in scientific optical imaging , ed .\nm. b. denton ( cambridge : royal society of chemistry ) , 11 merline , w. & howell , s. b. 1995 , exp .\n6 , 163 . mink , d.j .\n2002 in astronomical society of the pacific conference series , vol .\n281 , astronomical data analysis software and systems xi , ed .\nd. a. bohlender , d. durand , & t. h. handley , 169 mislis , d. , schmitt , j. h. m. m. , carone , l. , guenther , e. w. , & ptzold , m. 2010 , , 522 , 86 miyazaki , s. , komiyama , y. , sekiguchi , m. , et al .\n2002 , pasj , 54 , 833 padmanabhan , n. , schlegel , d. j. , finkbeiner , d. p. , et al .\n2008 , , 674 , 1217 pepper , j. , stanek , k. z. , pogge , r. w. , et al .\n2008 , , 135 , 907 pietrukowicz , p. , minniti , d. , fernndez , j. m. , et al .\n2009 , , 503 , 651 pont , f. , zucker , s. , & queloz , d. 2006 , , 373 , 231 protopapas , p. , giammarco , j. m. , faccioli , l. , et al .\n2006 , , 369 , 677 randall , s. k. , calamida , a. , fontaine , g. , et al .\n2011 , , 737 , 27 scargle , j. d. 1982 , , 263 , 835 skrutskie , m. f. , cutri , r. m. , stiening , r. , et al .\n2006 , , 131 , 1163 stetson , p. b. 1987 , , 99 , 191 stetson , p. b. 1990 , , 102 , 932 tamuz , o. , mazeh , t. , & zucker , s. 2005 , , 356 , 1466 twicken , j. d. , chandrasekaran , h. , jenkins , j. m. , et al .\n2010 , , 7740 , 62 van dokkum , p. g. 2001 , , 113 , 1420"}
{"lay_summary": " truncated fourier , gauss , kummer and exponential sums can be used to factorize numbers : for a factor these sums equal unity in absolute value , whereas they nearly vanish for any other number . \n we show how this factorization algorithm can emerge from superpositions of classical light waves and we present a number of simple implementations in optics . ", "article": "factorization of numbers into their prime factors is a hard non - polynomial problem for classical computers .\nit was shor @xcite who proposed a quantum algorithm which can solve the problem of factorization of numbers on a quantum computer with a tremendous speedup as compared to a classical computer .\na practical demonstration of shor s algorithm has been carried out by factorizing the integer 15 @xcite , using nuclear magnetic resonance .\nhowever , quantum computers capable of implementing shor s algorithm for larger numbers have not been developed yet .\nseveral approaches to factorize numbers based on interference of multiple quantum paths have been proposed dowling , summhammer , merkel2006,mahesh , mehring , gilowski2008,bigourd2008,sadgrove2008,stefanak .\nthose schemes do not use quantum entanglement and do not capitalize on quantum parallelism . as a consequence ,\nthese schemes scale exponentially with the number of digits of the factorized number .\nthis is in contrast to shor s algorithm which requires only a polynomial number of operations . nevertheless ,\nif the interference is implemented in a suitable way in a system , which does the factorization , then one can benefit because nature plays the role of a computer .\nas was pointed out by jones @xcite the proposed techniques for factorization based on gauss sums @xcite unfortunately do not provide useful methods to factorize numbers , because a precalculation of the factors is needed for the experiment . in spite of that\n, gauss sums would be useful if it is possible to avoid explicit precalculation stages of the algorithms .\nphysical systems that can implement the gauss sums must be described by complex numbers . in the present paper\nwe investigate how truncated fourier sum and its generalizations , like truncated gauss , kummer and exponential sums , could emerge from superposition of several oscillations .\nthose sums can be used successfully to factorize numbers . due to the wide use of interferences and beats in optics\n, we shall keep our consideration close to optics and our examples are in wave optics too .\nhowever , the proposed implementation can be extended to virtually any physical system where superposition among several different oscillations appear , from the mechanical pendulum with several degrees of freedom , through the atomic and solid state systems and their analogs in quantum mechanics .\nin order to find the factors of a given number @xmath0 we use the following truncated sum : @xmath1where @xmath2 is an integer and @xmath3 is the number of terms in the sum .\nthe argument @xmath4 scans through all integers between @xmath5 and @xmath6 for possible factors .\nthe capability of the sum of eq .\n( [ truncated sum ] ) to factor numbers originate from the fact that for an integer factor @xmath7 of @xmath0 with @xmath8 , all phases in @xmath9 are integer multiples of @xmath10 .\nconsequently , the terms add up constructively and yield @xmath11 .\nwhen @xmath4 is not a factor , the phases oscillate rapidly with @xmath12 , and @xmath9 takes on small values . in this interference pattern , larger truncation parameter @xmath3 leads to better convergency . in principle ,\nalready the first several terms of the sum are sufficient to discriminate factors from non - factors .\ndepending on the coefficient @xmath2 in eq.([truncated sum ] ) we distinguish several important cases :    [ fourier , gauss and kummer ] @xmath13    the use of quadratic phases to factor numbers ( gauss sum ) has the advantage of fewer terms needed in the sum to distinguish factors from non - factors compared to the linear phase ( fourier sum ) , which is because of high quasi - randomness for the quadratic phase @xcite . in the very same way\nthe kummer sum , and sums with nonlinear phases of higher order , has an advantage compared to the gauss sum @xcite .\nnow we consider a system with @xmath3 different oscillation modes , with frequencies @xmath14 , phases @xmath15 and amplitudes @xmath16    @xmath17    using the superposition principle we can write the resulting oscillation as the sum of all oscillations : @xmath18 in the sum of eq .\n( [ result oscilation ] ) we can vary the parameters @xmath19 , @xmath14 , @xmath15 and the time @xmath20 . in the next several sections we will show how truncated fourier , gauss , kummer and exponential sums could emerge when we fix three of the parameters for all oscillations , while changing the fourth parameter .\nfirst we consider the case when the parameters @xmath16 , @xmath14 , @xmath21 are equal for all oscillations in eq .\n( [ individual oscillation ] ) @xmath22thus the only parameter that is left not fixed in eq .\n( [ individual oscillation ] ) is the time @xmath20 .\nthis can be easily realized in optics by interferometry , where the individual oscillations describe the electric field for the different arms of the interferometer as shown in fig.[four arms ] .    from fig .\n[ four arms ] and eq .\n( [ result oscilation ] ) we see that we have the following sums of electric fields in the detector@xmath23where @xmath24 is the phase accumulated in the @xmath12 arm of the interferometer due to the difference in travel time through each arm .\nsuppose that each arm of the interferometer is with length @xmath25 the wave length of the light that we use in vacuum is @xmath26 and the corresponding frequency is @xmath27 , let the index of refraction in each arm of the interferometer is different and is denoted as @xmath28 .\nthen the phase @xmath24 for the beam that travels through the @xmath12-th arm of the interferometer is given as@xmath29here @xmath30 is the time that light travel in the @xmath12-th arm of the interferometer to pass length @xmath31 and @xmath32 is the speed of light in that arm .\nthe refraction index in arm @xmath12 of the interferometer is @xmath33thus @xmath34then the electric filed in the detector is @xmath35now if the index of reflection in the @xmath12 arm of the interferometer is @xmath36then @xmath37the detector registers the intensity,@xmath38various @xmath2 gives us a different type of truncated sum ( see eq .\n( fourier , gauss and kummer ) ) .\nthe number that we want to factorize is @xmath39 the trial factors are @xmath26 .\neach time when the trial factor @xmath26 is a factor of @xmath40 we will observe a maximum signal in the detector .\nthe number of the terms in the sum can be controlled by doubling the elements in the interferometer fig .\n[ four arms ] .\nthe numbers that could be factorized in this way are of order @xmath41 .\nnow we consider a train of pulses , where the delay of the @xmath12 pulse compared to first pulse is given as@xmath42here @xmath12 takes the values @xmath43 , while @xmath44 can be set as a unit of time .\nwe consider the case when all pulses have equal amplitudes @xmath45 and equal frequencies @xmath46 .\nthen the electric field for the @xmath12 pulse is given by eq .\n( [ individual oscillation ] ) and reads @xmath47let us make a different path way for every pulse in such a way that all pulses hit the same detector at the same time , this is equivalent to make @xmath48 at the place where all pulses collides .\nthen the intensity that the detector registers is a result from the superposition among all electric fields , e.g the sum from eq .\n( [ result oscilation]):@xmath49where @xmath50 . if one chooses the frequency @xmath51 as the number that we want to factorize ( @xmath0 ) and @xmath52 as a trail factor ( @xmath4 ) , then eq.([intensity ] ) reduces to the sum from eq .\n( truncated sum ) .\nif we now consider a system that exhibits several oscillations with the same amplitude @xmath53 and the same initial phases ( @xmath54 ) , but with different frequencies @xmath14 , then the individual oscillations ( individual oscillation ) are described by @xmath55the resulting oscillation ( [ result oscilation ] ) is @xmath56where @xmath57 .\nwe will observe beats when @xmath58 is a integer which could be used to find the factors of the number @xmath59 .\none physical realization of the above idea could be a light with several high - harmonic generated frequencies brabec2000,gavrila1992 , chosen in the way that they present for example the odd terms in the fourier sum : @xmath60then in the detector the time of the detection play the role of the test factors and whenever there is a beat we observe a maximum of the signal , thus this time is a real factor .\nthe last parameter that we can vary in eq .\n( [ individual oscillation ] ) is the amplitude of the individual oscillation .\nfor example if we work with laser light we can use the different polarization orientations of the electric field .\nthe electric field is a vector in the polarization plane , which can be described by complex electrical field .\nlet us consider the case when we have a linearly polarized light pulse , which is split in several parts and each part passes different pathways through faraday cells as shown in fig .\n[ faraday cells ] .    applying different faraday rotation angles\n@xmath15 on each pathway and collecting all of the light at the same place ( at the detector ) the resulting electric field is the superposition:@xmath61where @xmath53 is the electrical field amplitude of the initial beam .\nthe relation between the angle of polarization rotation due to the faraday effect @xmath15 and the magnetic field @xmath62 in a diamagnetic material @xcite is    @xmath63    where @xmath31 is the length of each pathway and @xmath64 is the verdet constant for the material @xcite . for the amplitude of the resulted electric field we have:@xmath65if we now have a magnetic field @xmath62 for the @xmath12-th faraday cell , which is given as : @xmath66then\nthe intensity in the detector is @xmath67here the number that we want to factorize is @xmath39 the trial factors are @xmath68 .\nwe have shown how the factorization algorithm based on truncated fourier , gauss , kummer or exponential sums emerges naturally from superpositions of classical light waves .\nwe have proposed a number of simple implementations in optics .\nthese implementations can be extended to virtually any physical system where superpositions of several different oscillations appear .\nthe factorization algorithms discussed in this paper are classical algorithms and thus their complexity scales exponentially with the number of digits .\nif an extension of this algorithm exists in entangled quantum systems , then a quantum computing parallelism would be involved with an exponential speedup of factorization .\nthe present solutions therefore could be the first step to an alternative quantum factorization algorithm to the famous shor algorithm .\nthis work has been supported by the eu tok project camel , the eu rtn project emali , the eu  itn project fastquast , and the bulgarian national science fund grants no .\nwu-2501/06 and no . wu-2517/07 .\nthe author is grateful to n. vitanov for stimulating discussions and critical reading of the manuscript . during the preparation of this paper ,\nthe author became aware of a related work by tamma et al ."}
{"lay_summary": " statistical learning theory chiefly studies restricted hypothesis classes , particularly those with finite vapnik - chervonenkis ( vc ) dimension . \n the fundamental quantity of interest is the sample complexity : the number of samples required to learn to a specified level of accuracy . \n here we consider learning over the set of all computable labeling functions . \n since the vc - dimension is infinite and a priori ( uniform ) bounds on the number of samples are impossible , we let the learning algorithm decide when it has seen sufficient samples to have learned . we first show that learning in this setting is indeed possible , and develop a learning algorithm . \n we then show , however , that bounding sample complexity independently of the distribution is impossible . \n notably , this impossibility is entirely due to the requirement that the learning algorithm be computable , and not due to the statistical nature of the problem . ", "article": "suppose we are trying to learn a difficult classification problem : for example determining whether the given image contains a human face , or whether the mri image shows a malignant tumor , etc .\nwe may first try to train a simple model such as a small neural network .\nif that fails , we may move on to other , potentially more complex , methods of classification such as support vector machines with different kernels , techniques to apply certain transformations to the data first , etc .\nconventional statistical learning theory attempts to bound the number of samples needed to learn to a specified level of accuracy for each of the above models ( e.g.  neural networks , support vector machines ) .\nspecifically , it is enough to bound the vc - dimension of the learning model to determine the number of samples to use  @xcite .\nhowever , if we allow ourselves to change the model , then the vc - dimension of the overall learning algorithm is not finite , and much of statistical learning theory does not directly apply .    accepting that much of the time the complexity of the model can not be a priori bounded , structural risk minimization  @xcite explicitly considers a hierarchy of increasingly complex models .\nan alternative approach , and one we follow in this paper , is simply to consider a single learning model that includes all possible classification methods .\nwe consider the unrestricted learning model consisting of all computable classifiers .\nsince the vc - dimension is clearly infinite , there are no uniform bounds ( independent of the distribution and the target concept ) on the number of samples needed to learn accurately  @xcite .\nyet we still want to guarantee a desired level of accuracy . rather than deciding on the number of samples a priori\n, it is natural to allow the learning algorithm to decide when it has seen sufficiently many labeled samples based on the training samples seen up to now and their labels . since the above learning model includes any practical classification scheme , we term it universal ( pac- ) learning .\nwe first show that there is a computable learning algorithm in our universal setting .\nthen , in order to obtain bounds on the number of training samples that would be needed , we consider measuring sample complexity of the learning algorithm as a function of the unknown correct labeling function ( i.e.  target concept ) . although the correct labeling is unknown , this sample complexity measure could be used to compare learning algorithms speculatively : \nif the target labeling were such and such , learning algorithm @xmath0 requires fewer samples than learning algorithm @xmath1 \" . by asking what is the largest sample size needed assuming the target labeling function is in a certain class\n, we could compare the sample complexity of the universal learner to a learner over the restricted class ( e.g.  with finite vc - dimension ) .\nhowever , we prove that it is impossible to bound the sample complexity of any _ computable _ universal learning algorithm , even as a function of the target concept .\ndepending on the distribution , any such bound will be exceeded with arbitrarily high probability .\nthe impossibility of a distribution - independent bound is entirely due to the computability requirement .\nindeed we show there is an uncomputable learning procedure for which we bound the number of samples queried as a function of the unknown target concept , independently of the distribution .\nour results imply that computable learning algorithms in the universal setting must  waste samples \" in the sense of requiring more samples than is necessary for statistical reasons alone .\nthere is comparatively little work in statistical learning theory on learning arbitrary computable classifiers compared to the volume of research on learning in more restricted settings . computational learning theory ( aka pac - learning )\nrequires learning algorithms to be efficient in the sense of running in polynomial time of certain parameters  @xcite .\nthat work generally restricts learning to very limited concept / hypothesis spaces such as perceptrons , dnf expressions , limited - weight neural networks , etc .\nthe purely statistical learning theory paradigm ignores issues of computability  @xcite .\nwork on learning arbitrary computable functions is mostly in the  learning in the limit \" paradigm  @xcite , in which the goal of learning is to eventually converge to the perfectly correct hypothesis as opposed to approximating it with an approximately correct hypothesis .\nthe idea of allowing the learner to ask for a varying number of training samples based on the ones previously seen was studied before in statistical learning theory  @xcite .\nlinial et al  @xcite called this model  dynamic sampling \" and showed that dynamic sampling allows learning with a hypothesis space of infinite vc - dimension if all hypotheses can be enumerated .\nthis is essentially theorem  [ thm : uncomputablealgorithm ] of our paper .\nhowever , the hypothesis space of all computable functions can not be enumerated by any algorithm , and thus these results do not directly imply the existence of a learning algorithm in our setting .    our proof technique for establishing positive results ( theorem  [ thm : learningalgorithmexists ] ) is parallel evaluation of all hypotheses , and is based on levin s universal search  @xcite . in learning theory , levin s\nuniversal search was previously used by goldreich and ron  @xcite to evaluate all learning algorithms in parallel and obtain an algorithm with asymptotically optimal computation time .\nthe main negative result of this paper is showing the absence of distribution independent bounds on sample complexity for computable universal learning algorithms ( theorem  [ thm : nobound ] ) .\nrecently ryabko  @xcite considered learning arbitrary computable classifiers , albeit in a setting where the number of samples for the learning algorithm is externally chosen .\nhe demonstrated a computational difficulty in determining the number of samples needed : it grows faster than any computable function of the length of the target concept . in contrast\n, we prove that distribution - independent bounds do not exist altogether for computable learning algorithms in our setting .\nthe _ sample space _ @xmath2 is the universe of possible points over which learning occurs . here\nwe will largely suppose the sample space @xmath2 is the set of all finite binary strings @xmath3 .\nconcept space _ @xmath4 and _ hypothesis space _\n@xmath5 are sets of boolean - valued functions over @xmath2 , which are said to _ label\n_ points @xmath6 as @xmath7 .\nthe concept space @xmath4 is the set of all possible labeling functions that our learning algorithm may be asked to learn from . in each learning scenario\n, there is some unknown _ target concept _ @xmath8 that represents the desired way of labeling points .\nthere is also an unknown _ sample distribution _ @xmath9 over @xmath2 .\nthe learning algorithm chooses a _\n@xmath10 based on iid samples drawn from @xmath9 and labeled according to the target concept @xmath11 . since we can not hope to distinguish between a hypothesis that is always correct and one that is correct most of the time , we adopt the  probably approximately correct \"  @xcite goal of producing with high probability ( @xmath12 ) a hypothesis @xmath13 such that the probability over @xmath14 that @xmath15 is small ( @xmath16 ) .    here we will mostly consider the concept space @xmath4 to be the set of all total recursive functions @xmath17 .\nwe say that this is a universal learning setting because @xmath4 includes any practical classification scheme .\nwe will mostly consider the hypothesis space to be the set of all partial recursive functions @xmath18 , where @xmath19 indicates failure to halt . from pac learning it is known that sometimes it helps to use different concept and hypothesis classes , if one desires the learning algorithm to be efficient  @xcite . in a related way , allowing our algorithm to output a partial recursive function that may not halt on all inputs seems to permit learning ( e.g.  theorem  [ thm : learningalgorithmexists ] ) .\nabusing notation , @xmath8 or @xmath10 will refer to either the function or to a representation of that function as a program .\nsimilarly @xmath4 and @xmath5 will refer to the sets of functions or to the sets of representations of the corresponding functions .\nwe assume all programs are written in some fixed alphabet and are interpreted by some fixed universal turing machine . if @xmath13 is a partial recursive function and @xmath20 then by convention @xmath21 for any partial recursive function @xmath22 ( even if @xmath23 also ) .\nwe can now define what we mean by a learning algorithm :    algorithm @xmath0 is a _ learning algorithm _ over sample space @xmath2 , concept space @xmath4 , and hypothesis space @xmath5 if :    * ( syntactic requirements ) @xmath0 takes two inputs @xmath24 and @xmath25 , queries an oracle for pairs in @xmath26 , and if @xmath0 halts it outputs a hypothesis @xmath10 . *\n( semantic requirements ) for any @xmath27 , for any concept @xmath8 , and distribution @xmath9 over @xmath2 , if the oracle returns pairs @xmath28 for @xmath29 drawn iid from @xmath9 , then @xmath0 always halts , and with probability at least @xmath12 outputs a hypothesis @xmath13 such that @xmath30 < { \\varepsilon}$ ]\n.    the always halting requirement seems a nice property of the learning algorithm and indeed the learning algorithm we develop ( theorem  [ thm : learningalgorithmexists ] ) will halt for any concept and sequence of samples . however , relaxing this requirement to allow a non - zero probability that the learning algorithm queries the oracle for infinitely many samples does not change our negative results ( theorem  [ thm : nobound ] ) , as long as a finite number of oracle calls implies halting .\nthe fundamental notion in statistical learning theory is that of sample complexity . since the vc - dimension of our hypothesis space is infinite , there is no _ uniform bound _\n@xmath31 on the number of samples needed to learn to the @xmath27 level of accuracy .\nwe will consider the question of whether for a given learning algorithm there is a _ distribution - independent bound _\n@xmath32 on the number of samples queried from the oracle where @xmath8 is the target hypothesis . in other words\nthe bound is allowed to depend on the target concept @xmath11 but not on the sample distribution @xmath9 .\nsuch a bound may be satisfied with certainty , or satisfied with high probability over the learning samples .\nwe first show that there is a computable learning algorithm in our setting .\n[ thm : learningalgorithmexists ] there is a learning algorithm over sample space @xmath2 of all finite binary strings , hypothesis space @xmath5 of all partial recursive functions , and concept space @xmath4 of all total recursive functions .    in order to prove this theorem we need the following lemma .\nresults equivalent to this lemma can be found in  @xcite .\n[ lem : m ] let @xmath2 be any sample space and @xmath9 be any distribution over @xmath2 . fix any function @xmath33 .\nsuppose hypothesis space @xmath5 is countable , and let @xmath34 be some ordering of @xmath5 .\nfor any @xmath27 , let @xmath35 .\nsuppose @xmath36 is an infinite sequence of iid samples drawn from @xmath9 .\nthen the probability that there exists @xmath37 such that @xmath38 > { \\varepsilon}$ ] , but @xmath39 agrees with @xmath11 on @xmath40 , is less than @xmath41 .\nthe probability that a particular @xmath39 with error probability @xmath38 > { \\varepsilon}$ ] gets @xmath42 i.i.d .\ninstances drawn from @xmath9 correct is less than @xmath43 . by the union bound ,\nthe probability that _ any _ @xmath39 with error probability greater than @xmath16 gets @xmath42 instances correct is less than @xmath44 .\n* proof of theorem  [ thm : learningalgorithmexists ] : * let @xmath34 be a recursive enumeration of @xmath5 ( for example in lexicographic order ) . for the given @xmath27 , let @xmath42 be defined as in lemma  [ lem : m ] .\nthe learning algorithm computes infinitely many threads @xmath45 running in parallel .\nthis can be done by a standard dovetailing technique .\n( for example use the following schedule : for @xmath46 to infinity , for @xmath47 to k , perform step @xmath48 of thread @xmath49 . )\nthread @xmath49 sequentially checks whether @xmath50 , @xmath51 , @xmath52 , @xmath53 , exiting if a check fails .\nif all @xmath42 checks pass , thread @xmath49 terminates and outputs @xmath39 .\nthe learning algorithm queries the oracle as necessary for new learning samples and their labeling .\nthe overall algorithm terminates as soon as some thread outputs an @xmath39 , and outputs this hypothesis . by lemma  [ lem : m ] , with probability at least @xmath12 , this @xmath39 has error probability less than @xmath16 .\nfurther , since @xmath54 , the learning algorithm will always terminate .\nnote that it seems necessary to expand the hypothesis space to include all partial recursive functions because the concept space of total recursive functions does not have a recursive enumeration ( it is uncomputable whether a given program is total recursive or not ) .\nwe will see in theorem  [ thm : nobound ] that there is no bound @xmath55 on the number of samples queried by any computable learning algorithm in our setting .\nlet us obtain some intuition for why that is true for the above learning algorithm .\nthen we will contrast this to the case of an uncomputable learning algorithm .\nin essence , we can make the above learning algorithm query for more samples than is necessary for statistical reasons alone .\nintuitively , suppose that an @xmath56 coming early in the ordering is always correct but takes a very long time to compute .\nthe learning algorithm can not wait for this @xmath56 to finish , because it does not know that any particular @xmath39 will ever halt . at some point it has to start testing @xmath39 s that come later in the ordering and that have larger @xmath42 s .\ntesting these requires more learning samples than @xmath57 .\nif we can know which @xmath39 s are safe to skip over since they do nt halt , and for which @xmath39 s we should wait , then the above problem is solved .\nindeed , the following theorem shows that there is no statistical reason why a distribution - independent bound @xmath55 is impossible .\nthe theorem presents a well defined method of learning ( albeit an uncomputable one ) for which there exists such a bound , and this bound is satisfied with certainty .\nbelow , the halting oracle gives @xmath7 answers to questions of the form @xmath58 where @xmath59 such that a @xmath60 answer indicates that @xmath61 halts and a @xmath62 answer indicates it does not ; the answers are clearly uncomputable .\n[ thm : uncomputablealgorithm ] if a learning algorithm is allowed to query the halting oracle , then there is a learning algorithm over sample space @xmath2 of all finite binary strings , hypothesis space @xmath5 of all partial recursive functions , and concept space @xmath4 of all total recursive functions , and a function @xmath63 , such that for any approximation parameters @xmath27 , any target concept @xmath8 , and any distribution @xmath9 over @xmath2 , the learning algorithm uses at most @xmath55 training samples .    rather than dovetailing\nas is done for the computable learning algorithm ( theorem  [ thm : learningalgorithmexists ] ) , we can sequentially test every @xmath39 on samples @xmath64 , @xmath52 , @xmath65 because we can determine whether @xmath39 halts on a given input .\nsince @xmath66 for some @xmath67 , the hypothesis @xmath39 we output will always satisfy @xmath68 , and therefore we will require at most @xmath69 samples .\nwe now show that for any _ computable _ learning algorithm , and any possible sample bound @xmath55 , there is a target concept @xmath11 and a sample distribution such that this sample bound is violated with high probability .\nthe probability of violation can be made arbitrarily close to @xmath70 ( which approaches @xmath60 as @xmath71 ) .\nin fact this theorem is stronger : it shows that given a learning algorithm , without varying the target concept , but just by varying the distribution it is possible to make the algorithm ask for arbitrarily many learning samples with high probability .\n[ thm : nobound ] for any learning algorithm over sample space @xmath2 of all finite binary strings , hypothesis space @xmath5 of all partial recursive functions , and concept space @xmath4 of all total recursive functions , there is a target concept @xmath8 , such that for any approximation parameters @xmath27 , for any @xmath72 , and for any sample bound @xmath73 there is a distribution @xmath9 over @xmath2 , such that the learning algorithm uses more than @xmath74 training samples with probability at least @xmath75 .\nthe key difference between a computable and an uncomputable learning algorithm , is that a concept can simulate a computable one . by simulating the learning algorithm , a concept can choose to behave in way that is bad for the learning algorithm s sample complexity .    to prove the above theorem\n, we will first need the following lemma .\nthe lemma essentially shows a situation such that any learning algorithm according to our definition must query for more than @xmath74 learning samples with high probability when the target concept is chosen adversarily .\nthe lemma is true even without requiring the learning algorithm to be computable .\nnote that the lemma does not directly imply the theorem above , even in its weaker form , because in order to increase the number of learning samples that are likely queried by the learning algorithm , we have to change the target concept . since @xmath55 is a function of @xmath11 ,\nthere is no guarantee that the bound does nt become larger as well .\n[ lem : probabilisticmethod ] let @xmath2 be a set of @xmath76 points , and let @xmath4 be the set of all labelings of @xmath2 .\nlet @xmath9 be a uniform distribution over @xmath2 .\nsuppose @xmath0 is a learning algorithm over sample space @xmath2 , concept and hypothesis space @xmath4 .\nfor any accuracy parameters @xmath27 and any @xmath77 , there is a concept @xmath8 such that when the oracle draws from @xmath9 labeled according to @xmath11 the probability that @xmath0 samples more than @xmath74 points is at least @xmath78 .\nwe use the probabilistic method to find a particularly bad concept @xmath79 .\nsuppose we do not start with a fixed target concept @xmath11 , but draw it uniformly from @xmath4 .\nin other words , @xmath11 is determined by values @xmath80 drawn uniformly from @xmath81 . given some @xmath82 , @xmath83 , and @xmath84 , the value of @xmath85 is a fair coin flip .\nthus if on @xmath82 labeled by @xmath83 , @xmath0 outputs a hypothesis without asking for more samples , then the hypothesis is incorrect on @xmath29 with probability @xmath86 . if we now let @xmath29 vary , the probability that the hypothesis is incorrect on @xmath29 is at least @xmath87 since there are at least @xmath88 points not in @xmath82 .\nnow suppose for any @xmath11 the probability that @xmath0 samples more than @xmath74 points is at most @xmath75 .\nthen the unconditional probability that the hypothesis output by @xmath0 is incorrect on a random sample point is at least @xmath89 .\nthis implies that there is a concept @xmath90 such that the probability that the hypothesis output by @xmath0 is incorrect on a random sample point is at least @xmath89 .    since @xmath0 is a learning algorithm , when we use @xmath79 to label the training points , and use accuracy parameters @xmath27 , the probability that the hypothesis produced by @xmath0 has error probability greater than @xmath16 is at most @xmath41 .\nif we make the worst case assumption that whenever the error probability of the hypothesis is larger than @xmath16 it is exactly @xmath60 , and otherwise the error probability is exactly @xmath16 , then the probability that the hypothesis output by @xmath0 is incorrect on a random sample point is at most @xmath91 .\nthus @xmath92 , implying that @xmath93 .\nnow in order to prove theorem  [ thm : nobound ] , we essentially show that there is some fixed concept @xmath79 that behaves as the bad @xmath11 s in arbitrary instances of lemma  [ lem : probabilisticmethod ] .\n* proof of theorem  [ thm : nobound ] : * consider the following program @xmath94 .\nfirst it interprets the given string @xmath95 as a tuple @xmath96 for @xmath24 , @xmath25 and @xmath97 using some fixed one - to - one encoding of such tuples as binary strings . if @xmath29 can not be decoded appropriately , or if @xmath98 then @xmath99 returns @xmath62\notherwise , for these @xmath100 , let @xmath101 be the set of @xmath76 strings which are interpreted as @xmath102 , @xmath52 , @xmath103 , and let @xmath104 be a uniform distribution over @xmath105 and @xmath62 elsewhere .\nlet @xmath106 be the set of all possible labelings of @xmath105 .\nfor each labeling @xmath107 , program @xmath99 computes the probability @xmath108 that @xmath0 given accuracy parameters @xmath27 , queries for more than @xmath74 sample points if points are drawn from @xmath104 labeled according to @xmath109 .\nfor each @xmath109 , this requires simulating @xmath0 for at most @xmath110 different sequences of sample points .\nlet @xmath111 , breaking ties in some fixed way .\nfinally @xmath99 outputs @xmath112 .\nobserve that @xmath99 is total recursive since @xmath0 spends a finite time on any finite sequence of sample points .\n( this is a weaker condition than the always halting requirement of our definition of a learning algorithm . )\nthus @xmath99 is some @xmath90 .\nfurther , for any @xmath100 , on all points @xmath113 for @xmath114 , @xmath99 finds the same @xmath115 , and thus on these points @xmath79 acts like this @xmath115 . by lemma  [ lem : probabilisticmethod ] , if @xmath77 then this @xmath115 has the property that @xmath116 .\ntherefore , if @xmath0 is given accuracy parameters @xmath27 , the target concept is @xmath79 , and the distribution @xmath9 is uniform over @xmath117 for some @xmath118 such that @xmath77 , then the probability that @xmath0 requests more than @xmath74 samples is at least @xmath78 . since we can choose @xmath9 such that @xmath76 is large enough , we obtain the desired result .\nwe have shown that learning arbitrary computable classifiers is possible in the statistical learning paradigm .\nhowever for any computable learning algorithm , the number of samples required to learn to a desired level of accuracy may become arbitrarily large depending on the sample distribution .\nthis is in contrast to uncomputable learning methods in the same universal setting whose sample complexity can be bounded independently of the distribution .\nour results mean that there is a big price in terms of sample complexity to be paid for the combination of universality and computability of the learner . specifically , by tweaking the distribution we can make a computable universal learner arbitrarily worse than a restricted learning algorithm on a finite vc - dimensional hypothesis space , or even an uncomputable universal learner .\nwhile we have presented a single computable learning algorithm in our universal setting , one would like to develop a measure that would allow different learning algorithms to be compared to each other in terms of sample complexity .\nwe have seen that sample complexity @xmath55 is not such a measure ; is there a viable alternative ?    finally , we have ignored computation time in our analysis . as such ,\nour learning algorithm is not likely to have practical significance .\nintegrating running time into the theory presented would be a critical extension ."}
{"lay_summary": " electroweak corrections to longitudinal gauge and higgs boson scattering amplitudes are calculated . due to sudakov \n double logarithms , the effect is a suppression of amplitude that grows rapidly with increasing center of mass energy leading to significant reduction of cross sections compared to tree level results . \n for example , the suppression factor for the cross section of @xmath0 scattering due to these corrections varies from @xmath1 at the center of mass energy of @xmath2 to a factor of @xmath3 at the center of mass energy of @xmath4 . \n the modification of sm unitarity bound due to these corrections is obtained . ", "article": "it is well known that in standard model ( sm ) the higgs quartic coupling has a landau pole for a sufficiently heavy higgs mass .\nthe position of the pole is a function of the higgs boson mass . for light enough mass of the higgs boson , either landau pole is higher than the plank scale or it disappears , and the unitarity of sm is preserved .\nhowever very quickly as @xmath5 approaches @xmath6 the landau pole becomes close to the @xmath7 scale and as a consequence the perturbative unitarity is broken in longitudinal gauge boson scattering amplitudes .\nthis is known as unitarity bound on higgs boson mass @xcite , which relates the higgs mass to the energy scale at which the unitarity is broken in sm .\nthis scale , as a function of @xmath5 represents a scale at which either some new particles should come in and save unitarity , or otherwise , the sm becomes strongly coupled .\nnote that in this paper we refer to unitarity of sm in the presence of the higgs boson , not to be confused with analysis of longitudinal gauge boson scattering in the absence of higgs boson , in which case unitarity is violated at much lower scales .    in the standard analysis of unitarity bound on higgs mass for sm the equivalence theorem@xcite\nis used to relate the longitudinal gauge boson scattering amplitude to the corresponding scalar scattering , including unphysical goldstone boson modes in the @xmath8 gauge . at tree level and high energies\nthese amplitudes are purely @xmath9waves , proportional to higgs self - coupling @xmath10 .\nnaive analysis of loop contributions of su(2 ) and u(1 ) gauge bosons to say @xmath11 amplitude seems to give very small result , because couplings @xmath12 are small .\nhowever such amplitudes contain sudakov double logarithms@xcite-@xcite , and in a series of recent papers @xcite@xmath13@xcite it was shown how in the effective theory approach one can resum these large logarithms .\nthe results of @xcite@xmath13@xcite are that at the @xmath7 scale such sudakov resummation leads to decrease in the cross section for processes like @xmath14 up to @xmath15 , a suppression factor that rapidly increases with the center of mass energy . in a recent paper @xcite\nit was shown that electroweak sudakov corrections play a significant role in top quark forward backward asymmetry .\nit is the purpose of this paper to go beyond the traditional tree level unitarity analysis of sm and study how higher order corrections , which are part of sm and can be calculated using existing techniques , modify the unitarity bound of sm .\nthe paper is organized as follows : in section [ seq : theo ] we briefly review the approach developed in @xcite@xmath13@xcite to resum electroweak logarithms for high - energy processes . in section [ seq : ww ]\nwe derive the effect of electroweak large logarithm resummation on the high energy behavior of longitudinal gauge bosons and higgs scattering amplitudes .\nwe study the applications of derived corrections to the sm unitarity bound in section [ seq : unitarity ] .\nwe conclude in section [ seq : concl ] .\nsoft collinear effective theory ( scet ) @xcite@xmath13@xcite is an effective theory for highly energetic quarks and gluons .\nrecently it has been extended in @xcite@xmath13@xcite to standard model to compute renormalization group improved amplitudes for sm including resummation of sudakov large double - logarithms from loops with su(2 ) and u(1 ) gauge bosons .\nthe computation can be divided in three steps .\nfirst we integrate out the hard modes at the scale of center of mass energy @xmath16 for our scattering process . for @xmath17 process\nwe match on four - particle contact operators in eft , which is referred to as @xmath18 with massless su(2 ) and u(1 ) gauge bosons .\nthis leaves us with some basis of operators and wilson coefficients , which only contain @xmath19 and can be minimized by scale choice @xmath16 .\nnext the effective operators in @xmath18 have to be evolved down to the weak scale @xmath20 . in order to relate the wilson coefficients at low scale to the ones obtained by matching on previous step at high scale one needs to exponentiate the anomalous dimension matrix , which consists from collinear and soft parts .\nthis anomalous dimension has been studied and calculated to one loop order for any process in sm in @xcite@xmath13@xcite . finally at the low scale @xmath21 one has to match onto broken theory where gauge bosons have been removed . as a result one gets the effective amplitude for scattering of gauge bosons and quarks and leptons with resummed large logarithms .\nthe corresponding amplitude in @xmath18 gets the following factorized form@xcite : @xmath22 \\,p\\exp\\left(\\int_{\\mu_h}^{\\mu_l}\\frac{d\\mu}{\\mu}{\\boldsymbol{\\gamma}}(\\alpha(\\mu))\\right)\\nonumber\\\\ & & \\qquad\\,\\,\\,\\times{\\boldsymbol{c}}\\left(\\alpha(\\mu_h),\\left\\{\\ln\\frac{p_i{\\!\\cdot\\!}p_j}{\\mu_h^2}\\right\\}\\right),\\label{mresummaster}\\end{aligned}\\ ] ] where @xmath23 is the column vector of wilson coefficients obtained from matching at high scale , @xmath24 is the anomalous dimension of effective operator , which is a matrix in the color space , and finally @xmath25 appears as a result of the low scale matching .\nthe anomalous dimension for a general hard scattering process has the form @xmath26 , where collinear anomalous dimension is a sum of collinear anomalous dimensions associated with each leg and soft anomalous dimension has a non - trivial color structure but is universal in the sense that it only depends on light - cone directions and color flow .\nwe derive in this section electroweak radiative correction contribution to the amplitude of longitudinal gauge and/or higgs boson scattering amplitude . the corresponding formalism has been developed in @xcite@xmath13@xcite and was briefly reviewed in section [ seq : theo ] .\nfollowing these references we use the equivalence theorem to relate gauge boson amplitude to the corresponding unphysical scalar amplitude in @xmath8 gauge .\nthis method was applied in refs .\n@xcite@xmath13@xcite to derive longitudinal gauge boson production at lhc to next - to - next - to - leading logarithmic order(nnll ) , except for scalar contribution at two loops that is missing for some parts .\nwe work at next - to - leading logarithmic order ( nll ) .      at the scale @xmath27\nwe integrate out hard modes and leave only collinear modes , corresponding to four external label momenta . for our purpose\nthe higgs quartic coupling gives the biggest contribution to the matching .\nwe neglect the gauge boson mediated interactions between the scalars , since they are suppressed by the ratio of weak coupling to higgs self - coupling @xmath28 . the tree level matching is given by higgs quartic term in the sm lagrangian , and is trivial : @xmath29 the higgs quartic coupling has a familiar landau pole at higher energies , and is given at one loop order : @xmath30 while @xmath31 .\nequation eq .   is valid approximation for @xmath32 . for lower masses\none has to include contribution of top quark yukawa coupling and the landau pole disappears . we come back to this case at the end of section [ seq : unitarity ] .      from high scale\nthe wilson coefficients must be evolved to the low scale @xmath34 which is of the order of the electroweak scale @xmath35 .\nthis is achieved by calculating the anomalous dimension of the four particle operator in the effective theory @xmath18@xcite .\nthe anomalous dimension for such process can be written as sum of process dependent collinear anomalous dimension , which is simply the sum over the corresponding terms for each leg , and the universal soft anomalous dimension @xcite , which only depends on kinematics and color structure , but is same for say scalars or fermions .\nthus the collinear part of anomalous dimension we know from @xcite@xmath13@xcite and the soft part of the anomalous dimension is same as in @xmath36 for @xmath37 and @xmath38 . for @xmath39 the soft anomalous dimension to one loop\nis known @xcite , it was derived for @xmath39 , @xmath37 and @xmath38 in refs\n. @xcite . since\nour effective operators are ( su(3))color singlets , the anomalous dimension gets contribution only from su(2 ) and u(1 ) gauge bosons .\nthe result for the total anomalous dimension is : @xmath40\\right)\\nonumber\\\\ & & + \\frac{\\alpha_1}{\\pi}2y_{\\phi}^2 \\left((t - u)-i\\pi\\right),\\label{gammasoft}\\end{aligned}\\ ] ] where the mandelstam invariants are defined according to @xmath41 and @xmath42 where @xmath43 is the scattering angle in the center of mass frame , defined as angle between momenta of @xmath44 and @xmath45 in the cm frame .\nwe will need the formula for the anomalous dimension in the universal form in terms of mandelstam variables @xmath46 , without assuming that @xmath47 as in eq .   above .\nthe corresponding analytic continuation looks as follows : @xmath48\\right),\\label{gtotanalytic}\\end{aligned}\\ ] ] where @xmath49 , @xmath50 @xcite .\nit is useful to have an analytical formula for ( matrix ) exponential of the integral from @xmath33 to @xmath34 of anomalous dimension in eq .\nthat appears in the resummed amplitude in eq .\n: @xmath51 evaluation of @xmath52 requires standard tricks to switch integration from @xmath53 to @xmath54 using the beta - function as well as matrix exponentiation .\nthe former has been analytically performed in the appendix a of ref .\n@xcite while the latter is a simple exercise for 2 by 2 matrices . rewriting the anomalous dimension in terms of cusp and non - cusp part : @xmath55 where @xmath56 and inex @xmath57 corresponds to @xmath38 and @xmath58 to @xmath37 parts of the sm gauge group and values for cusp and non - cusp parts are summarized in the table below\nnote that the @xmath33 dependence in the non - cusp part of the anomalous dimension is cancelled exactly by same dependence in the log term in eq .   and\nis introduced in order to use master formula from appendix a of ref .\n@xcite for the integral of the anomalous dimension .\nfinally we get for the exponential factor in eq .   a fully analytic expression :    @xmath59 , \\,\\,\\,\\text{where}\\\\ & & \\omega=\\sum_{k=1}^2\\frac{{\\pi a_{1k}}\\big[z_k\\ln z_k+1-z_k\\big]}{b_{0k}^2\\,\\alpha_k(\\mu_l)}+\\frac{a_{1k}b_{1k}}{4b_{0k}^3}\\left[\\ln z_k - z_k-\\frac{1}{2}\\ln^2{z_k}+1\\right]+\\frac{a_{2k}}{4b_{0k}^2}\\left[z_k-\\ln z_k-1\\right]-\\frac{\\tilde{b}_{1k}}{2b_{0k}}\\ln z_k,\\label{omegadinasour}\\\\ & & w=\\frac{2}{b_{02}}\\ln z_2 , \\qquad\\qquad\\delta=\\sqrt{\\frac{1}{4}\\text{l}_{tu / s^2}^2+\\frac{3}{4}\\text{l}_{t / u}^2}.\\end{aligned}\\ ] ]    in the equation above we defined @xmath60 , @xmath61 are the two lowest order beta - function coefficients for @xmath38 and @xmath37 and @xmath62 are the one and two - loop cusp anomalous dimension coefficients and one - loop non - cusp anomalous dimension coefficient .\nthey are all summarized in the table below .\nnote that @xmath63 is defined in such a way that it is same as @xmath64 for @xmath57 and is equal to part of @xmath65 which is proportional to unit matrix , i.e. omitting term @xmath66 , where @xmath67 is the matrix in the second term of the second line in eq .  , which comes from soft anomalous dimension .\nthe leading - logarithm ( ll ) expression is significantly simpler and is given by first term in the expression for @xmath68 in eq .  :\n@xmath69}{b_{0k}^2\\,\\alpha_k(\\mu_l)}}\\right),\\label{eq : gammall}\\end{aligned}\\ ] ] and unlike the nll expression , the ll one is proportional to unit matrix , has no angular dependance at fixed scales @xmath70 and does not depend on any momenta ( @xmath71 ) before setting the scale @xmath72 .    [ cols=\"<,^,>\",options=\"header \" , ]      at the low scale @xmath35 we integrate out @xmath73 and @xmath74 bosons , and match onto @xmath75 with only photons ( and of course gluons , but for our purpose they are irrelevant ) . at tree level\nwe simply rewrite each doublet @xmath76 in our operator basis @xmath77 in terms of broken fields : @xmath78 where @xmath79 and @xmath80 and we omitted the higgs vev since we are interested in four - particle interactions only .\nwriting the operators @xmath81 and @xmath82 in terms of four - particle operators involving fields @xmath83 is straightforward but contains a great number of terms .\nit is more convenient to work in the basis of fields @xmath84 , where @xmath85 since the number of possible terms with such a choice in the effective lagrangian is minimal . at the low scale @xmath34 the operators in eq .\nmatch onto the following ones : @xmath86 with wilson coefficients @xmath87 , where @xmath88 coefficients @xmath89 at the high scale are given in eq .\n-eq .  , while at the low scale they are equal to : @xmath90 the matching matrix @xmath91 at tree level is found simply by substituting eq .   into the definition of operators @xmath77 .\nthe result is : @xmath92^t.\\end{aligned}\\ ] ] finally for consistency if we stay at nll order we need to include the matching at low scale at one loop , because this matching contains large logarithms @xmath93 and due to finite difference @xmath94 in sm , these large logarithm has to be included at nll order in sm @xcite .\nthis calculation in sm is tricky and has been performed consistently in ref .\nthe result is that the scalar doublet has to be matched on physical states below @xmath34 , which are @xmath95 and each component of the doublet gets different matching correction which can be found in @xcite for general case @xmath96 . for nll order and setting @xmath97\n, the entire doublet gets the same matching correction .\nthe resummed matrix element gets multiplied as a result of low scale matching by a factor @xmath98 , where @xmath99 has simple expression for this case : @xmath100 by setting @xmath97 we get a simple expression , however the price we pay is that we will not be able to evaluate the low - scale variation consistently .\nwe will only include high - scale variation @xmath33 in our plots below . including the low scale matching ,\nthe tree level matrix @xmath101 gets modified : @xmath102      now that we have calculated the matrix element including resummation of electroweak sudakov logarithms , it is straightforward to construct the lagrangian of effective theory : @xmath103 another simplification we will use is to rewrite the color - triplet operator as a combination of two color singlet operators with different contractions : @xmath104 with @xmath105 for @xmath37 .\nthus , since momenta @xmath106 have to be summed over , and also the lagrangian before low - scale matching looks like @xmath107 , we can use identity in eq .   and reshuffle the momenta @xmath108 in the first term of eq .   to make it look like the second term ( @xmath82 ) with reshuffled momenta in the argument of the wilson coefficient @xmath109 . as a result we reduced our basis of operators to only one :\n@xmath82 and lagrangian takes form : @xmath110 there is one subtlety at this point , which is whether we set the hard scale @xmath111 before the summation in the lagrangian , or we set this scale after taking the matrix element with external states .\nwe chose to do the later while the former would give a different numerical result .\nhowever the difference should be within hard scale variation , thus of the higher order , i.e. nnll .    at nll order\nthe function @xmath112 is equal to : @xmath113 at ll it is independent of loop momenta completely : @xmath114 where @xmath115 is given in eq .  .      with effective theory lagrangian found in the previous subsection\nit is a straightforward exercise to evaluate matrix elements of longitudinal gauge and higgs boson scattering amplitudes .\nfor example the amplitude for @xmath11 scattering is given by : @xmath117 where this matrix element has to be evaluated with effective lagrangian given in eq .   and\nbasis operators @xmath118 in eq .  .\ndefining the basis of normalized states@xcite @xmath119 : @xmath120 and similarly in the final state the basis states @xmath121 can be found by substituting @xmath122 .\nthe @xmath123 matrix elements of effective theory in this basis equal to : @xmath124,\\nonumber\\\\\\label{smatrix}\\end{aligned}\\ ] ] where @xmath125 and @xmath126 appear due to combinatorics because of different contractions . at tree level\nthis leads to combinatorial factors , while in our case different contractions lead to different crossing of @xmath46 parameters : @xmath127 and function @xmath112 is given to ll order in eq .   and to nll order in eq .\nnote that at ll all functions @xmath128 are identical ( due to our choice to set the scale @xmath33 after taking the matrix element of effective theory operators , as we discussed above ) , and we get that the @xmath123 matrix has a simple form : @xmath129.\\nonumber\\\\\\label{llsmatrix}\\end{aligned}\\ ] ] thus we find a simple result that at leading - logarithm order , including electroweak sudakov logarithms , the entire tree level @xmath116matrix@xcite gets multiplied by a universal number @xmath130 given in eq .  .\nto get numerical results one has to plug in @xmath131 and scale variation can be used as usual as an estimate of theoretical uncertainties .    also note that the ll result for the amplitude has no angular dependence ,\nthe scattering remains @xmath9wave similarly to tree level result .\nthe non - trivial angular dependence appears only at nll order .\nfinally , note that @xmath132 , which follows from @xmath133 .\nthus in @xmath9 wave analysis , the amplitude @xmath134 including electroweak sudakov logarithms at nll order vanishes .\nsame is true at tree level : amplitude @xmath134 _ only vanishes in _ @xmath9wave and @xmath135 and @xmath136 _ vanish identically_@xcite .      in this subsection we will use the general @xmath116 matrix derived in the previous subsection at nll order to numerically study the nll order electroweak sudakov logarithms in @xmath138 cross section . this process does not provide the tightest bound for traditional unitarity bound analysis of standard model @xcite .\nnevertheless we provide this as an illustration to the effect of electroweak logarithms for longitudinal gauge boson scattering cross sections .\nas was found in the previous subsection at ll order all other processes are proportional to each other , i.e. to the one considered in this subsection , the only non - trivial difference appears at nll order .    since at ll @xmath9wave analysis is exact , at nll order we expect it to be a good approximation .\nthus , we define functions @xmath139 which are given by : @xmath140 how this functions depend on energy controls the @xmath9wave analysis of cross - section with longitudinal gauge and higgs bosons . in figure\n[ fig : numerics1 ] we present this dependence for all functions @xmath141 .\nthe left of this figure is function @xmath142 with breakdown of contributions from separately ll su(2 ) only sudakov corrections(red ) , ll su(2)xu(1 ) sudakov corrections(green ) and nll su(2 ) ( blue ) and finally full nll su(2)xu(1 ) sudakov corrections ( black ) .\nthe right plot in figure [ fig : numerics1 ] represents the full nll su(2)xu(1 ) sudakov corrections for each function @xmath143 .\nit turns out that to this order there are only two non - trivial functions : @xmath144 and @xmath145 as shown in that figure .\nthe reason @xmath144 has been explained at the end of previous subsection . by the same argument\nit is clear that @xmath146 and @xmath147 .\nnumerically it so happens that they all are the same at this order , which could be explained if one completely ignores the angular dependence in @xmath126 .\nthe horizontal axis for @xmath148 goes all the way to the planck scale . as expected at low energies the sudakov corrections\nare small , however very quickly they reduce amplitude at tree level by a factor of @xmath149 at the cm energy @xmath150 .\nhaving studied the generic behavior of scattering amplitudes of longitudinal gauge bosons ( and higgs ) , we specialize to the case of @xmath151 : @xmath152 where function @xmath153 we calculate by two methods .\nfirst is exact , keeping the full angular dependence in the amplitude , coming from nll order ( see eq .  ):\n@xmath154 in the second method we use @xmath9wave approximation : @xmath155 both functions are plotted in the left part of figure [ fig : numerics2 ] . it is comforting to see , that there is a good agreement between the exact and @xmath9wave approximated cross sections , since at leading logarithmic order the entire amplitude is a pure @xmath9wave . while it is interesting that the electroweak corrections reduce the @xmath156 scattering cross section so dramatically at high energies , @xmath157 at the cm energy of @xmath158 , one should keep in mind that depending on the higgs mass @xmath5 , the quartic coupling @xmath159 has a landau pole and extending predictions beyond that scale is meaningless . as an illustration , on the right part of figure [ fig : numerics2 ] we include the higgs coupling and plot the function @xmath160 for different higgs masses . as expected\nthe cross section blows up at the landau pole , which is unaffected by sudakov corrections .\nhowever for lighter higgs masses ( @xmath161 ) , almost everywhere except the vicinity of the landau pole , the cross section is significantly suppressed due to sudakov double logarithms .\nthe standard analysis of unitarity bound of sm @xcite includes longitudinal gauge boson scattering amplitudes at tree level @xcite and in refs .\n@xcite the running of the higgs quartic coupling @xmath159 is included as well as improved unitarity bound @xmath162 , where @xmath163 is the @xmath9partial wave of the scattering amplitude @xmath164 .\ngeneral expansion for the amplitude in terms of spherical harmonics is given by : @xmath165 inverting eq .\nwe find : @xmath166 taking into account the resummation of electroweak logarithms as derived in section [ seq : ww ] leads at nll order to some non - trivial @xmath167etc partial waves , due to angular dependence of @xmath168 , while at ll such dependence is absent . at tree level @xmath169 and plugging elements of eq .   into eq .   for @xmath170\nwe reproduce correctly the tree level result@xcite : @xmath171.\\end{aligned}\\ ] ]    the tightest bound for unitarity analysis is given by eigenvector of this matrix corresponding to largest eigenvalue .\nthe eigenvalues in the units of @xmath172 are @xmath173 .\nthe largest eigenvalue corresponds to eigenchannel @xmath174 .\nhowever in @xcite this state is not used for unitarity bound , since for heavy enough higgs mass the scale @xmath175 where unitarity of sm breaks becomes close to higgs mass , thus the state under consideration is kinematically not allowed .\ninstead in @xcite the isospin zero state @xmath176 is used and the unitarity bound is a factor of @xmath177 weaker for this state however the problem mentioned above is absent .\nnow our goal is to re - derive the scale where sm unitarity is broken by extending it from tree level , to including the sudakov double logarithms that we have calculated in section [ seq : ww ] for arbitrary longitudinal gauge or higgs boson scattering to nll order . since we found that at ll , there is a simple multiplicative factor for @xmath116 matrix ( see eq .  )\nwe can simply make the same choice of the state @xmath176 as in @xcite as our candidate to give the best unitarity bound .\nthis is not true at nll , but corrections should be small . also it is an apple - to - apple comparison to @xcite , where the tree level amplitude and one - loop higgs quartic running have been included into analysis .\nwe limit ourself to unitarity bound @xmath178 as in @xcite , although at very high energies as we will see below the imaginary parts and higher harmonics start to play role due to nll effects .    in order to understand the role of higher harmonics @xmath179 which appear due to nll order sudakov double logarithms , as well as the imaginary parts of scattering partial waves , we plotted in figure [ fig : numerics3 ] the real and imaginary parts of first three harmonics : @xmath180 as function of @xmath148 specifically for the @xmath176 channel , which is a simple exercise given eq .   and\neq .  . for energies around @xmath181\nhigher partial waves become comparable to @xmath163 , although still smaller . also for @xmath182 the imaginary part of @xmath163 becomes bigger than the real part .\nwe turn to the unitarity bound of standard model including the electroweak sudakov resummation . in figure\n[ fig : numerics4 ] we present our results for unitarity bounds on @xmath176 scattering .\nthe red curve is simply the position of landau pole as a function of higgs mass .\nwe use one - loop beta function for quartic coupling including only self coupling contribution to the beta function , which is a good approximation for heavier higgs masses . the green curve in figure [ fig : numerics4 ]\nrepresents the unitarity bound found in @xcite , i.e. requiring @xmath183 and including higgs quartic coupling one loop running .\nincluding electroweak logarithms into the formula for the amplitude we get the dashed blue curve ( ll ) and solid blue curve ( nll ) .\nfinally , let us address the role of electroweak logarithms and unitarity scales for the case of light higgs mass which is favorable from current lhc bounds .\nsimple formula in eq .\nconsidered above is not applicable in this case . in ref.@xcite beta functions of all couplings of sm\nare computed to two - loop order .\nfor simplicity we only use their results constraining ourselves to one - loop , including running of couplings of sm : @xmath184 and ignoring remaining yukawa couplings . note the different normalization(factor of 2 ) between @xcite and us for @xmath28 , and @xmath185 in @xcite\nis same as @xmath186 , while @xmath187 are same as our @xmath188 and @xmath189 and @xmath190 . as a result\nwe get the left plot in figure [ fig : numerics5 ] for higgs masses @xmath191 .\nas one can see the qualitative behavior is very much different than for heavy higgs masses . instead of landau pole , we get a fixed point at high energies as well as the change in the sign of the quartic coupling at an energy scale that depends on the mass of the higgs boson . similar behavior of quartic coupling was found for higgs mass around @xmath192 in ref.@xcite , which used state - of - the art analysis , including full two - loop running of all couplings .    as a result for light higgs masses shown in the left part of figure [ fig : numerics5 ]\nwe see that the coupling remains perturbative to planck scale .\nfurthermore , as one can see from the red plot in the right part of figure [ fig : numerics5 ] , the tree level @xmath9wave partial amplitude for unitarity constraining scattering of the state @xmath176 is within the unitary limit @xmath193 for all center of mass energies all the way to the planck scale . the electroweak logarithms modify this amplitude by reducing it significantly at high energies .\nfor example at @xmath194 the suppression factor is of the order @xmath195 .\nthus for phenomenologically interesting low higgs masses , the unitarity is preserved at all scales .\nthe role of electroweak logarithms is suppression of the amplitude ( and cross section ) at high energies compared to tree level result .\nwe have computed to next - to - leading logarithmic order the effect of electroweak sudakov logarithms for any longitudinal gauge or higgs boson scattering amplitude . at\nleading - logarithmic order the amplitude gets multiplied by a universal function @xmath196 , independent of the concrete process and with strong dependence on energy .\nfor example , the high energy behavior of the function @xmath112 for @xmath197reduces the tree level cross section suppressed by a factor ranging from @xmath198 at @xmath199 to @xmath200 at @xmath201 .\nthis correction does not depend ( at our order ) on higgs mass .\nof course the entire approach becomes intractable for energies above the landau pole of the quartic coupling @xmath28 .\nthis kind of behavior at high energies affects the unitarity bound of sm . despite the sudakov suppression ,\nwhen energy gets close to quartic landau pole , the singularity still wins in the very vicinity of the pole and the unitarity is still broken .    for heavier higgs masses , the landau pole appears very close to the higgs mass , so the electroweak logarithms do not get a chance to contribute significantly , since at those scales the logarithms are small . in this limit\nthe unitarity bound is unaffected .\nhowever for lighter higgs masses , ( but still @xmath202)when the landau pole gets further and further from the electroweak scale , the electroweak corrections play a dramatic role for the high energy behavior of the longitudinal gauge boson scattering , by pushing the scale where the unitarity of sm is broken very close to the landau pole energy scale , thus restoring unitarity except in the immediate vicinity of the pole .\nthis qualitative picture can be easily seen in figure [ fig : numerics4 ] .\nfinally for very light higgs mass around @xmath203 , which is currently phenomenologically favorable , the quartic coupling remains perturbative at all scales and preserves unitarity at all scales , both at tree level and when electroweak logarithms are included , which suppress amplitude and cross section of longitudinal gauge boson scattering significantly at high energies .\nthis can be seen from figure [ fig : numerics5 ] .\ni would like to thank vincenzo cirigliano , alexander friedland , terry goldman and michael graesser for useful discussions .\ni also thank aneesh manohar for helpful correspondence about the draft of this paper .\nspecial thanks to olga serafimova for inspiring me to complete this paper .\nthis research is supported by the us department of energy , office of science , under contract no .\nde - ac52 - 06na25396 and in part by the ldrd program at lanl and the jet topical collaboration .\nj.  y.  chiu , f.  golf , r.  kelley and a.  v.  manohar , phys .\nlett .   * 100 * , 021802 ( 2008 ) [ arxiv:0709.2377 [ hep - ph ] ] .\nj.  y.  chiu , f.  golf , r.  kelley and a.  v.  manohar , phys .\nd * 77 * , 053004 ( 2008 ) [ arxiv:0712.0396 [ hep - ph ] ] .\nj.  y.  chiu , r.  kelley and a.  v.  manohar , phys .\nd * 78 * , 073006 ( 2008 ) [ arxiv:0806.1240 [ hep - ph ] ] .\nj.  y.  chiu , a.  fuhrer , a.  h.  hoang , r.  kelley and a.  v.  manohar , phys .\nd * 79 * , 053007 ( 2009 ) [ arxiv:0901.1332 [ hep - ph ] ] .\nj.  y.  chiu , a.  fuhrer , r.  kelley and a.  v.  manohar , phys .\nd * 80 * , 094013 ( 2009 ) [ arxiv:0909.0012 [ hep - ph ] ] .\nj.  y.  chiu , a.  fuhrer , r.  kelley and a.  v.  manohar , phys .\nd * 81 * , 014023 ( 2010 ) [ arxiv:0909.0947 [ hep - ph ] ] .      c.  w.  bauer , s.  fleming and m.  e.  luke , phys .\nd * 63 * , 014006 ( 2000 ) [ arxiv : hep - ph/0005275 ] . c.  w.  bauer , s.  fleming , d.  pirjol and i.  w.  stewart , phys .\nd * 63 * , 114020 ( 2001 ) [ arxiv : hep - ph/0011336 ] . c.  w.  bauer , d.  pirjol and i.  w.  stewart , phys .\nd * 65 * , 054022 ( 2002 ) [ arxiv : hep - ph/0109045 ] . c.  w.  bauer and i.  w.  stewart , phys .\nb * 516 * , 134 ( 2001 ) [ arxiv : hep - ph/0107001 ] .\nn.  kidonakis , g.  oderda and g.  f.  sterman , nucl .\nb * 531 * , 365 ( 1998 ) [ arxiv : hep - ph/9803241 ] .\nh.  arason , d.  j.  castano , b.  keszthelyi , s.  mikaelian , e.  j.  piard , p.  ramond and b.  d.  wright , phys .  rev .\nd * 46 * , 3945 ( 1992 ) ."}
{"lay_summary": " we performed single point [ c  i ] @xmath0p@xmath1@xmath0p@xmath2 and co @xmath3=43 observations toward three t tauri stars , dm tau , lkca 15 , and tw hya , using the atacama large millimeter / submillimeter array ( alma ) band 8 qualification model receiver installed on the atacama submillimeter telescope experiment ( aste ) . \n two protostars in the taurus l1551 region , l1551 irs 5 and hl tau , were also observed . \n we successfully detected [ c  i ] emission from the protoplanetary disk around dm tau as well as the protostellar targets . \n the spectral profile of the [ c  i ] emission from the protoplanetary disk is marginally single - peaked , suggesting that atomic carbon ( c ) extends toward the outermost disk . \n the detected [ c  i ] emission is optically thin and the column densities of c are estimated to be @xmath4 @xmath5 and @xmath6 @xmath5 for the t tauri star targets and the protostars , respectively . \n we found a clear difference in the total mass ratio of c to dust , @xmath7(c)/@xmath7(dust ) , between the t tauri stars and protostellar targets ; the @xmath7(c)/@xmath7(dust ) ratio of the t tauri stars is one order of magnitude smaller than that of the protostars . \n the decrease of the estimated @xmath7(c)/@xmath7(dust ) ratios for the disk sources is consistent with a theoretical prediction that the atomic c can survive only in the near surface layer of the disk and c@xmath8/c / co transition occurs deeper into the disk midplane . ", "article": "the gaseous component of protoplanetary disks is crucial for understanding the planet formation process because it affects the structures and evolution of the disk via chemical reactions .\ntheoretical studies have predicted that protoplanetary disks have multiple layers in their vertical direction due to stellar radiation .\nthese include a relatively cool midplane , in which most of the molecules are depleted onto grains , a molecular - rich intermediate layer , and a hot surface layer ( e.g. , * ? ? ?\n* ) . because the physical environment differs among layers , gas phase abundances also vary significantly\natomic carbon ( c ) is considered to be abundant in the disk surface where far - ultraviolet ( fuv ) photons drive the energy balance and gas chemistry , i.e. , the photon dominated region ( pdr ) .\ntheoretical studies predict that in the pdr , fuv photons with energies less than the ionization energy of hydrogen ( 13.6 ev ) dissociate molecular hydrogen and carbon monoxide ( co ) and ionize c to yield ionized carbon ( c@xmath8 ) @xcite .\nwhen significant attenuation is achieved , a thin h / h@xmath9 transition layer should appear , beyond which hydrogen molecules dominate . because the ionization energy of c is 11.6 ev ,\nc@xmath8 is dominant at the lower density regions of the pdr .\ndeeper to the pdr , the carbon - ionizing radiation is attenuated , and co forms via various chemical reactions . as a result , for the uniform pdr\n, c exists in a thin layer sandwiched between the c@xmath8 and co layers .    because photoevaporation at the disk surface is believed to govern the gas dispersal @xcite , observations of c are crucial for understanding disk dissipation .\nmoreover , the observations of c are also important in terms of dust evolution in the disk because it affects the chemistry as a result of changes in the uv radiation field propagation and thus the intensity of the c line @xcite .\nhowever , detection of the submillimeter fine structure c lines has not been reported for protoplanetary disks thus far .\nalthough a few studies have attempted to detect the emission lines of c from protoplanetary disks around intermediate - mass stars , only upper limits have been obtained @xcite .    in this paper\n, we present the results of [ c  i ] @xmath0p@xmath1@xmath0p@xmath2 and @xmath10co @xmath3=43 observations with the band 8 qualification model receiver mounted on the atacama submillimeter telescope experiment ( aste ) , and report the first detection of [ c  i ] emission from a protoplanetary disk .\nwe estimate the optical depth of the emission to derive the column density of c , and discuss possible evolutionary trends in the total mass of atomic c.\nwe performed [ c  i ] @xmath0p@xmath1@xmath0p@xmath2 ( 492.161 ghz ) and co @xmath1143 ( 461.041 ghz ) observations toward three classical t tauri stars ( ttss ) , , , and , in november 2010 using the aste .\ntarget information is listed in table [ tab : info ] . in addition , we made [ c  i ] observations toward two protostars ( pss ) in taurus , l1551 irs 5 and hl tau , to check the consistency of the observational data .\nwe also used these data as a reference of the [ c  i ] intensity during the ps phase of star formation .\nthe observations were taken with an alma band 8 ( 400500 ghz ) qualification model heterodyne receiver ( band 8 qm ; * ? ? ?\n* ) mounted on the aste .\nthe band 8 qm uses sideband separating receivers that detect two orthogonal polarizations and down - convert the sideband - separated intermediate frequency signals to 48 ghz .\nthe half power beam width ( hpbw ) was @xmath12 and the main beam efficiency @xmath13 was estimated to be 45% from observations of jupiter . for the backend , we used mac , a 1024 channel digital auto - correlator , which has a band width of 128 mhz and a resolution of 125 khz , corresponding to 78 and 0.076 km s@xmath14 , respectively .\nthe position switch method was employed and a single spectrum toward the source position was obtained for each target . because our tts targets are well known to be less affected by surrounding clouds , we selected off positions near the targets to effectively remove atmospheric fluctuations ; 28 , 15 , and 1 arcmin from the stellar positions of dm tau , lkca 15 , and tw hya , respectively . for the pss , we employed an off position of ( @xmath15 , @xmath16)=(4@xmath17 32@xmath18 6@xmath190 , 17@xmath20 48@xmath21 51@xmath220 ) , which was determined to avoid the co @xmath1110 emission of the l1551 cloud @xcite .\nthe telescope pointing calibration was performed every 1.52 hours by observing o - cet and irc+10216 in the co @xmath1143 emission line , and the resulting pointing accuracy was @xmath233 . any time variation in intensity scale was checked by observing part of the orion horse - head nebula ( position a ; * ? ? ?\n* ) two or three times daily and was found to be less than @xmath2410% .\nthe [ c  i ] data were obtained under good sky conditions ( @xmath25 ) , whereas @xmath260.060.10 for the co observations .\nthe single sideband system noise temperatures were typically 2100 k and 3100 k for [ c  i ] and co , respectively .\ndata reduction and analysis were performed using the common astronomy software applications ( casa ) version 3.3.0 software suite , in addition to its asap modules .\nit should be noted that we reduced only one polarization dataset because of a beam alignment problem during the observations .\nbad data were removed by the _\nsdflag _ task , baseline fitting and subtraction of the baseline from the spectra were performed with the _ sdbaseline _ task , and the data sets were combined in each source with the _ sdaverage _ task .\nthe final spectra were obtained after smoothing with a five pixel boxcar function along the channel axis by the _ sdsmooth _\ntask , corresponding to a velocity resolution of @xmath27 km s@xmath14 .\nccccccccccccc    dm tau & 04:33:48.72 & @xmath2818:10:10.0 & 140 & m1 & 0.5 & 4.3 & 2.4 & 890 & 34 & 0.32 & 1,4,5,6 + lkca 15 & 04:39:17.80 & @xmath2822:21:03.5 & 140 & k5 & 1.0 & 312 & 4.8 & 905 & 52 & 0.25 & 1,6,7 + tw hya & 11:01:51.91 & @xmath2934:42:17.0 & 54 & k7 & 0.8 & 10 & 3.4 & 215 & 7 & 0.15 & 2,8 + l1551 irs5 & 04:31:34.07 & @xmath2818:08:04.9 & 140 & & & & 5 & & & 1 & 1 + hl tau & 04:31:38.44 & @xmath2818:13:57.7 & 140 & & & & 6 & & & 1 & 1,3 [ tab : info ]\nfigure [ fig : spec_tts ] shows the [ c  i ] @xmath0p@xmath1@xmath0p@xmath2 and co @xmath1143 spectra toward the three t tauri star targets , and the derived spectral line parameters are listed in table [ tab : spec ] .\nwe successfully detected [ c  i ] emission with a peak intensity of @xmath30 k toward .\nthe line profile is single peaked with a central velocity of @xmath316.1 km s@xmath14 , which is consistent with the systemic velocity of the circumstellar disk as estimated by molecular line observations ( 5.9 km s@xmath14 ; e.g. , * ? ? ?\nthe emission appeared to be slightly asymmetric with a somewhat larger extent to redshifted velocities .\nthis is similar to the spectral shape of the co @xmath1143 and other co transitions .\n@xcite . here\n, the emission component visible near @xmath32 km s@xmath14 was not analyzed because it most likely originates from the ambient cloud @xcite . for tw hya and lkca 15\n, we did not detect any [ c  i ] emission , and obtained only the 3@xmath33 upper limits shown in table [ tab : spec ] . to estimate upper limits to the total integrated intensity of the [ c  i ] emission lines , we assumed velocity widths of 3 and 1 km s@xmath14 for lkca 15 and tw hya , respectively , the values obtained by single dish co observations @xcite .\nsignificant [ c  i ] emission toward the pss l1551 irs 5 and hl tau was detected , as shown in figure [ fig : spec_ps ] .\nthe spectral profiles are single - peaked at values close to their systemic velocities .\nthe emission intensities are markedly higher than that of dm tau .\nemission in the co @xmath3=43 line was detected toward and .\nthe peak velocities and line profiles are in good agreement with those of high-@xmath3 co spectra @xcite .\nthe double - peaked profile of dm tau lies close to the systemic velocity . after correcting for the beam size and efficiency ,\nthe integrated intensity of co emission from tw hya was comparable to the marginal value reported by @xcite within the uncertainties .\nwe derived the optical depth of the [ c  i ] emission and thus the c column density using the equations reported by @xcite .\nthe optical depth at the peak velocity , @xmath34}$ ] , is given by @xmath35 } = -\\ln \\biggr ( 1- \\frac{t_\\mathrm{a}^\\ast/\\eta_\\mathrm{mb}}{f_\\mathrm{disk } [ j(t_\\mathrm{ex } ) - j(t_\\mathrm{bg } ) ] } \\biggl ) \\mathrm{,}\\ ] ] where @xmath36 is the beam filling factor of the source , @xmath37 is the excitation temperature , @xmath38 is the temperature of the cosmic background radiation , and @xmath3 is the radiation temperature defined by @xmath39 here @xmath40 is the planck constant , @xmath41 is the observed frequency , and @xmath42 is the boltzmann constant .\nthe factor @xmath36 was derived from the ratio of the solid angle of the disk to that of the telescope s beam , @xmath43 .\nthe solid angle @xmath44 was estimated by assuming that the extent of the [ c  i ] emission is identical to that of the resolved co disk @xcite .\nthe outer radius of the co disk and its inclination angle , in addition to the estimated @xmath36 , are listed in table [ tab : info ] .\nwe employed @xmath45 for the pss because they were expected to be embedded in extended envelopes that extend over the beam area . for the ttss\n, we assumed a constant @xmath37 of 50 k , as suggested by theoretical studies of protoplanetary disks around typical t tauri stars that predict the c@xmath8/c / co transition layer to appear at regions with @xmath46 k @xcite .\nconversely , we assumed @xmath47 k for the pss , which is the accepted value for [ c  i ] observations of a ps surrounded by an infalling envelope @xcite .    assuming that local thermodynamic equilibrium ( lte ) applies , we derived the averaged c column density over the source via @xmath48^{-1 } \\frac{\\tau_\\mathrm{[c~i]}}{1-\\exp(-\\tau_\\mathrm{[c~i ] } ) } f_\\mathrm{disk}^{-1 } \\ \\ \\ \\mathrm{.}\\end{aligned}\\ ] ] here\n, @xmath49 is the ground - state partition function for neutral atomic carbon , @xmath50 where @xmath51 and @xmath52 are the energies of the @xmath111 and 2 levels , respectively , and @xmath34}$ ] is the velocity - averaged optical depth of the [ c  i ] emission . in this study , however , we used the optical depth at the peak velocity instead of the velocity - averaged optical depth , which gives an upper limit to the column density .\nit should be noted that we assumed the optically thin condition ( @xmath34}\\ll1 $ ] ) for lkca 15 and tw hya because no [ c  i ] emission was detected .\nthe c column density so estimated are listed in table [ tab : quantity_ci ] .\nthe total mass of atomic carbon , @xmath7(c ) , was derived by integrating the column density over the solid angle of the source .\n@xmath7(c ) in the telescope beam can be uniquely determined regardless of source distribution .    table [ tab : quantity_ci ] clearly shows that all the detected [ c  i ] emission lines are optically thin .\nthe estimated c column density of the ttss is typically @xmath53 @xmath5 or less , whereas that of the ps is one order of magnitude higher ( @xmath6 @xmath5 ) .\naccordingly , the @xmath7(c ) values of the t tauri star targets are one order of magnitude smaller than those of the pss . these results can be attributed to the lack of dense envelopes around the ttss .\nthe [ c  i ] emission detected from dm tau is most likely associated with the rotating gas disk around the star .\nthe peak velocity and full width half maximum are consistent with those of the disk in molecular lines ( e.g. , * ? ? ?\n* ) . because of the modest upper energy of the ground state atomic c fine structure line ( @xmath54 k ) , the [ c  i ] emission is likely to be weighted toward the emission from the outer most part of the disk due to beam dilution\nin fact , the detected [ c  i ] emission shows a single - peaked profile near the systemic velocity , suggesting that the emission may dominate at the region where the rotation velocity is small , i.e. , the outer part of the disk if keplerian rotation applies .\nin addition , the fact that the total mass of c is one order of magnitude smaller than those of the pss ( table [ tab : quantity_ci ] ) supports the disk origin of the [ c  i ] emission .\nhowever , the actual nature of the [ c  i ] emission of dm tau remains unclear due to the large hpbw of the telescope .\nhigh - resolution observations are required to reveal the detailed spatial distribution of the [ c  i ] emission over the disk .\nthe estimated [ c  i ] intensity of dm tau is consistent with theoretical models of protoplanetary disk chemistry .\n@xcite , for example , calculated the [ c  i ] line intensity of a t tauri star with a massive disk of 0.07 @xmath55 through a self - consistent treatment of the pdr near the disk surface .\nthe resultant peak intensity is expected to be @xmath560.1 k in @xmath57 after correcting for the aste beam size and the distance to the source , which is comparable to our observed intensity .\nthe higher intensities of the pss than those of the ttss suggest that the atomic carbon line originates mainly from the envelopes .\nbecause the velocity width of the [ c  i ] emission is much narrower than that of the wing emission of a molecular outflow ( @xmath58 km s@xmath14 ) , the high velocity outflow is unlikely to affect the [ c  i ] emission @xcite .\nthere is a possibility of a low velocity cavity wall swept up by the outflow .\nhigh - resolution [ c  i ] observations are required to separate the envelope from such a low velocity entrainment component .\nwe introduce the total mass ratio of atomic c to dust grains , @xmath7(c)/@xmath7(dust)@xmath59 ) , to investigate the evolutional variation of m(c ) .\nthe dust mass , which is generally estimated by optically thin ( sub-)millimeter continuum observations , reflects the total gas mass of the system if the gas - to - dust ratio is constant .\ntherefore , @xmath60 is an indicator of a fraction of c with respect to the total amount of gas , which is described as @xmath61 , where @xmath62 is the gas - to - dust ratio , and @xmath63 is the fractional abundance of c with respect to h@xmath9 . it is important to state that , especially for a protoplanetary disk , the atomic c and the dust grains trace distinct vertical layers of the disk ; the atomic c presumably exists in the disk near - surface layers while the dust grains are mainly at the disk midplane .\ntherefore , @xmath60 practically indicates the mass of c near the pdr with respect to the total mass .\nwe compiled @xmath7(dust ) from previous studies , as listed in table [ tab : info ] .\nall @xmath7(dust ) data , except that for tw hya , were calculated from the total masses in @xcite , who measured ( sub-)millimeter flux densities with single dish telescopes .\ntheir beam sizes were typically @xmath561015@xmath64 , which is comparable to that of our [ c  i ] observations .\nthese authors estimated the total ( gas+dust ) disk mass by a simple disk model with power - law density and temperature profiles under an assumed gas - to - dust ratio of 100 . in table\n[ tab : info ] , we show the dust mass after correcting for the assumed gas - to - dust ratio . for tw hya , we took the mass estimate from @xcite , who also used a similar simple disk model to estimate the disk mass .\nalthough their observations were made with an interferometer , the flux density of the entire disk was correctly recovered because the disk size is comparable to the detectable scale mentioned in @xcite .\nthe derived @xmath60 is listed in table [ tab : quantity_ci ] . a clear difference in @xmath60 is apparent between the ttss and pss ; @xmath60 is typically an order of @xmath65 or less for the ttss , whereas the pss show @xmath66 , on average . it should be noted that these results are not significantly affected by the difference in the assumed value of @xmath37 . if we use @xmath6750 k for the pss , which is the same value as in the ttss , we obtain @xmath68 , on average , a value still significantly higher than that for the tts values .\nwhen @xmath6710 k , a typical value in molecular cloud cores , the difference was more noticeable .\nas defined above , the decrement of @xmath60 can be interpreted by either a reduced @xmath63 or @xmath62 .\nthe former case means that @xmath69(c ) decreases as star formation progresses .\nthe chemical lifetime of c has been theoretically predicted to drop substantially with increments in the gas density @xcite . because the gas density significantly increases from a tenuous protostellar envelope to a dense disk near a tts\n, a reduction in @xmath63 is expected at the tts stage .\nin fact , the typical density at the disk midplane is estimated to be @xmath70 @xmath71 at 100 au if we assume the minimum mass solar nebula @xcite , whereas the typical density of the pss is @xmath72 @xmath71 @xcite .\nif the reduced @xmath62 is the case , the gas in the disk must be depleted to a low level of @xmath73 to explain the @xmath60 decrement of at least one order of magnitude .\nhowever , such a high depletion of overall gas is not expected to occur in the disk , as discussed in  [ sec:4 - 3 ] .\nonly upper limits were obtained for the [ c  i ] emission from lkca 15 and tw hya , despite the fact that they also have disks as massive as that of dm tau .\none possible explanation is that overall gas depletion with disk evolution leads to a depletion of c. since all the targets are in the evolutional stage of a so - called transitional disk , their disks are expected to be evolved with respect to a filled disk @xcite .\nmoreover , their advanced stellar ages imply that the disks of lkca 15 and tw hya are older than the dm tau disk .\nthe actual gas mass is difficult to directly estimate because of the large optical depths of molecular lines .\nsome modeling efforts by using co data indicate a lower gas - to - dust ratio with respect to the standard interstellar value @xcite . however , as mentioned in  [ sec:4 - 2 ] , the gas mass estimation for tw hya by an hd line emission , which is believed to be a good tracer of gas mass , indicates that the disk is massive so that the gas - to - dust ratio is comparable to the standard interstellar value @xcite . taking into account the fact that the disk model with a nominal gas - to - dust ratio of 100 reproduces well the observed intensity @xcite , an overall gas depletion is unlikely the case .\nan alternative is the depletion of volatiles such as c - containing species at the surface with disk evolution .\nsuch a time - dependent sink mechanism of c is proposed based on the observational data of hd and co isotopologue lines @xcite .\ncccccccccc dm tau & 0.12@xmath240.03 & 6.1 & 1.4 & 0.17@xmath240.05 & 0.18@xmath240.03 & 6.2 & 1.1 & 0.20@xmath240.05 + lkca 15 & @xmath740.15 & & & & @xmath740.18 & & & + tw hya & @xmath740.24 & & & & 0.62@xmath240.08 & 2.8 & 0.7 & 0.43@xmath240.11 + l1551\nirs 5 & 1.77@xmath240.10 & 6.3 & 1.6 & 2.77@xmath240.21 & & & & + hl tau & 2.26@xmath240.08 & 6.4 & 2.0 & 4.55@xmath240.18 & & & & + [ tab : spec ]    cccccc dm tau & 0.02 & 1.6@xmath240.5 & 0.75@xmath240.22 & 3.1 + lkca 15 & @xmath740.03 & @xmath744.1 & @xmath741.48 & @xmath743.1 + tw hya & @xmath740.09 & @xmath743.6 & @xmath740.12 & @xmath740.4 + l1551 irs5 & 0.47 & 10.7@xmath240.8 & 15.3@xmath241.2 & 31 + hl tau & 0.65 & 19.0@xmath240.8 & 27.4@xmath241.1 & 46 + [ tab : quantity_ci ]    we acknowledge the aste staff for the operation and maintenance of the observational instruments .\nwe would like to thank h. nomura and d. ishimoto for fruitful discussions .\nt.t . and m.m .\nwere supported by jsps kakenhi grant no .\nwas supported by the french national research agency ( grant no .\nanr11bs560010 starfich ) ."}
{"lay_summary": " to study the dynamics of chemical processes , we often adopt rate equations to observe the change in chemical concentrations . \n however , when the number of the molecules is small , the fluctuations can not be neglected . \n we often study the effects of fluctuations with the help of stochastic differential equations .    \n chemicals are composed of molecules on a microscopic level . in principle \n , the number of molecules must be an integer , which must only change discretely . \n however , in analysis using stochastic differential equations , the fluctuations are regarded as continuous changes \n . this approximation can only be valid if applied to fluctuations that involve a sufficiently large number of molecules . in the case of extremely rare chemical species , \n the actual discreteness of the molecules may critically affect the dynamics of the system .    to elucidate the effects of the discreteness , we study an autocatalytic system consisting of several interacting chemical species with a small number of molecules through stochastic particle simulations . \n we found novel states , which were characterized as an extinction of molecule species , due to the discrete nature of the molecules . \n we also observed a strong dependence of the chemical concentrations on the size of the system , which was caused by transitions to the novel states . ", "article": "in nature , there exists a variety of systems that involve chemical reactions .\nsome are on a geographical - scale , while others on a nano - scale .\nchemical reactions are an integral part of life , including all living forms of life .    to study the dynamics of reaction systems , we often adopt rate equations in order to observe the change in chemical concentrations . in rate equations , we regard the concentrations as continuous variables ; the rate of the reaction as a function of the concentrations . in macroscopic systems ,\nthere are a vast number of molecules ; thus , continuous representations are usually applicable\n.    when the concentration of a certain chemical is small , fluctuations in the reactions or flow can be significant .\nwe often handle such systems with the help of stochastic differential equations , in which we regard noise as a continuum description of the fluctuations @xcite .\nsuch an approximation is useful when the number of molecules is intermediate .\nthe employment of stochastic differential equations led to some important discoveries such as noise - induced order @xcite , noise - induced phase transitions @xcite , and stochastic resonance @xcite .    in stochastic differential equations ,\nstill quantities of chemicals are regarded as continuous variables .\nessentially , on a microscopic level , chemicals are composed of molecules .\nthe number of molecules should be an integer ( @xmath0 , @xmath1 , @xmath2 , @xmath3 ) , which changes discretely .\nfluctuations are derivatives of discrete stochastic changes ; thus , continuum descriptions of fluctuations are not always appropriate and can be doubted . for chemicals with a small number of molecules of the order of @xmath1 ,\na single molecule is extremely significant ; therefore , the discreteness in the number is significant .\nbiological cells appear to be a good example .\nthe size of the cells is of the order of microns , in which nano - scale `` quantum '' effects can be ignored .\nhowever , in cells , some chemicals act at extremely low concentrations of the order of pm or nm .\nassuming that the typical volume of a cell ranges from @xmath1 to @xmath4 @xmath5 , the concentration of one molecule in the cell volume corresponds to @xmath6 pm@xmath6 nm .\nit is probable that the molecular numbers of some chemicals in a cell are of the order of @xmath1 , or sometimes reach @xmath0 .\nif such chemicals play only a minor role , we can safely ignore these chemicals .\nhowever , this is not always the case . in biological systems , chemical species with a small number of molecules may critically affect the behavior of the entire system .\nfor example , there exist only one or a few copies of genetic molecules such as dna , which are important to characterize the behavior , in each cell .\nfurther , some experiments show that doses of particular chemicals at concentrations of the order of pm or fm may alter the behavior of the cells ( e.g. , @xcite ) .\nbiological systems also include positive - feedback mechanisms such as autocatalytic reactions , which may amplify single molecular changes to a macroscopic level .\nthe effects due to small molecular numbers in cells have been noticed only recently , both theoretically @xcite and experimentally @xcite .    at present , we focus on the possible effects of molecular discreteness . to study such effects , we should adopt an appropriate method to handle molecular discreteness .\nsome numerical methods to investigate reaction systems that take into account discreteness and stochasticity already exist ( we briefly review these methods ; see appendix ) . among the methods , we adopted gillespie s direct method , which is popular and frequently used .\nfurthermore , some works related to molecular discreteness also exist .\nfor example , blumenfeld et al . showed that the mass action law may breakdown in a small system @xcite .\nstange et al . studied the synchronization of the turnover cycle of enzymes @xcite .\nwe regard it important to identify the phenomena for which molecular discreteness is essential .    through stochastic simulations ,\nwe show that discreteness can induce transitions to novel states in autocatalytic systems @xcite , which may affect macroscopic chemical concentrations @xcite .\nwe consider a simple autocatalytic network ( loop ) with @xmath7 chemicals .\nwe consider @xmath8 chemicals and assume @xmath9 reactions between these chemicals ( @xmath10 , @xmath2 , @xmath3 , @xmath7 ; @xmath11 ) .\nall the reactions are irreversible . for the reactor , we assume a well - stirred container with volume @xmath12 .\nthe set of @xmath13 , the number of @xmath8 molecules , determines the state of the system .\nthe container is in contact with a chemical reservoir , in which the concentration of @xmath8 is fixed at @xmath14 .\nthe flow rate of @xmath8 between the container and the reservoir is @xmath15 , which corresponds to the probability of the flowing out of a molecule per time unit is the diffusion rate across the surface of the container . here ,\nwe choose the flow proportional to @xmath12 , to have a well - defined continuum limit .\none might assume the flow proportional to @xmath16 , considering the area of the surface . by rescaling @xmath17 ,\nthe model can be rewritten into the case with @xmath16 for finite @xmath12 . ] .\nwe can consider the continuum limit as @xmath18 . in the continuum limit\n, the change of @xmath19 , the chemical concentration @xmath8 in the container , follows the rate equation @xmath20 where @xmath21 is the rate constant of the reaction @xmath22 , and @xmath23 .    for simplicity\n, we consider the case with equivalent chemical species , given as @xmath24 , @xmath25 , and @xmath26 for all @xmath27 ( @xmath28 , @xmath17 , @xmath29 ) . by this assumption\n, the rate equation has only one attractor : a stable fixed point @xmath30 for all @xmath27 . for any initial condition\n, each @xmath19 converges to @xmath31 , the fixed point value . around the fixed point ,\n@xmath19 vibrates with the frequency @xmath32 .\nif the number of molecules is finite but fairly large , we can estimate the dynamical behavior of the system using a langevin equation , obtained by adding a noise term to the rate equation .\neach concentration @xmath19 fluctuates and vibrates around the fixed point .\nan increase in the noise ( corresponding to a decrease in the number of molecules ) merely boosts the fluctuation .\nhowever , when the number of molecules is small , the behavior of the system is completely different .\nfirst , we investigate the case when @xmath33 , which is the smallest number of species to show the novel states described below .\nsubsequently , we investigate the dynamical behavior of the system with a small number of molecules . in order to detect the phenomena for which the discreteness of the number of molecules is crucial , we employ stochastic simulations .    here ,\nwe adopt gillespie s direct method .\nthe frequency ( expected number per unit time )    * of the reaction @xmath22 is @xmath34 ; * of the outflow of @xmath8 is @xmath35 ; * of the inflow of @xmath8 is @xmath36 .    in the continuum limit ( @xmath18 ) , these frequencies agree with the rate equation .\nwe calculate these frequencies with the current @xmath13 , and stochastically decide when and which event will occur next .    in this case , by an appropriate conversion of @xmath17 , @xmath12 , and @xmath37 , we can set @xmath28 and @xmath31 to be @xmath1 without loss of the generality ( @xmath38 and @xmath39 are the only independent parameters ) .\nwe assume that @xmath40 and @xmath41 for the purpose of further discussion .\nthe total number of molecules in the container , @xmath42 , is approximately @xmath43 on an average . by varying @xmath12\n, we can control the average number of molecules without changing the continuum limit .\nfirst , we consider the case of a large @xmath12 , i.e. , both the number of molecules in the container and flow of molecules between the container and the reservoir are large .\nas expected , the behavior of the system is similar to that of the rate equation with noise . as shown in fig .\n[ fig : a-512 ] , each @xmath13 fluctuates and vibrates around the fixed point value @xmath44 ( i.e. @xmath45 ) .\nthis is still in the realm of stochastic differential equations .\nhowever , when @xmath12 is small , we observe novel states that do not exist in the continuum limit . as shown in fig .\n[ fig : a-032 ] , continuous vibrations disappear .\nfurthermore , two chemicals are dominant and the other two are mostly extinct ( @xmath46 ) . in fig .\n[ fig : a-032 ] , at @xmath47 , @xmath48 and @xmath49 dominate the system and @xmath50 for the most part .\nwe call such a state the 1 - 3 rich state .\nreversely , at @xmath51 , @xmath52 and @xmath53 are large and usually @xmath54 .\nwe call this state the 2 - 4 rich state .\nthese states appear because of the following reason . in this system\n, the production of @xmath8 molecules requires at least one @xmath8 molecule as a catalyst . if @xmath8 becomes extinct , the production of @xmath8 halts .\n@xmath13 never regains before an @xmath8 molecule flows in .    in the rate equation ( eq .\n( [ eqn : tr1-rate ] ) ) , the concentration @xmath19 is a continuous variable , which can be an infinitesimal but positive value .\nthe consumption rate of @xmath19 is proportional to @xmath19 itself ; thus , @xmath19 can not reach @xmath0 exactly within finite time , even if it can go to @xmath0 asymptotically as @xmath55 .\nin fact , the number of molecules must be an integer .\ntransitions from @xmath56 to @xmath46 are probabilistic and may happen in finite time . for transitions to occur\n, it is important that the consumption rate of @xmath19 does not converge to @xmath0 at @xmath57 .\nthe average interval of a molecule flowing in is @xmath58 for each chemical .\nif @xmath17 and @xmath12 are small enough to ensure that the inflow interval is longer than the time scale of the reactions , it is likely that the state of the system @xmath56 drops to @xmath46 before an @xmath8 molecule enters .    when @xmath13 reaches @xmath0 , @xmath59 is also likely to become @xmath0 .\nfor example , if we assume that @xmath60 , then @xmath48 is likely to increase because the consumption of @xmath61 halts ; @xmath49 is likely to decrease because the production of @xmath62 halts .\nthus , this results in @xmath63 . when @xmath63 , the consumption rate of @xmath64 is larger than the production rate of @xmath64 ; therefore , @xmath53 starts to decrease and often reaches @xmath0 .\nwhen @xmath50 , all the reactions stop .\nthe system stays at @xmath50 for a long time as compared with the ordinary time scale of the reactions ( @xmath65 ) .\nthis is the 1 - 3 rich state .    in the 1 - 3 rich state\n, the system alternately switches between @xmath63 and @xmath66 .\nwe consider that the system is in the 1 - 3 rich state with @xmath63 .\none @xmath67 molecule flowing in may resume the reactions @xmath68 and @xmath69 .\ngenerally , the former is faster because @xmath63 ; hence , @xmath52 is likely to increase . since @xmath53 = 0 , the reactions are one - way ; @xmath48 decreases and @xmath49 increases . when @xmath66 , @xmath52 starts to decrease .\nfinally , when @xmath52 returns to @xmath0 , the reactions halt again .\nthe system stays in the 1 - 3 rich state , until @xmath48 reaches @xmath0 . in the same manner ,\nthe inflow of @xmath64 can switch the system from @xmath66 to @xmath63 in the 1 - 3 rich state .\nconsequently , we observe successive switching between @xmath63 and @xmath66 . in the 2 - 4 rich state ,\nthe system switches between @xmath70 and @xmath71 .    in this manner\n, even one molecule can switch the system within the 1 - 3 or 2 - 4 rich states .\nwe name these states `` switching states '' .\nnow , we investigate some properties of the switching states .\nwe introduce an index @xmath72 as a characteristic of the switching states . around the fixed point of the rate equation , @xmath73 ; in the 1 - 3 rich state , @xmath74 ; in the 2 - 4 rich state , @xmath75 .    the distribution of @xmath76 is shown in fig .\n[ fig : a - ac - bd ] . when @xmath77 , a single peak appears around @xmath78 , which corresponds to the fixed point . by decreasing @xmath12 ,\nthe peak broadens with fluctuations .\nwhen @xmath79 , double peaks appear at @xmath80 , which correspond to the switching states .\nwe clearly observe a symmetry - breaking transition between a continuous vibration around the fixed point with large @xmath12 and the switching states with small @xmath12 .\nthis is a discreteness - induced transition ( dit ) that occurs with decrease of @xmath12 , which is not seen in continuum descriptions .\nwe introduce another index @xmath81 , which represents the difference in concentrations : @xmath82 in the 1 - 3 rich state and @xmath83 in the 2 - 4 rich state . the distribution of @xmath84 is shown in fig .\n[ fig : a - ab - cd ] .\nthere are double peaks around @xmath85 , which imply large imbalances , such as @xmath86 and @xmath87 , between @xmath48 and @xmath49 in the 1 - 3 rich state ( as well as the 2 - 4 rich state ) .\nwe investigate some properties of the switching states .\nfirst , we examine how each @xmath13 changes in a switching event .\nwe assume the 1 - 3 rich state with @xmath88 , @xmath89 , and @xmath90 . here , one @xmath67 molecule flows in ( @xmath91 ) at @xmath92 , which starts up the reactions . assuming that @xmath93 is so small that no more molecules flow in or out throughout the switching , the total number of molecules @xmath94 is conserved at @xmath95 , and @xmath53 is always @xmath0 .\nwe can represent the state with two variables , @xmath48 and @xmath52 .    in this system ,\nonly the following types of reactions    * @xmath96 and * @xmath97    may change @xmath13 ; the others never take place . @xmath48\nmonotonously decreases . when @xmath52 reaches @xmath0 , these reactions halt completely , and the switching is completed . evidently , @xmath98 , where @xmath99 and @xmath100 are the final values of @xmath48 and @xmath49 , respectively .\nthe frequency of the reaction @xmath96 is @xmath101 and that of @xmath97 is @xmath102 we obtain the master equation @xmath103 for @xmath104 , the probability of residence in the state @xmath105 at time @xmath37 .\nthe initial condition is @xmath106 ; otherwise @xmath107 .\nwe can easily follow the master equation numerically .\nwe investigate the relationship between the initial state @xmath108 and the final state @xmath109 .    if the first reaction is @xmath97 , @xmath52 instantaneously reaches @xmath0 , and as a result @xmath110 . the system fails to switch .\nif @xmath111 , it is more probable that the first reaction is @xmath96 .\nsubsequently , the system carries out further reactions . in this case , it is probable that @xmath112 , i.e. , the system swaps @xmath48 and @xmath49 , as shown in fig .\n[ fig : a - swprob-128 ] .\nconsequently , we observe successive switching ( as seen in fig .\n[ fig : a-032 ] ) .    when @xmath113 , the system is likely to reach @xmath114 and break the 1 - 3 rich state . a large imbalance between @xmath48 and @xmath49 results in an unstable 1 - 3 rich state .\nnow , we investigate the requirements for the transitions to the switching states . the rate of residence of the switching states for several @xmath17 and @xmath12 is shown in fig .\n[ fig : a - type1a ] . for approximately @xmath115\n, we observe the switching states .\nif @xmath116 , the system mostly stays in the switching states .\nsubsequently , we expect that switching states appear even for large @xmath12 if @xmath17 is very small .\nin fact , we observe switching states for @xmath117 as shown in fig .\n[ fig : a-10000 ] .\nfurthermore , in this case also , a single molecule can induce switching .    strictly speaking ,\nif @xmath93 is the same , the rate of residence is a little smaller for larger @xmath12 .\nif @xmath12 is large , the system takes longer to reach @xmath46 even if the rate of reaction and the initial concentrations are the same .\nthus , it is less likely to exhibit switching states for the same interval of the inflow , @xmath58 .    in general , some reactions are much faster than the inflow .\nif the number of molecules which enter within the time scale of the reactions is of the order of @xmath1 for a certain chemical , the reactions may consume all the molecules of the chemical , and the molecular discreteness of the chemical becomes significant .\nin other words , for the effect of the discreteness to appear in a system with several processes , it is important that the number of events of a process within the time scale of another process is of the order of @xmath1 .\nonce the system is in the switching state , it is fairly stable and difficult to escape , especially if @xmath93 is small . to escape the 1 - 3 rich state and regain continuous vibration , at least one @xmath67 molecule and one @xmath64 molecule should flow in and\nit is required that after an @xmath67 molecule flows in , an @xmath64 molecule should flow in before @xmath52 returns to @xmath0 , or vice versa .\nwe put one @xmath67 molecule into the system in the 1 - 3 rich state at @xmath92 , and one @xmath64 molecule in at @xmath118 .\nwe assume that @xmath93 is so small that no more molecules flow in or out .\nthen , we judge whether the system escapes from the 1 - 3 rich state .\nin due course , the system returns to the 1 - 3 rich ( or sometimes 2 - 4 rich ) state because there is no further flow ; thus , we should judge at the right moment . here ,\nif @xmath119 for all @xmath27 at @xmath120 ( i.e. , waiting about 2.5 times longer than the period of the oscillation around the fixed point ) , we consider that the 1 - 3 rich state has been interrupted .\nwe measure the probability of interruption for various initial conditions and the delay @xmath121 as shown in fig . [\nfig : a - sw3b-32 ] .\nthe system requires adequate timing of inflow to escape the switching states , which may amplify the imbalance between the stability of each state .\nfor example , to escape the 1 - 3 rich , @xmath63 state , it is required that an @xmath67 molecule flows in , and then an @xmath64 molecule flows in with a certain delay @xmath121 , as shown in fig .\n[ fig : a - sw3b-32 ] .\nthus , the frequency of escape from the 1 - 3 rich state is approximately proportional to the product of the inflow frequencies of @xmath67 and @xmath64 .\nif each @xmath15 or @xmath14 is species - dependent , the stability of the 1 - 3 and 2 - 4 rich states may strongly depend on @xmath122 , the inflow frequency of @xmath8 .\nfurthermore , if at the outset @xmath123 , it is difficult for the system to escape from the 1 - 3 rich state . in some cases where the parameters are species - dependent , the flows or the switching may lead to @xmath123 , which stabilizes the 1 - 3 rich state .\nthese conditions are important to stabilize particular states and affect the macroscopic behavior of the system ( see section [ sect : tr2 ] ) .\nto close the section [ sect : tr1 ] , we briefly discuss the cases where @xmath124 .\nfigure [ fig : a - k356 - 16 ] shows the time series of each @xmath13 for @xmath125 , @xmath126 , and @xmath127 . when @xmath128 , 1 - 3 - 5 rich and 2 - 4 - 6 rich states appear .\nhowever , these states are less stable than the 1 - 3 and 2 - 4 rich states for @xmath33 .\nthese states collapse when any of the rich chemicals vanish ; thus , they are unstable for large @xmath7 .\nwhen @xmath7 is odd ( @xmath129 , @xmath126 , @xmath3 ) , there are no stable states where particular chemicals are extinct . however , additional reactions , or a variety of @xmath21 or @xmath14 , may stabilize or destabilize the states such that it is not always true that loops with odd-@xmath7 are unstable .\nthe discreteness - induced transitions are not limited in the autocatalytic loop .\nwe apply the abovementioned discussions to certain segments of a complicated reaction network with a slight modification .\nin the preceding section , we show that the discreteness of the molecules can induce transitions to novel `` switching '' states in autocatalytic systems .    for the case where @xmath33 with uniform parameters , the 1 - 3 rich state and the 2 - 4 rich state are equivalent . in due course , the system alternates between the 1 - 3 rich and 2 - 4 rich states .\nthe long - term averaged concentrations are still the same as the continuum limit value , @xmath130\n.    it will be important if macroscopic properties , such as the average concentrations , can be altered .\nwe show that the discreteness - induced transitions may alter the long - term averaged concentrations .\nonce again , here , we adopt the autocatalytic reaction loop @xmath9 for the @xmath33 species .\nnow we consider the case where the parameters @xmath15 , @xmath14 , or @xmath21 are species - dependent . in the continuum limit\n, the concentration @xmath19 is governed by the rate equation @xmath131 the rate equation does not contain the volume @xmath12 ; hence , the average concentrations should be independent of @xmath12 .    as discussed in the preceding section , for the transitions to the switching states to occur , it is necessary that the interval of the inflow is longer than the time scale of the reactions . in this model ,\nthe inflow interval of @xmath8 is @xmath132 , and the time scale of the reaction @xmath22 in order to use @xmath8 up is @xmath133 . if all the chemicals are equivalent , the discreteness of all the chemicals equally take effect , and the 1 - 3 and 2 - 4 rich states coordinately appear at @xmath134 .\nnow , since the parameters are species - dependent , the effect of discreteness may be different for each species .\nfor example , assuming that @xmath135 , the inflow interval of @xmath61 is longer than that of @xmath67 .\nthus , the discreteness of the inflow of @xmath61 may be significant for larger @xmath12 .    to demonstrate a possible effect of the discreteness on the macroscopic properties of the system\n, we measure each average concentration @xmath136 , sampled over a long enough time to allow transitions between the 1 - 3 and 2 - 4 rich states , by gillespie s direct method .\nnote that every @xmath136 does not depend on @xmath12 in the continuum limit .\ngenerally , in discrete simulations , the effect of the discreteness varies with @xmath12 and alters every @xmath136 .\nwhen @xmath12 is very large , the discreteness does not matter and @xmath136 is almost equal to the continuum limit value . in contrast ,\nwhen @xmath12 is small , the discreteness causes @xmath136 to be very different from the continuum limit .\nwe first investigate the case where each @xmath14 is species - dependent ( i.e. , each inflow rate is species - dependent ) , and each @xmath15 and @xmath21 are uniform ( @xmath25 , @xmath137 ) .\nlater , we briefly discuss the case where @xmath21 is inhomogeneous .\nas mentioned in section [ subsect : tr1-cond ] , for the effect of the discreteness to appear , it is important that the interval of events of a process is of the order of or longer than the time scale of another process . as regards the inflow ,\nthere are two indices to determine how the discreteness appears :    * the inflow interval , @xmath138 , * the number of molecules at equilibrium , @xmath139 .\nif the inflow interval , @xmath138 , is longer than the time scale of the reactions , the reactions may exhaust the chemical before the chemical enters , and the inflow discreteness becomes significant .\nfurthermore , if @xmath139 is smaller than @xmath1 , @xmath13 can reach @xmath0 because of the outflow .\nin such cases , the relation between the inflow interval and the outflow time scale is also important .\nthe approach time from @xmath140 to @xmath46 is of the order of @xmath141 .\nif the inflow interval of the chemical that causes the switching to raise @xmath13 is long enough to allow all @xmath8 molecules to flow out , the inflow discreteness may alter the stability of the states drastically .\nfrom this point of view , we classify the mechanism in cases i , i@xmath142 , and ii as follows .\nwe start with the simplest case , @xmath143 . in this case\n, the rate equation has a stable fixed point with @xmath144 .\nwhen @xmath12 is large , each @xmath19 fluctuates around the fixed point , and each average concentration @xmath136 is in accordance with the fixed point value .\nwhen @xmath12 is small , @xmath136 depends on @xmath12 .\n[ fig : tr2-average1 ] shows each @xmath136 as a function of @xmath12 . the difference between @xmath145 and @xmath146 increases for small @xmath12 .    by decreasing @xmath12 , first @xmath52 and @xmath53 reach @xmath0 and\nthe 1 - 3 rich state appears . to reach @xmath147 or @xmath148 , the inflow interval of @xmath67 or @xmath64\nshould be longer than the time scale of the reactions .\nwe set @xmath149 ; thus , the condition to achieve the 1 - 3 rich state is approximately @xmath150 , @xmath151 ; that for the 2 - 4 rich state is @xmath152 , @xmath153 .\nif @xmath12 satisfies @xmath152 , @xmath154 , @xmath155 , the 1 - 3 rich state appears but the 2 - 4 rich state does not .\nthus , @xmath145 and @xmath156 increase .\nwe actually observed this at @xmath157 , as shown in fig .\n[ fig : tr2-average1 ] .    for smaller @xmath12 that fulfills both the 1 - 3 and 2 - 4 rich states , the imbalance between the 1 - 3 and 2 - 4 rich states does not disappear\nonce the system is in the 1 - 3 rich state , adequate timing for the @xmath67 and @xmath64 inflow is required to escape the state .\nthus , the frequency of escape from the 1 - 3 rich state is approximately proportional to @xmath158 , the product of the inflow frequencies of @xmath67 and @xmath64 .\nthe average residence time in the 1 - 3 rich state as well as the 2 - 4 rich state is the reciprocal of the escape frequency .\nthe ratio of the average residence time in the 1 - 3 rich state to that in the 2 - 4 rich state is @xmath159 .\nin addition , after escaping the switching states , the system tends to reach the 1 - 3 rich state rather than the 2 - 4 rich state because of the biased inflow .\nthus , the ratio of the total residence time in the 1 - 3 rich state to that of the 2 - 4 rich state is larger than @xmath160 ; hence , @xmath145 , @xmath161 , @xmath162 , even for a small difference in @xmath14 .      in case\ni , we consider the imbalance between the @xmath61 , @xmath62 pair and the @xmath67 , @xmath64 pair .\nif another imbalance exists between the @xmath67 and @xmath64 inflows , the switching induced by these chemicals in the 1 - 3 rich state may be unbalanced .\nwe consider the case where @xmath163 .    in this case , the 1 - 3 rich state is more stable than the 2 - 4 rich state , which is identical to case i. in the 1 - 3 rich state , the system can be switched from @xmath63 to @xmath66 by an @xmath67 molecule ; and from @xmath66 to @xmath63 by an @xmath64 molecule .\nnow , the inflow rate of @xmath67 is larger than @xmath64 ; thus , switching from @xmath63 to @xmath66 is more probable than vice versa , and the system tends to stay in the @xmath66 state .\nconsequently , @xmath164 , as shown in fig .\n[ fig : tr2-average1 ] .\nthis effect requires switching states .\nwhen @xmath12 is large , @xmath145 and @xmath156 are almost the same .      here , we consider the case where @xmath165 . in this case\nalso , the rate equation has a stable fixed point , @xmath166 , @xmath167 and @xmath168 , @xmath169 . ] .\nwhen @xmath12 is small , both the 1 - 3 and the 2 - 4 rich states appear . here , we consider @xmath170 , the number of @xmath64 molecules when the concentration of @xmath64 in the container and in the reservoir are at equilibrium . if @xmath171 , @xmath53 reaches @xmath0 without undergoing any reaction .\nthe system takes @xmath172 time units to reach from @xmath173 to @xmath148 .\nthe reaction @xmath174 also uses @xmath64 such that @xmath53 decreases faster if @xmath175 is large .\nif @xmath176 , the inflow of @xmath62 may switch from @xmath70 to @xmath71 and raise @xmath53 again .\nthe inflow interval of @xmath62 is @xmath177 .\nif the interval is much shorter than the approach time to @xmath148 , the switching maintains @xmath176 .\nif the interval is longer , @xmath53 reaches @xmath0 before switching , and the 2 - 4 rich state is easily destroyed .\nin the 1 - 3 rich state , the system tends to maintain @xmath66 because the @xmath67 inflow is frequent .\nhowever , the @xmath61 inflow is also large enough to maintain @xmath178 .\nthe 1 - 3 rich state retains its stability .    in conclusion ,\nthe 1 - 3 rich state is more stable than the 2 - 4 rich state . in the 1 - 3 rich state ,\n@xmath66 is preferred , and @xmath156 increases . at this stage , it is possible that @xmath179 despite the fact that @xmath180 , as shown in fig .\n[ fig : tr2-average2 ] .      in summary ,\nthe difference in the `` extent of discreteness '' between chemical species induces novel transitions .\nthe `` extent of discreteness '' depends on @xmath12 ; thus , we observe transitions by changing @xmath12 .\nthe transition reported in section [ sect : tr1 ] is regarded as a _\nsecond order _ transition involving symmetry breaking ( see figs . [\nfig : a - ac - bd ] and [ fig : a - ab - cd ] ) , while the transition in this section corresponds to the _ first order _ transition without symmetry breaking ( see fig .\n[ fig : tr2-dist - ab - cd - casei ] ) in terms of thermodynamics .\nwe classified the mechanism in cases i , i@xmath142 , and ii .\nthese mechanisms can be combined .\nfor example , we demonstrate the case where @xmath181 , @xmath182 , and @xmath183 . in this case\n, each @xmath136 shows a three - step change with @xmath12 , as shown in fig .\n[ fig : tr2-average3 ] .    when @xmath12 is large , @xmath145 , @xmath184 , @xmath162 , since @xmath185 . at @xmath186 ,\nthe discreteness of the @xmath62 inflow becomes significant , and the 2 - 4 rich state appears . in the 2 - 4 rich state ,\nthe system tends to remain at @xmath70 because of the inflow imbalance between @xmath61 and @xmath62 , as observed in case i@xmath142 .\nfigure [ fig : tr2-dist - x2 ] shows the distribution of @xmath168 .\nthe major peak corresponds to the 2 - 4 rich , @xmath187 state for the cases when @xmath188 .    on the other hand , in the 2 - 4 rich state\n, the outflow of @xmath64 depresses @xmath53 toward @xmath170 , as observed in fig .\n[ fig : tr2-ts - amp ] . by decreasing @xmath12 ,\nthe imbalance between @xmath52 and @xmath53 increases because the rate of switching , which again raises @xmath53 , decreases in proportion to @xmath12 . finally , at @xmath189 , the 2 - 4 rich state loses stability , as seen in case ii .\nnow , the 1 - 3 rich state is preferred despite the fact that @xmath185 .\n@xmath156 increases to @xmath190 , which is more than @xmath191 times as large as that in the continuum limit .    for extremely small @xmath12 ,\nthe 1 - 3 rich state is also unstable because @xmath48 and @xmath49 easily reach @xmath0 .\nin such a situation , typically only one chemical species is in the container .\nthe system is dominated by diffusion , and @xmath146 increases again due to the large @xmath192 .\nnote that the chemical that becomes extinct depends not only on the flows but also on the reactions . in some cases , we observe smaller @xmath156 for larger @xmath193 .\nit is possible that each @xmath21 varies with the species . in such cases\n, we can discuss the effect of discreteness in a similar way .\nhowever , the change of @xmath136 with @xmath12 is different from the case with asymmetric flows .\nfor example , we assume that @xmath194 and @xmath195 . in the continuum limit or in the case of large @xmath12 , @xmath196 , as shown in fig .\n[ fig : tr2-average - r ] .\nin contrast , when @xmath12 is small , @xmath197 .\nif @xmath12 is very small , such that the total number of molecules is mostly @xmath0 or @xmath1 , reactions rarely take place .\nthe flow of chemicals dominate the system ; thus , @xmath198 .\nif both the reactions and the flows are species - dependent , we simply expect the behavior to be a combination of the abovementioned cases .\neven this simple system can exhibit a multi - step change in concentrations along with a change in @xmath12 .\nit is not limited to the simple reaction loop .\nin fact , we observe this kind of change in concentrations with a change in the system size in randomly connected reaction networks . for\na large reaction network with multiple time scales of reactions and flows , the discreteness effect may exhibit behavior that is more complicated . our discussion is largely applicable to such cases if we can define the time scales appropriately .\nas seen in this paper , the discreteness of molecules can alter the average concentrations . when the rates of inflow and/or the reaction are species - dependent , transitions between the discreteness - induced states are imbalanced .\nthis may alter the average concentrations drastically from those of the continuum limit case .\nwe demonstrated that molecular discreteness may induce transitions to novel states in autocatalytic systems , and that may result in an alteration of the macroscopic properties such as the average chemical concentrations .    in biochemical pathways , it is not anomalous that the number of molecules of a chemical is of the order of @xmath199 or less in a cell .\nthere are thousands of protein species , and the total number of protein molecules in a cell is not very large . for example , in signal transduction pathways , some chemicals work at less than @xmath200 molecules per cell .\nthere exist only one or a few copies of genetic molecules such as dna ; furthermore , mrnas and trnas are not present in large numbers .\nthus , regulation mechanisms involving genes are quite stochastic .\nmolecular discreteness naturally concerns such rare chemicals .\none of the authors , kaneko , and yomo recently provided the `` minority control conjecture , '' which propounds that chemical species with a small number of molecules governs the behavior of a replicating system , which is related to the origin of heredity @xcite .\nmatsuura et al . experimentally demonstrated that a small number of genetic molecules is essential for evolution @xcite .\nmolecular discreteness should be significant for such chemicals , and may be relevant to characters of genetic molecules .\nuntil now , we have modeled reactions in a well - stirred medium , where only the number of molecules is taken into account while determining the behavior . however ,\nif the system is not mixed well , we should take into account the diffusion in space .\nboth the total number of molecules and the spatial distributions of the molecules may be significant . from a biological point of view\n, the diffusion in space is also important because the diffusion in cells is not always fast as compared with the time scales of the reactions .\nif the reactions are faster than the mixing , we should consider the system as a reaction - diffusion one , with discrete molecules diffusing in space .\nthe relation between these time scales will be important , as indicated by mikhailov and hess @xcite .\nas regards these time scales , we recently found that the spatial discreteness of molecules within the so - called kuramoto length @xcite , over which a molecule diffuses in its lifetime ( lapses before it undergoes reaction ) , may yield novel steady states that are not observed in the reaction - diffusion equations @xcite .\nthere is still room for exploration in this field , e.g. , pattern formation .\nour result does not depend on the details of the reaction and may be applicable to systems beyond reactions , such as ecosystems or economic systems .\nthe inflow of chemicals in a reaction system can be seen as a model of intrusion or evolution in an ecosystem ; both systems with discrete agents ( molecules or individuals ) , which may become extinct . in this regard , our result is relevant to studies of ecosystems , e.g. , extinction dynamics with a replicator model by tokita and yasutomi @xcite\n. the discreteness of agents or operations might also be relevant to some economic models , e.g. , artificial markets .\nmost mathematical methods that are applied to reaction systems can not account for the discreteness .\nalthough the utility of simulations have become convenient with the progress of computer technology , it might be useful if we could construct a theoretical formulation applicable to discrete reaction systems .\non the other hand , in recent years , major advances have been made in the detection of a small number of molecules and fabrication of small reactors , which raises our hopes to demonstrate the effect of discreteness experimentally .\nwe believe that molecular discreteness is of hidden but real importance with respect to biological mechanisms , such as pattern formation , regulation of biochemical pathways , or evolution , to be pursued in the future .\nthis research is supported by grant - in - aid for scientific research from the ministry of education , culture , sports , science and technology of japan ( 11ce2006 , 15 - 11161 ) .\nis supported by a research fellowship from the japan society for the promotion of science .\nsince the 1970s , several methods have been suggested for simulating discrete reaction systems .\nwe briefly review some of these methods : stochsim method , gillespie s methods , and their improved versions .\nthese methods are based on chemical master equations . in chemical master equations ,\nwe define the state of the system as the number of molecules in each chemical ; the reaction process as a series of transitions between the states .\nwe consider each event , i.e. , a reaction event between molecules , inflow or outflow of a molecule , as a transition .\nthey take place stochastically with a certain frequency ( probability per time unit ) determined by the current state .    for the simulations used in this study , we adopted gillespie s direct method for simplicity .\nwe also attempted a direct simulation and the next reaction method , and confirmed that our result does not depend on the simulation method .        in this method , we fix the time step as @xmath201 . assuming that the frequency of the event-@xmath27 is @xmath202 , the average number of the event-@xmath27 for each step is @xmath203 . if @xmath204 , we approximately assume that at most one event occurs at each step , and the probability of the event-@xmath27 is @xmath203 ( it is possible that no event occurs in the step ) .\nwe select an event with a random number , change the state according to the event , and recalculate each @xmath202 .\nthe stochsim method adopts random sampling of molecules . for bimolecular reactions , we randomly choose two molecules from the system , and decide whether they react or not with certain probability .\nthe method requires three random numbers in total for each step . in case\nthere are some single molecular ( first - order ) reactions , we choose the second molecule from the molecules in the system and some pseudo - molecules ( dummies ) .\nif the second molecule is a pseudo - molecule , then we select the single molecular reaction of the first molecule , and determine whether it occurs .    in the stochsim method , @xmath201 is restricted by the fastest reaction ( with the largest reaction rate per pair of molecules ) .\nif most of the bimolecular pairs do not react with each other , or the reaction probability varies with the species , this method may be impractical because no reaction occurs in most steps\n.      incidentally , if the system consists of discrete molecules , it is typical that each frequency @xmath202 changes only when an event actually occurs . taking this into account ,\ngillespie suggested two exact simulation methods : the direct method @xcite and the first reaction method @xcite . in these methods , we do not fix the time step .\ninstead , we calculate the time lapse until the next event .    in the direct method , first , we consider the total frequency of the events , @xmath205 .\nif @xmath202 does not change until the next event , the time lapse until the next event , @xmath121 , is exponentially distributed as @xmath206 ( @xmath207 ) .\nwe determine the time lapse @xmath121 with an exponentially distributed random number .\nsubsequently , the probability that the next event is @xmath27 is @xmath208 .\nwe determine which event occurs with a random number .\nwe then set the time @xmath37 forward by @xmath121 , update the state according to the event , and recalculate each frequency @xmath202 .\niterate the above steps until the designated time elapses .\nthe first reaction method is similar to the direct method .\nit is based on the fact that @xmath209 , the time lapse until the next event-@xmath27 , is exponentially distributed as @xmath210 ( @xmath211 ) .\nonly the event with minimum @xmath209 actually occurs .\nwe update the state , recalculate each @xmath202 , and generate all @xmath209 again with the new corresponding @xmath202 .    in the first reaction method\n, we need as many random numbers each step as the types of events .\nwe calculate all @xmath209 , choose the earliest , and discard the others .\ngenerally , the processor time to generate random numbers is very large ; hence , a large amount of time is wasted for several types of events .      to solve this performance problem ,\ngibson and bruck proposed a refinement of the first reaction method : next reaction method @xcite .\nalthough , in general , monte carlo simulations require independency of random numbers , they proved a safe way of recycling random numbers , which drastically promotes efficiency .    in the next reaction method , we store @xmath212 , the absolute time when the next event-@xmath27 occurs , instead of @xmath209\nin the first step , we have to calculate @xmath213 for every @xmath27 , according to the exponential distribution @xmath210 ( @xmath211 ) .\nwe choose the event with the smallest @xmath212 . according to the event\n, we set the time @xmath37 forward to @xmath212 , change the state , and recalculate each @xmath202 .      1 .\nas regards the event just executed , we should recalculate @xmath214 with the exponential distribution of @xmath209 , identical to the first step .\nas regards other events whose frequency @xmath202 has changed , we should recalculate the corresponding @xmath212 .\nfor such events , we convert @xmath212 as @xmath215 @xmath216 is the @xmath212 before the event and @xmath217 is that after the event .\n+ with this conversion , the actual frequency is adjusted from @xmath218 to @xmath219 , without using random numbers .\n3 .   as for other events\nwhose frequency @xmath202 has not changed , we do not need to recalculate the corresponding @xmath212 .\nif the event executed does not influence @xmath202 , we do not need to recalculate the concerned @xmath202 and @xmath212 ( except for those of the event just executed ) .\nthus , it is useful to manage the dependency of @xmath202 on each event . with this intention\n, we prepare a dependency graph that shows which @xmath202 should be updated after event-@xmath220 ( event-@xmath27 depends on event-@xmath220 ) . in a large reaction network , such as biochemical pathways , one chemical species can react with only a small part of the chemicals in the entire system . in such cases ,\nrecalculation is not required for irrelevant chemical species ; hence , we can accelerate simulations with help of a dependency check .\nit is also important to find the smallest @xmath212 quickly . for this purpose\n, we use a heap , a binary tree in which each node is larger than or equal to its parent .\nthe root is the smallest at any instance ) sorting algorithm .\nif only one @xmath212 has changed in the step , the cost of resorting is o(@xmath221 ) . ] .\nx. wang , g. z. feuerstein , j. gu , p. g. lysko , and t. yue , `` interleukin-1@xmath222 induces expression of adhesion molecules in human vascular smooth muscle cells and enhances adhesion of leukocytes to smooth muscle cells '' , atherosclerosis * 115 * , 89 ( 1995 ) .                                                               for @xmath228 and @xmath227 .\nin this stage , @xmath13 can reach @xmath0 , and the switching states appear . in the 1 - 3 rich state ,\nthe system successively switches between the @xmath63 and @xmath66 states .\nthe interval of switching is much longer than the period of continuous vibration ( @xmath229 ) observed in figs .\n[ fig : a - cont ] and [ fig : a-512 ] . around @xmath230 ,\na transition occurs from the 1 - 3 rich to the 2 - 4 rich state.,width=260 ]    , sampled over @xmath231 time units .\n( @xmath76 is actually a discrete value . here\n, we show the distribution as a line graph for visibility . )\nwhen @xmath12 is large ( @xmath233 ) , there appears a single peak around @xmath78 , corresponding to the fixed point state @xmath225 . for @xmath234 ,\nthe distribution has double peaks around @xmath235 .\nthe peak @xmath74 corresponds to the 1 - 3 rich state , with @xmath236 , @xmath90 .\n@xmath75 corresponds to the 2 - 4 rich state as well.,width=260 ]    , sampled over @xmath231 time units .\nwhen @xmath12 is large , there appears a single peak around @xmath237 , corresponding to the fixed point .\nwhen @xmath12 is small and the system is in the switching states , the index @xmath84 shows an imbalance between the rich ( non - zero ) chemicals . for example , in the 1 - 3 rich state , @xmath84 corresponds to @xmath238 since @xmath90 for the most part .\nthe distribution shows double peaks around @xmath239 . assuming that @xmath240 and @xmath241 in the 1 - 3 rich state , @xmath239 correspond to @xmath242 , @xmath243 .\nboth the chemicals are likely to have a large imbalance.,width=260 ]     to @xmath109 .\nwe assume a switching event triggered by a single @xmath67 molecule in the 1 - 3 rich state , and we set the initial conditions as @xmath244 and @xmath245 . assuming that there is no further flow ( @xmath246 )\n, we numerically follow the master equation ( eq .\n( [ eqn : tr1-master ] ) ) until @xmath247 ( sufficiently large to ensure @xmath147 for most cases ) . for each initial condition\n, we show the transition probabilities of the final states @xmath109 .\n@xmath228 , @xmath248 .\nthe system shows high probabilities around @xmath249 ( immediately terminated ) and @xmath250 ( switching ; @xmath111).,width=260 ]    , i.e. , reactions have already stalled , as a function of @xmath37 ( in other words , the cumulative distribution of the time when @xmath52 reaches @xmath0 ) .\n@xmath228 , @xmath251 . in the case where @xmath252 or @xmath253 , the probability increases just after the reactions start . for such initial conditions ,\nthe reactions terminate near the initial state , as shown in fig .\n[ fig : a - swprob-128 ] .\nif @xmath113 , the probability steeply increases at @xmath254 , which corresponds to the switching .\nthe system takes @xmath255 time units to complete the switching.,width=260 ]    , the inflow frequency , sampled over @xmath256 ( @xmath257 ) , @xmath258 ( @xmath259 ) , and @xmath260 ( @xmath261 ) time units .\nhere , we define the 1 - 3 rich state as continuation of the state in which at least one of @xmath52 or @xmath53 is @xmath0 for @xmath262 time units or longer .\nthus , the system may contain states with only one or no chemical , especially for small @xmath12 .\nwe observe the switching states for @xmath263.,width=260 ]     for @xmath117 and @xmath264 .\nfor such a small @xmath17 , we observe the switching states for relatively large @xmath12 . in this case\nalso , a single molecule can induce switching .\none @xmath61 molecule flows in ( @xmath265 ) , propagates to more than @xmath266 , and then returns to @xmath0.,width=260 ]    , sampled over @xmath267 times for each condition .\nwe assume the system where @xmath90 .\nwe inject an @xmath67 molecule at @xmath92 , then an @xmath64 molecule at @xmath118 ( no further flow ) .\nif @xmath268 at @xmath120 , we ascertain that the system has escaped from the 1 - 3 rich state .\n@xmath228 , @xmath269 .\nan initial large imbalance , such as @xmath270 ( @xmath271 ) , makes it easier to escape the 1 - 3 rich state .\nthe system is unlikely to escape from the state when @xmath272 or @xmath252 .\nthe probability is maximum at @xmath273 , which approximately corresponds to a half of the period of the vibration around the fixed point.,width=260 ]     for @xmath125 , @xmath126 , @xmath127 , with @xmath274 and @xmath227 . for the case where @xmath128 , the transition occurs from the 1 - 3 - 5 rich state to the 2 - 4 - 6 rich state at @xmath275 . for the cases where @xmath125 and @xmath276 , there are no stable states such as the 1 - 3 rich state when @xmath33 or 1 - 3 - 5 rich state when @xmath128.,title=\"fig:\",width=260 ]   for @xmath125 , @xmath126 , @xmath127 , with @xmath274 and @xmath227 . for the case where @xmath128 , the transition occurs from the 1 - 3 - 5 rich state to the 2 - 4 - 6 rich state at @xmath275 . for the cases where @xmath125 and @xmath276 , there are no stable states such as the 1 - 3 rich state when @xmath33 or 1 - 3 - 5 rich state when @xmath128.,title=\"fig:\",width=260 ]   for @xmath125 , @xmath126 , @xmath127 , with @xmath274 and @xmath227 . for the case where @xmath128 , the transition occurs from the 1 - 3 - 5 rich state to the 2 - 4 - 6 rich state at @xmath275 . for the cases where @xmath125 and @xmath276 , there are no stable states such as the 1 - 3 rich state when @xmath33 or 1 - 3 - 5 rich state when @xmath128.,title=\"fig:\",width=260 ]     as a function of @xmath12 , sampled over @xmath256 ( @xmath257 ) , @xmath258 ( @xmath259 ) , and @xmath260 ( @xmath261 ) time units ( same for fig .\n[ fig : tr2-average2 ] ) . @xmath40 and @xmath232 .\n( a ) case i : @xmath277 , @xmath278 . when @xmath12 is small , the 1 - 3 rich state appears , and the difference between @xmath145 and @xmath146 increases .\n( b ) case i@xmath142 : @xmath279 , @xmath280 , @xmath281 .\nwhen @xmath12 is small , @xmath146 and @xmath162 decrease , identical to case i. in this case , the imbalance between @xmath145 and @xmath156 appears at the same time .\n( figures [ fig : tr2-average1 ] , [ fig : tr2-average2 ] , [ fig : tr2-average3 ] , and [ fig : tr2-dist - x2 ] are reproduced from ref .\n@xcite by permission of the publisher . ) , title=\"fig:\",width=260 ]   as a function of @xmath12 , sampled over @xmath256 ( @xmath257 ) , @xmath258 ( @xmath259 ) , and @xmath260 ( @xmath261 ) time units ( same for fig .\n[ fig : tr2-average2 ] ) . @xmath40 and @xmath232 .\n( a ) case i : @xmath277 , @xmath278 .\nwhen @xmath12 is small , the 1 - 3 rich state appears , and the difference between @xmath145 and @xmath146 increases .\n( b ) case i@xmath142 : @xmath279 , @xmath280 , @xmath281 .\nwhen @xmath12 is small , @xmath146 and @xmath162 decrease , identical to case i. in this case , the imbalance between @xmath145 and @xmath156 appears at the same time .\n( figures [ fig : tr2-average1 ] , [ fig : tr2-average2 ] , [ fig : tr2-average3 ] , and [ fig : tr2-dist - x2 ] are reproduced from ref .\n@xcite by permission of the publisher . ) , title=\"fig:\",width=260 ]    , for case i@xmath142 : @xmath279 , @xmath280 , @xmath281 , @xmath40 , and @xmath232 .\nthere is a peak around @xmath237 for large @xmath12 .\nthe difference in @xmath14 has a slight effect on @xmath136 .\nfor the case where @xmath282 , there appears another peak at @xmath283 , which corresponds to the 1 - 3 rich , @xmath284 state.,width=260 ]       for @xmath181 , @xmath182 , @xmath183 , @xmath40 , and @xmath286 , sampled over @xmath287 ( @xmath288 ) or @xmath289 ( @xmath79 ) time units . by decreasing @xmath12 ,\nfirst , the 2 - 4 rich state appears , as seen in case i. then , the 2 - 4 rich state becomes unstable and gives way to the 1 - 3 rich state , as seen in case ii .\nwhen @xmath12 is extremely small ( @xmath290 ) , the flow of molecules governs the system , and @xmath146 increases again.,width=260 ]     for @xmath181 , @xmath182 , @xmath183 , @xmath40 , and @xmath286 .\n( a ) @xmath291 .\nthe 2 - 4 rich state is dominant ( case i@xmath142 ) .\ninflow of @xmath62 molecules induces switching from @xmath70 to @xmath71 , which prevents @xmath53 from decreasing to @xmath0 .\n( b ) @xmath228 .\nnow , the @xmath62 inflow is rare , which allows @xmath53 to reach @xmath0 before the switching .\nthus , the 2 - 4 rich state is unstable ( case ii).,title=\"fig:\",width=260 ]   for @xmath181 , @xmath182 , @xmath183 , @xmath40 , and @xmath286 .\n( a ) @xmath291 .\nthe 2 - 4 rich state is dominant ( case i@xmath142 ) .\ninflow of @xmath62 molecules induces switching from @xmath70 to @xmath71 , which prevents @xmath53 from decreasing to @xmath0 .\n( b ) @xmath228 .\nnow , the @xmath62 inflow is rare , which allows @xmath53 to reach @xmath0 before the switching .\nthus , the 2 - 4 rich state is unstable ( case ii).,title=\"fig:\",width=260 ]     for @xmath181 , @xmath182 , @xmath183 , @xmath40 , and @xmath286 , sampled over @xmath287 . for large @xmath12\n, a single peak around @xmath292 appears , which corresponds to the fixed point in the continuum limit . at @xmath186 ,\ndouble peaks appear around @xmath293 and @xmath294 , which correspond to the 2 - 4 rich state . by decreasing @xmath12 , the two peaks spread apart . at @xmath189 ,\nthe skirt of the low - density ( left ) peak touches @xmath295 , implying that @xmath52 ( and @xmath53 ) is likely to reach @xmath0 , and thus , the 2 - 4 rich state loses stability .\na peak at @xmath295 steeply grows by decreasing @xmath12 further.,width=260 ]     for @xmath296 and @xmath232 with inequivalent reaction constants . for small @xmath12 ,\nthe flows of molecules dominate the system .\nthus , @xmath197 , which simply reflects @xmath297 ; this does not depend on how the continuum limit is imbalanced by the reactions .\n( a ) @xmath298 and @xmath299 .\n( b ) @xmath300 and @xmath301.,title=\"fig:\",width=260 ]   for @xmath296 and @xmath232 with inequivalent reaction constants . for small @xmath12 ,\nthe flows of molecules dominate the system .\nthus , @xmath197 , which simply reflects @xmath297 ; this does not depend on how the continuum limit is imbalanced by the reactions .\n( a ) @xmath298 and @xmath299 .\n( b ) @xmath300 and @xmath301.,title=\"fig:\",width=260 ]"}
{"lay_summary": " we report the discovery of 42 white dwarfs in the original _ kepler _ mission field , including nine new confirmed pulsating hydrogen - atmosphere white dwarfs ( zzceti stars ) . \n guided by the _ kepler_-int survey ( kis ) , we selected white dwarf candidates on the basis of their @xmath0 , @xmath1 , and @xmath2 photometric colours . \n we followed up these candidates with high - signal - to - noise optical spectroscopy from the 4.2-m william herschel telescope . using ground - based , time - series photometry \n , we put our sample of new spectroscopically characterized white dwarfs in the context of the empirical zzceti instability strip . prior to our search \n , only two pulsating white dwarfs had been observed by _ \n kepler_. ultimately , four of our new zzcetis were observed from space . \n these rich datasets are helping initiate a rapid advancement in the asteroseismic investigation of pulsating white dwarfs , which continues with the extended _ kepler _ mission , _ k2_.    [ firstpage ]    asteroseismology , surveys , stars : white dwarfs , oscillations ", "article": "white dwarfs are the end points of all low- to intermediate - mass stars , which are the majority of stars in the universe .\nthey are dense stellar remnants composed of electron degenerate cores surrounded by non - degenerate envelopes .\nthese evolved stars provide key insight into galactic star formation and evolution .    to use white dwarfs as tracers of galactic evolution , we must determine their basic physical parameters , such as effective temperatures ( @xmath3 ) , surface gravities ( @xmath4 ) and masses .\nmore than 80percent of white dwarfs have hydrogen - rich atmospheres , known as da white dwarfs @xcite .\nspectroscopy has been a successful tool in obtaining da atmospheric parameters , yet it only provides a view of the outermost layers of the white dwarf , and it is subject to systematic problems that require correction if the star is cooler than roughly @xmath5k and the surface is convective @xcite .\nasteroseismology , however , can probe deep into the interior of a white dwarf and provide information on its composition , rotation period , magnetic field strength , mass , temperature and luminosity , by matching the observed non - radial @xmath6-mode pulsations to theoretical models ( see reviews by @xcite ) .\nas white dwarfs cool , they pass through instability strips depending on their outermost envelope composition , which coincides with the onset of a partial ionization zone .\nthis zone efficiently drives pulsations , which cause periodic brightness variations of the white dwarf @xcite . the variable da white dwarfs ( davs ) , also known as zzceti stars , are the most commonly found and studied type of pulsating white dwarfs .\ntheir effective temperatures range between @xmath7k for a typical mass of m @xmath8 0.6@xmath9 , with pulsation periods ranging from @xmath10s @xcite .\nground - based studies of zzceti stars have been carried out for decades , but very few have been observed long enough to resolve more than six pulsation modes .\ncrucially , there are potentially nine free parameters in the asteroseismic modeling of pulsating white dwarfs @xcite , which has required holding fixed many parameters in order to constrain the internal properties of zzcetis .\nit is clear that fully constraining these free parameters and thus the internal white dwarf structure and evolution will require a larger sample of rich asteroseismic observations .\nconsiderable effort has been expended to obtain uninterrupted photometry from coordinated , multi - site , ground - based campaigns to study pulsating white dwarfs , especially through the whole earth telescope @xcite , which has been operating for more than two decades ( e.g. , @xcite ) . however , the _ kepler _ planet - hunting spacecraft offers a unique opportunity to obtain high - quality , space - based light curves of variable stars , white dwarfs included .\nunfortunately , few white dwarfs were known in the original _ kepler _ mission field , and only two pulsating white dwarfs were discovered within the first two years of the mission @xcite . in order to increase this sample , we began the search for all white dwarfs in the original field of the _ kepler _ mission , and more specifically any possible zzceti stars .\nwe created the _ kepler_-int survey ( kis , @xcite ) in order to select white dwarf candidates using colour - colour diagrams , and report on that search here .    in sections\n[ selection ] and [ spec ] , we describe the selection method of our white dwarfs and present their spectroscopic observations . in section [ astero ] , we focus on the nine new pulsating white dwarfs . we conclude in section [ conclusion ] .\nwe selected our white dwarf candidates using @xmath0 , @xmath1 and @xmath11 , @xmath12 colour - colour diagrams using data from the _ kepler_-int survey ( kis ) , shown in fig .\n[ fig : colours ] .\nkis is a deep optical survey using the wide field camera on the 2.5-m isaac newton telescope ( int ) , taken through four broadband filters ( @xmath13 ) and one narrowband filter ( h@xmath14 ) , covering more than 97percent of the original _ kepler _ field down to @xmath1520@xmath16 mag @xcite .\nall magnitudes for the kis survey are expressed in the vega system .\nwhite dwarfs have bluer colours than main - sequence stars , and most single da white dwarfs also have strong h@xmath14 absorption lines , leading to @xmath17 ( see bottom panel of fig .  [\nfig : colours ] ) .\nwe have integrated the atmospheric models of canonical - mass 0.6@xmath9  ( @xmath18  @xmath19 ) white dwarfs of @xcite with the various filter profiles to guide our colour cuts , similar to @xcite .\nour photometric selection recovered kic4552982 , the first zzceti star in the _ kepler _ field @xcite .\nwe narrowed our selection to a small region around kic4552982 and to candidates close to the empirical ( @xmath3 , @xmath20  @xmath6 ) instability strip projected into @xmath21 space .\nthis left more than 60 white dwarf candidates , 43 of which we were able to follow up spectroscopically ( table  [ phot - summary ] ) .\nwe were awarded a total of eight nights on the 4.2-m william herschel telescope ( wht ) in 2012 , 2013 , and 2014 , where we obtained intermediate resolution spectra of 43 of our candidates in order to confirm their identities as white dwarf stars and to characterize their atmospheric parameters , especially their effective temperatures and surface gravities .\nwe used the intermediate - dispersion spectrograph and imaging system ( isis ) , with the r600r and r600b gratings on the red and blue arms , respectively .\nthe slit widths were chosen close to the seeing of each night to maximize spectral resolution ( @xmath22 ) .\na full journal of observations is included in table  [ tab : specjour ] .\nthe blue arm was centred at 4351  and the red arm at 6562 .\nthe spectra covered a wavelength range from roughly @xmath23  in the blue ( see fig .  [ spec - fit ] ) , and roughly @xmath24  in the red\n. however , since the higher - order balmer lines contain the most information about the atmospheric parameters ( e.g. , @xcite ) , we only used the blue arm for our balmer profile fits ( section  [ sec : atmosparams ] ) .\n.journal of spectroscopic observations . [ cols=\"<,^,^,^,^ \" , ]      in addition to the confirmation of nine new zzceti stars , our ground - based photometry has put relatively strong limits on the lack of photometric variability in eight other white dwarfs with effective temperatures near the zzceti instability strip .\nthose limits are quoted as a 3@xmath25 threshold in table  [ astero - summary ] , and represented visually with a ft for each object in figure  [ fig : ftnewnov ] .\nseveral of these non - variable white dwarfs have atmospheric parameters that place them within the empirical zzceti instability strip given their uncertainties , most recently updated by @xcite .\nit has been assumed that all white dwarfs in this region can foster a partial ionization zone and thus pulsate  that the instability strip is pure  but this claim is still under review @xcite , although there is good agreement between the observed and theoretical zz ceti instability strip ( e.g. , @xcite ) .\nwe will not address that issue here , other than to say there are a number of reasons why these objects may appear not to pulsate .\nfirstly , it is possible the white dwarfs really do vary , but at lower amplitudes than our detection limits allow ( e.g. , @xcite ) .\nadditionally , it is possible that subtle issues in the flux calibration of our spectra have introduced unaccounted for systematic uncertainties in the derived atmospheric parameters , and the stars may have true temperatures outside the instability strip . given that the non - variable stars are more or less uniformly distributed in the ( @xmath3 , @xmath26 ) plane , it is likely that the low signal - to - noise of the time - averaged spectra is responsible for some interlopers , as demonstrated quantitatively by @xcite .\nthe most interesting white dwarf not observed to vary in our sample is the ultramassive j1926 + 3703 , which sits in the middle of the empirical instability strip . at @xmath27@xmath9\n, it would be the second - most - massive white dwarf known to pulsate , behind only gd518 @xcite .\nwhite dwarfs this massive likely have at least partially crystallized interiors .\nwe did not detect photometric variability in this relatively faint target ( @xmath28mag ) to a limit of roughly 6.9ppt , but it is quite possible that this white dwarf pulsates at lower amplitude .\nfor example , the two most massive known pulsating white dwarfs have low pulsations amplitudes , which rarely exceed 5ppt in a given night and are often far lower in amplitude @xcite .\nthe _ kepler _ mission would have given at least an order - of - magnitude improvement on these nov limits , were these targets observed from space .\nfor example , @xcite showed that j1909 + 4717 did not vary to at least an amplitude of 0.13ppt using just one month of _ kepler _ data in q4.1 .\nhowever , only the four known pulsating white dwarfs listed at the end of section  [ sec : confirmationnewzzcetis ] were observed before the spacecraft had a failure of its second reaction wheel .\nwe note that many white dwarfs with atmospheric parameters within the empirical instability strip remain unobserved , and we encourage additional follow - up to constrain pulsational variability in these white dwarfs . we especially encourage further monitoring of the ultramassive j1926 + 3703 .\nusing photometric colour selection from the kis survey and subsequent medium - resolution spectroscopy from isis on the wht , we have discovered and characterized 42 new white dwarfs in the original _ kepler _ mission field .\nfollow - up , high - speed photometry from ground - based telescopes confirmed that at least nine of these objects are zzceti stars .\nfour were subsequently observed from space using the _ kepler _ space telescope , and @xcite report on the first zzceti found in this project , kic11911480 .\nasteroseismic inferences from the extended datasets on the other three will be presented in a forthcoming publication .\nunfortunately , the failure of the second and critical reaction wheel that kept _ kepler _ precisely pointed towards its original mission field occurred within months of our discovery of many of these new zzceti stars , and our sparse ground - based discovery light curves are so far the only time - series photometry for most of the targets here . at the end of its roughly four years\npointed towards its original field , _ kepler _ observed a total of six pulsating white dwarfs .\nhowever , the two - reaction - wheel controlled _ k2 _ mission will cover a significantly larger footprint as it tours the ecliptic @xcite , and _\nk2 _ will likely observe more than a thousand white dwarfs , dozens of them pulsating .\nalready several important discoveries have come from these _ k2 _ observations of pulsating white dwarfs @xcite .\nthe colour selection methods honed in this work have ensured that dozens of pulsating white dwarfs have been or will be observed by _\nk2 _ for up to 80d at a time , using selection from a variety of multiwavelength photometric surveys .\nthe authors acknowledge fruitful conversations with a. gianninas during the preparation of this manuscript .\nthe research leading to these results has received funding from the european research council under the european union s seventh framework programme ( fp/2007 - 2013 ) / erc grant agreement n. 320964 ( wdtracer ) .\nsupport for this work was provided by nasa through hubble fellowship grant # hst - hf2 - 51357.001-a , awarded by the space telescope science institute , which is operated by the association of universities for research in astronomy , incorporated , under nasa contract nas5 - 26555 .\nd.s . acknowledges support from stfc through an advanced fellowship ( pp / d005914/1 ) as well as grant st / i001719/1 .\nk.j.b . acknowledges funding from the nsf under grants ast-0909107 and ast-1312983 , the norman hackerman advanced research program under grant 003658 - 0252 - 2009 , and the _ kepler _ cycle 4 guest observer program 11-kepler11 - 0050 .\nthis paper makes use of data collected at the isaac newton telescope and the william herschel telescope , both operated on the island of la palma , by the isaac newton group in the spanish observatorio del roque de los muchachos , as well as data taken at the mcdonald observatory of the university of texas at austin ."}
{"lay_summary": " we present a combined analysis of the low - mass initial mass function ( imf ) for seven star - forming regions . \n we first demonstrate that the ratios of stars to brown dwarfs are consistent with a single underlying imf . by assuming that the underlying imf is the same for all seven clusters and by combining the ratio of stars to brown dwarfs from each cluster we constrain the shape of the brown dwarf imf and find it to be consistent with a lognormal imf . \n this provides the strongest constraint yet that the substellar imf turns over ( @xmath0 , @xmath1 ) . ", "article": "speculations concerning the existence and frequency of brown dwarfs can be traced to before the introduction of the term @xcite . since then , wide - field surveys have uncovered hundreds of candidates in the field and revealed two new spectral types , the l and t dwarfs @xcite . yet the frequency of brown dwarfs compared to stars has remained a topic of confusion and debate . in a pioneering work ,\n@xcite attempted the first census of the substellar initial mass function ( imf ) based on results from the two micron all sky survey @xcite .\nthey presented evidence for a low - mass imf that was more shallow than a salpeter @xcite slope , suggesting that brown dwarfs were not a significant contributor to dark matter .\n@xcite used a bayesian approach to constrain the power - law slope below 0.08 @xmath2 to be in the range @xmath3 with a confidence level of 60% , where a salpeter slope is @xmath4 .\nthese results indicate that , although brown dwarfs do not contribute significantly to the mass of typical stellar populations , they might still be as abundant as stars @xcite .\nthe classical approach to deriving the mass function for stars and substellar objects is to take an observed luminosity function and apply a mass - luminosity relationship in order to derive the present - day mass function .\nthen , corrections , based on the theory of stellar evolution , permit one to estimate an _ initial _ mass function from the present - day mass function ( see e.g. @xcite for complete descriptions of this process ) .\nthe confounding variable in these analyses is the star formation history of the galactic disk , which is vital for substellar objects whose mass  luminosity relationship evolves with time .    a different approach is to use star clusters of known age as laboratories to measure the imf .\nopen clusters are in principle good candidates because of their richness .\nyet they suffer from the effects of dynamical evolution , mass segregation , and evaporation ( e.g. * ? ? ?\nyoung ( @xmath5 10 myr ) embedded clusters are attractive alternatives as they are compact and rich ( from hundreds to thousands of stars within 0.31 pc ) , and yet to emerge as unbound ob / t associations , and the low mass objects are 101000 times more luminous than their older open cluster counterparts ( 0.116 gyr ) because they shrink and cool as they age .\nindeed , embedded clusters have been the targets of aggressive photometric and spectroscopic surveys in an attempt to search for variations in the imf as a function of initial conditions .\n@xcite found that the ratio of high - mass ( 110 @xmath6 ) to low - mass ( 0.11 @xmath6 ) stars for an ensemble of young clusters within 1 kpc was consistent with ( 1 ) each other and ( 2 ) having been drawn from the field star imf .\nmore recent studies have pushed well into the substellar mass regime ( see @xcite for a recent review ) .\nthere have been some claims for variations in the brown dwarf imf between nearby star - forming regions .\n@xcite argued that the low - density taurus dark cloud had a dearth of brown dwarfs compared to the rich orion nebula cluster ( onc ) .\nhowever , this preliminary result has been updated as additional data have become available and as the statistics improved for both clusters @xcite .\nhere we use observations of seven nearby star clusters to constrain the combined brown dwarf imf . in section 2\n, we describe the data , illustrate that there is no strong evidence for variation in the substellar imf between the star - forming regions , and outline our approach to constrain the low - mass imf . in section 3 we present our results , and in section 4 we discuss our results in the context of previous work as well as theories of star ( and substellar object ) formation .\nwe have compiled the ratio of stars to brown dwarfs in nearby , well - studied young embedded clusters and the pleiades .\nthe regions included in this study are described briefly below , where the ratio of stars ( 0.081.0 @xmath2 ) to brown dwarfs ( 0.030.08 @xmath2 ) is calculated .\nfor all the regions , we consider the _ system _ imf , uncorrected for multiplicity within 200 au .\nthe sample is focused on embedded clusters , in which spectroscopy has been used to determine the age of the cluster , field star contamination has been taken into account , and an extinction - limited sample has been defined . furthermore , we have included the pleiades , because it is one of the best - studied open clusters and bacause its substellar imf has been estimated .\nthe break point at 0.08 @xmath2 has been adopted in accordance with the break point for the @xcite imf , similar to the characteristic mass in the @xcite single object imf .\nonly a few of the clusters adopted here have the imf derived in an extinction - limited sample reaching 0.02 @xmath2 and we have opted for 0.03 @xmath2 as a lower mass limit to obtain a larger sample of clusters .\n_ @xcite imaged a 4 deg@xmath7 region of taurus that focused on the denser filaments , to identify cluster candidates .\ncandidates were confirmed as cluster members , by use of follow - up intermediate - resolutionoptical spectroscopy , on the basis of their effective temperature , luminosity , and spectral features . in total ,\n112 objects were confirmed members with derived masses between 0.03 and 1.0 @xmath2 and extinctions a@xmath8 mag .\nsome 96 objects were stars and 16 were brown dwarfs .\nthus , the ratio of stars to brown dwarfs in taurus was found to be @xmath9 where the errors are estimated using the method of @xcite .\n_ @xcite imaged a 42@xmath1028  region of the ic 348 cluster to identify cluster candidates . by the use of intermediate - resolution spectroscopy ,\nmost of the candidates were confirmed as cluster members , on the basis of their effective temperature , luminosity , and spectral features , which indicated that the objects were young . in total , @xcite found 168 cluster members with masses between 0.03 and 1.0 @xmath2 and extinctions a@xmath8 mag .\nthe ratio of stars to brown dwarfs was found to be @xmath11 .    _\n_ @xcite imaged the central 1@xmath101  of the embedded cluster associated with mon r2 by utilizing the near - infrared camera andd multi - object spectrometer on board the _ hubble space telescope _ ( _ hst _ ) .\nan extinction - limited sample a@xmath12 mag was defined and a total of 19 objects were detected with masses between 0.03 and 1 @xmath2 .\nthe ratio of stars to brown dwarfs was found to be @xmath13 .\n_ chameleon 1 .\n_ @xcite obtained an extinction - limited sample in chameleon 1 that was complete down to 0.01 @xmath2 for a@xmath14 mag , by use of observations of a 0.22@xmath100.28  region with the advanced camera for surveyes on board _ hst _ and a subsequent spectroscopic follow - up of cluster member candidates .\nthe sub - sample from 0.03 to @xmath15 @xmath2 includes 24 objects and the ratio @xmath16 was found to be @xmath17 .\n_ pleiades . _\nthe pleiades is one of the best - studied open clusters , and numerous derivations of the imf have been published .\nhere we focus on the survey by @xcite who covered a 6.4 deg@xmath7 region of the pleiades .\nthe survey had a saturation limit of 0.48 @xmath2 .\nfor higher masses , the survey was combined with a mass function built using the @xcite database .\nthe pleiades suffer relatively low ( @xmath18 mag ) , mostly uniform , extinction , with negligible impact on the completeness of this sample , so we did not apply a reddening criterion .\nthe ratio of stars to brown dwarfs was found to be @xmath19 .    _ the orion nebular cluster . _\nthe onc has been the subject of extensive studies @xcite .\nwe take the adopted ratio of stars to substellar objects from the study of @xcite . the total sample , covering the central 5.1@xmath105.1 , contains approximately 200 objects with masses between 0.02 and 0.6 @xmath6 and a@xmath20 mag . using their figure 14 , and extrapolating the slope from 0.080.6 to 1.0 @xmath6 ( one additional bin in their plot ) , we arrive at a ratio of stars to substellar objects of @xmath21 .\n_ ngc 2024 . _\nthe ratio of stars to brown dwarfs in ngc 2024 was found by @xcite from their photometric and spectroscopic study , covering the central 10@xmath1010 .\nthey assigned masses to the photometric objects on the basis of the mass distribution in each magnitude bin , determined from the spectroscopic sample as in @xcite .\nthe result was that a total of 148 objects in their survey area has masses between 0.02 and 1 @xmath6 and extinctions a@xmath22 15 mag . based on their figure 9\n, we find that there are 27 objects between 0.03 and 0.08 @xmath6 resulting in a ratio of stars to substellar objects of @xmath23 .\ntable  [ results ] shows the ratio of stars to brown dwarfs for nearby embedded clusters and the pleiades , as described above , and the distribution of ratios is shown in fig ,  [ figure1 ] .\nthe weighted mean of the ratios is found to be 4.3 , and the standard deviation of the weighted mean is 1.6 .\nall of the measurements presented are consistent with the weighted mean within 2@xmath24 .\nthere is thus little evidence for variation in the low - mass imf between the different regions and we have adopted the hypothesis that the imf is universal . under this assumption ,\nthe complete set of imf determinations can be combined to place constraints that are stronger than for each of the individual measurements .\nfor each cluster , we have calculated the probability of obtaining the observed ratio of stars to brown dwarfs for a given imf or greater .\nthe ratio of stars to brown dwarfs drawn from a given sample size with an assumed imf is determined by the binomial theorem .\nthe predicted distribution of ratios from both segmented power - laws and a ( * ? ? ? * @xmath25 , @xmath26 , @xmath27 ) lognormal imf for a cluster of 100 objects with unresolved binaries is shown in the lower panel in fig .\n[ figure1 ] .\nthe peak mass in the lognormal is slightly higher , and the width is slightly more narrow than is presented in @xcite .\nthe change in the best - fit parameters in @xcite is due to an updated luminosity function @xcite .\na similar increase in the peak mass has been suggested by @xcite .\nthe slope of the segmented power - law between 0.08 and 1.0 @xmath2 was chosen to be @xmath28 , and the slope has been varied below 0.08 @xmath2 in the range @xmath3 , which is the 60% confidence interval presented by @xcite .\nit is clear that the rising and flat imfs ( @xmath29 , and @xmath30 , respectively ) are difficult to reconcile with the observed distribution of ratios .\nwe have quantitatively assessed the likelihood of obtaining the observed ratios from an assumed imf as follows . for each of the seven measurements ,\nthe probability of obtaining that ratio or higher , assuming an underlying imf , is calculated by adopting the binomial theorem .\nthe product of the seven probabilities is then calculated .\nwe find these values , which we refer to as the binomial tail product , or btp , to be @xmath31 , @xmath32 , @xmath33 , and @xmath34 , for a chabrier , falling , flat , and rising imf , respectively . if each cluster sample was drawn from the assumed underlying imf , and if each cluster had an infinite number of objects , we would expect the combined product of this statistic for a sample of seven clusters to be @xmath35 .\nthe lognormal imf appears to reproduce the observed ratios best , followed by the falling power - law imf .\nhow consistent are the measured ratios with a chabrier imf and with what confidence can other imfs be ruled out ?\nwe have investigated that question by performing monte carlo simulations .\nwe created an artificial set of seven clusters , each containing 100 objects ( the median number of objects in our sample ) .\nthe 100 objects are then assigned masses according to the assumed underlying imf , and the ratio of stars to brown dwarfs for each cluster is determined .\nfor each of the ratios , the probability of observing that value or higher is calculated and the seven probabilities are multiplied , as was done for the observed set of clusters .\nthe btp for the observed clusters is then compared with the distribution of btps just derived . because each factor in the btp is drawn from a binomial distribution ( of varying shapes ) , each imf gives the same expected distribution of btps .\nfigure  [ figure2 ] shows the cumulative distribution of btps for a set of 10,000 simulations .\noverplotted are the probabilities obtained above for the observed set of clusters assuming the four different underlying imfs .\nwe find that 37% of the simulations have a probability equal to or lower than what was found assuming a chabrier imf , and in only @xmath360.05%-0.1% of the simulations is the probability equal to or lower than found assuming a falling power - law imf . in none of the simulations\ndid the low probabilities for the flat or rising power - law imfs occur ( p @xmath5 0.01 % ) .\nthe results indicate that the imf is falling in the brown dwarf regime and that the chabrier imf is consistent with the observations .\nthe results on the imf presented here are based on the system imf , including binaries unresolved within 200 au . as such , they may be difficult to compare directly with the locally derived ( within 20 pc ) field imf discussed in @xcite that suffers from a much smaller fraction of unresolved binaries . yet the overall binary frequency for ultra - cool dwarfs ( m6 and later ) appears to be low ( @xmath3620% , * ? ? ?\n* ) , and furthermore the _ relative _ number of companions with separations @xmath3715 au and mass ratios q @xmath37 0.4 may be extremely low around very cool stars @xmath36 1% ; @xcite .    indeed ,\nif the companion mass ratio distribution follows the chabrier imf at wide separations , then one could expect fewer very low mass companions as one surveys progressively lower mass primaries ( e.g. * ? ? ?\n* ) , consistent with the observations by @xcite . if the imf follows a chabrier imf in the brown dwarf regime below 0.03 @xmath2 ( say , down to the opacity limit for fragmentation of @xmath36 0.001 - 0.004 @xmath2 ; @xcite , then the number of stars below 1 @xmath2 will outnumber brown dwarfs 4.7 to 1 .\nthe sense of our results , that the mass function is falling in the bd regime , is consistent with various ideas put forward to explain the shape of the imf ( @xcite and references therein ) .\nbuilding on the ideas of @xcite , @xcite produced an imf that is only weakly dependent on the jeans mass through dynamical interactions in the cluster .\nhowever , @xcite show that the turbulent fragmentation models by @xcite predict too few low - mass binary systems .\n@xcite , on the other hand , suggest that the imf should peak at higher masses in regions with low turbulence ( e.g. taurus ) which would result in a higher ratio of stars to brown dwarfs .\nthe lack of a strong variations in the ratio of stars to brown dwarfs is a problem for the turbulence models in general ; for example , magnetic turbulence models predict strong variations in the low - mass imf as a function of mach number and density @xcite .\nif the preliminary results indicated here are borne out through further observations , then models that depend only weakly on initial conditions would be required ( e.g. @xcite ; @xcite ) .\npossible imf variations at least within 1 kpc are smaller than can be detected by comparing the currently observed clusters .\nthus , there are two challenges in detecting imf variations : ( 1 ) one needs clusters with a well - sampled population to minimize the inherently stochastic nature of populating an imf , and ( 2 ) a larger set of clusters is needed to detect even small imf variations with initial conditions .\nalthough it appears that the variations in the imf down to 30 @xmath38 are modest , we still expect that variations will be seen at the lowest masses where the opacity limit for fragmentation can be reached @xcite and the metallicity of the star forming region could be imprinted in the lower mass limit .\ntaurus & 140 & 13 & 112 & 4.0 & @xmath39 & 0.286 & 0.030 & 0.002 & 2.47@xmath40 + onc & 480 & 1 & 185 & 2.0 & @xmath41 & 0.907 & 0.744 & 0.365 & 0.066 + mon r2 & 830 & 1 & 19 & 10 & @xmath42 & 0.359 & 0.182 & 0.093 & 0.035 + chamaeleon & 160 & 2 & 24 & 5.0 & @xmath43 & 0.795 & 0.569 & 0.375 & 0.187 + pleiades & 125 & 120 & 200 & 1.0 & @xmath44 & 0.560 & 0.056 & 0.002 & 7.39@xmath45 + ngc 2024 & 460 & 1 & 50 & 11.0 & @xmath46 & 0.877 & 0.591 & 0.317 & 0.097 + ic 348 & 315 & 2 & 168 & 4.0 & @xmath47 & 0.031 & 3.00@xmath48 & 1.88@xmath45 & 8.21@xmath49 + [ results ]"}
{"lay_summary": " the robust effect of curvature on spin polarization is reported in a three - terminal bridge system where the bridging material is subjected to rashba spin - orbit interaction . \n the results are examined considering two different geometric configurations , ring- and linear - like , of the material which is coupled to one input and two output leads . \n our results exhibit absolute zero spin polarization for the linear sample , while finite polarization is obtained in output leads for the ring - like sample . ", "article": "the study of spin dependent transport in low - dimensional systems has been largely dominated in the last few decades due to the rapid advancement in nano - scale science and technology  @xcite .\ncontrolling electron s spin degree of freedom is extremely important for the development of quantum information processing as well as quantum computation  @xcite .\nthe spin - orbit ( so ) interaction which couples the electron s spin to the charge degree of freedom provides a much deeper insight for generating spin current and also its manipulation  @xcite rather than the usual methodologies  @xcite .\nearlier , people were mainly using  @xcite ferromagnetic leads or external magnetic field to get spin filtering action though these are not very suitable especially for low - dimensional systems , since in one case a large resistivity mismatch is observed while in the other case the main difficulty appears for confining a huge magnetic field into a narrow region , like a nano - ring .    depending on the sources , spin - orbit interaction\nis classified in two different categories : one is called extrinsic type which appears mainly due to magnetic impurities , while the other is defined as intrinsic type that appears as a result of lacking of inversion symmetry . in this category generally\ntwo kinds of spin - orbit interactions are taken into account .\nthey are called as rashba and dresselhaus so interactions  @xcite .\nthe first one is associated with the inversion asymmetry of the structure and its strength can be regulated by means of external gate potential , and the second one is related to the bulk inversion asymmetry whose coupling strength depends on the material .\nconsidering the coupling of spin degree of freedom to the momentum of an electron , spin polarized currents in output terminals of a multi - terminal conductor can be achieved from a purely unpolarized electron beam injected to the input terminal  @xcite .\nthe existing literature suggest that a lot of theoretical progress has already been done to explore spin selective transmission through different model geometries .\nfor example , a planar t - shaped conductor  @xcite with a ring resonator exhibits polarized spin currents in outgoing leads in presence of rashba so interaction . in other work peeters _ et al . _\nhave shown how a ring - like geometry can be utilized as an electron spin beam splitter exploring the possible quantum interference effect in presence of so coupling  @xcite . at the same time nikolic and his group  @xcite put forward several key ideas in this particular field .    in spite of the considerable volume of work available in this particular area ,\na practically unexplored issue is how does the curvature of a material which is clamped within input and output leads influence spin polarization .    to the best of our knowledge , this part is unaddressed so far . in the present work\nwe essentially focus towards this direction .\nwe investigate the curvature effect on spin polarization by considering two simple geometries : a simple linear conductor and a ring - like geometry which is formed by bending the chain .\nthe results are quite interesting . using a tight - binding ( tb ) framework and based on green s function formalism\nwe show that for a ring shaped conductor spin polarized currents are obtained in output leads of a multi - terminal geometry from a completely unpolarized beam of electrons , while absolute zero spin polarization is obtained for the linear conductor .\nthe rest of the paper is organized as follows .\nsection ii illustrates two different models together with a brief theoretical description to obtain spin polarization in two output leads .\nsection iii contains numerical results and discussion , and finally , in section iv we summarize our essential results .\nin this section we describe two different systems of our study and present a general theory for calculating spin polarization coefficient @xmath0 in two output leads based on green s function formalism .\nthe three - terminal bridge setup is schematically shown in fig .  [ model ] , where we take two different configurations of the same material . in one configuration\nwe choose a finite one - dimensional ( @xmath1d ) chain , which is then bent to form a @xmath1d ring to generate another configuration . in both these two cases the material , subjected to rashba spin - orbit interaction ,\nis connected with one input ( lead-1 ) and two output leads ( lead-2 and lead-3 ) .\na tight - binding framework is given under the nearest - neighbor hopping approximation to describe the bridging material ( ring / chain ) and the side - attached leads .\nthe tb hamiltonian of the entire system reads as , @xmath2 where three different terms in the right side correspond to the hamiltonians of three different regions of the bridge system those are elaborately explained below .\nthe first term , @xmath3 , describes the hamiltonian of the conductor placed between the incoming and outgoing leads . depending on its geometry ( ring - like or chain - like ) the hamiltonian looks different . for a @xmath4-site linear conductor subjected to rashba so interaction the tb hamiltonian  @xcite gets the form : @xmath5_z   \\mbox{\\boldmath $ c$}_{n+1 } + h.c .\n\\right ) \\label{eq2}\\end{aligned}\\ ] ] where , + @xmath6 @xmath7 @xmath8 + @xmath9 +   + in the above expression , @xmath10 and @xmath11 are the creation and annihilation operators , respectively , for an electron with spin @xmath12 at the @xmath13-th atomic site of the sample .\n@xmath14 is the on - site energy and @xmath15 measures the isotropic nearest - neighbor hopping integral .\nthe parameter @xmath16 describes the rashba so coupling strength and the term @xmath17 gives the spin angular momentum of the electron .\nthe unit vector @xmath18 describes the direction of the movement of an electron between the sites @xmath13 and @xmath19 .\nwhen this @xmath4-site linear conductor is bent to form a ring the hamiltonian becomes  @xcite , @xmath20 where , + @xmath21 with @xmath22 .\nall the other symbols used in eq .\n[ eq3 ] carry their usual meanings .    in our theoretical framework ,\nthree metallic leads are considered to be identical , semi - infinite and free from any kind of impurities and spin - orbit interaction .\nwe can express them as , @xmath23 where @xmath24 for the three leads . in the absence of\nany so coupling @xmath25 takes the form : @xmath26 with @xmath27 and @xmath28 .\n+   + where @xmath29 and @xmath30 are the site energy and nearest - neighbor hopping integral , respectively , in the @xmath31-th lead .\nother factors carry their usual meanings as stated earlier .\nout of these three leads , lead-1 is treated as the input terminal , while the other two are considered as the output terminals and all of them are coupled to the conductor through the hopping integral @xmath32 . here\nwe assume that the lead-1 is always attached to site @xmath1 and the other two leads are coupled to the sites @xmath33 and @xmath34 , those are variables , of the conductor .\nfollowing the same footing as above , we can write the tb hamiltonian to describe the conductor - to - lead coupling as , @xmath35 here , @xmath36 \\label{eq7}\\ ] ] with @xmath37 + the site @xmath38 corresponds to the boundary site of the lead , and it is coupled to the @xmath13-th site of the conductor , which is variable .      the spin polarization coefficient in the output leads is defined as  @xcite , @xmath39 where , @xmath40 gives the transmission probability of an injecting electron with spin @xmath41 which gets transmitted through the drain with spin @xmath42 .\nwhen @xmath43 we get pure spin transmission , while for the other case spin flip transmission is obtained .\nequation  [ eq8 ] is the general expression of spin polarization coefficient between any two leads @xmath38 and @xmath44 , and , for our three - terminal system we call the polarization coefficients in two outgoing leads as @xmath45 and @xmath46 . in the present approach we select the quantization direction along the @xmath47 axis for simplification .    to calculate transmission coefficient\n@xmath40 we use green s function formalism  @xcite . in this framework the two - terminal transmission probability between the leads @xmath38 and @xmath44 is defined as @xmath48 $ ] . here\n@xmath49 and @xmath50 are the retarded and advanced green s functions , respectively , of the sample considering the effects of the electrodes .\n@xmath51 , where @xmath52 is the energy of an injecting electron , and @xmath53 s ( @xmath54 ) are the self - energies due to coupling of the conductor to the leads and @xmath55 s are their imaginary parts . in refs .\n@xcite the detailed calculations of self - energy matrices are available .\nbased on the above theoretical framework we now analyze our numerical results . throughout the analysis we fix the electronic temperature of the system to absolute zero , and for simplification , we put @xmath56 .\nother common parameters are as follows : @xmath57 and @xmath58 .\nthe rashba so coupling strength @xmath16 and all the energy scales are measured in unit of the hopping integral @xmath15 .    before focusing to the central point i.e. , the curvature effect on spin polarization in a multi - terminal ( more than one output lead ) system in presence of rashba so interaction ,\nwe want to have a short glimpse on the system where a conductor subjected to so interaction is coupled to a single input and a single output lead i.e. , a two - terminal system . following our extensive numerical calculations\nwe can conclude that irrespective of the curvature of the bridging material , only so interaction can not induce spin polarization in output lead of a two - terminal system .\nwe verify it considering different geometrical shapes of the conductor , e.g. , circle , square , triangle , polygon , linear , etc .\nin few recent works  @xcite it has also been shown that only so interaction    is incapable of producing spin polarization .\nthe reason is that , in presence of so coupling the time - reversal symmetry is still preserved , and therefore , it does nt break the kramer s degeneracy between the @xmath59 and @xmath60 states which results vanishing spin current in the output lead of a two - terminal system .\nthe degeneracy gets removed when the system is subjected to any kind of magnetic impurity or external magnetic field . under this situation a two - terminal system with so coupling exhibits polarized spin currents  @xcite .\nthis phenomenon has already been established in the literature , but the essential issue of our present analysis \nthe interplay between the curvature of the material and the multi - leads has not been addressed earlier .    to explore it , in fig .\n[ ringpola ] we present the results for a three - terminal mesoscopic ring considering @xmath61 and @xmath62 . here\n, the two outgoing leads are attached    symmetrically ( @xmath63 and @xmath64 ) with respect to the incoming lead , as shown schematically in fig .\n[ model](a ) .\nthe upper panel of fig .\n[ ringpola ] corresponds to the energy dependence of spin polarization coefficient for the one output lead , while for the other output terminal it is shown in the middle panel of fig .\n[ ringpola ] , and , finally they are placed together in the lower panel of this figure to compare the polarization coefficients properly . from these spectra it is observed that finite spin polarizations , associated with the energy eigenvalues of the ring subjected to only so interaction , are obtained in both the two outgoing leads though the system is free from any kind of magnetic impurities .\nmost interestingly , we also see that the coefficients @xmath45 and @xmath46 are exactly identical in magnitude and opposite in sign for each value of the incident electron energy @xmath52 .\nthis phenomenon can be explained as follows .\nthe spin polarization    coefficient @xmath0 describes the normalized difference among the up and down spin charge currents propagating through the outgoing leads , since in our present scheme we assume the quantized direction along the z direction . in a multi - lead geometry\ni.e. , when more than one outgoing lead is coupled to the system the kramer s degeneracy between the @xmath65 and @xmath66 gets removed and depending on the allowed paths of the moving electrons spin dependent scattering takes place . the spin dependent force associated with the\nso coupling is responsible for this scattering .\nnow , in the ring - like geometry electrons can go through two different paths , and accordingly , the up and down spin electrons get deflected in two opposite directions by the spin dependent force during the movement of electrons through the ring geometry in presence of so interaction which results spin selective transmission through the outgoing leads .\nthis is the key aspect of observing mesoscopic spin hall effect  @xcite and the accumulation of opposite spin electrons on the opposite edges of a finite width conductor .\nsince the two outgoing leads are coupled symmetrically to the ring geometry with respect to the incoming lead , @xmath45 and @xmath46 get equal magnitude .\ntheir sign reversals are also understood from eq .\n[ eq8 ] .    by breaking the ring - lead interface geometry\none can achieve spin polarizations with unequal magnitudes .\nthe results are shown in fig .\n[ ringpolanew ] when the output leads are attached asymmetrically with respect to the source lead . here\nwe fix @xmath67 and @xmath68 , and all the other parameters are kept identical as set in fig .\n[ ringpola ] .\nit is clearly seen that , unlike the symmetric configuration , the magnitudes of @xmath0 in two output leads are no longer equal for the asymmetrically connected ring - lead bridge setup .\nthis is exclusively due to the quantum interference effect among the electronic waves propagating through different arms of the ring geometry .\napart from getting unequal magnitudes of polarization coefficients in two output leads , all the other properties remain exactly invariant as described earlier in the case of symmetric configuration .    from these results\nwe can emphasize that , for the three - terminal ring geometry we get spin polarization due to so interaction only , since the sample is free from any kind of magnetic impurity or external magnetic field , but a two - terminal ring geometry can not provide polarize spin current under this situation . here , it is important to note that although the kramer s degeneracy between the @xmath65 and @xmath66 gets removed by coupling the conductor with a third lead or more , but it does nt ensure to get non - vanishing spin polarization in output leads which can be clearly understood from the following discussion .    the scenario becomes highly significant when the ring - like sample is transformed into the linear - like one .\nthe results are shown in fig .\n[ chainpola ] considering two different chain - to - lead interface geometries . in one configuration ( fig .\n[ chainpola](a ) ) the outgoing leads are coupled to the sites @xmath69 and @xmath70 of the linear conductor , while these coupling sites are @xmath71 and @xmath72 for the other configuration ( fig .  [ chainpola](b ) ) . the total number of atomic sites @xmath4 and the rashba so coupling are kept unchanged as taken in fig .\n[ ringpola ] . from the spectra presented in fig .\n[ chainpola ] , we interestingly see that both @xmath45 and @xmath46 drop exactly to zero for the entire energy band spectrum , and , these results are independent of the chain - to - lead interface geometry as well as the strength of the so coupling , which we confirm through our considerable numerical work .\nthis is really appealing in the sense that a same material subjected to so coupling exhibits finite spin polarization for one geometrical shape , while absolute zero spin polarization is obtained in the other geometrical configuration for a multi - terminal bridge setup .\nthis is solely due to the effect of curvature . for the linear chain\nthe up and down spin electrons can propagate only in a particular direction .\neither it can be along x or y direction depending on the choice of the co - ordinate system .\nunder this situation , the spin dependent force which essentially scatter opposite spin electrons becomes zero , and therefore , no spin polarization is available even though the kramer s degeneracy is broken for such a multi - terminal bridge setup .\nthe disappearance of such spin dependent force in a linear sample can be justified from the following analysis . for a linear chain\nthe rashba dependent hamiltonian in the continuum model representation gets the form  @xcite : @xmath73 , assuming the movement of electrons along the x direction .\nconsidering this hamiltonian if we calculate , being the position operator , then the output becomes exactly zero which immediately suggests vanishing spin dependent force since the force is directly proportional to . to get a finite spin    dependent force both the components @xmath74 and\n@xmath75 are needed in the rashba term which is not possible in the case of a linear chain .\ntherefore , spin dependent scattering is no longer available , even in the presence of multi - leads .\nnow , an important point which should be noted here that when a linear conductor is properly bent to form a regular ring shaped geometry , the so coupling strength may be affected due to its curvature , but that does nt at all change the present physical scenario , and therefore , we consider the identical coupling strength for both these two geometrical configurations for the sake of simplification in our model calculations .    the results presented so far to explore the curvature effect on spin polarization in a three terminal geometry are computed for a conductor with only @xmath70 sites . keeping in mind a possible experimental realization\none may think how such a small sized conductor can be used to design a conductor - lead bridge setup . to establish this fact now we present the spin polarization coefficients @xmath45 and @xmath46 taking a @xmath76-site conductor for its two different shapes as considered earlier i.e. , ring - like and the linear - like one .\nfor the ring - like geometry , the results are presented in fig .\n[ bigring ] , whereas for the other case they are shown in fig .\n[ bigchain ] , and for both these two cases the results are computed for two distinct electrode - to - conductor configurations ( symmetric and asymmetric ) to justify the robustness of our investigation . from the spectra given in fig .\n[ bigring ] it is observed that , like fig .\n[ ringpola ] , here also the polarization coefficients @xmath45 and @xmath46 become exactly identical in magnitude and opposite in sign ( 1st column of fig .\n[ bigring ] ) when the ring is attached symmetrically to    the outgoing leads . these coefficients @xmath45 and @xmath46 are no longer identical in magnitude for the asymmetric ring - lead configuration ( 2nd column of fig .\n[ bigring ] ) , as expected .\nthis is exactly what we get in a @xmath70-site ring as shown in fig .\n[ ringpolanew ] .\nfor the linear - shaped conductor with @xmath77 a vanishing spin polarization is obtained ( fig .\n[ bigchain ] ) in its output leads for the entire energy band region irrespective of the chain - to - lead interface geometry and it is exactly similar in nature which we get earlier in the case of a @xmath70-site chain ( fig .\n[ chainpola ] ) . from these results\nwe can emphasize that apart from getting more peaks and dips in @xmath0-@xmath52 spectrum for the ring - shaped conductor with increasing @xmath4 , all the basic physical properties i.e. , non - vanishing spin polarization coefficients with equal and/or unequal magnitudes associated with the ring - lead interface geometry and absolute zero spin polarization in the linear - like conductor irrespective of its coupling configuration to side - attached leads remain exactly unchanged .\nfor a very large sized ring several peaks and dips appear in @xmath0-@xmath52 spectrum from which it may seem that the spectrum is quasi - continuous , but looking it carefully one can always find distinct peaks since @xmath4 is finite .\nthus , our essential goal of getting finite and vanishing spin polarizations in a multi - terminal geometry constructed with the same material with different curvatures is established .\nthe author is thankful to prof .\ns. sil and m. dey for useful discussions .\nto summarize , in the present communication we establish the curvature effect on rashba spin - orbit interaction induced spin polarization in a three - terminal bridge setup within a tight - binding framework based on green s function formalism .\nthe results are analyzed considering two different shaped geometries of the same material . in one configuration\nwe select the bridging material in a linear - like , which is then bent to form a ring - like geometry . quite interestingly , we find that finite polarization is obtained in two output leads for ring shaped geometry , while absolute zero spin polarization is noticed when the sample becomes linear .\nthis phenomenon also holds true even for any other higher - terminal bridge setup and independent of the lead - conductor interface geometries .\nin addition to this ring - like geometry one might expect finite spin polarization in output leads for other geometrical configurations , except the linear one , which essentially leads to the robust effect of curvature on spin polarization in a multi - terminal bridge system .\nall the results described in this communication are worked out at absolute zero temperature , though the finite temperature extension of this analysis is extremely trivial .\nthe thing is that at finite temperature no new phenomenon will appear and all the physical pictures presented here remain unaltered even at finite ( low ) temperature since the broadening of energy levels of the conductor due to its coupling with the side - attached leads is too large compared to the thermal broadening  @xcite .    in the present work ,\nwe ignore the effect of on - site electron - electron ( e - e ) interaction .\nwe can incorporate this effect in our formalism in different ways .\none possible route is the mean field approximation  @xcite .\nbut , for this particular study e - e interaction does nt provide any such new insight since it can not scatter up and down spin electrons in opposite edges of the sample , as spin - orbit interaction does .\nonly some modifications in magnitudes of @xmath45 and @xmath46 can be expected .\nbefore we end , it should be noted that to explore the effect of curvature on spin polarization in a three - terminal bridge setup we compute our numerical results considering some typical values of the parameters describing the systems .\nbut , all these physical properties i.e. , vanishing spin polarization in output leads of a linear - like conductor and finite spin polarization for a ring - like geometry remain absolute unchanged for any other set of parameter values .\nthese features certainly demand an experiment in this line ."}
{"lay_summary": " research on the implications of anxiety in parkinson 's disease ( pd ) has been neglected despite its prevalence in nearly 50% of patients and its negative impact on quality of life . \n previous reports have noted that neuropsychiatric symptoms impair cognitive performance in pd patients ; however , to date , no study has directly compared pd patients with and without anxiety to examine the impact of anxiety on cognitive impairments in pd . \n this study compared cognitive performance across 50 pd participants with and without anxiety ( 17 pda+ ; 33 pda ) , who underwent neurological and neuropsychological assessment . \n group performance was compared across the following cognitive domains : simple attention / visuomotor processing speed , executive function ( e.g. , set - shifting ) , working memory , language , and memory / new verbal learning . \n results showed that pda+ performed significantly worse on the digit span forward and backward test and part b of the trail making task ( tmt - b ) compared to the pda group . \n there were no group differences in verbal fluency , logical memory , or tmt - a performance . in conclusion , \n anxiety in pd has a measurable impact on working memory and attentional set - shifting . ", "article": "anxiety affects quality of life in those living with parkinson 's disease ( pd ) more so than overall cognitive status , motor deficits , apathy , and depression [ 13 ] .\nalthough anxiety and depression are often related and coexist in pd patients , recent research suggests that anxiety rather than depression is the most prominent and prevalent mood disorder in pd [ 5 , 6 ] . yet ,\nour current understanding of anxiety and its impact on cognition in pd , as well as its neural basis and best treatment practices , remains meager and lags far behind that of depression .\noverall , neuropsychiatric symptoms in pd have been shown to be negatively associated with cognitive performance .\nfor example , higher depression scores have been correlated with lower scores on the mini - mental state exam ( mmse ) [ 8 , 9 ] as well as tests of memory and executive functions ( e.g. , attention ) [ 1014 ] .\nlikewise , apathy and anhedonia in pd patients have been associated with executive dysfunction [ 10 , 1523 ] .\nhowever , few studies have specifically investigated the relationship between anxiety and cognition in pd .\none study showed a strong negative relationship between anxiety ( both state and trait ) and overall cognitive performance ( measured by the total of the repeatable battery for the assessment of neuropsychological status index ) within a sample of 27 pd patients .\nfurthermore , trait anxiety was negatively associated with each of the cognitive domains assessed by the rbans ( i.e. , immediate memory , visuospatial construction , language , attention , and delayed memory ) .\ntwo further studies have examined whether anxiety differentially affects cognition in patients with left - sided dominant pd ( lpd ) versus right - sided dominant pd ( rpd ) ; however , their findings were inconsistent .\nthe first study found that working memory performance was worse in lpd patients with anxiety compared to rpd patients with anxiety , whereas the second study reported that , in lpd , apathy but not anxiety was associated with performance on nonverbally mediated executive functions and visuospatial tasks ( e.g. , tmt - b , wms - iii spatial span ) , while in rpd , anxiety but not apathy significantly correlated with performance on verbally mediated tasks ( e.g. , clock reading test and boston naming test ) .\nfurthermore , anxiety was significantly correlated with neuropsychological measures of attention and executive and visuospatial functions . taken together ,\nit is evident that there are limited and inconsistent findings describing the relationship between anxiety and cognition in pd and more specifically how anxiety might influence particular domains of cognition such as attention and memory and executive functioning .\nit is also striking that , to date , no study has examined the influence of anxiety on cognition in pd by directly comparing groups of pd patients with and without anxiety while excluding depression .\ngiven that research on healthy young adults suggests that anxiety reduces processing capacity and impairs processing efficiency , especially in the central executive and attentional systems of working memory [ 26 , 27 ] , we hypothesized that pd patients with anxiety would show impairments in attentional set - shifting and working memory compared to pd patients without anxiety .\nfurthermore , since previous work , albeit limited , has focused on the influence of symptom laterality on anxiety and cognition , we also explored this relationship .\nseventeen pd patients with anxiety and thirty - three pd patients without anxiety were included in this study ( see table 1 ) .\nthe cross - sectional data from these participants was taken from a patient database that has been compiled over the past 8 years ( since 2008 ) at the parkinson 's disease research clinic at the brain and mind centre , university of sydney .\ninclusion criteria involved a diagnosis of idiopathic pd according to the united kingdom parkinson 's disease society brain bank criteria   and were confirmed by a neurologist ( sjgl ) .\npatients also had to have an adequate proficiency in english and have completed a full neuropsychological assessment .\nten patients in this study ( 5 pd with anxiety ; 5 pd without anxiety ) were taking psychotropic drugs ( i.e. , benzodiazepine or selective serotonin reuptake inhibitor ) .\npatients were also excluded if they had other neurological disorders , psychiatric disorders other than affective disorders ( such as anxiety ) , or if they reported a score greater than six on the depression subscale of the hospital anxiety and depression scale ( hads ) .\nthus , all participants who scored within a  depressed  ( hads - d > 6 ) range were excluded from this study , in attempt to examine a refined sample of pd patients with and without anxiety in order to determine the independent effect of anxiety on cognition .\nthis research was approved by the human research ethics committee of the university of sydney , and written informed consent was obtained from all participants .\nself - reported hads was used to assess anxiety in pd and has been previously shown to be a useful measure of clinical anxiety in pd .\na cut - off score of > 8 on the anxiety subscale of the hads ( hads - a ) was used to identify pd cases with anxiety ( pda+ ) , while a cut - off score of < 6 on the hads - a was used to identify pd cases without anxiety ( pda ) .\nthis criterion was more stringent than usual ( > 7 cut - off score ) , in effort to create distinct patient groups .\nthe neurological evaluation rated participants according to hoehn and yahr ( h&y ) stages   and assessed their motor symptoms using part iii of the revised mds task force unified parkinson 's disease rating scale ( updrs ) . in a similar way\nthis was determined by calculating a total left and right score from rigidity items 3035 , voluntary movement items 3643 , and tremor items 5057 from the mds - updrs part iii ( see table 1 ) .\nprocessing speed was assessed using the trail making test , part a ( tmt - a , z - score ) .\nattentional set - shifting was measured using the trail making test , part b ( tmt - b , z - score ) .\nworking memory was assessed using the digit span forward and backward subtest of the wechsler memory scale - iii ( raw scores ) .\nlanguage was assessed with semantic and phonemic verbal fluency via the controlled oral word associated test ( cowat animals and letters , z - score ) .\nthe ability to retain learned verbal memory was assessed using the logical memory subtest from the wechsler memory scale - iii ( lm - i z - score , lm - ii z - score , % lm retention z - score ) . the mini - mental state examination ( mmse )\ndemographic , clinical , and neuropsychological variables were compared between the two groups with the independent t - test or mann  whitney u test , depending on whether the variable met parametric assumptions .\nchi - square tests were used to examine gender and symptom laterality differences between groups .\nall analyses employed an alpha level of p < 0.05 and were two - tailed .\nspearman correlations were performed separately in each group to examine associations between anxiety and/or depression ratings and cognitive functions .\nas expected , the pda+ group reported significant greater levels of anxiety on the hads - a ( u = 0 , p < 0.001 ) and higher total score on the hads ( u = 1 , p < 0.001 ) compared to the pda group ( table 1 ) .\ngroups were matched in age ( t(48 ) = 1.31 , p = 0.20 ) , disease duration ( u = 259 , p = 0.66 ) , updrs - iii score ( u = 250.5 , p = 0.65 ) , h&y ( u = 245 , p = 0.43 ) , ledd ( u = 159.5 , p = 0.80 ) , and depression ( hads - d ) ( u = 190.5 , p = 0.06 ) .\nadditionally , all groups were matched in the distribution of gender (  = 0.098 , p = 0.75 ) and side - affected (  = 0.765 , p = 0.38 ) .\nthere were no group differences for tmt - a performance ( u = 256 , p = 0.62 ) ( table 2 ) ; however , the pda+ group had worse performance on the trail making test part b ( t(46 ) = 2.03 , p = 0.048 ) compared to the pda group ( figure 1 ) .\nthe pda+ group also demonstrated significantly worse performance on the digit span forward subtest ( t(48 ) = 2.22 , p = 0.031 ) and backward subtest ( u = 190.5 , p = 0.016 ) compared to the pda group ( figures 2(a ) and 2(b ) ) .\nneither semantic verbal fluency ( t(47 ) = 0.70 , p = 0.49 ) nor phonemic verbal fluency ( t(47 ) = 0.39 , p = 0.70 ) differed between groups .\nlogical memory i immediate recall test ( u = 176 , p = 0.059 ) showed a trend that the pda+ group had worse new verbal learning and immediate recall abilities than the pda group . however , logical memory ii test performance ( u = 219 , p = 0.204 ) and logical memory % retention ( u = 242.5 , p = 0.434 ) did not differ between groups .\nthere were also no differences between groups in global cognition ( mmse ) ( u = 222.5 , p = 0.23 ) .\nparticipants were split into lpd and rpd , and then further group differences were examined between pda+ and pda. importantly , the groups remained matched in age , disease duration , updrs - iii , dde , h&y stage , and depression but remained significantly different on self - reported anxiety .\nlpda+ demonstrated worse performance on the digit span forward test ( t(19 ) = 2.29 , p = 0.033 ) compared to lpda , whereas rpda+ demonstrated worse performance on the digit span backward test ( u = 36.5 , p = 0.006 ) , lm - i immediate recall ( u = 37.5 , p = 0.008 ) , and lm - ii ( u = 45.0 , p = 0.021 ) but not lm % retention ( u = 75.5 , p = 0.39 ) compared to rpda.\nthis study is the first to directly compare cognition between pd patients with and without anxiety .\nthe findings confirmed our hypothesis that anxiety negatively influences attentional set - shifting and working memory in pd .\nmore specifically , we found that pd patients with anxiety were more impaired on the trail making test part b which assessed attentional set - shifting , on both digit span tests which assessed working memory and attention , and to a lesser extent on the logical memory test which assessed memory and new verbal learning compared to pd patients without anxiety . taken together ,\nthese findings suggest that anxiety in pd may reduce processing capacity and impair processing efficiency , especially in the central executive and attentional systems of working memory in a similar way as seen in young healthy adults [ 26 , 27 ] .\nalthough the neurobiology of anxiety in pd remains unknown , many researchers have postulated that anxiety disorders are related to neurochemical changes that occur during the early , premotor stages of pd - related degeneration [ 37 , 38 ] such as nigrostriatal dopamine depletion , as well as cell loss within serotonergic and noradrenergic brainstem nuclei ( i.e. , raphe nuclei and locus coeruleus , resp . , which provide massive inputs to corticolimbic regions ) . over time\n, chronic dysregulation of adrenocortical and catecholamine functions can lead to hippocampal damage as well as dysfunctional prefrontal neural circuitries [ 39 , 40 ] , which play a key role in memory and attention .\nrecent functional neuroimaging work has suggested that enhanced hippocampal activation during executive functioning and working memory tasks may represent compensatory processes for impaired frontostriatal functions in pd patients compared to controls . therefore , chronic stress from anxiety ,\nfor example , may disrupt compensatory processes in pd patients and explain the cognitive impairments specifically in working memory and attention seen in pd patients with anxiety .\nit has also been suggested that hyperactivation within the putamen may reflect a compensatory striatal mechanism to maintain normal working memory performance in pd patients ; however , losing this compensatory activation has been shown to contribute to poor working memory performance .\nanxiety in mild pd has been linked to reduced putamen dopamine uptake which becomes more extensive as the disease progresses .\nthis further supports the notion that anxiety may disrupt compensatory striatal mechanisms as well , providing another possible explanation for the cognitive impairments observed in pd patients with anxiety in this study .\nnoradrenergic and serotonergic systems should also be considered when trying to explain the mechanisms by which anxiety may influence cognition in pd . although these neurotransmitter systems are relatively understudied in pd cognition , treating the noradrenergic and serotonergic systems has shown beneficial effects on cognition in pd .\nselective serotonin reuptake inhibitor , citalopram , was shown to improve response inhibition deficits in pd , while noradrenaline reuptake blocker , atomoxetine , has been recently reported to have promising effects on cognition in pd [ 45 , 46 ] .\noverall , very few neuroimaging studies have been conducted in pd in order to understand the neural correlates of pd anxiety and its underlying neural pathology .\nfuture research should focus on relating anatomical changes and neurochemical changes to neural activation in order to gain a clearer understanding on how these pathologies affect anxiety in pd . to further understand how anxiety and cognitive dysfunction are related ,\nfuture research should focus on using advanced structural and function imaging techniques to explain both cognitive and neural breakdowns that are associated with anxiety in pd patients .\nresearch has indicated that those with amnestic mild cognitive impairment who have more neuropsychiatric symptoms have a greater risk of developing dementia compared to those with fewer neuropsychiatric symptoms .\nfuture studies should also examine whether treating neuropsychiatric symptoms might impact the progression of cognitive decline and improve cognitive impairments in pd patients .\nprevious studies have used pd symptom laterality as a window to infer asymmetrical dysfunction of neural circuits .\nfor example , lpd patients have greater inferred right hemisphere pathology , whereas rpd patients have greater inferred left hemisphere pathology .\nthus , cognitive domains predominantly subserved by the left hemisphere ( e.g. , verbally mediated tasks of executive function and verbal memory ) might be hypothesized to be more affected in rpd than lpd ; however , this remains controversial .\nit has also been suggested that since anxiety is a common feature of left hemisphere involvement [ 48 , 49 ] , cognitive domains subserved by the left hemisphere may also be more strongly related to anxiety .\nresults from this study showed selective verbal memory deficits in rpd patients with anxiety compared to rpd without anxiety , whereas lpd patients with anxiety had greater attentional / working memory deficits compared to lpd without anxiety .\nalthough these results align with previous research , interpretations of these findings should be made with caution due to the small sample size in the lpd comparison specifically .\nrecent work has suggested that the hads questionnaire may underestimate the burden of anxiety related symptomology and therefore be a less sensitive measure of anxiety in pd [ 30 , 50 ] . in addition , our small sample size also limited the statistical power for detecting significant findings .\nbased on these limitations , our findings are likely conservative and underrepresent the true impact anxiety has on cognition in pd . additionally , the current study employed a very brief neuropsychological assessment including one or two tests for each cognitive domain .\nfuture studies are encouraged to collect a more complex and comprehensive battery from a larger sample of pd participants in order to better understand the role anxiety plays on cognition in pd .\nanother limitation of this study was the absence of diagnostic interviews to characterize participants ' psychiatric symptoms and specify the type of anxiety disorders included in this study .\nfuture studies should perform diagnostic interviews with participants ( e.g. , using dsm - v criteria ) rather than relying on self - reported measures to group participants , in order to better understand whether the type of anxiety disorder ( e.g. , social anxiety , phobias , panic disorders , and generalized anxiety ) influences cognitive performance differently in pd .\none advantage the hads questionnaire provided over other anxiety scales was that it assessed both anxiety and depression simultaneously and allowed us to control for coexisting depression .\nalthough there was a trend that the pda+ group self - reported higher levels of depression than the pda group , all participants included in the study scored < 6 on the depression subscale of the hads .\ncontrolling for depression while assessing anxiety has been identified as a key shortcoming in the majority of recent work .\nconsidering many previous studies have investigated the influence of depression on cognition in pd without accounting for the presence of anxiety and the inconsistent findings reported to date , we recommend that future research should try to disentangle the influence of anxiety versus depression on cognitive impairments in pd . considering the growing number of clinical trials for treating depression , there are few if any for the treatment of anxiety in pd .\nanxiety is a key contributor to decreased quality of life in pd and greatly requires better treatment options .\nmoreover , anxiety has been suggested to play a key role in freezing of gait ( fog ) , which is also related to attentional set - shifting [ 52 , 53 ] .\nfuture research should examine the link between anxiety , set - shifting , and fog , in order to determine whether treating anxiety might be a potential therapy for improving fog ."}
{"lay_summary": " small non - coding rnas include sirna , mirna , pirna and snorna . \n the involvement of mirnas in the regulation of mammary gland tumorigenesis has been widely studied while the role for other small non - coding rnas remains unclear . here \n we summarize the involvement of mirna in breast cancer onset and progression through regulating the cell cycle and cellular proliferation . \n the regulation of breast cancer stem cells and tumor regeneration by mirna is reviewed . \n in addition , the emerging evidence demonstrating the involvement of pirna and snorna in breast cancer is briefly described . ", "article": "small non - coding rnas are transcribed into mrna but remain untranslated in eukaryotic cells .\nthey include sirna ( small interfering rna ) , mirna ( microrna ) , pirna ( piwi - interacting rna ) and snorna ( small nucleolar rna ) .\nmirnas are a class of multifunctional singled - stranded small rna which are ~20  nt in length and regulate the stability or translational efficiency of targeted messenger rna depending on the base - pairing complementarity between the mirna and its target mrna [ 1 , 2 ] . although over 1,000 mirna sequences have been identified from the tissues or cells of human origin and other species , as many as 1,000 to 10,000 mirnas per genome have been predicted [ 3 , 4 ] .\nmirnas regulate a broad range of biological processes including timing of development , cell cycle progression , stem cell self - renewal , differentiation , cancer initiation , cancer cell proliferation , metastasis and apoptosis [ 511 ] .\ncancer is caused by multiple processes including uncontrolled cellular proliferation and inappropriate survival of apoptotic cells .\nmany regulatory factors switch on or off genes that govern cell division and direct cellular proliferation .\nmirnas regulate gene expression and play important roles in the onset and progression of tumorigenesis .\nemerging evidence demonstrates the involvement of mirna in mammary gland tumorigenesis , functioning either as tumor suppressors or oncogenes .\nalthough the current treatment of radiation therapy , chemotherapy and hormone therapy slow mammary gland tumor growth , prolong survival and improve the quality of patients life , metastatic breast cancer still remains incurable due to our limited understanding of the molecular mechanisms through which tumorigenesis and metastasis occur .\nas small non - coding rnas regulate gene expression and tumorigenesis , they may represent a novel cancer therapy .\nunlike mrna , mirnas are transcribed but never translated . some mirnas are transcribed from non - coding regions between genes , deriving from independent transcription unit .\nother mirnas are transcribed together with coding mrnas from the coding region of the genome , deriving from the introns of gene transcripts [ 13 , 14 ] .\nmirna gene copy number gain / loss and mirna gene mutation have been observed in breast cancer resulting in the aberrant expression of mirna .\nthe first study about the altered expression of mirnas in human breast cancer patients and human breast cancer cell lines was reported in 2005 by lorio et al . ,\nin which 29 mirnas were identified with aberrant expression based on microarray and northern blot analysis of 76 breast tumor samples and 14 human breast cell lines .\nzhang and colleagues analyzed 283 human mirna genes on 55 human breast primary tumors and 18 human breast cancer cell lines using array - based comparative genomic hybridization .\nthe results demonstrated a high frequency ( ~72.8% ) of gene copy number abnormality in mirna - containing regions in human breast cancer .\nwang et al . collected 68 patients with newly diagnosed breast cancer and examined the expression of selected mirnas in tumor and adjacent non - tumor tissues .\nmir-21 , mir-106a and mir-155 were significantly over - expressed in the tumor specimens compared with normal controls , whereas mir-126 , mir-199a and mir-335 were significantly decreased in expression in the tumor samples .\nour studies of the mir-17 - 92 cluster demonstrated decreased expression of mir-17/20 in human breast cancer specimens compared with matching normal breast tissue from the same patient .\nsubsequent analysis identified reduced mir-17/20 expression in node - positive compared with node - negative breast cancers and demonstrated that mir-17/20 inhibited breast cancer cell migration and invasion via a heterotypic signaling .\nalthough the tendency for a global decrease of mirna expression in human cancers originally suggested a general tumor suppressor function of mirnas , subsequent studies showing the aberrant expression of specific mirnas in breast cancer suggest mirna - specific roles in breast cancer onset and progression .\nmany distinct mirnas have been shown to regulate breast cancer cell proliferation , apoptosis , cancer stem cell expansion , and tumorigenesis .\nmirna may function as either tumor suppressors or oncogenes depending on the cell type , culture conditions , target genes and pathway .\nthe involvement of mirna in mammary gland tumorigenesis has been reviewed recently [ 21 , 22 ] .\nle et al . described the expression pattern and regulatory network of key mirnas in breast cancer , including let-7 , mir-34 , mir-125 , mir-200 family , mir-205 , mir-21 , mir-10 and the mir-17 - 92 cluster .\nadams et al . reviewed the mirna regulation of estrogen signaling pathway and erbb2/her signaling pathway in breast cancer .\nthe understanding of how mirnas are involved in breast cancer through regulating the cell cycle remains rudimentary .\nherein we summarize the recent literature and research progress on the mechanism by which mirnas regulate the breast cancer cell cycle and cellular proliferation ( fig . \n1mirna regulation of mammary gland tumorigenesis in control of the cell cycle . through targeting different genes and different cyclin / cdk complexes , mir-17/20 and\nlet-7 regulate the g1-s transition ; mir-21 and mir-27a regulate the g2-m checkpoint mirna regulation of mammary gland tumorigenesis in control of the cell cycle . through targeting different genes and different cyclin / cdk complexes , mir-17/20 and\nlet-7 regulate the g1-s transition ; mir-21 and mir-27a regulate the g2-m checkpoint cyclin d1 is either overexpressed or amplified in ~50% of breast cancer .\nthe abundance of cyclin d1 is rate - limiting in breast cancer cellular proliferation and g1-s phase transition [ 23 , 24 ] .\nin addition , cyclin d1 is a critical downstream target of erbb2- , ras- and -catenin- induced breast cancers , and is sufficient for the induction of mammary tumors when targeted to the mammary gland of mice .\nantisense inhibition of cyclin d1 expression in vivo suppressed the growth of neut - transformed mammary adenocarcinoma cells in nude mice .\nconserved sequences of the cyclin d1 3utr contain potential binding sites for multiple mirnas including mir-17/20/106 , mir-15/16 , mir-23 and let-7 .\nmir-17/20 binds the cyclin d1 3utr , inhibiting the expression of cyclin d1 , resulting in cell cycle arrest at the g1 phase and suppression of mcf-7 cell proliferation [ 18 , 26 ] .\nthe regulation of cyclin d1 expression by mir-17 - 92 , as well as mir-15/16 , was confirmed by deshpande et al . .\nthe let-7 family functions as a tumor suppressor in a variety of cancers including lung , colon , ovarian   and breast cancer .\nschultz et al . demonstrated the downregulation of cyclin d1 by mirna let-7 in control of cancer cell growth .\nthe regulation of cyclin d1 by mirna is likely of broad importance as cyclin d1 encodes the regulatory subunit of a kinase that phosphorylates and inactivates the prb family proteins to inhibit dna synthesis , and phosphorylates nuclear respiratory factor 1 ( nrf-1 ) to inhibit mitochondria biogenesis [ 32 , 33 ] .\nfurthermore , cyclin d1 promotes breast epithelial cell angiogenesis and migration , and promotes chromosomal instability which in turn contributes to tumorigenesis .\nthe mir-221/222 cluster regulates the cell cycle , cell growth and epithelial - to - mesenchymal transition ( emt ) in breast cancer .\nmir-221/222 inhibited p27 and p57 abundance , facilitating g1-s phase transition , thereby promoting cancer cell proliferation [ 36 , 37 ] .\nmoreover , mir-221/222 may contribute to the aggressive clinical behavior of basal - like breast cancers .\nthe breast cancer basal - like subtype - specific mirnas , mir-221 and mir-222 , promote emt in breast cancer by targeting trps1 ( trichorhinophalangeal syndrome type 1 ) which inhibits emt by repressing zeb2 expression .\nmir-221 and/or mir-222 expression in mcf-7 and t47d breast cancer cells decreased er expression associated with tamoxifen resistance .\nthe onco - mirna mir-21 is overexpressed in a wide variety of cancers including breast cancer [ 40 , 41 ] .\nmir-21 induced cellular proliferation , migration , invasion , emt , cancer stem cell characteristics and chemotherapy resistance in human breast cancer [ 42 , 43 ] .\nhigh mir-21 level is associated with poor prognosis , advanced stage , positive lymph node status and reduced survival time in breast cancer .\nmir-21 promotes mcf-7 cellular proliferation in part through inhibiting the expression of a tumor suppressor gene programmed cell death 4 ( pdcd4 ) . in colon cancer ,\nmir-21 participates in a dna damage - induced g2-m checkpoint through suppressing the cell cycle regulator cdc25a .\na recent report demonstrated the mir-21 regulates the cell cycle through targeting cdc25a in mcf-7 breast cancer cells . with a potential anti - cancer chemical 3,3-diindolylmethane treatment ,\nmir-27a expression is upregulated in human breast cancer cell lines . in mda - mb-231 cells ,\nmir-27a negatively regulated the zinc finger zbtb10 gene and myt-1 , thereby promoting breast cancer cell proliferation .\nmir-27a suppressed myt-1 , increased cdc2/cyclin b activity and promoted the g2-m checkpoint in mda - mb-231 cells . thus , distinct mirnas affect key genetic targets that govern distinct cell - cycle checkpoints including cyclins , cdks , cdk inhibitors and the g2-m regulation apparatus .\nin addition to cell - cycle control , breast tumor onset and progression and breast tumor stem cells are also regulated by distinct mirnas .\ncancer stem cells ( cscs ) are characterized by their self - renewal capacity , an ability to differentiate into non - tumorigenic cell progeny , and their ability to seed tumors when transplanted into animal hosts .\ncell surface markers such as cd44 , cd24 , cd133 , epithelial - specific antigen and aldehyde dehydrogenase-1 are frequently used to isolate and enrich cscs .\nthe involvement of mirnas in regulating tumor formation by cscs or tumor - initiating cells ( t - ic ) has been widely investigated .\nlet-7 expression is very low to undetectable level in embryonic stem cells ( es cells ) and increases with differentiation .\na comparison of mirna expression between breast t - ic and non - t - ic demonstrated reduced let-7 expression in t - ic and increased abundance with differentiation .\ntransduction of breast cscs with let-7 reduced the proportion of undifferentiated cells , inhibited cell proliferation , mammosphere formation , and tumor formation in vivo .\nclarke and colleagues identified 37 mirnas which were differentially expressed between human breast cscs ( cd44cd24lineage ) and lineage nontumorigenic breast cancer cells .\nthe mir-200 family members were downregulated in human breast cscs and normal mammary stem / progenitor cells .\nexpression of mir-200 inhibited breast cancer stem cell expansion in vitro , and suppressed the tumor formation ability of human breast cancer stem cell in vivo .\nectopic mir-34c expression reduced breast t - ics self - renewal , inhibited emt and suppressed tumor cell invasiveness via silencing notch4 .\nzhu et al . found the reduced mir-128 expression in human breast t - ic was accompanied by bmi-1 and abcc5 overexpression , and associated with chemotherapeutic resistance and poor survival .\nenforced mir-128 expression increased the sensitivity of breast cancer cells to doxorubicin - induced apoptosis and dna damage .\nemerging evidence has demonstrated the importance of cscs in cancer initiation , cancer metastasis and drug resistance .\ncscs are believed to be one of the most promising targets for cure of cancer .\nthe discovery that non - coding rnas regulate cscs widens our understanding of cscs , and may provide potential novel strategies for breast cancer therapy .\ndeletion of chromosome 6q , including region 6q14-q16 , is frequently observed in breast cancer .\nthe small non - coding snorna u50 is a candidate tumor suppressor gene in the 6q14 - 16 region , playing a role in the development and/or progression of breast cancer .\ngenomic deletion and transcriptional downregulation of snorna u50 was detected in breast cancer cell lines .\nre - expression of snorna u50 inhibited colony formation of the human breast cancer cells hs578 t and mda - mb-231 .\npirnas are small non - coding rna that form rna - protein complexes through interactions with piwi proteins .\npirna was initially discovered in germ line cells , and considered as germ line - specific small rnas .\nemerging evidence indicates that pirna expression occurs in somatic cells [ 57 , 58 ] and piwil2 expression has been identified in human breast cancer cells .\nhigh - throughput deep sequencing identified a group of small rnas matching pirna sequences in human breast cancer tissues and breast cancer cell lines .\nthe study of these non - coding small rnas in human cancer is just starting .\nthe identification of the expression signature of these non - coding small rnas in breast cancer subtypes , and an understanding of their functional significance to oncogene expression , tumor initiation and tumor cell metastasis may shed important new perspectives on the role of these non - coding small rnas in breast cancer .\nsmall non - coding rna - based diagnostic and therapeutic applications for human cancer are expected in the near future . although tumor - targeted delivery and local administration are still major challenges to the practical application of gene therapy for cancer , mirna - based cancer therapeutic approaches are being established and tested in animal models .\nsynthetic mirna mimics or mirna expression vectors have been successfully applied to restore or overexpress mirna in vitro . chemically modified lna anti - sense mirna inhibitor and other approaches have been used to block mirna function in cells .\nkim et al . recently reported significant anti - tumor effect of virus - mediated delivery of mir-145 combined with 5-fu to treat breast cancer .\nintranasal delivery of let-7   and intravenous delivery of mir-34a mimics   for non - small - cell lung cancer treatment and a virus - mediated delivery of mir-26a for liver cancer treatment in mouse model   demonstrate the promise of mirna for treatment of cancer .\ndysregulated expression of mirnas has implicated components of the non - coding genome as either oncogenes or tumor suppressors of breast cancer .\nexperimental evidence has shown specific mirnas regulating the initiation , progression , metastasis and drug resistance of breast cancer via control of the cell cycle , altering cellular proliferation , altering cellular apoptosis and/or controlling the population of tumor stem cells . dysregulated\nmirna expression has also been observed in cancer associated fibroblasts ( caf ) and in the systemic circulation [ 65 , 66 ] .\nthe circulating mirnas have the potential to serve as novel diagnostic and prognostic biomarkers for breast cancer .\na specific subset of dysregulated mirnas in breast cancer cells may serve as targets for gene therapy either alone or as an adjuvant treatment to current clinical protocols for breast cancer patients ."}
{"lay_summary": " objective : to evaluate the efficacy and safety of outpatient management of severe ovarian hyperstimulation syndrome  ( ohss ) requiring placement of a pigtail catheter.methods : retrospective analysis of thirty - three consecutive patients who underwent in - vitro fertilization  ( 2003 - 2009 ) and developed severe / critical ohss requiring placement of a pigtail catheter . \n patients who were managed on outpatient basis were monitored by frequent office visits , daily phone calls , and received iv normal saline for hydration when required.results : in 3 patients  ( 9.1% ) ohss started early , requiring placement of a pigtail catheter 4.3 + 0.6 days after retrieval . in 30 patients  ( 90.9% ) \n ohss started late  ( 14  4 days after retrieval ) . \n the mean amount of ascitic fluid drained immediately after placement of the catheter was 2085  1018 cc . \n the pigtail catheter was removed after 7.8  5.3 days . \n of the 31 patients who had embryo transfer  ( two had total freeze ) , 84% conceived . \n twenty - nine patients  ( 88% ) were managed on outpatient basis without any complications . \n four patients required hospital admission for 1 - 7 days  ( 3.0  2.7 ) . \n one patient with severe ohss was admitted for work up for chest pain . \n three patients with critical ohss with severe pleural effusion requiring thoracentesis were admitted for supportive measures.conclusion : the placement of a pigtail catheter resulted in safe and effective outpatient management for the majority of patients with severe ohss . ", "article": "ohss is a serious complication of ovulation induction , occurring in 1 - 10% of in vitro fertilization patients  ( rizk and aboulghar , 1991 ; brinsden et al . , 1995 ) .\nthis iatrogenic condition has a spectrum of clinical and laboratory manifestations ranging from mild to severe , even life - threatening conditions  ( rizk et al . , 1990 ) . among the serious manifestations of ohss are ascites and pleural effusion  ( rizk and smitz , 1992 ) .\nvascular endothelial growth factor has emerged as one of the factors most likely involved in the pathophysiology of ohss  ( geva and jaffe , 2000 ; rizk and aboulghar , 2010 ) .\nvascular endothelial growth factor is an angiogenic cytokine that is a potent stimulator of the vascular endothelium and appears to play an integral role in follicular growth , corpus luteum function and ovarian angiogenesis  ( rizk et al . , 1997 ) .\nvascular endothelial growth factor causes increased capillary permeability with its sequelae of ascites and possible pleural effusion  ( rizk et al . , 1997 ; gomez et al . , 2002 ) .\nhuman chorionic gonadotrophin is thought to play a crucial role in the development of ohss  ( rizk et al .\ntwo distinct forms of severe ohss have been described : early and late forms  ( papanikolaou et al . , 2005 ; mathur et al . , 2000 ) .\nearly ohss is caused by the administration of exogenous human chorionic gonadotrophin  ( hcg ) and it starts before the 10th day after oocyte retrieval , while the late form is the result of endogenous human chorionic gonadotrophin release in the event of pregnancy , and it starts after the 10th day following oocyte aspiration  ( papanikolaou et al . , 2005 ;\nsuch strategies included the use of low dose gonadotropins and frequent monitoring during controlled ovarian stimulation , cycle cancellation , coasting , freeze all embryos and the use of gonadotropin releasing hormone  ( gnrh ) agonist as an oocyte trigger in gnrh antagonist cycles  ( rizk et al .\nthe use of antagonist in the luteal phase with total freeze of embryos to prevent severe ohss has also been suggested  ( lainas et al . , 2012 ) .\nsuch strategies should be used especially in patients at high risk for developing severe ohss , including those who are young , have low body weight , have polycystic ovary syndrome , those who experience high estradiol levels , rapidly increasing estradiol levels , high number of follicles during controlled ovarian stimulation and those with high number of oocytes retrieved  ( rizk and aboulghar , 1999 ; delvigne , 2009 ) .\ndopamine agonists have been proposed for the prevention of ohss in women at high risk . however , the study by lvarez et al . \n( 2007 ) suggested that it was only effective in reducing the incidence of moderate ohss , but not in its severe form  ( alvarez et al . , 2007 ) .\nlow - dose aspirin therapy and doxycycline have also been suggested to inhibit angiogenesis  ( fainaru et al . , 2009 ) .\n( 2011 ) believes that the concept of an ohss - free clinic has become a reality .\nthe authors suggest that this approach should include pituitary down - regulation using a gnrh antagonist , ovulation triggering with a gnrh agonist and vitrification of oocytes or embryos  ( devroey et al . , 2011 ) .\nsevere and critical forms of ohss are associated with significant ascites  ( golan et al . , 1989 ; rizk et al . ,\nascites results in an increased abdominal pressure compromising venous return , cardiac output and renal perfusion  ( navot et al .\nparacentesis is frequently needed , as prompt drainage of fluid produces a significant clinical and biochemical improvement , including spontaneous diuresis and hastening the resolution process  ( rizk et al .\n, multiple paracenteses may be required to relieve symptoms and avoid serious sequelae of hemoconcentration , hypotension , decreased renal perfusion and severe respiratory compromise . instead of multiple interventions ,\nthe placement of a catheter temporarily for a few days will permit complete drainage through one procedure  ( rizk and aboulghar , 1999 ) .\npigtail catheters have been used for drainage in various clinical situations . in a previous study we described the use of percutaneous placement of a pigtail catheter for drainage of ascites caused by severe / critical ohss  ( abuzeid et al . , 2003 ) .\nin this study we established the efficacy and safety of pigtail catheter drainage in the management of severe / critical ohss in patients who underwent in vitro fertilization and embryo transfer at our centre between 1999 and 2001 on both inpatient and outpatient basis .\nthe aim of the current study was to evaluate the role of the pigtail catheter drainage in outpatient management of patients with early onset severe ohss .\nthis is a retrospective study that included all patients who underwent in vitro fertilization and developed severe or critical ohss by the golan classification  ( golan et al . , 1989 ) in the period between 2004 and 2009 .\nall patients underwent an ultrasound evaluation which documented the presence of severe ascites and bilateral ovarian enlargement .\nall patients presented with shortness of breath , marked abdominal distension , nausea , weight gain and lower abdominal pain .\nthirteen patients complained of vomiting , and 3 patients reported decreased urine output  ( less than 720 cc per 24  hours ) and had haemoglobin   15 g / dl .\nall 33 patients were offered treatment using pigtail catheter insertion as an alternative to trans - vaginal paracentesis .\nblood studies including a complete blood count , creatinine , electrolytes , serum albumin and total protein , and coagulation panel were ordered prior to the procedure .\nall 33  patients were rehydrated with intravenous crystalloid solutions  ( 0.9% normal saline ) .\ncare was taken to give the patient the same amount of fluid as the amount that was drained from the peritoneal cavity .  \nall pigtail catheter placements were performed in the operating room at our surgical centre . the catheter  ( 6 - 0 french , 2.0 mm , boston scientific , quincy , ma , usa ) was introduced utilizing a non - disposable metal gamete intra - fallopian treatment  ( gift ) trocar and cannula  ( embryon gift catheter , ivf online , gilford , ct , usa ) which was introduced into the largest accessible ascitic fluid pocket in the upper outer quadrant of the abdominal wall under local anaesthesia and trans - abdominal ultrasound guidance . the trocar was then removed and a glide wire  ( boston scientific corp . , watertown , ma , usa ) was threaded through the gift canula . the canula was removed with care so as to keep the glide wire in the peritoneal cavity .\nthe pigtail catheter was guided into the peritoneal cavity by the wire after removal of the stylet of the pigtail catheter .\nthe catheter was anchored to the skin using 2 - 0 silk suture and it was supported by gauze , which was covered by a tegaderm .\nthe catheter was connected to a three - way stop cock which was connected to a drainage bag .\ninitial amount of drained fluid was calculated and subsequently the patients were trained to drain 1000 cc per day  ( 500 cc in the morning and 500 cc in the evening ) .\none liter normal saline and 500 cc of 6% hydroxyethyle starch solution  ( hespan ) was administered to the patient on the same day of pigtail catheter placement .\nany patient with critical ohss according to the golan classification , or those in whom the presenting symptoms and signs did not completely subside after drainage of ascitic fluid and iv fluid replacement , were admitted to the hospital for observation and further management .\nall other patients were sent home . once there was minimal or no drainage from the catheter , the patient returned to the office for removal of the catheter .\nthe patients were encouraged to drink plenty of fluids and to increase their protein intake .\nall patients kept a diary for body weight , abdominal girth , and urine output before and after the procedure .\npatients were seen in the office as needed for evaluation and hydration with normal saline .\ndemographic data including mean age  ( years ) , duration of infertility  ( years ) , bmi  ( kg / m2 ) and aetiology of infertility are illustrated in table i. ovarian stimulation data including number of treatment days , total dose of recombinant follicle stimulating hormone , hormone serum levels , endometrial thickness , number of follicles and number of patients receiving only 5000 iu of human chorionic gonadotrophin is illustrated in table ii .\nour data include the number of patients requiring early versus late placement of pigtail catheter , mean amount of ascitic fluid drained immediately after pigtail placement , number of days of pigtail catheter drainage and the number of days between oocyte retrieval and the onset of severe ohss symptoms requiring pigtail placement .\ntable iii also illustrates the number of patients who underwent coasting , number of patients who received prophylactic hespan on day of egg retrieval .\nvalues are expressed as mean + standard deviation values are expressed as mean  +  standard deviation : rfsh  =  recombinant fsh ; hmg  = human menopausal gonadotropins ; hcg  =  human chorionic gonadotropin ; e2  =  estradiol values are expressed as mean + standard deviation three patients  ( 9% ) required an early placement of a pigtail catheter while 30 patients  ( 91% ) had late placement of the catheter  ( table iii ) .\ntwenty - nine patients  ( 88% ) were managed on an outpatient basis without any complications .\nfour patients  ( 12% ) required hospital admission for 1 - 7 days  ( 3 + 2.7 ) , three for associated severe pleural effusion requiring thoracentesis .\nthese three patients were admitted to the hospital immediately after insertion of the pigtail catheter for management of severe pleural effusion and careful observation .\none patient was admitted 48 hours after insertion of the pigtail catheter for work up for chest pain , all tests were negative .\nnavot et al . , 1992 ; rizk and aboulghar , 1999 ) , but perhaps the most accepted classification of ohss is the one described by golan et al as mild , moderate and severe  ( golan et al . , 1989 ) .\nhowever , clinicians should be aware that ohss is a dynamic condition and moderate ohss may progress to severe ohss within hours  ( rizk and aboulghar , 1999 ; rizk , 2009 ) .\ntherefore , the practice committee of the american society for reproductive medicine  ( asrm ) proposed a classification for ohss of mild , worsening and serious  ( the practice committee of the american society for reproductive medicine , 2008 ) . recognizing the patients at high - risk , prevention and early recognition are the most important steps in the management of ohss  ( rizk , 2006 ) .\nhowever , severe forms of ohss , especially late onset type that occurs when patients are pregnant , most likely will continue to happen , albeit at much lower rate , unless one reverts to a total freeze of all embryos after the use of gnrh agonist as a trigger shot in a gnrh antagonist cycle  ( donoso and devroey , 2013 ; devroey et al . , 2011 ) .\ntraditional treatment consists mainly of supportive management until spontaneous resolution occurs  ( rizk , 1994 ) .\nalthough moderate ohss does not usually require intervention , outpatient monitoring is essential to identify progression to a severe form  ( rizk , 2006 ) .\npatients with moderate ohss can be managed on an outpatient basis by adequate hydration and close daily monitoring of weight gain and abdominal girth to detect progression to severe ohss , and to provide intervention , if required  ( rizk , 2010 ) .\npatients presenting with severe forms of ohss are usually managed on inpatient basis and most patients with critical ohss are admitted to intensive care units for aggressive supportive measures to avoid maternal morbidity and mortality  ( the practice committee of the american society for reproductive medicine , 2008 ) .\ncorrection of hypovolemia , electrolyte imbalance and hypoalbuminemia are the basic principles during the treatment of severe ohss  ( rizk , 1994 , 2006 ; myrianthefs et al . , 2000 ) .\n( 1992 ) suggested that paracentesis is the single most important treatment modality in life - threatening ohss not controlled by medical therapy .\nparacentesis and removal of ascites result in relieving the pressure on the inferior vena cava and improvement in venous return , cardiac output and renal perfusion  ( padilla et al . , 1990 ) .\ntherefore , prompt drainage of fluid produces significant clinical and biochemical improvement , including spontaneous diuresis and hastening the resolution process  ( abuzeid et al .\n, 2003 ; the practice committee of the american society for reproductive medicine , 2008 ) .\nit is also possible that removal of ascites decreases the amount of vegf and its effects on vascular permeability .\ntherefore ultrasound guided drainage of the ascitic fluid should be performed in severe cases of ohss with respiratory distress , oliguria or severe abdominal pain  ( padilla et al . , 1990 ) .\nthis can be done either trans - vaginally  ( aboulghar et al . , 1990 ) or trans - abdominally  ( padilla et al . ,\n1990 ) . however , recurrence of ascites is common in severe cases of ohss .\nplacement of a pigtail catheter has been proposed by some investigators to allow drainage of ascitic fluid whenever it accumulates without the need for further surgical procedures  ( abuzeid et al . , 2003 ) .\nin a previous study we reported the use of percutaneous pigtail catheter for drainage of ascites in severe ohss as an alternative to repeated paracentesis  ( abuzeid et al . , 2003 ) .\nthis procedure is relatively simple and requires a short period of time as compared to the time needed to gradually aspirate any fluid accumulation transvaginally .\nimmediate relief of symptoms and signs of severe ohss after pigtail catheter insertion was an important finding .\nin addition , the ease by which any accumulated ascitic fluid was drained resulted in a faster resolution of ohss  ( abuzeid et al . ,\nno infection was reported  ( abuzeid et al . , 2003 ) . in that study the first 13 patients\nthey were discharged home with the pigtail catheter in place and managed on an outpatient basis until ohss subsided ; thereafter the catheter was removed .\nthe last 13 patients were managed on an outpatient basis without any problem  ( abuzeid mi , et al . , 2003 ) .\nour previous study confirmed the safety and effectiveness of the pigtail catheter for the management of severe ohss .\ntherefore , we embarked on the current study to evaluate the role of pigtail catheter drainage in outpatient management of patients with severe ohss syndrome . in the current study we demonstrated that patients who were diagnosed very early with severe ohss can be managed safely and effectively on outpatient basis using pigtail catheter drainage , iv fluid replacement and careful monitoring .\nalthough all 33 patients presented with shortness of breath , marked abdominal distension , nausea , weight gain and lower abdominal pain , and 13 of them complained of vomiting ,  ( all are criteria for hospital admission according to the practice committee of the american society for reproductive medicine on ohss ) , 30 patients were sent home as their presenting symptoms were relieved .\nearly diagnosis and intervention resulted in rapid elimination of the symptoms of severe ohss and normalization of vital signs , which allow us to manage the patients on outpatient basis .\nthe pigtail catheter placements were performed without complications and patients were discharged home after a few hours of observation .\nthe patients who needed hospital admission were those with associated severe pleural effusion requiring thoracentesis .\nanother patient was admitted to the hospital for 1 day for work up for chest pain and possible diagnosis of pulmonary embolism .\nonce pulmonary embolism was ruled out , she was discharged home with a pigtail catheter in place and she was managed on outpatient basis .\noutpatient management of ohss has no place in those who fail to have complete resolutions of their symptoms , or those with severe hyperproteinuria or electrolyte imbalance .\ncertainly it has no place in patients with critical ohss such as those with severe pleural effusion , diminished urine output , severe hemoconcentration and those at increased risk of thromboembolic risks  ( rizk , 2010 ) .\nit is imperative to stress that such a protocol can only be used in patients who are motivated , reliable and have the necessary support at home to allow them to return to the clinic or go to the emergency room if the need arises .\nit also requires dedicated in vitro fertilization nurses to educate and follow up the patient on a daily basis .\ncontrary to other reports that state that access to intravenous albumin is a critical part of outpatient management for severe ohss , we did not use any albumin replacement  ( lincoln et al . , 2002 ) .\nthe reason behind the use of intravenous albumin is to increase intravascular oncotic pressure , thereby curtailing the exodus of free water from the intravascular space . in our study\nwe used hespan instead of albumin , as some investigators have shown that it is beneficial in reducing the incidence of severe ohss  ( youssef et al . , 2011 ) . by increasing the intravascular oncotic pressure\nin addition , the majority of our patients had late onset ohss as a result of pregnancy .\nhespan should be used with caution in patients with late onset ohss only when benefits outweigh risks.it is a fact that outpatient management of early severe ohss is a common practice among infertility specialists after trans - vaginal aspiration of ascitic fluid and iv fluid hydration .\noutpatient management by repeated abdominal or trans - vaginal paracentesis has been reported to be safe , effective and cost effective  ( lincoln et al .\n, 2002 ; shrivastav et al . , 1994 ; fluker et al . , 2000\n( 1994 ) were the first to suggest that day care management in patients with severe ohss with abdominal paracentesis and iv hydration was simple , safe and effective compared with traditional treatment with in - patient hospitalization and supportive measures .\n( 2002 ) concluded that the need for hospitalization for hyperstimulated patients can be minimized by outpatient management of severe ohss with trans - vaginal culdocentesis and rehydration with crystalloids and albumin .\n( 2000 ) advocated in a pilot study an active management strategy for moderate ohss , which involved early paracentesis designed to minimize the progression from moderate to severe ohss , instead of late paracentesis aimed at speeding up recovery in severely ill patients .\n( 2010 ) concluded that early outpatient paracentesis for moderate to severe ohss is the most cost effective management plan when compared with traditional conservative inpatient therapy .\n( 2009 ) reported a large series of patients with severe ohss in whom the vast majority were successfully managed as outpatients with use of aggressive trans - vaginal paracentesis  ( smith et al . , 2009 ) . despite the findings in our study\nit is important to emphasize that ohss remains a serious disorder with the potential for rapid deterioration , requiring hospitalization and intensive treatment of a critically ill patient .\nthe life - threatening complications of ohss are secondary to thromboembolism or compromised pulmonary or cardiovascular function and multi - organ failure\n. there have been isolated reports of women dying from the complications associated with ohss .\nthe mortality rate related to ohss is very low and was estimated by brinsden et al . \nmore recently , reports regarding maternal mortality rates due to ohss in the netherlands and united kingdom demonstrate an incidence of approximately 3 deaths per 100,000 in ivf cycles  ( braat et al .\n, 2006 ; lewis , 2007 ) . eleven lethal complications of assisted reproductive technology have been documented and summarized by braat et al . \nseveral investigators reported sporadic fatality as a result of ohss due to adult respiratory distress syndrome , massive pulmonary oedema , myocardial infarction , and carotid artery occlusion resulting in cerebral infarction . in this study\nwe describe a modified technique of what interventional radiologists usually use for pigtail catheter placement .\nwe observed that in the obese patients the metal introducer provided in the pigtail catheter kit is difficult to use ; instead we used the non disposable gamete intra - fallopian treatment trocar and cannula to facilitate the introduction of the catheter through the abdominal wall of such patients .\nthis technique helps to manage the patients in the office without the need for sending her to the hospital for an interventional radiologist to place the catheter .\nhowever , the patients in this study were identified from our in vitro fertilization database ; the study included every patient who developed severe / critical ohss .\nin addition , the lack of a control group that was managed without pigtail catheter placement limits the conclusions that can be drawn from our study . in summary ,\ndrainage of ascitic fluid in patients with severe / critical ohss is an important step in the management of this condition  ( rizk , 2010 ) .\nthe placement of a pigtail catheter resulted in a safe and effective outpatient management of the majority of patients with severe ohss .\nhowever , outpatient management of this potentially fatal condition requires clear understanding that rapid deterioration may occur , which may necessitate hospitalization and intensive treatment of a critically ill patient  ( rizk , 2006 , 2010 ) .\npatients with critical ohss and those with persistence of symptoms of severe ohss despite insertion of a pigtail catheter and drainage of ascitic fluid should be admitted to the hospital for inpatient management ."}
{"lay_summary": " congenital adrenal hyperplasia is a group of autosomal recessive disorders caused by enzyme deficiency which leads to defects in biosynthesis of steroid precursors . \n most common is 21 hydroxylase deficiency . \n clinical spectrum varies from non - classical cah to classic cah , and it may be simple virilising form or salt - wastinfg type . \n 29 patients were included in our study from january 2012 to october 2012 . \n 76% were females . \n male babies typically presented with adrenal crisis between 3rd to 6th week of life . around 20% of females \n were identified and appropriately treated only after late adolescence . \n short stature was seen in 1/3rd of patients . \n 1/3rd of patients had suppressed 17 ohp levels suggestive of over - replacement therapy which may contribute to final reduction in adult height . ", "article": "congenital adrenal hyperplasia ( cah ) refers to a group of autosomal recessive disorders caused by an enzyme deficiency which leads to defects in biosynthesis of steroid precursors .\ndepending on the severity and degree of 21 hydroxylase deficiency , the clinical spectrum may vary from mild form of non classical cah to classic cah .\nhowever , the non classical cah variant is more common with a prevalence rate of 1 in 1000 .\nit also helps in maintaining normal levels of precursors by suppressing adreno cortico trophic hormone ( acth ) . during childhood\n, the management is largely focused on achieving normal growth and attaining appropriate final adult height .\njohns medical college hospital , bangalore by the department of endocrinology on patients diagnosed to have cah and seen in the outpatient clinic between january 2012 and october 2012 . during this period\ndata regarding demography , clinical presentation at time of diagnosis , treatment details , height sds and bmi were collected .\nall patients underwent biochemical testing for 17 hydroxy progesterone ( 17 ohp ) levels for assessment of adequacy of therapy . bone age assessment with left hand and wrist\nbmi was calculated for all patients and obesity was defined using who charts as values above 95th percentile .\n17 ohp levels between 1 ng / ml and 12 ng / ml were considered appropriate ; values below 1 ng / ml suggested suppression and over treatment and values above 12 ng / ml suggested under treatment .\n29 patients were included in the study of which 22 were females ( 76% ) and 7 were males ( 24% ) . based on the cross sectional data collected , 11 patients were adults ( age > 18 ) and 18 patients were children ( 62% ) . among the males ,\none child was identified at birth via a neonatal screening program , one child presented with early pubarche , the other 5 infants presented between their 3rd and 6th week of life with features suggestive of adrenal crisis - poor feeding , vomiting and failure to gain weight .\none of the male patients incidentally also had a penoscrotal hypospadias which was surgically corrected . among the females ,\n9 infants were identified at birth due to presence of genital ambiguity ( 40% ) , 1 presented with symptoms of adrenal crisis at 4 weeks of life , 4 patients presented in the pre pubertal period due to early onset adrenarche ( 18% ) , 5 patients presented in the late adolescent period with marked virilization ( 23% ) and 3 patients presented with features of poly cystic ovarian disease ( pcos ) .\nall the five patients who presented in the late adolescent period had obvious genital ambiguity from birth , however , they sought medical attention only much later due to marked virilization and failure to attain menarche .\none among them had actually been evaluated and even underwent a clitoroplasty at a young age , but unfortunately , the diagnosis of cah was missed as she was mistakenly categorized as probable ovo testicular dsd due to presence of mullerian structures with a phallic length of around 6 cm .\nall these 5 women had a masculine built at presentation with poor breast development , severe hirsutism , muscular body habitus , temporal balding and varying degrees of deepening of voice .\nthe non classical cah ( nccah ) patients presented in adulthood with complaints of irregular cycles and hirsutism ; they had no features of virilisation .\nsimple virilizing was the most common sub class seen among the women ( 81% ) whereas the salt wasting type was predominant among boys ( 85% ) .\naround 35% of patients had short stature as defined by height sds < -2.0 ; 2 patients who presented with adrenarche had increase in height sds , however , their bone age was also correspondingly advanced .\nall the children were treated with hydrocortisone ; almost all adult patients were on dexamethasone .\nnone of the nccah patients were treated with glucocorticoids ; they were on anti - androgen therapy along with oral contraceptive pills .\nmost adult classic cah patients with complaints of hirsutism were treated with either spironolactone or finasteride .\npubertal induction with ethinyl estradiol was initiated for three of the adult patients who sought medical care late .\nanalysis of 17 ohp levels revealed that 32% were suppressed with levels less than 1ng / ml ; appropriate in 47% and inadequate in 21% of patients .\nwe report the phenotypic features of a cohort of patients with cah being evaluated and managed in a tertiary centre in southern india . in this series ,\nthe typical presentation of male babies were with adrenal crisis between the 3 and 6 week of life . around 20% of female patients with classic cah\nwere identified and appropriately treated only after late adolescence even when genital ambiguity was present since birth .\nshort stature was seen in one third of patients on therapy and the average final adult height among patients with classic cah was 142.37 , which was significantly lower than the mean adult height for females in our population .\nthe mean final adult height of 157.5 cm for those with nccah was better than their classic cah counterpart .\nobesity and hypertension were not found to be significantly higher in this cohort of cah patients .\none third of patients had suppressed 17 ohp levels suggestive of over replacement therapy which may also contribute to the reduction in the final adult stature ."}
{"lay_summary": " objective(s):pentoxifylline is an immunomodulatory and anti - inflammatory agent and is used in vascular disorders . \n it has been shown that pentoxifylline inhibits proinflammatory cytokines production . \n the purpose of this study was to investigate the therapeutic effects of pentoxifylline on the treatment of autoimmune diabetes in mice.materials and methods : diabetes was induced by multiple low dose of streptozotocin ( mlds ) injection ( 40 mg / kg / day for 5 consecutive days ) in male c57bl/6 mice . \n after induction of diabetes , mice were treated with pentoxifylline ( 100 mg / kg / day ip ) for 21 days . \n blood glucose levels and plasma levels of insulin were measured . \n splenocytes were tested for proliferation by mtt test and cytokine production by elisa.results:pentoxifylline treatment prevented hyperglycemia and increased plasma insulin levels in the diabetic mice . aside from reducing lymphocyte proliferation , pentoxifylline significantly inhibited the production of proinflammatory interleukin 17 ( il-17 ) as well as interferon gamma ( ifn- ) , while increased anti - inflammatory cytokine il-10 as compared with those in mlds group ( diabetic control group).conclusion : these findings indicate that pentoxifylline may have therapeutic effect against the autoimmune destruction of the pancreatic beta - cells during the development of mlds - induced type 1 diabetes in mice . ", "article": "type 1 diabetes ( t1d ) results from the destruction of insulin producing pancreatic  cells by a  cell specific autoimmune process ( 1 ) . chronic pancreatic inflammation ( insulitis ) and destruction of islet -cells in type 1 diabetes\nis mediated by the immune cells , particularly autoreactive cd4 and cd8 t lymphocytes , b cells , macrophages and dendritic cells ( 2 ) . in order to obtain insight into type 1 diabetes pathogenic mechanisms in humans and to test novel therapeutic approaches for its treatment , different preclinical models of the disease such as spontaneous and accelerated diabetes in the non - obese diabetic ( nod ) mice ,\nbiobreeding rats , or diabetes induced in susceptible rodent strains by multiple low doses of streptozotocin ( mlds ) are now available ( 3 ) . in the pathogenesis of t1d , several proinflamma - tory cytokines including ifn -  , tnf- , il-1 , as well as il-17 ( 4 - 6 ) , have been implicated .\nit is also thought that the production of anti - inflammatory cytokines such as il-4 , il-10 and tgf- correlates with protection from t1d ( 6 ) .\nit has been shown that some drugs such as pentoxifylline ( ptx ) have immunomodulatory and anti - inflammatory activity , which might represent a potential preventive therapy for autoimmune diseases .\nptx is a methyl xanthine - derived general phosphodiesterase ( pde ) inhibitor that has been available for many years to treat vascular disorder ( 7 ) .\nphosphodiesterases ( pdes ) are a family of enzymes that regulate intracellular levels of the cyclic nucleotides cyclic adenosine monophosphate ( camp ) and cyclic guanosine monophosphate ( cgmp ) by catalyzing their breakdown to inactive metabolites .\ndrugs that increase the levels of camp , tend to reduce the production of proinflammatory mediators and increase the production of anti - inflammatory mediators by immune cells ( 8) . in recent years , the potential of ptx as an immunomodulatory and anti - inflammatory agent gained interest as it has been shown to effectively suppress the synthesis of tnf- and other pro inflammatory cytokines such as ifn -  and il-12 in vitro and in vivo ( 9 - 10 ) .\nptx has been successfully used for the treatment of experimental autoimmune diseases including experimental autoimmune myocarditis ( eam ) ( 11 ) , experimental autoimmune encephalomyelitis ( 12 ) , and adjuvant arthritis ( 13 ) . in the present study\n, we hypothesized that pentoxifylline , due to its anti - inflammatory and immunosuppressive activity , may affect autoimmune diabetes .\nconsequently , we decided to investigate whether pentoxifylline treatment could prevent the development of mlds - induced diabetes in mice .\nstreptozotocin ( stz ) , citrate buffer , pentoxifylline ( ptx ) , rpmi 1640 , l - glutamine , dimethylsul- foxide ( dmso ) , concanavalin a , mtt ( ( 3-(4,5-dimethyl - thiazolyl)-2,5-diphenyl - tetrazolium bromide ) ) and fetal calf serum fetal were purchased from sigma - aldrich ( st.louis , mo ) .\nmale c57bl/6 mice , weighing 20 to 25 g , were housed in a room with a 12-hr light / dark cycle .\ndiabetes was induced by multiple low - dose of streptozotocin ( mlds ) injection in male c57bl/6 mice .\nstz was dissolved in 0.1 m citrate buffer ( ph 4.5 ) and injected intraperitoneally ( ip ) , within 10 min of preparation , at a dose of 40 mg / kg / day for 5 consecutive days .\nthe blood samples were obtained from the tail vein of non - fasted mice , and glucose was measured using a glucometer ( accu - chech active ) .\nmice were considered diabetic when their non - fasting blood glucose level was > 250 mg / dl ( 14 ) .\nsubsequently , the mice were allocated to three therapeutic groups ( n=7 per group ) ( normal control group , mlds group ( diabetic control group ) and treatment group ) . treatment with ptx ( 100 mg / kg / day for 21 days , ip )\nplasma , separated from blood by centrifugation , was stored at -80c until insulin assay .\nmice were euthanized and their splenic tissues were removed on day 21 for cytokine assay and mtt test .\nnon - fasting blood sugar level was measured in 0 , 7 , 14 and 21 days after streptozotocin induced diabetes by using a glucometer ( accu - chech active).the blood samples were obtained from the tail vein of non - fasted mice ( 14 ) . before mice were euthanized , blood was collected from each mouse on day 21 in heparinized tubes .\nmice were euthanized and their spleens were removed on day 21 for cytokine production assay .\nafter aseptic removal , spleens were placed in cold hanks solution and teased apart with a pair of forceps and a needle .\na single cell suspension was obtained by passing it through a 200-mesh net and hemolyzed by the buffer solution containing 1 mmol / l tris  hcl and 1% nh4cl ( ph 7.2 ) .\nsubsequently , the macrophage cell content was depleted by incubation of the cell suspension in tissue culture dishes at 37c ( air+5% co2 ) to allow these cells to adhere to the bottom of the culture dishes .\nremaining free floating cells were seeded on culture dishes at a density of 510cells / ml in rpmi 1640 with 10% fetal calf serum , and 2\nthe splenocytes ( 510cells / ml ) were treated with 2 g / ml concanavalin a for 72 hr , and cell supernatants were collected , then the levels of il-10 , il17 and ifn -  were measured by elisa kits according to the manufacturers instructions .\nmouse splenic lymphocytes ( 110cells / ml ) were incubated in the absence or presence of concanavalin a ( 1.25 g / ml ) in a 96-well flat - bottom microculture plat in triplicate for 72 hr . thirty microliters of 5 mg / ml mtt ( ( 3-(4,5-dimethylthiazolyl)-2,5-diphenyl - tetrazolium bromide ) ) in pbs was added to each well , and the plate was incubated at 37c for 4 hr .\nafter incubation at 37c for 5 min , absorbance was measured spectro - photometrically at 490 nm . the stimulation index si ) was calculated according to the following formula : si= od concanavalin a ( con a ) stimulated lymphocyte proliferation / od spontaneous lymphocyte proliferation without con a. one - way analysis of variance ( anova ) followed by tukey s test were used for multiple comparisons between groups .\nstreptozotocin ( stz ) , citrate buffer , pentoxifylline ( ptx ) , rpmi 1640 , l - glutamine , dimethylsul- foxide ( dmso ) , concanavalin a , mtt ( ( 3-(4,5-dimethyl - thiazolyl)-2,5-diphenyl - tetrazolium bromide ) ) and fetal calf serum fetal were purchased from sigma - aldrich ( st.louis , mo ) .\nmale c57bl/6 mice , weighing 20 to 25 g , were housed in a room with a 12-hr light / dark cycle .\ndiabetes was induced by multiple low - dose of streptozotocin ( mlds ) injection in male c57bl/6 mice .\nstz was dissolved in 0.1 m citrate buffer ( ph 4.5 ) and injected intraperitoneally ( ip ) , within 10 min of preparation , at a dose of 40 mg / kg / day for 5 consecutive days .\nthe blood samples were obtained from the tail vein of non - fasted mice , and glucose was measured using a glucometer ( accu - chech active ) .\nmice were considered diabetic when their non - fasting blood glucose level was > 250 mg / dl ( 14 ) .\nsubsequently , the mice were allocated to three therapeutic groups ( n=7 per group ) ( normal control group , mlds group ( diabetic control group ) and treatment group ) . treatment with ptx ( 100 mg / kg / day for 21 days , ip ) was initiated in treatment group when they were considered diabetic . at the same time , the control groups received saline vehicle alone with the same schedule .\nplasma , separated from blood by centrifugation , was stored at -80c until insulin assay .\nmice were euthanized and their splenic tissues were removed on day 21 for cytokine assay and mtt test .\nnon - fasting blood sugar level was measured in 0 , 7 , 14 and 21 days after streptozotocin induced diabetes by using a glucometer ( accu - chech active).the blood samples were obtained from the tail vein of non - fasted mice ( 14 ) .\nbefore mice were euthanized , blood was collected from each mouse on day 21 in heparinized tubes .\nmice were euthanized and their spleens were removed on day 21 for cytokine production assay .\nafter aseptic removal , spleens were placed in cold hanks solution and teased apart with a pair of forceps and a needle .\na single cell suspension was obtained by passing it through a 200-mesh net and hemolyzed by the buffer solution containing 1 mmol / l tris  hcl and 1% nh4cl ( ph 7.2 ) .\nsubsequently , the macrophage cell content was depleted by incubation of the cell suspension in tissue culture dishes at 37c ( air+5% co2 ) to allow these cells to adhere to the bottom of the culture dishes .\nremaining free floating cells were seeded on culture dishes at a density of 510cells / ml in rpmi 1640 with 10% fetal calf serum , and 2 mmol / l l - glutamine .\nthe splenocytes ( 510cells / ml ) were treated with 2 g / ml concanavalin a for 72 hr , and cell supernatants were collected , then the levels of il-10 , il17 and ifn -  were measured by elisa kits according to the manufacturers instructions .\nmouse splenic lymphocytes ( 110cells / ml ) were incubated in the absence or presence of concanavalin a ( 1.25 g / ml ) in a 96-well flat - bottom microculture plat in triplicate for 72 hr . thirty microliters of 5 mg / ml mtt ( ( 3-(4,5-dimethylthiazolyl)-2,5-diphenyl - tetrazolium bromide ) ) in pbs was added to each well , and the plate was incubated at 37c for 4 hr . the plate was then centrifuged and followed by removal of medium .\nafter incubation at 37c for 5 min , absorbance was measured spectro - photometrically at 490 nm . the stimulation index si ) was calculated according to the following formula : si= od concanavalin a ( con a ) stimulated lymphocyte proliferation / od spontaneous lymphocyte proliferation without con a.\none - way analysis of variance ( anova ) followed by tukey s test were used for multiple comparisons between groups .\nall stz - induced diabetic mice with ptx treatment remained hyperglycemic on day 14 , and no significant difference in blood glucose levels was demonstrated between ptx and mlds(diabetic control group ) group .\nhowever , the levels of glucose in diabetic mice were significantly reduced after treatment with ptx ( p<0.05 ) , for 21day , when compared to the values of diabetic control mice ( figure 1 ) .\neffect of pentoxifylline treatment on blood glucose levels ( * p<0.05 ) to evaluate -cell function in terms of insulin release , we measured the plasma insulin levels on day 21 ( figure 2 ) .\nptx prevented the mlds - induced reduction in plasma insulin , indicating a possible protective effect of ptx against -cell damage .\neffect of pentoxifylline treatment on plasma levels of insulin ( * p<0.05 ) treatment of mice with ptx significantly decreased mlds - induced production of ifn-  and il-17 , while increased il-10 as compared with those in mlds group ( diabetic control group ) ( p<0.05)(figure 3 ) .\neffect of pentoxifylline on productions of ifn  il-10 and il-17 of diabetic murine splenocytes induced by con a ex vivo ( * p<0.05 versus diabetic control group ) the stimulation index ( si ) in treatment group with ptx showed a significant decrease as compared with that in mlds group ( diabetic control group ) ( p<0.05)(figure 4 ) .\neffects of pentoxifylline on the proliferation of splenic lymphocytes induced by con a after 72 hr ( * p<0.05 )\nall stz - induced diabetic mice with ptx treatment remained hyperglycemic on day 14 , and no significant difference in blood glucose levels was demonstrated between ptx and mlds(diabetic control group ) group .\nhowever , the levels of glucose in diabetic mice were significantly reduced after treatment with ptx ( p<0.05 ) , for 21day , when compared to the values of diabetic control mice ( figure 1 ) .\neffect of pentoxifylline treatment on blood glucose levels ( * p<0.05 ) to evaluate -cell function in terms of insulin release , we measured the plasma insulin levels on day 21 ( figure 2 ) .\nptx prevented the mlds - induced reduction in plasma insulin , indicating a possible protective effect of ptx against -cell damage .\ntreatment of mice with ptx significantly decreased mlds - induced production of ifn-  and il-17 , while increased il-10 as compared with those in mlds group ( diabetic control group ) ( p<0.05)(figure 3 ) .\neffect of pentoxifylline on productions of ifn  il-10 and il-17 of diabetic murine splenocytes induced by con a ex vivo ( * p<0.05 versus diabetic control group )\nthe stimulation index ( si ) in treatment group with ptx showed a significant decrease as compared with that in mlds group ( diabetic control group ) ( p<0.05)(figure 4 ) .\neffects of pentoxifylline on the proliferation of splenic lymphocytes induced by con a after 72 hr ( * p<0.05 )\nin rodents , experimental insulin - dependent diabetes can be induced by multiple low doses of streptozotocin ( mlds ) ( 15 ) .\nthis model is a commonly used animal model that has many histological and clinical features similar to those of human type 1 diabetes and involves the participation of macrophages and t cells .\nstreptozotocin ( stz ) is a pancreatic  cell toxin that induces inflammation of the islets by immune cells when it is given in multiple low doses ( 16 ) .\nthis model of diabetes offers some advantages , such as simultaneous appearance of diabetes mellitus in all animals and not having immune abnormalities that may complicate studies in spontaneous diabetes in non - obese diabetic ( nod ) mice or bio breeding ( bb ) rats .\ntherefore , this model as a good model has been applied extensively to investigate the type 1 diabetes mellitus , especially study the immune pathways and modulations of autoimmune insulitis and  cell death ( 17 - 18 ) .\nc57bl/6 mice , also called  c57 black 6  or simply  black 6  has the advantage of strain stability and easy breeding .\nthe most common application of c57bl/6 mice is to serve as physiological or pathological models for in vivo experiments ( 19 ) . as such\n, mlds induced c57bl/6j mice were chosen to evaluate the anti - hyperglycemic activity of ptx and investigate the immunotherapeutic molecular mechanisms of how ptx attenuated the development of t1d .\nptx is commonly used for the treatment of microcirculatory disorders and yields only minimal side effects in patients .\nin addition , due to its varied immunomodulatory effects , ptx has been used in several autoimmune diseases including rheumatoid arthritis ( 20 ) , multiple sclerosis ( 21 ) , and systemic lupus erythematosus ( 22 ) .\ndrugs that increase the level of camp , including pde inhibitors , are known to prevent or attenuate inflammatory cell responses ( 20 ) .\nprevious studies have also shown that ptx lowers blood glucose levels in diabetic animals ( 23 ) , and the results from the present studies also indicated that ptx possessed an anti - hyperglycemic property .\nmore importantly , the present data demonstrated that ptx could increase serum insulin concentrations in type 1 diabetic mice .\nit has been shown that ptx could reduce ( but not abrogate ) the insulin requirements or lengthen the  honeymoon  ( non - insulin - requiring ) period in a study of 21 children with new - onset type 1diabetes ( 24 ) .\nt helper 1 cells produce proinflammatory cytokines ( tnf- , ifn -  , il-1 , il-6 , and il-12 ) , which activate macrophages and cytotoxic t cells to destroy -cells , whereas anti - inflammatory cytokines ( il-4 and il-10 ) that are produced by activated t helper 2 cells , prevent -cell destructive insulitis ( 25 ) .\nil-10 has been shown to prevent the onset of diabetes in mice ( 26 ) . in response to cytokine stimulation , -cells generate reactive oxygen species ( ross ) and reactive nitrogen species such as nitric oxide ( no ) , which facilitate their destruction ( 27 ) .\nno is also synthesized within cytokine - activated macrophages by inducible nitric oxide synthase ( inos ) ( 28 ) .\nmore recently , the role of il-17-producing t cells have been demonstrated in the development of several autoimmune diseases , including multiple sclerosis , rheumatoid arthritis and type 1 diabetes .\nil-17 is a proinflammatory cytokine that is detrimental to pancreatic islet cells ( 29 ) .\nil-17 promotes infiltration of neutrophils and macrophages , stimulates the production of other proinflammatory cytokines , including tnf- , il-1 , il-6 and il-12 , by activated macrophages and induces nitric oxide release from  cells that interferes with their function and cause -cell destruction ( 30 , 5 ) .\nit has been assumed that ptx similar to camp elevating agents , selectively suppresses the production of t helper type 1(il-2 , ifn -  ) , but not t helper type 2(il-4 , il-6 , il-10 ) cytokines ( 31 ) .\nhowever , it has also been demonstrated that the effect of ptx on cytokine production is cell - specific ( 32 ) .\nthe present study shows that ptx is not only able to inhibit the release of proinflammatory cytokines ( ifn -  and il-17 ) , but can also increase the production of anti - inflammatory cytokines ( il-10 ) . since ptx has been found to be able to inhibit the release of proinflammatory cytokines ( 33 ) , and favor th2 response ( 34 ) , it may indirectly interfere with the induction of inos .\nit has been shown that pde inhibitors elevate camp , prevent or attenuate inflammatory cell responses ( 35 ) and suppress proliferation of lymphocytes ( 36 ) .\nour findings are consistent with previous studies , showing that ptx treatment prevented lymphocyte proliferation .\nin summary , results of the present work demonstrated that the suppressive effect of the ptx treatment on t1d was accompanied by decreased blood glucose level , increased plasma insulin level , suppression of t cell proliferation , down - regulation of th1 and th17 cytokines ( ifn -  and il-17 ) and increase in the production of il-10 in supernatant of splenic culture of the treated mice .\nit seems that pentoxifylline treatment has a therapeutic effect against mlds - induced diabetes in mice ."}
{"lay_summary": " abstractobjective : to determine the presence of staphylococcal superantigen - specific ige antibodies and degree of ige - mediated sensitization , as well as whether or not those are associated with the severity of asthma in adult patients . \n methods : this was a cross - sectional study involving outpatients with asthma under treatment at a tertiary care university hospital in the city of rio de janeiro , brazil . \n consecutive patients were divided into two groups according to the severity of asthma based on the global initiative for asthma criteria : mild asthma ( ma ) , comprising patients with mild intermittent or persistent asthma ; and moderate or severe asthma ( msa ) . \n we determined the serum levels of staphylococcal toxin - specific ige antibodies , comparing the results and performing a statistical analysis . \n results : the study included 142 patients : 72 in the ma group ( median age = 46 years ; 59 females ) and 70 in the msa group ( median age = 56 years ; 60 females ) . in the sample as a whole , 62 patients ( 43.7% ) presented positive results for staphylococcal toxin - specific ige antibodies : staphylococcal enterotoxin a ( sea ) , in 29 ( 20.4% ) ; seb , in 35 ( 24.6% ) ; sec , in 33 ( 23.2% ) ; and toxic shock syndrome toxin ( tsst ) , in 45 ( 31.7% ) . \n the mean serum levels of ige antibodies to sea , seb , sec , and tsst were 0.96 u / l , 1.09 u / l , 1.21 u / l , and 1.18 u / l , respectively . \n there were no statistically significant differences between the two groups in terms of the qualitative or quantitative results . \n conclusions : serum ige antibodies to sea , seb , sec , and tsst were detected in 43.7% of the patients in our sample . \n however , neither the qualitative nor quantitative results showed a statistically significant association with the clinical severity of asthma . ", "article": "determinar a presena de anticorpos ige especficos para superantgenos estafiloccicos e o grau de sensibilizao mediada por esses , assim como se esses esto associados  gravidade da asma em pacientes adultos .\nestudo transversal incluindo asmticos adultos em acompanhamento ambulatorial em um hospital universitrio tercirio no rio de janeiro ( rj ) .\nos pacientes foram alocados consecutivamente em dois grupos de gravidade da asma segundo critrios da global initiative for asthma : asma leve ( al ) , com asmticos leves intermitentes ou persistentes , e asma moderada ou grave ( amg ) .\nforam determinados os nveis sricos de anticorpos ige antitoxinas estafiloccicas , e os resultados foram comparados por anlise estatstica .\nforam includos 142 pacientes no estudo : 72 no grupo al ( mediana de idade = 46 anos ; 59 do sexo feminino ) e 70 do grupo amg ( mediana de idade = 56 anos ; 60 do sexo feminino ) .\nna amostra geral , 62 pacientes ( 43,7% ) apresentaram resultados positivos para dosagens de anticorpos ige antitoxinas estafiloccicas : enterotoxina ( tx ) a , em 29 ( 20,4% ) ; txb , em 35 ( 24,6% ) ; txc , em 33 ( 23,2% ) ; e toxic shock syndrome toxin ( tsst ) , em 45 ( 31,7% ) . as mdias das dosagens sricas de anticorpos ige especficos anti - txa , txb , txc e tsst foram , respectivamente , de 0,96 u / l , 1,09 u / l , 1,21 u / l , e 1,18 u / l .\na presena de anticorpos ige sricos anti - txa , txb , txc e tsst , foi detectada em 43,7% nessa amostra de pacientes , mas no houve associao estatisticamente significativa entre seus resultados qualitativos ou quantitativos e gravidade clnica da asma .\n\n staphylococcus aureus is a gram - positive bacterium that can colonize the human skin and respiratory tract .\nthe most important are toxic shock syndrome toxin ( tsst ) , staphylococcal enterotoxin a ( sea ) , seb , sec , sed , see , seg , seh , and sei , the activities of which include superantigen activity , pyrogenicity , and potentiation of lethality of other toxins . \n\n\n\n \nthe superantigen activity of staphylococcal toxins consists of direct stimulation of class ii mhc receptors and t cells , independently of antigen presentation by antigen - presenting cells , stimulating the proliferation and activity of cd4 and cd8 t lymphocytes .\nthis mechanism is related to the worsening of allergic diseases by the production of staphylococcal toxin - specific ige antibodies , as well as by a direct effect on tissue mast cells , leading to their degranulation . \n\n\n\n  in asthma patients\n, staphylococcal toxins also act as superantigens , stimulating cd4 t lymphocyte proliferation and activity and leading to an increased production of staphylococcal toxin - specific ige antibodies , causing an allergic - type reaction by biding to mast cells in the respiratory tract .\nthis reaction results in the release of mediators such as histamine , kinins , platelet - activating factor , and arachidonic acid metabolites ( prostaglandins and leukotrienes ) , as well as of chemokines , eliciting immediate and late inflammatory responses ( by the recruitment and activation of neutrophils and eosinophils ) and culminating in asthma worsening . \n\n\n\n \nstaphylococcal superantigens have been shown to play roles in atopic dermatitis , rhinosinusitis , and asthma , being correlated with their severity . \n\n\n  with regard to asthma , kowalski et al . found ige antibodies to sea , sec , and tsst in 89.7% of 237 asthma patients ( mean levels of 1.096  3.25 ku / l ) ; although there was no significant difference between those with severe asthma and those with non - severe asthma in terms of the prevalence of staphylococcal toxin - specific ige antibodies ( 81.4% vs. 69.2% ) , mean levels were higher in the former than in the latter ( 1.65  3.25 ku / l vs. 0.54  0.72 ku / l ) . \n  in another study ( n = 210 ) , the same authors obtained similar results , the prevalence of staphylococcal toxin - specific ige antibodies being 76.1% in patients with severe asthma and 71.1% in those with non - severe asthma , mean levels being three times higher in the former than in the latter . \n \nbachert et al . found a significant increase in staphylococcal toxin - specific ige antibodies in patients with severe asthma when compared with those with mild asthma and controls ( n = 70 ) . \n  in a more recent study ( n = 387 ) , the same group of authors found a significant increase in staphylococcal toxin - specific ige antibodies in patients with severe uncontrolled asthma ( 59.6% ) when compared with those with controlled asthma ( 40.8% ) and controls ( 13.0% ) .\nhigh levels of staphylococcal toxin - specific ige antibodies have been found to be a risk factor for asthma ( or = 7.6 ) and severe asthma ( or = 11.09 ) . \n\n  in latin\namerica , there have been no studies correlating staphylococcal superantigens with the severity of asthma .\ntherefore , we investigated a population of asthma patients treated at a university hospital in the city of rio de janeiro , brazil , and having no risk factors for increased staphylococcal colonization or infection in order to correlate the clinical severity of asthma with the presence of staphylococcal toxin - specific ige antibodies and degree of ige - mediated sensitization .\nthis was a cross - sectional study including adult patients clinically and functionally diagnosed with asthma and receiving outpatient treatment at the clementino fraga filho university hospital , located in the city of rio de janeiro , brazil . between 2009 and 2013 ,\nconsecutive patients were divided into two groups according to the clinical severity of asthma based on the global initiative for asthma criteria \n\n\n : the mild asthma ( ma ) group , comprising patients with mild intermittent or persistent asthma ; and the moderate or severe asthma ( msa ) group .   according to the global initiative for asthma\n, \n\n\n  asthma severity can be evaluated on the basis of the treatment required in order to control the disease .\npatients with mild asthma are defined as those requiring only rescue medication , low - dose inhaled corticosteroids / leukotriene receptor antagonists , or a combination of the two .\npatients with moderate asthma are defined as those using long - acting 2 agonists and inhaled corticosteroids at low or moderate doses .\npatients with severe asthma are defined as those using long - acting 2 agonists and inhaled corticosteroids at high doses or other bronchodilators and anti - inflammatory drugs for asthma control .  \nthe criteria for inclusion in the present study were as follows : being an adult patient clinically and functionally diagnosed with asthma , \n\n\n  regardless of the presence of rhinitis and positive skin test results to aeroallergens .  \nthe exclusion criteria were as follows : presence of copd , atopic dermatitis , or both ; asthma exacerbation in the last four weeks ; presence of respiratory infection or use of antimicrobial agents in the last six weeks ; use of systemic corticosteroid therapy for seven or more days in the last four weeks ; history of immunodeficiency , neoplasia , connective tissue disease , kidney failure , sinonasal polyposis , chronic sinus disease , cystic fibrosis , or bronchiectasis ; pregnancy ; smoking in the last twelve months ; and declining to participate in the study or give written informed consent .  \nthe sample size calculation was based on a study by kowalski et al . \n  and was performed with a specific statistical calculation program ( openepi ) . for a paired relationship , with a 95% confidence interval and a power of 80% ,\nthe required sample size was calculated to be 140 ( 70 per group ) .  \nprocedures included the following : clinical history taking ; physical examination ; routine tests ( including blood count , esr measurement , determination of total ige levels , parasitological stool examination , chest x - rays , and sinus x - rays ) ; pulmonary function tests ( spirometry and pef measurement ) ; skin prick tests to aeroallergens ; and determination of serum levels of ige antibodies ( to sea , seb , sec , and tsst ) .\nspirometry was performed with a spirometer ( jaeger , wrzburg , germany ) , in accordance with the american thoracic society guidelines \n\n\n  and the reference values proposed by knudson et al . \n \na finding of obstruction and positive bronchodilator test results with reversal or significant improvement were consistent with asthma . \n\n\n  for pef measurement , a peak flow meter ( mini - wright afs ;\nclement clarke international , essex , england ) was used , the reference values being those proposed by nunn and gregg . \n \nskin tests to aeroallergens were performed with the use of the puncture technique and standard antigens . \n  for determination of serum levels of staphylococcal toxin - specific ige antibodies , an immunoassay system ( immunocap 100 ; phadia , uppsala , sweden ) was used . \n \n, we used the student 's t - test or the mann - whitney test , as appropriate , through the analysis of the kolmogorov - smirnov and shapiro - wilk coefficients . in order to compare categorical variables\n, we used the chi - square test or fisher 's exact test , as appropriate .\nthe sample size was calculated in order to provide a power of 80% , and values of p < 0.05 were considered statistically significant .  \nthe present study was approved by the research ethics committee of the federal university of rio de janeiro clementino fraga filho university hospital .\nall participating patients gave written informed consent , and the treatment provided to those who declined to participate in the study was in no way affected by their decision .\nthis was a cross - sectional study including adult patients clinically and functionally diagnosed with asthma and receiving outpatient treatment at the clementino fraga filho university hospital , located in the city of rio de janeiro , brazil . between 2009 and 2013 ,\nconsecutive patients were divided into two groups according to the clinical severity of asthma based on the global initiative for asthma criteria \n\n\n : the mild asthma ( ma ) group , comprising patients with mild intermittent or persistent asthma ; and the moderate or severe asthma ( msa ) group .   according to the global initiative for asthma\n, \n\n\n  asthma severity can be evaluated on the basis of the treatment required in order to control the disease .\npatients with mild asthma are defined as those requiring only rescue medication , low - dose inhaled corticosteroids / leukotriene receptor antagonists , or a combination of the two .\npatients with moderate asthma are defined as those using long - acting 2 agonists and inhaled corticosteroids at low or moderate doses .\npatients with severe asthma are defined as those using long - acting 2 agonists and inhaled corticosteroids at high doses or other bronchodilators and anti - inflammatory drugs for asthma control .  \nthe criteria for inclusion in the present study were as follows : being an adult patient clinically and functionally diagnosed with asthma , \n\n\n  regardless of the presence of rhinitis and positive skin test results to aeroallergens .  \nthe exclusion criteria were as follows : presence of copd , atopic dermatitis , or both ; asthma exacerbation in the last four weeks ; presence of respiratory infection or use of antimicrobial agents in the last six weeks ; use of systemic corticosteroid therapy for seven or more days in the last four weeks ; history of immunodeficiency , neoplasia , connective tissue disease , kidney failure , sinonasal polyposis , chronic sinus disease , cystic fibrosis , or bronchiectasis ; pregnancy ; smoking in the last twelve months ; and declining to participate in the study or give written informed consent .  \nthe sample size calculation was based on a study by kowalski et al . \n  and was performed with a specific statistical calculation program ( openepi ) . for a paired relationship , with a 95% confidence interval and a power of 80% ,\nprocedures included the following : clinical history taking ; physical examination ; routine tests ( including blood count , esr measurement , determination of total ige levels , parasitological stool examination , chest x - rays , and sinus x - rays ) ; pulmonary function tests ( spirometry and pef measurement ) ; skin prick tests to aeroallergens ; and determination of serum levels of ige antibodies ( to sea , seb , sec , and tsst ) . spirometry was performed with a spirometer ( jaeger , wrzburg , germany ) , in accordance with the american thoracic society guidelines \n\n\n  and the reference values proposed by knudson et al . \n \na finding of obstruction and positive bronchodilator test results with reversal or significant improvement were consistent with asthma . \n\n\n  for pef measurement , a peak flow meter ( mini - wright afs ;\nclement clarke international , essex , england ) was used , the reference values being those proposed by nunn and gregg . \n \nskin tests to aeroallergens were performed with the use of the puncture technique and standard antigens . \n  for determination of serum levels of staphylococcal toxin - specific ige antibodies , an immunoassay system ( immunocap 100 ; phadia , uppsala , sweden ) was used . \n \nin order to compare numerical variables , we used the student 's t - test or the mann - whitney test , as appropriate , through the analysis of the kolmogorov - smirnov and shapiro - wilk coefficients . in order to compare categorical variables\n, we used the chi - square test or fisher 's exact test , as appropriate .\nthe sample size was calculated in order to provide a power of 80% , and values of p < 0.05 were considered statistically significant .\nthe present study was approved by the research ethics committee of the federal university of rio de janeiro clementino fraga filho university hospital .\nall participating patients gave written informed consent , and the treatment provided to those who declined to participate in the study was in no way affected by their decision .\na total of 142 patients were studied . of those , 72 ( 17 with mild intermittent asthma and 55 with mild persistent asthma )\nwere allocated to the ma group and 70 ( 53 with moderate asthma and 17 with severe asthma ) were allocated to the msa group .\nthe median age was 52.5 years ( 46 years in the ma group and 56 years in the msa group ) , females and white individuals having predominated . in the sample as a whole , the mean body mass index ( bmi ) was 27.09 kg / m ,\n128 patients had rhinitis , 131 had positive skin test results to aeroallergens , and 99 had a family history of atopy . only 37 ( 26.1% ) had a history of smoking .\nmean percent predicted pef was 72.59% , mean percent predicted pre - bronchodilator fev1 was 71.55% , and mean percent predicted post - bronchodilator fev1 was 81.48% .\nmean eosinophil count was 4.4% , and mean total ige levels were 574.92 iu / ml .\ntable 1 shows the distribution of sociodemographic and clinical variables , and table 2 shows lung function parameters and laboratory findings in the ma and msa groups .  \n\nstudent 's t - test ( for age ) and chi - square test or fisher 's test ( for the remaining parameters ) . \n \n* student 's t - test ( for age ) and chi - square test or fisher 's test ( for the remaining parameters ) . \n\ntable 2lung function parameters and laboratory findings in the study population , by asthma severity . \n\nstudent 's t - test or mann - whitney test . of the sample as a whole ,\n62 patients ( 43.7% ) tested positive for staphylococcal toxin - specific ige antibodies : sea , in 29 ( 20.4% ) ; seb , in 35 ( 24.6% ) ; sec , in 33 ( 23.2% ) ; and tsst , in 45 ( 31.7% ) .\nthe mean serum levels of ige antibodies to sea , seb , sec , and tsst were 0.96 u / l , 1.09 u / l , 1.21 u / l , and 1.18 u / l , respectively .  \nas can be seen in tables 3 and \n , there were no statistically significant differences between the two groups regarding the frequency of ige - mediated sensitization and serum levels of staphylococcal toxin - specific ige antibodies .  \n\ntable 3frequency of ige - mediated sensitization to staphylococcal toxins in the study population , by asthma severity .\nsea : staphylococcal enterotoxin a ; seb : staphylococcal enterotoxin b ; sec : staphylococcal enterotoxin c ; and tsst : toxic shock syndrome toxin .\nsea : staphylococcal enterotoxin a ; seb : staphylococcal enterotoxin b ; sec : staphylococcal enterotoxin c ; and tsst : toxic shock syndrome toxin .\ntable 4serum levels of staphylococcal toxin - specific ige antibodies in the study population , by asthma severity .\nsea : staphylococcal enterotoxin a ; seb : staphylococcal enterotoxin b ; sec : staphylococcal enterotoxin c ; and tsst : toxic shock syndrome toxin . * chi - square test or mann - whitney test . \n \nsea : staphylococcal enterotoxin a ; seb : staphylococcal enterotoxin b ; sec : staphylococcal enterotoxin c ; and tsst : toxic shock syndrome toxin . * chi - square test or mann - whitney test .\nthere were statistically significant differences between the two groups of patients in the present study regarding their clinical and sociodemographic characteristics ( including age , bmi , and prevalence of rhinitis ) .\nthe fact that the patients in the msa were significantly older than were those in the ma group might be due to the fact that asthma tends to be more severe in older individuals , especially those in whom the onset of asthma occurred at an older age . \n\n\n \nour finding of a significantly higher bmi in the msa group is consistent with the literature , obesity having been reported to be a risk factor for and an aggravator of asthma .\nrecent studies have established a relationship between obesity - induced changes in the gastrointestinal and respiratory microbiome and the etiopathogenesis of obesity - related asthma . \n\n\n\n\n \nour finding of a higher prevalence of rhinitis in the ma group suggests that atopy was more common in the ma group than in the msa group , supporting the concept that atopic manifestations tend to be less common in asthma patients with disease that is more severe . \n\n\n\n  with regard to the lung function parameters assessed in the present study , absolute and percent predicted pef\nwere significantly lower in the msa group , as were percent predicted pre - bronchodilator fev1 and percent predicted post - bronchodilator fev1 .\nthese findings were expected and are consistent with the literature , showing the usual correlation between clinical severity and lung function parameters . \n\n\n\n  of the 142 patients studied , 62 ( 43.7% ) tested positive for staphylococcal toxin - specific ige antibodies , ige antibodies to tsst being the most prevalent .\nour findings are different from those of two studies in the literature and similar to those of two other studies . in one study , kowalski et al . found an 89.7% prevalence of positivity for staphylococcal toxin - specific ige antibodies in severe and non - severe asthma patients ; in another study , they found a 76.1% prevalence in patients with severe refractory asthma and a 71.1% prevalence in patients with non - severe asthma . \n\n\n \nin one study , bachert et al . found a 38.1% prevalence of positivity for staphylococcal toxin - specific ige antibodies in patients with asthma ( independently of disease severity ) and a 62% prevalence in patients with severe asthma ; in another study , they found a 59.6% prevalence in patients with severe uncontrolled asthma and a 40.8% prevalence in patients with controlled asthma , \n\n\n  the latter prevalence being closer to that found in the present study .  \naureus , such as sinonasal polyposis , bronchiectasis , chronic bronchitis , and atopic dermatitis , were not included in the present study . by facilitating colonization or infection with s .\naureus , the aforementioned conditions can lead to increased quantities of staphylococcal toxins in the body , resulting in increased ige - mediated sensitization and , consequently , a heterogeneous population of asthma patients .\nthe studies conducted by kowalski et al . \n\n\n  and bachert et al . \n\n\n  had no such exclusion criteria and included patients with chronic sinus disease and sinonasal polyposis , as was the case with the most recent study by kowalski et al . , \n  who nevertheless found no statistically significant differences between asthma patients with polyposis and those without regarding their levels of staphylococcal toxin - specific ige antibodies .\nthis might explain the differences between our results and those obtained by the two aforementioned groups of authors regarding the degree of ige - mediated sensitization .\naureus in the brazilian population ; therefore , it is currently impossible to determine whether or not it is lower than that in the european population .\nit is also impossible to determine whether the allergic immune response to staphylococcal toxins is lower in asthma patients in brazil than in those in other countries .   in the present study\n, there were no statistically significant differences between the two groups regarding the frequency of staphylococcal toxin - specific ige antibodies .\nour results are qualitatively similar to but quantitatively different from those obtained by kowalski et al . , \n\n\n  who found significantly higher levels of staphylococcal toxin - specific ige antibodies in patients with severe asthma .\nin addition , our results are qualitatively and quantitatively different from those obtained by bachert et al . \n\n\n \nthese differences are also due to the exclusion criteria used in the present study , which were not used in any of the aforementioned studies , and to specific characteristics of our study population , as previously mentioned .   in the present study , ige antibodies to sea , seb , sec , and tsst\nwere found in 62 ( 43.7% ) of the 142 asthma patients analyzed , and neither the frequency of staphylococcal toxin - specific ige antibodies nor the serum levels of those antibodies were associated with the clinical severity of asthma .\nthese results are extremely relevant because this is the first study on this topic in latin america , the results of which differed from those of previous studies conducted in europe , indicating a \" negative \" association\n.   the limitations of the present study lie in the fact that it was a single - center study conducted at a tertiary care university hospital , in a single demographic area of brazil .\nour primary objective was to evaluate the influence of serum levels of staphylococcal toxin - specific ige antibodies and their association with asthma severity , meaning that this was not a population prevalence study of ige sensitization in asthma patients and healthy individuals in our region . if that had been the case , a much larger sample size would have been required , and it would have been impossible to obtain that in a single - center study .\ntherefore , in the present study , each group served as the control group for the other , without the use of a third group , comprising healthy individuals .  \nmulticenter studies in brazil and other latin american countries are needed in order to determine more accurately the role of ige - mediated sensitization to staphylococcal toxins as an aggravator of asthma , as well as to determine its prevalence in asthma patients and healthy individuals .\nsuch studies should include asthma patients with and without diseases that can lead to increased colonization or infection with s ."}
{"lay_summary": " background : since the family is a social system , the impairment in each of its component members may disrupt the entire family system . \n one of the stress sources for families is accidents leading to hospitalization particularly in the intensive care unit ( icu ) . in many cases , \n the families needs in patient care are not met that cause dissatisfaction . since the nurses spend a lot of time with patients and their families , they are in a good position to assess their needs and perform appropriate interventions . \n therefore , this study was conducted to determine the effectiveness of nursing interventions based on family needs on family satisfaction level of hospitalized patients in the neurosurgery icu.materials and methods : this clinical trial was conducted in the neurosurgery icu of al - zahra hospital , isfahan , iran in 2010 . \n sixty four families were selected by simple sampling method and were randomly placed in two groups ( test and control ) using envelopes . in the test group , \n some interventions were performed to meet their needs . in the control group , \n the routine actions were only carried out . \n the satisfaction questionnaire was completed by both groups two days after admission and again on the fourth day.findings:both of the intervention and control groups were compared in terms of the mean satisfaction scores before and after intervention . \n there was no significant difference in mean satisfaction scores between test and control groups before the intervention . \n the mean satisfaction score significantly increased after the intervention compared to the control group.conclusions:nursing interventions based on family needs of hospitalized patients in the icu increase their satisfaction . \n attention to family nursing should be planned especially in the icus . ", "article": "the family is the cornerstone of human social support network and its presence is essential in everyone s life . changes inevitably occur in families with illness and hospitalization of a family member . in other words , among the sources of stress for families are accidents leading to hospitalization particularly intensive care unit ( icu ) .\nstatistics show that 8% of hospital beds in the united states are occupied by the intensive care units .\nstress in the family while the patient is in the icu can disrupt the harmony power of the family members and finally , it may causes disturbances in the support of the patient .\nin addition to the various sources of stress in intensive care units such as the patient s fear of death , financial problems , lack of awareness about the environment and etc . , their satisfaction level is another important source of stress for the patient s family .\ntoday , the family needs of hospitalized patients in the icu are summarized in five sections .\nthese factors may include receiving assurance , staying close to the patient , receiving information , feeling comfortable and receiving support .\nhowever , in many cases , the patient s family needs and their expectations in the icu will not be fulfilled which will cause dissatisfaction . since , how families deal with mental stress is the most important components of comprehensive care , it should be known that attention to the family needs of the patients hospitalized in intensive care units could increase their satisfaction and thus a reduction in stress disorders .\nstudies showed that the nurses in particular sections focus primarily on the patient and the disease .\ntherefore , attention to the families should be considered as an important part in patient management .\neffective interventions targeted at the needs and expectations of family members should help to reduce the stress and improve their satisfaction .\nfox et al . stated that the needs of the family members were not often overlooked by the nurses .\nhowever , the nurses spend a lot of time with the patients and their families and are in a good position to assess their needs and plan for meeting these needs with appropriate interventions .\nthe reason of investigating the satisfaction of the families of the patients in the icu is that the patients are facing life - threatening illness experiences and complex treatments , different technologies and different equipment are used for them .\nthese cases could potentially lead to the dissatisfaction of their families . in the meantime ,\nthe families of trauma and neurosurgical patients are more vulnerable than the other groups of patients .\nthey need supports that are more emotional and should be accepted by the icu staff . today , there are many theories expressed that in intensive care units , the patient and his family should be considered as a single unit . by providing care to this unit ,\nthe aim of this study was to analyze the satisfaction of the families of icu patients .\nthe tool of society of critical care medicine s family needs assessment ( sccmfna ) ( which has been validated in 1998 by johnson ) was used in that study .\nthe results showed that most of the family satisfaction was related to the communication and patient care and the lowest level of satisfaction was about the ability of staff to patients family comfort .\nbailey et al . have conducted a study in 2009 with the purpose of investigating the relationship between informational support to families of special care patients and their anxiety and satisfaction .\nthey showed that there is a direct link between the informational support and their satisfaction .\nthe study of fumis et al . in 2008 also showed that the increase in the availability of physicians for giving the information to the patient s family and as well as nurses efforts to provide understandable explanations about the patient s condition to them will increase the patient s family satisfaction .\nthis clinical trial was performed with respect to the existing gap for a study carried out for investigating the interventions for the satisfaction of the patients in the special care units and their families in iran .\nthe purpose of the study was to determine the effectiveness of nursing interventions based on family needs on family satisfaction level of hospitalized patients in the neurosurgery intensive care unit of al - zahra hospital in 2010 .\nthe statistical research community was the families of hospitalized patients in neurosurgery intensive care unit of al - zahra ( sa ) hospital , isfahan , iran from may to september 2010 .\nwith respect to inclusion criteria , the families of 64 patients were selected with simple sampling . after obtaining the informed consents from the hospitalized patients , by using the envelopes , which were prepaid by using a table of random numbers , they were divided into two groups ( intervention and control ) .\nthe inclusion criteria was included as the following cases : to be a first - degree member of the family , to be older than 18 years , willing to participate in the study , having the power to speak and write in farsi , to be hospitalized one day before the study , lack of physical or mental problem in the family member , no responsibility for the care of another patient , introduced as the first person responsible for the patient care .\nobtaining the written informed consent , completion of the questionnaires about demographic information and the families satisfaction were performed in the second day of hospitalization of the patients in icu in both groups .\njohnson questionnaire for the satisfaction of the family of icu patients was used to measure the family satisfaction .\nthe rating of the questionnaire was performed by using the likert scale with four options of 0 to 4 as follows : almost all the time ( 3 scores ) , often ( 2 scores ) , only occasionally ( 1 score ) and never ( zero score ) .\njohnson s questionnaire was the modified type of multer patient s family needs , which was evaluated in various scientific researches and there are extensive evidences for its validity .\nthe interventions were performed in the second and the third day of hospitalization of the patient in the neurosurgery icu by the researcher in the morning shift for the intervention group .\nthus , the researcher provided understandable explanations about the disease to the patient s family and answered honestly to the questions about the patient and the disease .\nthe researcher ensured them for providing the best care in the section and spoke about the prognosis of the disease .\nthe researcher took the family member to the patient s room and gave the necessary information about the room space , equipment , personnel departments and the actions that were done for the patient .\nthe patient family member was contacted if there was a change in the patient condition .\nthey let the family help the patient in some cases of the public health ( such as hand and foot massage and giving food ) .\nlocations of rest , nutrition , prayer room , bathroom and buffet of the hospital were introduced to them .\nthe telephone numbers of hospitals and wards ( and if necessary , the social worker and supervisor ) were given .\nvarious departments and personnel of the hospital were taught to accept the families and communicate with them . the hospital social worker was introduced and if necessary , the patient s family was allowed to express their feelings .\nthese interventions were performed in the evening shift of the second and the third day of the patient reception .\nthe actions were carried out by the fellow researcher . while , for the control group , only the routine work was done . on the fourth day , the satisfaction survey was completed by the selected family member in both of the intervention and control groups .\nstatistical methods used in this study were 2 test , man - whitney , independent student s t - test and paired t - tests .\nthe findings did not show statistically significant difference in the demographic characteristics of the intervention and control groups , such as : age ( p < 0.99 ) , gender ( p < 0.79 ) , marital status ( p < 0.41 ) , educational level ( p < 0.12 ) and relation with patient ( p < 0.54 ) . as shown in table 1\n, there was no significant difference in the mean satisfaction score before the intervention in the intervention and control groups ( p > 0.05 ) .\nthe mean satisfaction score after the intervention in the intervention group was significantly more than the control group ( p < 0.001 ) .\nthe mean satisfaction score in the intervention group after the intervention was significantly higher than before the intervention ( p < 0.001 ) .\nthere was no significant difference in the mean satisfaction score in the control group before and after the intervention ( p > 0.05 ) ( table 2 ) .\ncomparison of mean satisfaction score ( 100 * ) of participants in the intervention and control groups the mean of satisfaction score changes of the studied subjects in the intervention and control groups after intervention\nthe results of the present study showed that the nursing interventions based on the family needs increased the patient s family satisfaction in the neurosurgery intensive care unit of al - zahra hospital .\ndue to the differences in the study design , study population , the number of samples and methods of intervention , it would be difficult to compare the results . in chien et al .\nstudy , the results showed that performing the training based on the patients family needs in the icu , decreased the anxiety and increased their satisfaction . in the study of myhren et al . indicated that effective communication of the staff with the families of icu patients would increase their satisfaction .\nin the study by rosher and robinson , it showed that involving the families in patient care led to increase their satisfaction than before the intervention .\nthe mentioned results were consistent with the results of this study , because all of these interventions were some parts of the interventions performed in this study .\nhowever , the study of steele et al . indicated that clinical training had no impact on the family satisfaction of the patient hospitalized in the icu\n. therefore , there was no statistically significant difference in the satisfaction level in the control and intervention group .\nin this study , it was shown that the use of nursing interventions based on family needs ( confidence , support , information , proximity and convenience ) had significant impact on the family satisfaction of the patient hospitalized in intensive care unit .\nthey should be based on the family investigation and recognition and their priority needs should be determined in order to cause the greatest satisfaction .\nthe icu nurses must also accept their role in the care of patient s family members .\nthe findings of this study could be a basis for performing further studies about family needs of the patients in the icu especially with the different forms of culture and economy .\nconsequently , the increase in family satisfaction of patients can reduce the stress disorders and improve their mental state and ultimately better support of the patient by the family .\nthis study only examined the effect of nursing interventions in the first days of hospitalization on the satisfaction of the families but the effects on the patient s entire hospitalization period has not been assessed . by performing other researches in this field\n, it would be possible to compare the differences in the effects of nursing interventions based on the needs of families in the early days and the whole period of the patient s hospitalization ."}
{"lay_summary": " background and objective :   anxiety and depression are among the psychological disorders in heart \n surgeries . establishing a simple communication is essential to reduce anxiety and depression . \n hence , the objective of the present studywas to examine the impact of peplau therapeutic communication model on anxiety and depression in patients , who were candidate for coronary artery bypass in al - zahra heart hospital , shiraz during 2012 - 2013 . \n \n methods :   this is a clinical trial in which 74 patients were randomly divided into intervention and control groups , each consisted of 37 patients . anxiety and depression levels were assessed before , and two and four months after intervention using the hospital anxiety and depression scale ( hads ) . \n seven therapeutic communication sessions were held in four stages . \n data were analyzed with the spss ( version 16 ) using analysis of covariance . \n results :   the mean anxiety and depression levels decreased in the intervention group after the therapeutic communication ( p<0.01 ) . \n anxiety scores in the intervention group before and after intervention were 10.23 and 9.38 , respectively . while the corresponding scores in the control group were 10.26 and 11.62 , respectively . \n depression scores in the intervention group before and after intervention were 11 and 9.13 , respectively . \n the corresponding scores in the control group were 11.30 and 12.08 , respectively . \n conclusion :   the results demonstrated the positive role of therapeutic communication in reducing anxiety and depression of the patients . \n therefore , the therapeutic communication is recommended as a simple , cost effective and efficient method in this area . \n ", "article": "development of human societies and industrialization as well as changes in stress sources has changed disease pattern in civilized societies . as a result , the disease pattern has changed from traditional diseases such as infectious diseases and malnutrition to diseases such as heart disease , diabetes , accidents and so forth . among them\ncoronary artery disease is the most cardiovascular disorder as a health problem in developing and developed countries .\nin fact , this is not only a chronic disease associated with high mortality , but it causes limitations in life and disability in a large part of the productive forces of the country .\nit is also associated with reduced production and increased medical costs [ 3 - 5 ] . nowadays ,\ncardiovascular diseases are among the most widespread chronic diseases in most countries . according to forecasts ,\nthe mortality rate in eastern mediterranean countries including iran will be 30 - 35% [ 6 , 7 ] . despite the emphasis on prevention and development of newtreatments , surgery is the only choice for many patients with cardiovascular disease .\none of the surgical procedures for the treatment of cardiovascular patients is coronary artery bypass surgery .\nin fact , heart surgery significantly influences on the quality of life of patients with cardiovascular diseases .\nhence , heart surgery is an important event in the lives of patients causing collapse of economic , professional and personal life . on the other hand , each surgical procedure\nis associated with several psychological complications for patients . of the most important complications are anxiety and depression so that approximately 65% of cardiovascular patients experience them after surgical and medical interventions .\nin fact , anxiety and depression complicate the treatment process [ 7 , 8 ] .\nsome scientists believe that anxiety is one of the essential elements of human life . however , acute and long - term anxiety is integral part of all psychological diseases . according to nemati and colleagues ,\nin fact , anxiety is a common psychological response of cardiovascular patients which is associated with reduced quality of life and psychological morbidity [ 11 , 12 ] . on the other hand ,\nanxiety causes increased heart rate and breathing as well as high blood pressure and even mortality .\nit is associated with increased risk of mortality , disability , increased medical care and functional impairment in daily activities [ 12 , 13 ] . clinical depression has been reported in 54% of patients after bypass surgery . according to world health organization ( who ) , depression is the fourth chronic disease where its disability is comparable with 8 major chronic disorders .\nthe outcome of depression in patients with cardiovascular disease is deterioration of physical and emotional state . given the incidence of such complications in patients with cardiovascular disease\nthe best practice in this area is appropriate communication with patient [ 13 , 15 ] .\ngood and effective communication is very valuable from the perspective of patients . in general , communication is a set of learning skills .\nin fact , poor communication is the cause of most problems in treatment of patients .\nin fact , communication at the bedside is a therapeutic and professional communication . in health professionals ,\ncommunication and communication skills play a very important role in satisfaction of patients and solving their problems .\nthis is more important , especially in patients with chronic diseases or those requiring long - term care .\nthe therapeutic communication is formed from the first encounter of the patient with the medical team [ 21 , 22 ] .\nhowever , studies have shown that the communication between patient and medical team is not efficient .\nthe health personnel don not have adequate communication skills . in fact , nursing and medical team spend very little time to communicate with patients .\naccordingly , patients are not often satisfied with received information as well as the level and method of communication .\nhence , to achieve best therapeutic results , special attention should be paid to communication [ 16 , 19 , 22 ] .\nsince nursing is a practical discipline based on professional knowledge , it is necessary to use knowledge infrastructure to develop new approaches in clinical practice .\ntheories proposed by nursing scientists can be useful in this area [ 16 , 19 , 23 ] . for this purpose\nthe nurse - patient communication is an essential element of this theory [ 21 , 24 ] . according to peplau theory ,\nthe purpose of nursing care is to achieve a common good nurse - patient communication . according to peplau ,\npeplau refers to the importance of therapeutic communication with patients and its important role in reducing anxiety [ 21 , 23 , 24 ] .\nin fact , this theory provides a framework for nurse - patient communication . following this framework\n, the nurse will be able to respond communication needs of patients through establishing a good therapeutic communication with the patient [ 16 , 19 , 23 ] .\nhospitalization and a complex surgery such as heart surgery is a stressful process leading to depression in patients .\nfurthermore , the need for security and psychological comfort is one of the basic needs of patients achieved through a proper structured therapeutic communication with low cost .\naccordingly , the objective of the present study is to examine the impact of peplau therapeutic communication model on anxiety and depression in patients who were candidate for coronary bypass surgery .\nthis is a clinical trial with pre / post testing scheme examined the impact of independent variable ( peplau therapeutic communication ) on the dependent variables ( anxiety and depression ) .\nthe population consisted of all patients who were candidates for coronary artery bypass referred to the research environment on non - emergency basis .\nthe research environment was al - zahra heart hospital in shiraz due to the easy access to subjects and sufficient number of patients .\ndata were collected using the hospital anxiety and depression scale ( kanter et al . ) .\nthe reliability and validity of the scale have been studied by montazeri et al in 2003 .\nan internal consistency of 78% and 86% was respectively calculated for anxiety and depression using cronbach 's alpha .\nthere are 14 four - option questions , each with a score of zero to 3 .\nodd and even questions are used to measure anxiety and depression , respectively ( seven questions to assess anxiety and seven questions to assess depression ) .\na score of zero to 21 is given to each patient based on responses in each area ( a score of zero - seven : normal , eight-10 : moderate and > 10 : disease ) .\ndue to the lack of access to error rate to calculate the sample size , 10 patients were selected as pilot ( with a depression and anxiety score of 10 or more based on the hospital anxiety and depression scale ) . after performing tests ,\nthe subjects were randomly divided into test and control groups ( using a coin ( toss ) ) .\nz12+z12s12+s22x1x22 the inclusion criteria were : being in a bypass list , having moderate to severe depression and anxiety scores , no history of mental illness , interesting in participating in the study ( i.e. the tendency of the patient and his family to participate in the intervention ) , lack of previous bypass surgery , aged between 35 and 70 years , ability to communicate verbally and ability to speak persian .\nthe exclusion criteria included : lack of cooperation of patients and families during the intervention , failure to perform coronary artery bypass surgery for various reasons , mortality during the study , failure to attend therapeutic communication sessions ( at least the absence in two sessions ) .\ntherapeutic communication sessions were held for the intervention group based on peplau 's model at four stages including : orientation , identification , exploitation and resolution . in total , seven sessions were held individually with the consent of the patient and his family at the hospital and patient 's home\n. it should be notedthat during therapeutic communication , duration of each session was variable given the location and patient 's needs .\nthe place of each meeting was determined with the consent of the patient . at all meetings , the researcher used verbal and nonverbal communication skills to communicate with patients . to ensure the correct application of therapeutic communication skills , a self - control researcher - made tool approved by experts was used .\nthe depression and anxiety of patients in both groups were assessed using the hospital anxiety and depression scale ( hads ) at baseline and then two and four months after surgery .\nthe obtained data were analyzed using descriptive statistics as well as covariance analysis with the help of spss 16 .\nthis study was approved by the ethics committee of the jondi shapoor medical university of ahvaz with rec.1392.58 code .\nthe ethical issues considered in this study include an adequate explanation for the patients and their permission to participate in the study , the lack of any compulsion for patients to participate in the study , refusing to disclose secrets or private matters of patients and confidentiality of information , announcing the results without names and personal details .\nfurthermore , the present study was registered with the irct2013072214110n1 code in clinical trial center ( irct.ir ) .\nthis study was approved by the ethics committee of the jondi shapoor medical university of ahvaz with rec.1392.58 code .\nthe ethical issues considered in this study include an adequate explanation for the patients and their permission to participate in the study , the lack of any compulsion for patients to participate in the study , refusing to disclose secrets or private matters of patients and confidentiality of information , announcing the results without names and personal details .\nfurthermore , the present study was registered with the irct2013072214110n1 code in clinical trial center ( irct.ir ) .\nthe percentage of male and female patients in the intervention group was 70.3% and 29.7% , respectively .\nthe percentage of males and females in the control group was 51.4% and 48.6% , respectively .\nthe status of the underlying disease was depicted in both intervention and control groups . according to results\n, the majority of patients were suffering from high blood pressure in both groups with a high frequency of 35.1% ( table 1 ) .\nas shown in table 2 , anxiety was reduced in the intervention group , while postoperative anxiety in the control group was increased . the hospital anxiety in the intervention group\nthis indicates the role of peplau 's therapeutic communication in reducing hospital anxiety of patients .\nanalysis of covariance was used to determine the effect of peplau 's therapeutic communication on anxiety level of the subjects . since\nhospital anxiety scale was used to measure anxiety , analysis of variance was performed using hospital anxiety scores .\nthe results showed significant differences between experimental and control groups in terms of anxiety level immediately after surgery , two and four months after surgery after adjustment for post - test scores by eliminating the effect of pre - test .\nadjusted mean anxiety scores suggest that anxiety in the intervention group was lower than the control group .\nin fact , the mean anxiety scores of patients in the intervention group in pre - test and post - test stages represent the independent role of peplau 's therapeutic communication model in reducing anxiety in the intervention group ( f=174.02 , p=0.000 ) .\nmoreover , the anxiety level in the intervention group two and four months after the intervention was decreased compared to the control group ( f=38.37 , p=0.000 ; f=11.58 , p=0.000 ) ( table 3 ) . as shown in table 4 , the mean depression in the intervention group was reduced after the surgery . the mean postoperative depression in the control group was increased .\nin fact , the hospital depression in the intervention group was reduced after the therapeutic communication .\nthis indicates that the role of peplau 's therapeutic communication model in reducing hospital depression .\nanalysis of covariance was used to determine the effect of peplau 's therapeutic communication on depression level of the subjects . since\nhospital depression scale was used to measure depression , analysis of variance was performed using hospital depression scores .\nthe results showed significant differences between experimental and control groups in terms of depression level immediately after surgery , two and four months after surgery after adjustment for post - test scores by eliminating the effect of pre - test .\nadjusted mean depression scores suggest that anxiety in the intervention group was lower than the control group .\nin fact , the mean depression scores of patients in the intervention group in pre - test and post - test indicate the independent role of peplau 's therapeutic communication model in reducing depression in the intervention group ( f=163.27 , p=0.000 ) . such a difference is not observed in the control group .\nmoreover , the depression level in the intervention group four months after the intervention was decreased compared to the control group ( f=20.58 , p=0.000 ) . however , no significant difference was found between two groups in terms of hospital depression two months after intervention ( p=0.61 ) ( table 5 ) .\naccording to the results , peplau 's therapeutic communication is effective in reducing anxiety and depression in patients who were candidate for coronary artery bypass .\nit resulted in a dramatic decrease in anxiety and depression scores in the intervention group .\ndepression and anxiety are the most important preventive factors in cardiovascular diseases   causing disease rejection by the patient and reduce the incentive to treat and increase the likelihood of disease recurrence [ 25 - 27 ] .\nmost patients with coronary heart disease who survive after surgery resume their normal life after several weeks or several months .\nprevious studies show that patients suffer from anxiety and depression several months and sometimes several years after the surgery [ 26 , 27 , 29 ] .\ntherefore , follow - up and strategies to deal with postoperative psychological complications are of utmost importance .\nit is not possible except through establishing a coherent and targeted therapeutic communication . indeed , effective communication enables the medical team to identify patients needs and take steps to solve problems and meet their needs . according to dadashi , hosseini and moghaddam ( 2009 ) , staff had close encounters with patients in 85.5% of cases .\naccording to mastaneh and mouseli ( 2013 ) , the rate of respecting patient rights in terms of communication was 60% indicating a moderate level of communication skills . on the other hand , duration and how to communicate with patients , particularly in dealing with patients with chronic diseases are essential in the hope and positive attitude to treatment and follow - up after discharge [ 29 - 31 ] .\nin fact , the patient gains motivation to cope with illness and trust in nurses through proper therapeutic communication , because the care of patients with either physical or mental illness requires correct and consistent communication [ 30 , 31 ] .\ntherefore , implementing a communication pattern will help medical team to establish a proper communication .\npeplau 's model is one of these communication patterns . to communicate with patients , especially patients with chronic diseases ,\npeplau 's described four stages and defined roles for the nurse at every step as someone who is in close relationship with the patient [ 16 , 23 ] .\npeplau 's communication model helps nurses and patient to identify the disease , concerns and questions of the patient . through defining different roles for the nurse\nthis model refers to nursing skills and abilities to establish a simple convenient therapeutic communication .\nthe model enables nurses help the patient after discharge and to spend more time with patient [ 16 , 23 , 24 ] .\nfor example , it has been used in communicating with cancer patients and solving systematic problems of families [ 32 , 33 ] . in this study ,\npeplau 's communication models were employed as communication sessions for patients who were candidates for coronary artery bypass through applying nursing roles .\nthe results showed that holding communication meetings with patients immediately after surgery dramatically reduced hospital anxiety and depression .\naccordingly , to improve the nurse - patient communication and establish more effective therapeutic communication processes which improves clinical basis and can have a positive impact on the treatment and discharge processes and rehabilitation of patients , especially in patients with chronic diseases , training courses should be included in in - service courses to train and introduce medical team with simple and inexpensive communication skills .\nfurthermore , there is evidence that workshops on communication skills for health team can improve health outcomes and satisfaction of patients .\nanother limitation of this study is the lower percentage of females ( 29.7% ) in the intervention group with respect to the control group ( 51.4% ) .\nthe lower anxiety score in the intervention group could be due to therapeutic communication but also to gender differences .\nto write this article not contributed any financial resources and costs are the responsibility of the authors .\nall rights of this article reserved is owned by the ahvaz jundishapur university of medical sciences ."}
{"lay_summary": " worldwide emergence of variant viruses has prompted a change in the 20052006 h3n2 influenza a vaccine strain . ", "article": "sixty - four patients in nepal that met us department of defense enrollment criteria ( 9 ) for influenzalike illness were evaluated by using onsite rapid influenza tests ( optical immunoassay rapid diagnostic tests , thermo electron corp .\nthroat swab specimens were collected within the first 72 hours of onset of symptoms , routed through the armed forces research institute for medical sciences in bangkok , thailand , and shipped on dry ice to brooks city base in san antonio , texas , for clinical characterization and diagnosis using traditional culturing techniques and monoclonal antibody staining ( 10 ) .\nantigenic analysis of select isolates was performed at the centers for disease control and prevention ( cdc ) in atlanta , georgia , by using the hemagglutination inhibition ( hi ) assay and postinfection ferret antisera ( 11 ) .\nrna was extracted from 48-hour shell vial cultures ( 10 ) by using the magnapure lx ( roche molecular , mannheim , germany ) and rna isolation kit ii ( roche molecular ) according to the manufacturer 's protocols . for reverse transcription - polymerase chain reaction ( rt - pcr ) amplification ,\n5 l rna was added to a 50-l master mixture containing 1 reaction buffer , 1.6 mmol / l mgso4 , 1 enzyme mixture , and 400 nmol / l primers ( h3-f7 , 5-act - atc - att - gct - ttg - agc-3  and h3r-1184 , 5-atg - gct - gct - tga - gtg - ctt-3  ) by using the superscript iii one - step rt - pcr system ( invitrogen , carlsbad , ca , usa ) .\npcr thermocycling consisted of an rt step at 50c for 30 min , hot start activation at 95c for 3 min , followed by 40 amplification cycles of 95c for 30 s , 52c for 15 s , and 68c for 1 min , with a final extension cycle at 68c for 7 min .\nall pcr products were visualized after electrophoresis in 2% precast gels stained with ethidium bromide ( invitrogen ) under uv illumination .\nthe ha1 amplicon ( 1177 bp ) was sequenced by using the h3-f7 and h3r-1184 pcr primers ( described above ) and 2 additional internal oligonucleotides , h3r-466 ( 5-ggt - gca - acc - aat - tca - atc-3  ) and h3f-282 ( 5-cag - caa - ctg - tta - ccc-3  ) .\nunincorporated fluorescent nucleotides were removed by using a dye ex 96-well plate kit ( qiagen ) according to the manufacturer 's recommendations .\nnucleotide sequencing was performed by using the big dye terminator v3.1 kit and analyzed by using an abi 3100 genetic analyzer ( both from applied biosystems , foster city , ca , usa ) according to the manufacturer 's specifications .\nmultiple sequence alignments , protein translation , and phylogenetic analysis were performed with the dnastar ( dnastar inc . ,\nthree - dimensional ha protein structures were generated by using molmol ( 12 ) and the swiss - pdb viewer programs ( 13 ) .\nha nucleotide sequences for all 26 nepal isolates depicted in the phylogenetic analysis are available from genbank under accession nos .\nsixty - four patients in nepal that met us department of defense enrollment criteria ( 9 ) for influenzalike illness were evaluated by using onsite rapid influenza tests ( optical immunoassay rapid diagnostic tests , thermo electron corp .\nthroat swab specimens were collected within the first 72 hours of onset of symptoms , routed through the armed forces research institute for medical sciences in bangkok , thailand , and shipped on dry ice to brooks city base in san antonio , texas , for clinical characterization and diagnosis using traditional culturing techniques and monoclonal antibody staining ( 10 ) .\nantigenic analysis of select isolates was performed at the centers for disease control and prevention ( cdc ) in atlanta , georgia , by using the hemagglutination inhibition ( hi ) assay and postinfection ferret antisera ( 11 ) .\nrna was extracted from 48-hour shell vial cultures ( 10 ) by using the magnapure lx ( roche molecular , mannheim , germany ) and rna isolation kit ii ( roche molecular ) according to the manufacturer 's protocols . for reverse transcription - polymerase chain reaction ( rt - pcr ) amplification ,\n5 l rna was added to a 50-l master mixture containing 1 reaction buffer , 1.6 mmol / l mgso4 , 1 enzyme mixture , and 400 nmol / l primers ( h3-f7 , 5-act - atc - att - gct - ttg - agc-3  and h3r-1184 , 5-atg - gct - gct - tga - gtg - ctt-3  ) by using the superscript iii one - step rt - pcr system ( invitrogen , carlsbad , ca , usa ) .\npcr thermocycling consisted of an rt step at 50c for 30 min , hot start activation at 95c for 3 min , followed by 40 amplification cycles of 95c for 30 s , 52c for 15 s , and 68c for 1 min , with a final extension cycle at 68c for 7 min .\nall pcr products were visualized after electrophoresis in 2% precast gels stained with ethidium bromide ( invitrogen ) under uv illumination .\nthe ha1 amplicon ( 1177 bp ) was sequenced by using the h3-f7 and h3r-1184 pcr primers ( described above ) and 2 additional internal oligonucleotides , h3r-466 ( 5-ggt - gca - acc - aat - tca - atc-3  ) and h3f-282 ( 5-cag - caa - ctg - tta - ccc-3  ) .\nunincorporated fluorescent nucleotides were removed by using a dye ex 96-well plate kit ( qiagen ) according to the manufacturer 's recommendations .\nnucleotide sequencing was performed by using the big dye terminator v3.1 kit and analyzed by using an abi 3100 genetic analyzer ( both from applied biosystems , foster city , ca , usa ) according to the manufacturer 's specifications .\nmultiple sequence alignments , protein translation , and phylogenetic analysis were performed with the dnastar ( dnastar inc . , madison , wi , usa ) software package .\nthree - dimensional ha protein structures were generated by using molmol ( 12 ) and the swiss - pdb viewer programs ( 13 ) .\nha nucleotide sequences for all 26 nepal isolates depicted in the phylogenetic analysis are available from genbank under accession nos .\nclinical evaluations and throat specimens were obtained from 64 patients from 3 refugee camps in southeastern nepal ( figure 1 ) .\nof the 64 patients , 61 were refugees from bhutan , 1 was a foreign aid worker from japan , and 2 were nepalese nationals .\nmost of the patients were < 10 years of age ; 36 were male and 28 were female .\nnone had previously been vaccinated against influenza and of the 64 specimens collected , 42 ( 66% ) tested positive for influenza a by culture .\nthe green circle shows the location of 3 bhutan refugee camps where the outbreak occurred in early july 2004 .\n( map courtesy of http://www.maps.com ) hi was performed by using postinfection ferret antisera with reference antigens that included the 20042005 h3n2 vaccine seed strain ( a / wyoming/03/2003 ) and the 20052006 southern hemisphere h3n2 vaccine strain ( a / wellington/1/2004 ) . when compared with a / wyoming/03/2003 , 4 of 9 nepal isolates showed 4-fold lower titers ( 1:320 versus 1:1,280 hi units ) than that allowed for homologous titer of the reference antisera .\nsix of 9 nepal isolates were antigenically distinct when compared with the a / wellington/1/2004 strain and showed a 4-fold ( 1:160 versus 1:640 ) reduction in titer to ferret antisera ( table 1 ) .\n* test antigens are considered antigenically different from the reference strain if hi titers show a 4-fold difference .  a\nrt - pcr - based molecular subtyping showed that all 42 specimens were the h3n2 influenza subtype .\ntwenty - six of the 42 influenza a  positive samples were randomly selected for molecular characterization using direct nucleotide sequencing of the ha gene .\nthe 26 nepal isolates exhibited 99.8% nucleotide sequence identity and contained the fujian - like amino acid substitutions at positions 155 ( h155 t ) and 156 ( q156h ) in the ha protein ( table 2 ) .\nalignment of the 329amino acid ha protein from 26 isolates obtained from this outbreak with the 2004/05 a / wyoming/3/03 vaccine strain and previous h3n2 vaccine strains indicated 4 evident amino acid changes present in most of the isolates ( table 2 ) .\nall 4 amino acid changes observed within most of these outbreak isolates are present within a / california/7/04 , a variant strain selected as the h3n2 vaccine strain for the 20052006 influenza season . *\nn , asparagine ; t , threonine ; h , histidine ; i , isoleucine ; p , proline ; k , lysine ; s , serine ; v , valine ; q , glutamine . \nconsensus sequence derived from a multiple sequence protein alignment of 26 ha1 hemagglutinin sequences from nepal .\nof the 26 nepal strains examined , 24 exhibited a novel lysine - to - asparagine substitution at position 145 in the ha protein ( k145n ) .\nthis substitution is noteworthy because most strains characterized in 20032004 , including the fujian/411/2002 vaccine strain , contained a lysine ( k ) at this position .\nprior to this outbreak , the us department of defense had only observed k145n substitutions in 6 strains obtained from ramstein , germany , ( data not shown ) in june 2004 .\nadditionally , all 26 nepal sequences exhibited a serine - to - asparagine substitution at position 189 ( s189n ) that had also been observed in the 6 isolates from germany , as well as in a few isolates from asia characterized at the end of the 20032004 influenza season .\ntwo other substitution mutations in the ha1 hemagglutinin , i.e. , valine to isoleucine at position 226 ( v226i ) and serine to proline at position 227 ( s227p ) , were also observed in 24 ( 92% ) and 26 of 26 of the nepal isolates , respectively .\nboth substitutions differ from most influenza a h3n2 field isolates collected in 20032004 , including the fujian and wyoming vaccine strain for 20042005 ( table 2 ) .\nthe phylogeny of h3n2 ha proteins indicates a drifting of the nepal isolates from the a / fujian/411/03 and a / wyoming/03/03 vaccine strains and shows that these outbreak isolates have a higher genetic homology to a / wellington/1/04 , a prototype strain selected as the 20052006 southern hemisphere h3 vaccine strain ( figure 2 ) .\nthe a / wellington/1/04 strain contains 2 of the 4 amino acid changes ( s227p and s189n ) observed in the nepal isolates , but does not contain the k145n and v226i substitutions .\nunrooted phylogenetic analysis of ha1 hemagglutinin nucleotide sequences from 26 nepal isolates and h3n2 vaccine and reference strains .\nthe nepal isolates have drifted from the 20042005 a / fujian/411/03 vaccine strain ( and a / wyoming/03/03 vaccine seed strain ) and are genetically equivalent to a / california/7/04 , the 20052006 northern hemisphere vaccine strain . a k145n substitution ( branch point indicated by the arrow )\nwas observed in 24 of 26 nepal isolates and represents a genetic marker for the dominant lineage of h3n2 viruses during the 20042005 season .\nnucleotide and amino acid sequences for all nepal isolates are available from genbank under accession no .\nthe asterisk indicates isolates from table 2 that were antigenically distinct from a / wyoming/303 .\nthree - dimensional views of influenza ha proteins highlighting amino acid changes in a representative nepal isolate and the a / wyoming/3/03 vaccine strains are shown in figure 3a and b , respectively .\nthe mutation at position 145 ( shown in yellow ) , which is located adjacent to antibody - binding site a and within a known glycosylation site , introduces an asparagine - for - lysine substitution .\nthis substitution results in a more accessible receptor - binding cleft located directly above residue 145 ( comparing panels a and b ) . located above the receptor - binding pocket is a serine - to - asparagine change ( shown in green ) that possibly alters the regional surface topography at position 189 within antibody - binding site b. a serine - to - proline mutation at position 227 ( shown in magenta ) appears to marginally affect the ha surface features .\nthis substitution resides within antibody - binding site d , which corresponds to residues 225228 , which make up the left side of the receptor - binding pocket ( 14 ) .\ninterestingly , this proline residue is located within a  barrel ( a protein motif consisting of an antiparallel  sheet domain ) and does not appreciably alter the predicted protein structure , as shown by the absence of any substantial changes in the computer - modeled , 3-dimensional structure compared with the ha1 of a / wyoming/3/2003 .\nthree - dimensional top view of the ha1 hemagglutinin structures for a ) a representative a / nepal/1648/04 virus and b ) vaccine strain a / wyoming/3/03 .\nmost ( 24/26 ) of the nepal isolates contain a lysine to asparagine substitution ( shown in yellow ) at position 145 ( k145n ) .\nmagenta , residues 226 and 227 ; orange , residue 189 ; green , residues 155 and 156 ; yellow , residue 145 .\nhemagglutinin molecules were generated by using the respective amino acid sequences with molmol ( 12 ) .\nclinical evaluations and throat specimens were obtained from 64 patients from 3 refugee camps in southeastern nepal ( figure 1 ) .\nof the 64 patients , 61 were refugees from bhutan , 1 was a foreign aid worker from japan , and 2 were nepalese nationals .\nmost of the patients were < 10 years of age ; 36 were male and 28 were female .\nnone had previously been vaccinated against influenza and of the 64 specimens collected , 42 ( 66% ) tested positive for influenza a by culture .\nthe green circle shows the location of 3 bhutan refugee camps where the outbreak occurred in early july 2004 .\nhi was performed by using postinfection ferret antisera with reference antigens that included the 20042005 h3n2 vaccine seed strain ( a / wyoming/03/2003 ) and the 20052006 southern hemisphere h3n2 vaccine strain ( a / wellington/1/2004 ) . when compared with a / wyoming/03/2003 , 4 of 9 nepal isolates showed 4-fold lower titers ( 1:320 versus 1:1,280 hi units ) than that allowed for homologous titer of the reference antisera .\nsix of 9 nepal isolates were antigenically distinct when compared with the a / wellington/1/2004 strain and showed a 4-fold ( 1:160 versus 1:640 ) reduction in titer to ferret antisera ( table 1 ) .\n* test antigens are considered antigenically different from the reference strain if hi titers show a 4-fold difference .  a\nrt - pcr - based molecular subtyping showed that all 42 specimens were the h3n2 influenza subtype .\ntwenty - six of the 42 influenza a  positive samples were randomly selected for molecular characterization using direct nucleotide sequencing of the ha gene .\nthe 26 nepal isolates exhibited 99.8% nucleotide sequence identity and contained the fujian - like amino acid substitutions at positions 155 ( h155 t ) and 156 ( q156h ) in the ha protein ( table 2 ) .\nalignment of the 329amino acid ha protein from 26 isolates obtained from this outbreak with the 2004/05 a / wyoming/3/03 vaccine strain and previous h3n2 vaccine strains indicated 4 evident amino acid changes present in most of the isolates ( table 2 ) .\nall 4 amino acid changes observed within most of these outbreak isolates are present within a / california/7/04 , a variant strain selected as the h3n2 vaccine strain for the 20052006 influenza season . *\nn , asparagine ; t , threonine ; h , histidine ; i , isoleucine ; p , proline ; k , lysine ; s , serine ; v , valine ; q , glutamine .  consensus sequence derived from a multiple sequence protein alignment of 26 ha1 hemagglutinin sequences from nepal . of the 26 nepal strains examined ,\n24 exhibited a novel lysine - to - asparagine substitution at position 145 in the ha protein ( k145n ) .\nthis substitution is noteworthy because most strains characterized in 20032004 , including the fujian/411/2002 vaccine strain , contained a lysine ( k ) at this position .\nprior to this outbreak , the us department of defense had only observed k145n substitutions in 6 strains obtained from ramstein , germany , ( data not shown ) in june 2004 .\nadditionally , all 26 nepal sequences exhibited a serine - to - asparagine substitution at position 189 ( s189n ) that had also been observed in the 6 isolates from germany , as well as in a few isolates from asia characterized at the end of the 20032004 influenza season .\ntwo other substitution mutations in the ha1 hemagglutinin , i.e. , valine to isoleucine at position 226 ( v226i ) and serine to proline at position 227 ( s227p ) , were also observed in 24 ( 92% ) and 26 of 26 of the nepal isolates , respectively .\nboth substitutions differ from most influenza a h3n2 field isolates collected in 20032004 , including the fujian and wyoming vaccine strain for 20042005 ( table 2 ) .\nthe phylogeny of h3n2 ha proteins indicates a drifting of the nepal isolates from the a / fujian/411/03 and a / wyoming/03/03 vaccine strains and shows that these outbreak isolates have a higher genetic homology to a / wellington/1/04 , a prototype strain selected as the 20052006 southern hemisphere h3 vaccine strain ( figure 2 ) .\nthe a / wellington/1/04 strain contains 2 of the 4 amino acid changes ( s227p and s189n ) observed in the nepal isolates , but does not contain the k145n and v226i substitutions .\nunrooted phylogenetic analysis of ha1 hemagglutinin nucleotide sequences from 26 nepal isolates and h3n2 vaccine and reference strains .\nthe nepal isolates have drifted from the 20042005 a / fujian/411/03 vaccine strain ( and a / wyoming/03/03 vaccine seed strain ) and are genetically equivalent to a / california/7/04 , the 20052006 northern hemisphere vaccine strain . a k145n substitution ( branch point indicated by the arrow )\nwas observed in 24 of 26 nepal isolates and represents a genetic marker for the dominant lineage of h3n2 viruses during the 20042005 season .\nnucleotide and amino acid sequences for all nepal isolates are available from genbank under accession no .\nthe asterisk indicates isolates from table 2 that were antigenically distinct from a / wyoming/303 .\nthree - dimensional views of influenza ha proteins highlighting amino acid changes in a representative nepal isolate and the a / wyoming/3/03 vaccine strains are shown in figure 3a and b , respectively .\nthe mutation at position 145 ( shown in yellow ) , which is located adjacent to antibody - binding site a and within a known glycosylation site , introduces an asparagine - for - lysine substitution .\nthis substitution results in a more accessible receptor - binding cleft located directly above residue 145 ( comparing panels a and b ) .\nlocated above the receptor - binding pocket is a serine - to - asparagine change ( shown in green ) that possibly alters the regional surface topography at position 189 within antibody - binding site b. a serine - to - proline mutation at position 227 ( shown in magenta ) appears to marginally affect the ha surface features .\nthis substitution resides within antibody - binding site d , which corresponds to residues 225228 , which make up the left side of the receptor - binding pocket ( 14 ) .\ninterestingly , this proline residue is located within a  barrel ( a protein motif consisting of an antiparallel  sheet domain ) and does not appreciably alter the predicted protein structure , as shown by the absence of any substantial changes in the computer - modeled , 3-dimensional structure compared with the ha1 of a / wyoming/3/2003 .\nthree - dimensional top view of the ha1 hemagglutinin structures for a ) a representative a / nepal/1648/04 virus and b ) vaccine strain a / wyoming/3/03 .\nmost ( 24/26 ) of the nepal isolates contain a lysine to asparagine substitution ( shown in yellow ) at position 145 ( k145n ) .\nmagenta , residues 226 and 227 ; orange , residue 189 ; green , residues 155 and 156 ; yellow , residue 145 .\nhemagglutinin molecules were generated by using the respective amino acid sequences with molmol ( 12 ) .\nthe 4 substitutions described represent a growing lineage of influenza a ( h3n2 ) viruses characterized since july 2004 .\nthree amino acid changes are confined within known antibody - binding sites , i.e. , the s189n change within antibody - binding site b ( 4,5 ) and the v226i and s227p changes residing in antibody - binding site d ( 4,5 ) . because of rotational restrictions , a proline substitution at position 227 ( s227p ) would typically give rise to considerable conformation change ; however , this particular substitution is located within a  barrel motif and therefore has little effect on regional protein conformation . cumulatively , field isolates characterized subsequent to this outbreak continue to exhibit these 4 changes , and they appear to constitute a distinct branch in the phylogeny of ha sequences when compared with h3n2 isolates from the 20032004 season .\n. this change may affect protein - protein interactions since it is immediately adjacent to antibody - binding site a , where neutralizing antibodies have been shown to bind ( 4,5 ) .\nfurthermore , since the k145n substitution is located within a glycosylation site , the charge alteration may affect glycosyl transferase activity , which results in altered glycosylation .\ndifferences in glycosylation have been shown to contribute to antigenic variation by preventing antibody binding to antigenic sites ( 15 ) .\nadditionally , 3-dimensional analysis suggests this amino acid substitution may also promote enhanced receptor binding since the asparagine r group is shorter , which may make binding requirements less stringent and the receptor cleft more accessible .\nthe 3-dimensional depiction provides a unique regional residue perspective , demonstrating how the rapidly evolving ha surface antigens in the vaccine strain differ at the molecular level .\ncollectively , the clinical isolates obtained from this outbreak in nepal can not be considered antigenically distinct from the a / wyoming/3/03 vaccine strain because only 4 of 9 isolates evaluated exhibited 4-fold lower titers by hi ( table 1 ) .\nfurthermore , the varying reactivity noted in several isolates from this outbreak having identical ha1 sequences is suggestive that other viral antigens aside from the ha1 protein may have contributed to the antigenic variability observed in the hi panel . with the exception of a / nepal/1670/2004 and a / nepal/1672/2004 , all isolates evaluated by hi ( table 1 ) exhibited identical ha1 amino acid sequences and varying antigenicity profiles to a / wyoming/03/2003 reference antisera .\none explanation for this observation is that genetic differences in other influenza surface proteins contribute to the observed immunoreactivity .\nalternative viral surface protein candidates include the neuraminidase , ha2 , and m2 glycoproteins , which have been shown to exhibit antigenic properties ( 1619 ) . in this report\n, we describe the genetic analysis of the ha proteins from viruses obtained from an early season outbreak and compare them to current vaccine strains .\nthree amino acids changes ( s189n , i226v , and s227p ) were noted in known ( 4,5 ) antibody - binding sites ( table 2 ) . the fourth change ( k145n ) , which was located within a glycosylation site , may enhance viral binding since the smaller asparagine r group is located close to the ha receptor - binding cleft ( figure 3 ) .\nphylogenetic analyses show that the nepal isolates make up a distinct branch in the evolution of h3n2 viruses when they are compared with vaccine and reference strains ( figure 2 ) . however , antigenic data appear more ambiguous , suggesting a multigenic effect that can not solely be attributed to properties of the influenza ha ( table 1 ) .\nstudies are in progress to characterize the neuraminidase , m2 , and ha2 proteins to determine the molecular basis responsible for antigenicity differences observed within isolates from this outbreak .\nthe k145n substitution change has become a marker for an increasingly large subset of the fujian - like viruses .\ncdc and the us department of defense have recently characterized viruses with the k145n change in singapore , taiwan , china , australia , canada , and the united states . in february 2005 , who reported the emergence of a new influenza h3n2 strain in the united states .\nthe a / california/7/2004 strain , which was first identified in the united states in september 2004 , contains all 4 changes observed in isolates from this nepalese outbreak .\nthe a / california/7/2004 strain differs by only 1 amino acid in ha1 ( which is of no immunologic importance ) from most isolates from the outbreak in nepal .\nall viruses characterized ( 150 globally isolated strains ) subsequent to the preparation of this report ( march 2005 ) by the us department of defense are genetically similar in amino acid sequence to these nepalese strains ( and the a / california strain ) .\nmost of the isolates ( 80% ) analyzed by cdc since october 2004 are antigenically related to a / california ( 20 ) , which indicates that this strain has emerged as the dominant influenza a h3n2 strain .\nthese data indicate that these viruses may persist as the dominant strain at the onset of the 20052006 influenza season . in february 2005 , who recommended inclusion of an a / california/7/2004-like strain in the 20052006 trivalent influenza vaccine to afford immunologic protection from this variant h3n2 virus .\nour findings emphasize the importance of continued molecular surveillance for characterizing emerging influenza drift variants ."}
{"lay_summary": " excess weight has generally been associated with adverse health outcomes ; however , the link between overweight and health outcomes may vary with socioeconomic , cultural , and epidemiological conditions . \n we examine associations of weight with indicators of biological risk in three nationally representative populations : the us national health and nutrition examination survey , the english longitudinal study of ageing , and the social environment and biomarkers of aging study in taiwan . \n indicators of biological risk were compared for obese ( defined using body mass index ( bmi ) and waist circumference ) and normal weight individuals aged 54 + . generally , obesity in england \n was associated with elevated risk for more markers examined ; obese americans also had elevated risks except that they did not have elevated blood pressure ( bp ) . including waist circumference in our consideration of bmi indicated different links between obesity and waist size across countries ; we found higher physiological dysregulation among those with high waist but normal bmi compared to those with normal waist and normal bmi . \n americans had the highest levels of biological risk in all weight / waist groups . \n cross - country variation in biological risk associated with obesity may reflect differences in health behaviors , lifestyle , medication use , and culture . ", "article": "rising levels of obesity are becoming a worldwide phenomenon and are increasingly identified as a health problem across the globe [ 14 ] .\nhigher weight has been associated with adverse health indicators and outcomes , including cardiovascular disease [ 512 ] , stroke [ 5 , 13 ] , cognitive and functional decline [ 1418 ] , metabolic syndrome [ 19 , 20 ] , inflammation [ 21 , 22 ] , and mortality [ 20 , 2325 ] .\nobesity among aging populations is relatively recent and aging among people who have been obese for much of their lives is also a new phenomenon . from 1980 to 2004 , the prevalence of obesity in the us has continued to rise from about 17% to 25% for men aged 5059 . while obesity in england has also increased during this period , from approximately 9% in 1980 to 15% in 2004 for men aged 5564 , the level of obesity remains much lower in england .\nadditionally , the difference in obesity between the us and england is more pronounced for women .\nthe level of obesity in us women was about 24% in 1980 and rose to 37% in 2004 ( age 5059 ) ; in england , levels for women were 9% in 1980 and 14% in 2004 ( age 5564 ) .\nthe aim of this paper is to investigate differences in how obesity relates to indicators of physiological dysregulation in men and women of diverse populations .\nthis comparison will lead to an improved understanding of how obesity might be differentially related to health and mortality across cultures and lifestyles .\nobesity was relatively rare in most populations until the second part of the last century , but it has now become common in many countries\n. the us population is recognized as among the most obese in the world , although many other countries are now approaching the us level and most countries are experiencing increasing obesity .\nthis worldwide obesity epidemic began with the epidemiological revolution and the virtual elimination of infectious disease ; the decline in manual labor needed to provide sustenance with the industrial revolution ; and the increasing availability and decreasing cost of food [ 2729 ] .\nobesity reflects some combination of calorie intake , diet content , and amount of physical activity . in some cultures ,\nlack of physical activity can be a more important determinant of obesity ; in other cultures , overeating or food composition may be the more important determinant of obesity .\nit is also true that within countries , individuals could differ in the causes of obesity .\nfor instance , changes in activity might be more characteristic of women or men resulting in different reasons for obesity by gender .\nthese differences may affect how obesity is related to other risk factors for poor health , and it may determine the overall health risk associated with obesity . if physical activity is maintained , the overall effect of obesity may be less than if the activity is not .\none indication of the cause of obesity may be the relationship between waist size and weight [ 30 , 31 ] . in societies where obese people are more physically active , waist size of the obese\nwaist circumference has also been linked to late life mortality , where high waist circumference has been associated with increased mortality among men and women in the netherlands , while high bmi was not associated with mortality .\nthis paper builds upon current obesity research by using both bmi and waist circumference to quantify obesity in order to determine how a combined indicator of weight and adiposity is related to physiological dysregulation in populations with different cultures , diets , behaviors , and epidemiological histories .\nobesity has been related to many indicators of physiological dysregulation including cardiovascular risk factors such as hypertension   and metabolic dysregulation in lipid levels or insulin resistance .\nmost studies that investigate the differences in biological risk associated with excess weight have examined western populations [ 33 , 36 ] .\ncomparative studies on the health risks associated with obesity that examined the us and england reported that obese americans had an increased risk of diabetes and a higher waist circumference [ 37 , 38 ] .\nthese studies suggested that differences in physical activity , diet , and social environments may explain these national differences .\nwhile these differences have been observed between the us and england , these two western countries have roughly similar life expectancy , levels of living , history , and culture even while the us has poorer health by a number of indicators of disease prevalence and biological risk [ 36 , 39 ] .\ncomparative studies of the links between obesity and health outcomes and risk factors for obesity comparing western and non - western countries indicate important differences in the causes and consequences of obesity .\na comparison of the association of disease with overweight and obesity in japan and the us indicated that the associations were stronger in the us than in japanese women and that there was no association in japanese men .\nlinks between social , demographic , and behavioral risk factors for obesity also differ markedly in japan , korea , and the us .\nthe availability of biomarker data from taiwan  a middle - income country undergoing rapid economic growth , increasing obesity , and with life expectancy recently increasing to levels similar to that of the us and england  allows for investigation of the biological risk associated with obesity in a population characterized by very different cultural , behavioral , socioeconomic , and dietary parameters .\nwe examine how elevated weight and obesity ( using an indicator that considers both bmi and waist circumference ) relate to having levels defined as clinical risk for cardiovascular , metabolic , and inflammatory markers in three aging societies that are now relatively similar in life expectancy but that differ in the timing of the epidemiological transition and obesity epidemic , history of economic development , socioeconomic levels , general lifestyle habits , health behaviors , and health care systems : the us , england , and taiwan .\nfinding differences in the relationship between obesity and indicators of physiological dysregulation in these three aging societies will clarify whether increases in weight gain are equally problematic across all countries .\nwe use data from three nationally representative samples : the us national health and nutrition examination survey ( nhanes , 20032006 ; n = 3855 ) , the english longitudinal study of ageing ( elsa , 2004 - 2005 ; n = 9139 ) , and the social environment and biomarkers of aging study ( sebas ) in taiwan ( 2000 ; n = 1023 ) .\nthese surveys collect information on demographics , as well as anthropometric , physical , and biological measures .\nevery year , approximately 5,000 individuals undergo detailed interviews and medical examinations , which include collection of several physiological measures .\nnhanes utilizes a complex sampling design , and when weights are applied , the sample is representative of the noninstitutionalized american population .\nwe use the 20032006 data since nhanes data is released in two - year intervals , and this sample is centered on 2004 - 2005 , which matches the period in which elsa was collected .\nfor nhanes , we use individual - level data based on a sample of 1,513 fasting individuals aged 54 and older .\nelsa includes participants drawn from households responding to the health survey for england ( hse ) in 1998 , 1999 , and 2001   and is representative of the english population aged 50 and older .\nthe core elsa sample ( wave 1 : 2002 - 2003 ) includes people living in an hse responding household who were born prior to march 1 , 1952 , and their partners who could be under age 50 . wave 4 of elsa ( 2008 - 2009 ) , which includes a nurse visit , includes wave 1 core members , if they are still alive and do not refuse further contact after the first interview at wave 1 .\nit also includes a refresher sample to maintain the age structure of the sample ( in waves 3 and 4 ) , and their partners . for elsa , we use individual - level data based on a sample of 7,384 individuals aged 54 and older .\nsebas is drawn from a follow - up survey of the survey of health and living status of the near elderly and elderly in taiwan ( also known as the taiwan longitudinal study of aging ( tlsa ) ) , a nationally representative survey of taiwanese adults ( including institutionalized individuals ) collected in 1989 , 1993 , 1996 , 1999 , and 2000 . in 2000 , a subsample of individuals was randomly selected for inclusion in sebas .\nsebas consists of adults aged 54 and older in 2000 , with in - home interviews and medical exams taken in a hospital . for sebas ,\nthe sample averages 66.8 years of age in england , and the us and taiwan mean age is about the same ( table 1 ) .\nthere are more men in taiwan ( 56% ) and england ( 53% ) and fewer in the us ( 44% ) .  \nwe examine the following indicators of physiological dysregulation often associated with obesity and also associated with increased risk for multiple adverse health outcomes and obesity [ 43 , 44 ] : ( 1 ) cardiovascular markers : high systolic ( sbp ) and diastolic blood pressure ( dbp ) ; ( 2 ) metabolic markers : high levels of blood lipids ( total and low - density lipoprotein ( ldl ) cholesterol , and fasting triglycerides ) , low levels of high - density lipoprotein ( hdl ) cholesterol , and high fasting glucose and glycated hemoglobin ; ( 3 ) high levels of inflammatory markers c - reactive protein ( crp ; available in nhanes and elsa ) and interleukin-6 ( il-6 ; available in sebas ) , as crp and il-6 have been positively associated with bmi . for each indicator\nwe use clinical cutpoints or widely used research - based cutpoints to indicate high levels of risk which are shown in table 1 [ 39 , 43 , 45 ] .\nthere has been debate as to the best indicator of obesity : body mass index ( bmi ) or waist circumference .\nwaist circumference is thought to be a better measure of abdominal adiposity than bmi and a better indicator of risk of poor health outcomes , including all - cause and cardiovascular mortality [ 46 , 47 ] . for this reason\nwe investigate the association between bmi and biomarkers across categories of bmi ( underweight < 18.5  kg / m , normal and overweight 18.529.9  kg / m , obese 3034.9  kg / m , and very obese 35  kg / m ) and waist circumference categorized as normal or high waist ( high waist : men 120  cm , women 88  cm ) . we create a composite measure of obesity and adiposity by categorizing individuals into five groups : ( 1 ) underweight and normal waist ( all underweight individuals had a normal waist circumference ) , ( 2 ) normal / overweight bmi ( termed normal bmi ) and normal waist circumference ( reference group ) , ( 3 ) normal / overweight bmi ( termed normal bmi ) and high waist circumference ( termed high waist ) , ( 4 ) obese and high waist ( all obese individuals had a high waist circumference ) , and ( 5 ) very obese .\nwe also evaluate an alternate definition for obesity in taiwan based on bmi 27 , as it has been suggested by some that obesity levels should be differentially defined for asians [ 48 , 49 ] .\na similar composite measure of obesity and adiposity was calculated using this alternate definition of bmi in taiwan . because these risk factors are all assumed to be associated with obesity and because dysregulation in multiple physiological systems has been shown to predict many of the poor health risk outcomes associated with aging , we also create two summary measures of risk based on the total number of at - risk levels of biomarkers , either 9 or 8 . because crp values for sebas are not available , this measure\nis not included in the 9-item summary measure for taiwan , but a summary measure ( range 09 ) was calculated for taiwan using il-6 , another indicator of inflammation , instead of the crp values included for the us and england . a second alternate summary measure of biological risk , excluding the inflammatory marker ( range 08 ) ,\nbiological risk summary scores were computed for individuals who had missing values on no more than 3 biological markers .\nwe examine multiple covariates in our investigation of the relationship between obesity and biological risk .\nself - reported use of antihypertensives was determined in all three countries , and use of lipid - lowering statins was only asked in the us sample .\ndichotomous variables were created to indicate whether the respondent reported being a current smoker and participating in at least moderate physical activity for exercise ( e.g. , brisk walking , running , or swimming ) in the past 30 days ( for the us and england ) or generally exercising once a week ( for taiwan ) .  \nwe use logistic regression models to determine the odds of having at - risk levels of a specific biomarker for obese men and women among the three populations . for all countries ,\nthe comparison group for bmi and waist circumference is the normal bmi and normal waist group .\nthe regressions included indicators of age , use of antihypertensives , current smoking status , and having exercised in the past 30 days .\nordinary least squares ( ols ) regression models were used to determine the relationship between the summary measures of biological risk and the composite measure of obesity and adiposity .\nwe begin by examining national differences in the high risk levels of individual biomarkers ( table 1 ) .\nlow levels  or high risk levels  of hdl cholesterol are also more common in taiwan .\nhigh total and ldl cholesterol is more common among the english ; lower levels of plasma glucose , crp , and glycated hemoglobin are also characteristic of the english .\nfew adults in england have elevated levels of fasting glucose ( 2.2% ) , while this is observed in 17.3% and 13.2% of american and taiwanese adults . \n\nmost people in this age range are in the normal to overweight category ( 64.7% , 67.2% , and 89.4% in the us , england , and taiwan , respectively ) ( table 2(a ) ) .\namericans are more likely to be obese ( 33.7% ) compared to the english ( 32.1% ) and taiwanese ( 7.2% ) . among the obese , americans are much more likely to be very obese : 13.4% of the total us sample , 10.1% in england , and about 1% in taiwan .\nboth among the obese and very obese , the average bmi is higher in the us and england compared to taiwan .\nfew are underweight in any country ( 1.7% , 0.8% , and 3.4% in the us , england , and taiwan , resp . ) .  \nwhen we examine waist circumference , the us has the highest average waist circumference , with 65.5% of americans , 55.9% of english , and 15.8% of taiwanese having a high waist size ( table 2(a ) ) .\nthis means that high waist characterizes a substantial number of those who would be categorized as normal weight in the us and england . among those in the normal and overweight group about half ( 49.5% ) of americans and a third ( 36.4% ) of the english\nalmost all obese individuals have a high waist in the us and england ( 98.3% in the us and 96.5% in england ) , but only 78.4% of the obese in taiwan also have a high waist . when we use the alternate obese cutpoint of 27  kg / m in taiwan , less than half of the obese individuals have a high waist ( not shown here ) . \n\namericans exhibit the highest proportion of the older population taking antihypertensive medication ( 47.1% ) ( table 1 ) .\nthe percentage who reports taking antihypertensives is lower in england ( 32.0% ) and taiwan ( 28.6% ) .\namericans are more likely to be current smokers ( 24.5% ) than persons in taiwan ( 22.5% ) and england ( 13.9% ) .\nmore than half of the population in all countries report having exercised in the past 30 days , with more english exercising ( 82.2% ) compared to taiwan ( 61.4% ) and the us ( 58.5% ) . \n\nmen with normal bmi and high waist have a greater likelihood than men with normal bmi and normal waist size of having high - risk levels of triglycerides in all three countries . in the us and england ,\nmen with high waist are more likely to have high levels of glycosylated hemoglobin and higher crp ; fasting glucose is also elevated among this group in the us ( table 3(a ) ) .\nmen who are obese in the us have fewer elevated risk factors than those with high waist who are not obese ; in the us , obese men are only more likely than normal weight men without high waist to have elevated glycated hemoglobin , fasting glucose and crp .\nenglish men who are obese have more elevated risk : both blood pressure indicators , hdl cholesterol , triglycerides , glycated hemoglobin , and crp .\nvery obese men in england have the same elevated risk factors with the exception of dbp .\nvery obese men in the us are more likely to have elevated fasting glucose in addition to crp and glycated hemoglobin .\nenglish and taiwanese women with normal weight and high waist are more likely to have elevated sbp , dbp , and glycosylated hemoglobin ; only british women with higher waist have significantly elevated triglycerides and only the taiwanese women had more hdl risk .\nhigh risk crp is more common among both american and english women with normal bmi and high waist , and this risk of elevated crp is also higher in the obese and very obese ( table 3(b ) ) .\nobese women in britain had elevations in the same markers as normal bmi and high waist english women , while obese women in the us only have elevated fasting glucose , glycated hemoglobin , and crp ; obese women in taiwan only had high dbp . with the exception of taiwan , levels of the inflammatory markers ( crp in the us and england ; il-6 in taiwan ) are more likely to be elevated among persons with a high waist and normal bmi , obese or very obese , compared to their normal bmi and normal waist counterparts . among men ,\nan increase in the biological risk summary score ( range 09 ) is associated with having a high waist relative to being of normal bmi and normal waist in all three countries ( table 4(a ) ) .\nbeing obese or very obese is also related to a higher biological risk summary score ( 09 ) for men in the us and england .\nthese equations explain 6 to 11 percent of the variance in the summary indicator of biological risk .\nthese relationships are similar for women ( table 4(b ) ) , with one exception : obese taiwanese women do not have a significantly increased biological risk compared to their normal weight and normal waist counterparts .\nwhen we consider the alternate summary score that excludes our indicators of inflammation ( range 08 ) , being obese or very obese is no longer associated with a higher biological risk summary score in us men compared to men with a normal bmi and normal waist when controls for health behaviors and medication use are included ( table 5(a ) ) .\nthe size of the effects of the obesity categories is reduced on the 8-indicator summary measure in both england and the us , indicating the strong link between crp and obesity .\nthe r is also reduced in these equations for england and the us . for taiwan ,\nwomen in england and taiwan , but not women in the us , with a higher waist but who are not obese have significantly higher physiological dysregulation compared to their normal bmi and normal waist counterparts .\nobese women in all three countries have elevated risk and the very obese have even higher risk ( table 5(b ) ) . the alternate biological risk summary measure ( 08 )\nyields different relationships between weight and physiological dysregulation in the us and taiwan . in the us ,\nonly very obese women have a higher alternate biological risk summary score ( 08 ) . in taiwan , obese and normal bmi and high waist women exhibit higher alternate biological risk summary scores compared to their normal bmi and normal waist counterparts , except when smoking status , physical activity , and use of hypertensives are included .   figures 1(a ) and 1(b ) illustrate the predicted alternate biological risk score ( 08 ) for each weight category for men and women ( respectively ) aged 65 who are nonsmokers , do not engage in physical activity , and are currently taking antihypertensive medication .\nthis figure allows for country comparisons of individuals with these characteristics within each weight category and across weight categories .\nthe predicted values indicate that the us has the highest biological risk score within each respective weight category among men and women of the same age and lifestyle behaviors . with the exception of women in the normal bmi and high waist group ,\nengland has the second highest biological risk score within each weight category , followed by taiwan . among 65-year - old women with the noted lifestyle behaviors and with a normal bmi and high waist\nwhen we consider the alternate bmi cutpoint for obesity in taiwan ( bmi  27  kg / m ) , our findings for the individual biomarkers and summary measures of biological risk are similar to using the bmi  30  kg / m cutoff for taiwan except that the category normal weight with high waist no longer differs from the omitted category ( results not shown ) .\nthis study observes three general findings about how biological risk is associated with obesity in three countries that differ in lifestyle and culture .\nfirst , obesity is associated with physiological dysregulation in all countries with differences in the links between specific indicators of biological risk and obesity .\ngenerally , obesity in england is associated with hypertension , dyslipidemia , and elevated glycated hemoglobin ; americans who are obese are not more likely to have hypertension . in taiwan ,\nobese women are more likely to have elevated dbp and obese men have an increased risk of elevated triglycerides and glycated hemoglobin compared to their nonobese , normal waist counterparts .\nour biological risk summary scores indicate that at all levels of weight physiological dysregulation was highest in the us , followed by england ( with one exception ) , with taiwanese exhibiting the lowest biological risk in all groups among the three countries .\nsecond , these relationships remain after controlling for demographic factors , participation in physical activity , and other behavioral factors .\nthird , similar to obese older adults , high waist individuals with normal bmi also exhibit greater physiological dysregulation in all countries compared to their normal bmi and normal waist counterparts .\nour finding of a higher physiological dysregulation , as shown by the alternate biological risk summary score , in taiwan compared to the us and england could be due to a couple of potential explanations .\nthe prevalence of obesity in the us and england is much higher than in taiwan , indicating an earlier initial rise in obesity relative to taiwan . from 1978 to 2002 , the proportion of obese americans and britons exhibited stark increases ( 1332% and 623% for men and women , resp . ) .\nthe estimates for obesity prevalence in taiwan indicate a recent increase for men but not women . from 19931996 to 2000 - 2001 , the age - adjusted prevalence of obesity rose from 10.5% to 15.9% for men and declined from 13.2% to 10.7% in women .\nit may be that the lower levels of risk among older adults who have lived longer years with obesity could be a reflection of better pharmacologic control of physiological dysregulation ( e.g. , through statin use ) , which may in turn confer less biological risk in these populations compared to populations of currently obese taiwanese adults who may have more recently begun living with obesity .\na second reason for the observed country differences in obesity may be due to differences in dietary habits and lifestyle .\nthe us and england are two modern , western populations whose diets have been influenced by increased industrialization and have over time come to be characterized by high glycemic loads and high fatty acid composition .\ntaiwan , on the other hand , represents a country that has experienced the effects of the industrial and scientific revolutions later than that of the us and england but is currently rapidly undergoing economic development and demographic change .\nthe recent economic changes in taiwan may indicate that obese older adults in taiwan have more recently begun to consume high - fat diets , which could result in greater initial physiological dysregulation associated with access to western - influenced dietary habits . despite controlling for lifestyle behaviors thought to be linked with health , the country differences in obesity and physiological regulation remain .\nmoreover , the consideration of antihypertensives does not alter our substantive conclusions on these associations .\nthis suggests that despite the greater use of medications to treat hypertension in the us , obesity among americans is associated with greater overall biological risk than the other two countries .\nthis is supported by findings from the general population of americans relative to england , which report that the us is faced with greater health disadvantages than england in adulthood   and across the life span .\nwe also note differences in biological profiles of obese individuals between the two westernized countries : the us and england . the excess risk of hypertension associated with obesity in england was not found in the us .\nthese differences may be due to the higher use of medications among americans compared to the english , with about 16% more men and 18% more women in the us aged 65 + taking antihypertensive medication compared to their british counterparts .\nthe greater use of hypertensive medications in the us is also noted when compared to japan and countries across europe .  \ntwo notable differences in country patterns of the relationship between obesity and physiological dysregulation by sex are found . among men in england and taiwan ,\nthe order of magnitude of physiological dysregulation increases with higher weight categories ; however , this is not observed for us men .\nthis difference may be due to our inability to consider statin use in england and taiwan , which may be particularly important in the relationship between obesity and physiological dysregulation for men .\nconversely , the importance of considering statin use may be less vital to understanding the country differences in the association between obesity and physiological dysregulation among women , given that the relationship for women is more consistent across countries , namely in the us and england .\nwomen , underweight corresponds with higher biological risk ( though nonsignificant ) compared to women with normal bmi and normal waist .\nunderweight among men in taiwan is significantly associated with much lower biological risk than their normal bmi and normal weight counterparts .\nfurther studies will be required to explore possible explanations for these differences in physiological dysregulation .\nthe higher biological risk observed among normal bmi and high waist individuals relative to normal bmi and normal waist older adults builds upon previous studies that report on alternate indicators of body shape , which vary across countries .\nthe importance of waist circumference is underscored by our current study , as well as a growing body of literature on the predictive value of waist circumference on indicators of health .\nhigher rates of diabetes among older americans compared to britons have been accounted for by high waist circumference as opposed to bmi differences . additionally , increasing waist circumference is more predictive of greater risk of incident diabetes than bmi in middle - aged british men ( and the european prospective investigation into cancer and nutrition ( epic)-potsdam study ) .\nwaist circumference , as an indicator of central fat mass , is thought to be more strongly associated with disease risk , and in our case with physiological dysregulation , compared to bmi , which is considered a cruder index of adiposity .\nbanks and colleagues   cite differences in physical activity , diet and greater psychosocial environmental challenges in america compared to england as potential mechanisms linking central adiposity and type 2 diabetes .\nour study considers some of these possible mechanisms ( e.g. , physical activity and antihypertensive use ) but finds that they explain little of the relationship between biological risk and adiposity among the three countries .\ntogether , these results highlight the importance of considering waist circumference in investigating the links between indicators of health and adiposity .\nour finding of the biological risks associated with obesity among older taiwanese adults underscores the growing concern for risks associated with obesity in countries rapidly undergoing modernization . in comparing the biological risk of obese individuals among the three countries , we are able to use these international comparisons to our advantage to examine how differences in modernization influence the health of older adults in different populations\nthis may have potential health policy implications that underscore the importance of addressing and controlling the rising obesity epidemic that has become most widespread in countries , like the us and england , that have long experienced high economic growth and in countries currently undergoing rapid economic development .\nthe increasing use of biological information to inform our understanding of health represents an innovative method in biodemography that will further contribute to the testing of current comparative theory and the potential creation of new paradigms surrounding the influence of modernization on health .\nfirst is the use of a broad range of biological markers across three large - scale population surveys . the inclusion of biological information as objective precursors of health allows , to some extent , a fairly comparable comparison of indicators of health across the different populations .\nan exception to this uniform comparison of biomarkers across the three surveys is our use of inflammatory marker crp in the us and england and our inclusion of a different marker of inflammation ( il-6 ) in taiwan . of note , crp seems to be more strongly associated with obesity than il-6 .\na growing body of literature has made distinctions between bmi and waist circumference , namely , suggesting that waist circumference is a better indicator of abdominal obesity , which in turn has been associated with obesity - related health risks .\nour findings generally report a similar association between increased biological risk and ( 1 ) normal bmi and high waist and ( 2 ) obese and high waist .\nusing the us nhanes ,   reported that when both waist circumference and bmi were included in their analyses , only waist circumference was a significant predictor of comorbidity . although this and other studies have suggested that waist circumference may be a better indicator of obesity and risk for adverse health outcomes , our study finds the two indicators to be similarly associated with biological risk across the three countries .\nfirst , we examine population - based data from three countries at a single time point .\nfuture studies of longitudinal data will allow for further investigations of the potential role of obesity on biological risk observed in the current associations .\nsecond , we do not have measures of some lifestyle and medical behaviors for some of the datasets ( e.g. , statin use ) , which likely influence the relationship between obesity and biological risk .\nas such , we are unable to include such factors in our analyses of all three countries .\nit is possible that these lifestyle behaviors are key explanatory factors to the noted cross - country differences in obesity - related biological risk .\nthe cross - country differences in the relationship between increased biological risk for individuals who are obese and have a high waist underscore potential differences in health and lifestyle behaviors .\nthese behaviors may be a result of country differences in economic development that we are not able to observe in this study .\nthe country differences in the links between obesity and physiological dysregulation are particularly marked when comparing obesity among taiwanese older adults relative to westernized populations , such as the us and england .\nfurther examination of these relationships over time and across other countries will contribute to our understanding of the potential factors responsible for these country - specific variations in biological risk , as obesity becomes increasingly more prevalent and older adults in various countries live more years with obesity and increased adiposity ."}
{"lay_summary": " background : suppurative meningitis ( sm ) or bacterial meningitis is a life - threatening condition , which is exceptionally due to pituitary tumors ( pt ) . our aim was to analyze its frequency among male macroprolactinomas ( mprl ) deemed to be aggressive , to report the cases we observed in our practice and describe the circumstances under which sm appeared.materials and methods : we retrospectively analyzed 82 male mprl in order to look for a history of well proved sm and the circumstances under which sm appeared . \n we also took into account the possibility of sm relapsing.results:four out of 82 male mprl had sm = 4.87% . \n three consulted for sm symptoms . \n sm was confirmed in infectious diseases department , but only one had rhinorrhea . hormonal assessment and \n cerebral magnetic resonance imaging pleaded for aggressive prolactinomas . \n after antibiotics , sm was sterilized . \n then , mprl were treated with bromocriptine , which normalized prolactin and reduced pt . \n sm never relapsed . \n the 4th case was hospitalized for a large multidirectional prolactinoma invading and/or arising from the skull base . \n he was operated on 3 times and then he was given bromocriptine . \n after 3 months , he had rhinorrhea and then sm which was successfully treated by antibiotics . \n sm never relapsed after tumor reduction.conclusion:sm was demonstrated in 4.87% . \n sm has revealed mprl in 3 cases and appeared after bromocriptine intake in the 4th one . \n endocrinologists should be aware of this severe condition , which can be avoided by repairing as soon as possible the bony defect secondary to aggressive tumors , unless it is clogged by fibrosis : what probably happened in our cases . ", "article": "male macroprolactinomas ( mprl ) are usually revealed by headaches , visual troubles and gonadal insufficiency .\nsuppurative meningitis ( sm ) , a life - threatening condition , is scarcely observed in subjects with macro tumors secreting prolactin ( prl ) and in other pituitary tumors ( pt ) .\nhowever , in some very rare cases it can be a primary presentation or appear after radiotherapy or medical treatment used for tumors destroying the sellar floor and/or the skull base .\nthis destruction leads to cerebral spinal fluid ( csf ) leak , which can act as an entry portal for organisms predisposing to meningitis .\nour aim was to analyze sm frequency among male mprl deemed to be very invasive tumors , to report our cases and analyze the circumstances under which the dangerous neurological complication appeared .\nin this retrospective study , we analyzed 82 subjects with mprl to look for symptoms , clinical signs and biological proof of sm .\n, we took into account medical history , clinical examination , routine exploration , csf analysis and hormonal assessment .\nthat one was based on prl , growth hormone ( gh ) , insulin growth hormone ( igf1 ) , cortisol , adrenocorticotropic hormone , testosterone , follicle stimulating hormone , luteinizing hormone , thyroid stimulating hormone and free thyroxin .\nradiological assessment was based on cerebral computed tomography scan and/or magnetic resonance imaging ( mri ) .\nthree were first hospitalized in the department of infectious diseases for typical symptoms and signs of sm ; that one was proved by csf biochemical analyses .\nthe fourth one was hospitalized in our department for the fourth episode of sm which was proved by csf analysis after lumbar puncture .\ncerebral mri showed a pt invading cavernous sinuses , the sphenoid sinus and the brain [ figure 1 ] . hormonal assessment [ table 1 ] demonstrated high prl with gonadotroph deficit .\nthen , the pt was treated with dopamine agonists that were successful on prl ( 25 ng / ml ) and on tumor size [ figure 1 ] . after a follow - up of 7 years ,\ninvasive and aggressive pituitary tumor destroying the sella floor , responsible for suppurative meningitis ( sm ) in a 22-year - old man .\n( a ) before bromocriptine ; ( b ) after treatment , bromocriptine intake and sm disappearance tumor size , hormonal assessment of our 4 patients , and bromocriptine dose used to reduce tumor volume and normalize prolactin .\ncerebral mri showed an invasive and multidirectional pt measuring 47 mm  40 mm  30 mm destroying the sella floor and filling the sphenoid sinus [ figure 2 ] .\nthe pt was secreting prl [ table 1 ] . that one was normalized by bromocriptine and the tumor size was significantly reduced .\nlarge invasive tumor destroying the sella floor , responsible for suppurative meningitis in a 49-year - old man .\n( a ) before medical treatment ; ( b ) liquification of the tumor after bromocriptine a man aged 25 , with a history of chronic otitis and arrested puberty , was diagnosed as a multidirectional prolactinoma destroying the sella floor and measuring 30 mm  30 mm  30 mm [ figure 3 ] .\nsm was sensitive to antibiotics . under dopamine agonists prl was normalized and the tumor volume decreased .\nthe pituitary tumor filling the sphenoid sinus before bromocriptine ( a ) and after bromocriptine ( b ) a 29-year - old man was sent to our unit for a prolactinoma revealed by epilepsy crises .\nthe pt was very large ( 68 mm  50 mm  50 mm ) and multidirectional with an extension to the chiasm , cavernous sinuses , posterior and nasal areas [ figure 4 ] .\nafter 3 months he had rhinorrhea , then one episode of sm sterilized by antibiotics . sm never relapsed after a follow - up of over 2 years .\nmri showing a large tumor invading cavernous sinuses , the brain and sphenoid sinus ( a ) .\nafter dopamine agonists ( b ) the tumor size was reduced the table 1 shows tumor sizes , hormonal parameters and bromocriptine dose which was used to treat the 4 prolactinomas .\ncerebral mri showed a pt invading cavernous sinuses , the sphenoid sinus and the brain [ figure 1 ] . hormonal assessment [ table 1 ] demonstrated high prl with gonadotroph deficit .\nthen , the pt was treated with dopamine agonists that were successful on prl ( 25 ng / ml ) and on tumor size [ figure 1 ] . after a follow - up of 7 years ,\ninvasive and aggressive pituitary tumor destroying the sella floor , responsible for suppurative meningitis ( sm ) in a 22-year - old man .\n( a ) before bromocriptine ; ( b ) after treatment , bromocriptine intake and sm disappearance tumor size , hormonal assessment of our 4 patients , and bromocriptine dose used to reduce tumor volume and normalize prolactin .\nthe previous ones were proved in 1984 , 1988 and 1990 . clinical examination confirmed the meningeal syndrome and noticed rhinorrhea .\ncerebral mri showed an invasive and multidirectional pt measuring 47 mm  40 mm  30 mm destroying the sella floor and filling the sphenoid sinus [ figure 2 ] .\nthe pt was secreting prl [ table 1 ] . that one was normalized by bromocriptine and the tumor size was significantly reduced .\nlarge invasive tumor destroying the sella floor , responsible for suppurative meningitis in a 49-year - old man .\n( a ) before medical treatment ; ( b ) liquification of the tumor after bromocriptine\na man aged 25 , with a history of chronic otitis and arrested puberty , was diagnosed as a multidirectional prolactinoma destroying the sella floor and measuring 30 mm  30 mm  30 mm [ figure 3 ] .\nsm was sensitive to antibiotics . under dopamine agonists prl was normalized and the tumor volume decreased .\nthe pituitary tumor filling the sphenoid sinus before bromocriptine ( a ) and after bromocriptine ( b )\na 29-year - old man was sent to our unit for a prolactinoma revealed by epilepsy crises .\nthe pt was very large ( 68 mm  50 mm  50 mm ) and multidirectional with an extension to the chiasm , cavernous sinuses , posterior and nasal areas [ figure 4 ] .\nafter 3 months he had rhinorrhea , then one episode of sm sterilized by antibiotics .\nmri showing a large tumor invading cavernous sinuses , the brain and sphenoid sinus ( a ) .\nafter dopamine agonists ( b ) the tumor size was reduced the table 1 shows tumor sizes , hormonal parameters and bromocriptine dose which was used to treat the 4 prolactinomas .\nwhen it happens , it is usually observed in post - operative period or after tumor reduction by radiotherapy , apoplexy or medicine intake .\nthe situation is observed in people in whom meninges and sella floor are destroyed by an aggressive pt or an ectopic one arising from the skull base .\nour 4 cases can be explained by the fact that prolactinomas are the largest and the most invasive pt , especially in males .\nmale prolactinomas often destroy the sellar floor and invade the sphenoid sinus , then the nasopharynx .\nthe meningeal and bony breaches lead to intra and extradural spaces communication , which is responsible for bacterial infection of meninges and encephalic structures .\nthe most difficult differential diagnosis with meningitis occurring in people with pt is pituitary apoplexy , which mimics perfectly bacterial meningitis symptoms .\nhowever , a real microbial meningitis with or without rhinorrhea can be observed in apoplexy .\nthe true microbial meningitis secondary to pt is an exceptional phenomenon compared to pituitary apoplexy , which is relatively more frequent . to our best knowledge\nonly 15 sm , revealing pituitary adenomas or appearing under medical treatment have been reported so far .\ncsf leak may proceed or not sm , and can be totally unnoticed . according to lam et al . who analyzed 29 articles published between 1980 and 2011 there were only 52 pt with csf leak .\nthe seven cases were divided in two groups : the primitive meningitis or meningitis occurring prior to any treatment of the pt , and secondary meningitis occurring after surgery and/or dopamine agonists intake as in our 4 observation .\nour personal research found 15 cases meningitis secondary to pt . if we add our 4 cases , one can totalize 19 cases . in this group\nmost pt were prolactinomas , especially males ones . among this group 14 were primitive .\nsecondary ones ( n = 5 ) appeared under medical treatment , preceded or not by surgery or radiotherapy .\nsellar floor destruction was obvious on radiographies in all except one case [ table 2 ] .\ntheir age ( varying between 22 and 69 years ) did not seem to be a determining factor , but the nature of the adenoma and sphenoid sinus invasion seem fundamental . according to ciatto and to lascelles et al .\nwe find only one case concerning gh adenoma treated by somatostatin 's analogs . a case of recurrent meningitis which appeared many years after neurosurgery was observed in nelson syndrome too .\ncuriously sm was not reported in mixed pt and gonadotroph adenomas which are usually very large and very invasive .\ncontrary to many authors and in agreement with ciatto , we think the association of pituitary adenoma and meningitis is more common than it is generally supposed as we observed it in nearly 5% of our male mprl .\nso , one should think about it more often even if a cause of sm seems obvious from the first sight as in our 4 case who suffered from chronic otitis .\nradiological research for pt should be systematic , especially if headaches , visual troubles , and gonadal abnormalities with or without anterior or posterior pituitary deficiencies are present .\nphysicians who deal with large pt should be aware of high risk spontaneous meningitis , but also of secondary sm which can appear 1 month to 4 years or even more after medical treatment initiation by dopamine agonists or somatostatin 's analogs or radiotherapy . on another hand\n, medical treatment initiation should be gradual , especially for huge tumors as rapid shrinkage may lead to csf leak apparition .\nif this situation appears , a medical solution may be tried using temporary lumbar puncture or a lumboperitoneal shunt until the bony defect is clogged by fibrosis .\nif this attitude fails , surgical repair is recommended although the reparation may represent a great challenge because of the many potential sites of the csf around the tumor . if surgical repair in not feasible some authors recommend a vaccination against pathogens of the upper respiratory tract such as streptococcus pneumonia , haemophilus influenza and neisseria meningitidis to prevent sm .\nthree revealed the pt , and one was observed after medical treatment . in 2 cases\nthe described cases emphasize the necessity of an early diagnosis and treatment of large and invasive pt , especially male mprl . medical treatment , which is now the gold standard for prolactinomas ,\nshould be gradual and well monitored to avoid rhinorrhea or otorrhea which can lead to potentially fatal bacterial meningitis ."}
{"lay_summary": " background : posterior endoscopic discectomy is an established method for treatment of lumbar disc herniation . \n many studies have not been reported in literature for lumbar discectomy by destandau endospine system . \n we report a series of 300 patients operated for lumbar dissectomy by destandau endospine system.materials and methods : a total of 300 patients suffering from lumbar disc herniations were operated between january 2002 and december 2008 . \n all patients were operated as day care procedure . \n technique comprised localization of symptomatic level followed by insertion of an endospine system devise through a 15 mm skin and fascial incision . \n endoscopic discectomy is then carried out by conventional micro disc surgery instruments by minimal invasive route . \n the results were evaluated by macnab 's criteria after a minimum followup of 12 months and maximum up to 24 months.results:based on modified macnab 's criteria , 90% patients had excellent to good , 8% had fair , and 2% had poor results . \n the complications observed were discitis and dural tear in five patients each and nerve root injury in two patients . \n 90% patients were able to return to light and sedentary work with an average delay of 3 weeks and normal physical activities after 2 months.conclusion:edoscopic discectomy provides a safe and minimal access corridor for lumbar discectomy . \n the technique also allows early postoperative mobilization and faster return to work . ", "article": "many studies have not been reported in literature for lumbar discectomy by destandau endospine system .\nwe report a series of 300 patients operated for lumbar dissectomy by destandau endospine system .\na total of 300 patients suffering from lumbar disc herniations were operated between january 2002 and december 2008 .\ntechnique comprised localization of symptomatic level followed by insertion of an endospine system devise through a 15 mm skin and fascial incision .\nendoscopic discectomy is then carried out by conventional micro disc surgery instruments by minimal invasive route .\nthe results were evaluated by macnab 's criteria after a minimum followup of 12 months and maximum up to 24 months .\nbased on modified macnab 's criteria , 90% patients had excellent to good , 8% had fair , and 2% had poor results .\nthe complications observed were discitis and dural tear in five patients each and nerve root injury in two patients .\n90% patients were able to return to light and sedentary work with an average delay of 3 weeks and normal physical activities after 2 months .\nthe advantages of use of minimal invasive spinal surgical techniques in treatment of lumbar disc herniation is small incision , limited tissue disruption , enhanced visualization due to better magnification and illumination , shorter hospital stay , and faster recovery time.13 among many posterior spinal endoscopic systems used for disc surgery , destandau endospine system and foley and smith 's metrx system are seen as viable alternatives to open disc surgery.46 the aim of this study was to present results in 300 patients operated by edoscopic discectomy and to discuss technical points to shorten the learning curve .\na total of 475 patients suffering from different type and level of lumbar disc herniation with radiculopathy and degenerative lumbar canal stenosis were operated between january 2002 and december 2008 .\nthe inclusion criteria were patients having lumbar disc prolapse with unilateral radiculopathy , on clinical evaluation , positive straight leg raise or femoral stretch test , and identification of a single nerve root lesion on mri .\npatients with bilateral symptoms , double root involvement , cauda equina syndrome and whose clinical symptoms did not match mri picture were excluded from present study .\nall these patients had fair trial of conservative treatment in the form of rest , medication ( nsaid ) , activity modification , and physiotherapy ( minimum 6 weeks ) before they were advised to undergo surgery .\nhowever , in present study , none of the patients opted for surgery at 6 weeks after completion of conservative treatment .\nthere were 206 males and 94 females aged between 18 to 72 years ( mean , 38.4 years ) .\nlevels operated upon included l1-l2 ( n=3 ) , l2-l3 ( n=2 ) , l3-l4 ( n=6 ) , l4-l5 ( n=205 ) , and l5-s1 ( n=84 ) .\nthere were 235 extruded , 20 contained , 15 foraminal , and 30 sequestrated herniations .\nresults were evaluated as poor , fair , and good or excellent using modified macnab 's criteria .\nmodified macnab 's grading was as follows : excellent - no pain / restriction of activity and being able to do all activities ; good - occasional pain with relief of presenting symptoms and returning to work with some modification ; fair - some improved functional capacity but still handicapped or unemployed ; and poor results - having objective symptoms of root involvement or repeat surgery at the index level .\nthe clinical material included preoperative history , physical examination , plain x - rays and mri studies of lumbosacral spine , laboratory tests , and intraoperative video documentation .\npostoperative follow - up was carried out on third day , 2 weeks , 6 weeks , 3 , 6 , 12 , and 24 months .\nit consists of endospine tube , trocar , and working insert [ figure 1a and b ] .\none port for 0 degree endoscope , second for suction cannula , third port ( biggest ) for working instrument , and fourth port for dural and nerve root retractor .\nthe procedure of discectomy can be carried out under general , spinal , epidural , or local anesthesia .\nthe operative technique consists of knee chest positioning after administration of anesthesia followed by level localization by localization devise [ figure 1c ] . at marked point ,\n15 mm skin incision is made aponeurosis is incised using mayo 's scissors ; 1.5 cm wide periosteal elevator is used to elevate paravertebral muscles subperiostealy , thus exposing the interlaminar window and part of the affected side facet . (\na ) clinical photograph showing patient positioning and level marking ( b ) destandau endospine system ( c ) iitv picture of marked level ( d ) position of endospine tube ( e ) endoscopic view of decompressed nerve root the endospine tube with trocar is pushed through the incision in the direction of posterior arch over interlaminar window followed by withdrawal of trocar . the working insert\nany soft tissue bulging in the mouth of tube is removed till boundaries of interlaminar window such as superior and inferior lamina , facet joint are clearly visualized [ figure 1e ] .\nthis follows part resection of inferior margin of the superior lamina followed by excision of ligamentum flavum leading to exposure of the dural sac and nerve root under endoscopic vision .\nonce the nerve root has been accurately identified , it is retracted using a nerve root retractor .\n. it also helps to keep the field dry . depending on local findings , discectomy involving the extraction of the nucleus pulposus\nonce satisfactory nerve root decompression is achieved , endospine tube along with working insert is withdrawn .\naponeurosis is sutured using vicryl fine suture followed by closure of the skin in a subcuticular fashion . a water - impermeable dressing\n( a ) preoperative sagittal t2wi mri of prolapsed l5-s1 disc ( b ) postoperative sagittal t2wi mri of l5-s1 disc after endoscopic discectomy at 2 years follow up ( c ) axial t2wi mri section at l5-s1 disc after endoscopic discectomy at 2 years follow up shows no compression these patients were followed up on third day , 2 weeks , 6 weeks , 3 , 6 , 12 , and 24 months .\npatients were followed up for minimum of one year and maximum of 2-year duration . on second visit on third day ,\nwound was inspected for any drainage or evidence of infection . complains about fever , backache , and leg discomfort\nat final follow - up , 90% patients were relieved of sciatica and were satisfied with procedure .\n285 patients were operated as day care cases and were mobilized and discharged same evening from day care facility .\nbased on modified macnab 's criteria 90% patients had excellent to good , 8% had fair , and 2% had poor results .\nfive patients who had interaoperative minor dural tears were hospitalized and were observed for any dural leak .\ncausative factor for dural tears in present study were as follows : three patients had dural rent due to forceful retraction of dura and nerve root by dural and nerve root retractor .\nthis was observed in patients in whom there was significant posterolateral herniation resulting in tenting of dura and nerve root at recess .\nin this situation , authors have found gentle mobilization of nerve root and dura by nerve root hook or approaching and debulking the offending disc through axilla before proceeding with retraction of nerve root and discectomy .\nthis happened when kerrison rongeur was used to open the tight recess resulting in dural tear and nerve root injury .\nthese dural tears were managed by water tight closure of muscle , fascia , and skin and bed rest for duration of one week .\nsuperficial delayed wound healing was observed in 20 patients , which healed in 21 days by regular dressings rest and administration of antibiotics .\nthe diagnosis of postsurgical discitis was based on mainly clinical grounds and laboratory evidence of raised counts , esr , and c - reactive proteins .\nclinical criteria included recurrence of severe and unrelenting back pain within first week of surgery , keeping patient awake at night after initial recovery .\nno biopsy of disc was resorted to ; however , mri of lumbosacral spine was ordered in all these patients which did not contribute much to the diagnosis .\nlizolid 600 mg / bd ) for first week followed by oral antibiotics for 5 weeks .\nall these patients responded well to antibiotics and no further intervention of any kind was carried out .\nafter initial back pain for 6 weeks , these patients had occasional residual backache which was treated by analgesics , activity modification , lumbar support , and rest during subsequent follow - up visits .\nnerve root injuries ( n=2 ) were encountered while trying to do a medial facetectomy to open the recess by a kerrison rongeur causing severe laceration of nerve root . however , nerve root was in continuity .\n, patties were used for gentle retraction and procedure of discectomy was successfully completed endoscopically without resorting to open discectomy .\n276 patients were able to return to sedentary work with an average delay of 2 weeks , except 24 patients who had complains of backache , occasional leg discomfort , discitis , and nerve root injuries .\nmedial facetectomy was resorted to in 59 patients to open the recess to decompress the nerve root in addition to discectomy .\nmixter and barr7 discovered the pathophysiology of discogenic sciatica and suggested laminectomy and discectomy as operative treatment .\nthe overall results of standard discectomy range from 68 to 95% in different series.8 the operative microscope and microsurgical techniques were developed in mid-1960 's by yasargil and krayenbuhl910 and these techniques revolutionized spine surgery leading to smaller incisions , less blood loss , increased visualization of site of pathology , decreased hospitalization , shorter postoperative recovery , and earlier return to activities compared with previous operative interventional techniques .\nthe results of microdiscectomy also range from 85 to 98%.1113 katayama et al.14 compared the results of open vs gold standard microdiscectomy and observed no difference between the surgical outcomes in both the groups but microdiscectomy gave better lighting , magnification , and therefore decreased the length of incision and tissue invasion .\nmicrodiscectomy also allowed the patients to return to early work with lesser use of narcotic medication .\nmicroendoscopic dissectomy ( med ) combines standard microsurgical technique with an endoscope , enabling the surgeons to address all types of disc herniations including decompression of nerve root and lateral recess .\nchemonucleolysis was reported by smith.15 nonetheless , based upon various randomized clinical trials , the efficacy of chemonucleolysis compared with more traditional and open procedures for the operative treatment of lumbar disc herniations remained speculative.16 the use of percutaneous nucleotomy , laser discectomy , and intradiscal electrothermal annuloplasty ( idet ) compared with microdiscectomy remains unclear , and it is attributed to the lack of high - quality studies.17 conclusions about the efficacy of some of the aforementioned minimally invasive procedures ( e.g. , chemonucleolysis , apd , idet ) were questionable with regard to disc - related pathology.18 therefore , lumbar microdiscectomy remained the gold standard for addressing a herniated or sequestrated intervertebral disc ; however , a movement toward more minimally invasive approaches that would yield superior outcomes , while minimizing excessive soft and bony tissue removal and minimizing soft tissue trauma , were sought . as such ,\nan evolution in procedures toward smaller incisions , less tissue trauma , and quicker return to daily activities took center stage in spine surgery .\nthe use of muscular retractor system was reported initially by faubert and caspar.1920 perez - curet and fessler,21 described for the first time a myriad of spine pathologies that could be addressed using tubeology .\nthough from our initial experience , endospine technique is minimal invasive , but limitation of study has been lack of comparison with gold standard microscopic discectomy technique .\nhowever , in a study by shin et al.,22 15 cases each were compared of med and microscopic group ( md ) .\nthe mean cpk - mm levels were lower for the med group than for the md group at both 3 ( 576.1286.3 iu / l compared with 968.1377.8\niu / l ) and 5 days ( 348.1231.0 iu / l compared with 721.7463.2 ) postoperatively ( p<0.05 ) . the mean vas scores for postoperative back pain were lower in the med group than in the md group , both at 1 ( 3.32.3 compared with 5.81.5 ) and 5 days ( 1.91.1 compared with 3.61.1 ) postoperatively ( p<0.01 ) .\naforementioned authors concluded that the med procedure is less invasive than md , and causes less muscle damage and backache .\nthe 90% excellent results in present study is comparable with other surgical procedures for herniated lumbar discs such as those of destandau , perez - cruet et al . , and\ntheir average surgical time was 66 minutes , average blood loss was 22 ml , average hospital stay was 7.7 hours , complication rate was 5% , reoperation rate was 4% , and average return to work was 17 days with excellent result in 94% patients .\naverage operative time was 50 minutes average blood loss was 45 ml ( range , 30 - 70 ml ) .\nreturn to work ( 21 days ) and overall results ( 90% ) which are comparable . in another prospective and randomized evaluation of surgical treatment for lumbar disc herniation by hermantin et al.,24 satisfactory results of 97% in endoscopic group ( n=30 ) and 93% in open laminectomy group ( n=30 ) were reported .\nhowever , in endoscopic group , these authors had excluded large central herniations and extra ligamentous herniations between l5 and first sacral vertebra .\nhowever , present endoscopic technique could be used for all levels and all type of herniations . in our current series , there was 5% discitis and 5% incidence of dural injury .\ncaspar and ebling,2526 authors have reported reoperation rate of 5.5 , 5.7 , and 3% , respectively .\nanother measure of success is reflected by the patient 's ability to return to previous employment .\nour patients returned to previous employment on an average at 15 days with restriction to avoid heavy manual work for 2 months .\ndiscectomy ( med ) by endospine system has claimed even lesser tissue invasion than microdiscectomy with even smaller skin incision , lesser use of analgesics , and early return to work .\nleast tissue invasion is established by many reports comparing the postoperative mri signal of paraspinal muscles,27 intraoperative electromyographic findings establishing less invasion to nerve roots,28 and by measuring serum levels of biochemical parameters reflective of a postoperative inflammatory reaction and damage to the paravertebral muscles.29 our personal opinion is similar , though this was not the parameter studied in our series .\nminimal invasive microendoscopic decompression technique has been used not only for paracentral disc herniations , but also for all types including far lateral , cephalad , caudal migrated , and central and recurrent disc herniations.3032 one of the driving forces behind the minimal invasive spine surgery is economics , shorter hospital stay , reduced postoperative morbidity , and quicker recovery times . in our series , 90% patients were operated as day care cases .\nposterior paraspinous process endoscopic access to lumbar disc herniation requires creation of working space where no or little space existed before .\ninternal view of operating site is magnified and well illuminated . with advent of this system ,\ndiscectomy can be done as day care procedure ensuring reduced postoperative morbidity , minimal or no hospitalization , less pain , and faster recovery .\nwith proper patient selection , discectomy and adequate nerve root decompression by doing foraminotomy or opening a lateral recess stenosis by minimally invasive technique can be achieved with this system .\nhowever , the endospine system has been excellent modality to address discogenic radiculopathy and to decompress lumbar canal stenosis .\nmany surgeons are convinced of advantages of the system and have included this system as part of their inventry . however , due to difficulty in orientation with scope and two - dimensional vision , availability of less space , frustrating and steep learning curve , and inability to master hand eye coordination , majority of surgeons are not able to continue with the technique .\nthe patience and persvrance to work through narrow confines and work closely with a surgeon who has mastered the technique is the key to learn .\nsecond step would be to become comfortable with 2 dimensional vision of endoscopic camera and to master orientation , triangulation .\ndepth perception in these techniques comes from experience rather than observation ; hence , surgeon keen to learn these techniques must combine these procedures during early phase of learning with standard procedures he is doing in his clinical practice . gradually , as surgeons master the learning curve , he will be able to use this as treatment method for his patients .\nthere is also a need to establish cadaveric labs and dummy models on line of arthroscopic learning centers where surgeons can practice hands - on cadavers and models to improve triangulation , depth perception , and hand eye coordination ."}
{"lay_summary": " background : role of information source , perceived benefits and risks , and destination image has significantly been examined in travel and tourism literature ; however , in medical tourism it is yet to be examined thoroughly . \n the concept discussed in this article is drawn form well established models in tourism literature.methods:the purpose of this research was to identify the source of information , travel benefits and perceived risks related to movement of international patients and develop a conceptual model based on well - established theory . \n thorough database search ( science direct , utmj.org , nih.gov , nchu.edu.tw , palgrave - journals , medretreat , biomedcentral ) was performed to fulfill the objectives of the study.results:international patients always concern about benefits and risks related to travel . \n these benefits and risks form images of destination in the minds of international patients . \n different sources of information make international patients acquaint about the associated benefits and risks , which later leads to development of intention to visit . \n this conceptual paper helps in establishing model for decision - making process of international patients in developing visit intention.conclusion:ample amount of literature is available detailing different factors involved in travel decision making of international patients ; however literature explaining relationship between these factors is scarce . ", "article": "medical tourism is illustrated as occurrence in which individuals travel abroad to receive healthcare services ( 1 ) .\nit is a multi - billion dollar industry and countries like india , thailand , singapore , malaysia , belgium , costa rica , cuba , dubai , hungary , israel , jordan , south africa and many others are being benefited in their economy by this recent phenomenon ( 2 , 3 ) .\nthe prime driving factors in medical tourism are increased medical costs , increased insurance premiums , increasing number of uninsured or partially insured individuals in developed countries , long waiting lists for procedures in countries having public healthcare system , availability of high quality services at affordable price , and cheaper airfare . increased communication and internet access in developing countries\nare other supporting factors , which help patients to develop awareness about international travel for medical care ( 47 ) .\nestimations can vary but still some of reliable sources claim ; gross medical tourism revenue worldwide was more than us$ 40 billion in year 2004 and reached up to us$ 100 billion by year 2012 ( 8) . in year 2007\n, it was estimated that around 750,000 us residents traveled abroad . accordingly , the base case estimated form 2007 to 2010 for the annual growth rate for outbound patients was 100 per cent in us ( 9 ) .\nforbes business estimated around 1.25 million americans were expected to travel outside for medical treatment in year 2014 ( 10 ) .\nafter thorough review it was found that there is huge gap in literature available in medical tourism .\naccounts detailing size and market of the industry are large in number yet there is scarcity of literature detailing about role and significance of different variables and linking them to form conceptual and theoretical framework which reflects decision making of international patients for taking part in medical tourism .\navailable literature explore various factors related to patients travel such as source of information , perceived risks , benefits of medical tourism and attributes of medical tourism destinations in sufficient amount but almost all of these related accounts are exploratory in nature and do not provide conceptual frameworks for testing .\nmany researchers ( 2 , 6 , 11 , 12 ) made calls to explore more about the decision making process based on conceptual models and test them empirically , so managers in medical tourism industry will be more acquainted about the needs and requirements of patients and design their future strategies accordingly and at the same time patients will also be benefited by receiving more quality services from the providers .\nthis article will draw a conceptual model based on patients source of information , perceived benefits , perceived risks , and medical tourism destination image with available literature that will be helpful to mangers to draw their future course of action for competitive advantage and at the same time fulfill the gap in available literature .\nimage formation agents are the factors which control the perception and evaluation of image ( 13 ) . researchers addressed amount and diversity of information sources that expose individuals including information related to destination acquired through visiting particular place .\nvarious studies performed on destination selection behavior of tourists explored that with combination of other different factors , information sources explored by individuals determined certain destinations as possible alternatives ( 1317 ) .\nconsumer behavior studies have already established the effects of source of information on purchase behavior ( 18 ) .\namount and type of different information sources directly influence in development of cognitive image formation of destination ( 19 ) .\nsource of information is a vital antecedent of destination image formation and destination choice intention ( 20 ) .\nthere are four ( i ) professional advice ( tour operators , travel agents , airlines ) ( ii ) word of mouth ( friends , relatives , social media ) ( iii ) advertisement , and ( iv ) news / books / movies , different categories of type of information sources usually consider responsible for destination image formation ( 13 ) , this article use these four categories of source of information for medical tourism destinations image formation .\nmedical tourism facilitators are specialized in promotion of medical services abroad and offer supportive services such as assisting in selection of country and hospital , correspondence with doctors , travel arrangements , and arrangements of required paper work ( 21 , 22 ) .\njudgment of agent related to travel of their clients has high influence on decisions of clients ( 23 ) .\nthese facilitators serve as motivators also due to providing much - needed assistant to those unenthusiastic potential international patients who do not want to make their trip arrangements by their own .\nmany hospitals and clinics linked themselves with airlines to promote their services and offer discounts ( 2 , 5 , 2426 ) .\nliterature on medical tourism also reveals the role of practitioner in promotion of medical tourism mainly in underdeveloped countries due to various reasons such as lack of resources , unavailability of equipment , unavailability of infra - structure , unavailability of specialized manpower , and unavailability of medication ( 2730 ) .\nword of mouth and recommendation also has high influence in decision making of international patients in selection of destinations , hospitals , and doctors .\nstudies revealed large numbers of patients visit different countries for medical services were received recommendations from family members , friends , relatives , and colleagues ( 3134 ) .\nwebsites and online forums created by experienced international patients to share their experiences with medical tourism are also considered as decisive source of information for those planning to take medical services abroad ( 35 , 36 ) .\nprinted materials are also used to promote the services by hospitals and clinics , for example air mauritius in - flight magazine provides details about procedures and services provided by the hair grafting clinics in mauritius ( 2 ) .\nmajor medium of promotion of services by destination countries are trade fairs , travel markets / travel fairs , exhibitions , seminars and conferences to make potential patients informed about products and services offered by destinations .\nsome of these fairs and exhibitions are organized in collaboration with government agencies like tat , ministry of foreign affairs and department of export promotion but some providers organized these events by their own in cooperation with local institutes , medical schools and universities ( 37 ) .\nprint media play an important role in promotion and advertising medical tourism in major source countries , publish attractive and evidence based stories in their different segments related to health and travel .\nlos angeles time first examined about the growth of medical tourism and marked it as trend . later on new york times and los angeles times published stories of satisfied patients .\nfox , cbs s  60 minutes  and cnn aired their segments on patients traveling to medical services .\nmagazines like forbes and wall street journal analyzed the business aspect of medical tourism as  brokers assertively marketed medical tourism to consumers , employers , and insurers ( 38 ) .\nliterature revealed that not every physical attribute of a destination has influence on image formation process .\nthere is substantial inequality between descriptive dimensions of image and the attributes which are considered important for decision making within individuals ( 39 ) .\nit is generally presumed in marketing that products with similar characteristics will be equally preferred by the consumers , however , attributes , which make the product similar to other products , will not be necessarily same at the time of actual purchase . the importance of attributes will be change according to the need of consumer ( 40 ) . wish ( 1971 ) cited in ( 40 ) found that despite have many similarities individual like one country and dislike another one .\nthis is due to dimensions of liking may not be agree with the dimensions of similarity .\nliterature revealed that many researchers made distinction between physical and beneficial aspect of a product .\nfew researchers explained it as  characteristic and  benefits to the physical and beneficial aspect of product respectively ( 41 ) .\nthe typology of different attributes of product has been proven fruitful because by this a product s features can be segments into three groups as characteristic , beneficial , and imagery .\nthere are three components of vacation destination image formation ; ( i ) based on awareness : rely on the information sources , tourist believes about what a destination possesses , ( ii ) based on attitude : feelings and beliefs about destination , and ( iii ) based on expectations : expected benefits obtain from a tourist product ( 43 ) .\nthe above mention discussion clearly indicates that process of image formation is not just emphasis on physical attributes of destination but also depends on benefits or consumption values of product or service consumers hold in their minds .\nbenefits offered by a product or service are considered as consumption value of the same ( 44 ) .\nsheth , newman and gross ( 1991 ) developed a theory known as theory of consumption values , which focuses on consumption values of products and services ( 45 ) .\nconditional value. the decision making of consumer choice behaviour can be based on all five or any of the five consumption values .\nconsumption value model define the characteristics of  functional value as price , credibility , and durability .\nmedical tourism destinations offer very low price for medical services to international patients in comparison to developed countries , and most of the time price of a procedure in india and other asian destination is equal to 1/10 of price in us or european countries ( 4 , 4648 ) .\nquality of medical services is one of the aspects which drive medical tourism high towards success .\nmost of the hospitals in india provide medical care services to international patients are certified by jci which has reputation for hospital safety and regulatory management and recognized worldwide ( 49 ) .\nhigh procedure success rate also forms image as quality medical tourism destination of various destinations at south asian , african and latin america ( 48 , 49 ) .\nalthough availability of literature explain  social value in medical tourism is less , little available literature clearly define the \nsocial value aspect has been clearly observed in yemeni patients travel abroad for treatment ( 27 , 50 ) .\nsenior male members of the household consider it as opportunity to increase their reputation in society . availing expensive and prestigious medical care service in foreign countries and the associated sacrifices with it would make stories full of pride to tell to others ( 51 ) .\nmost of the citizens of yemen do not obtain resources to go for leisure travel at different parts of the world therefore traveling to foreign country for medical services provide chance to explore new territory , meet new people , and experience different social culture ( 27 , 50 ) .\nhowever , the concept of social value and epistemic value may not be associated with patients from developed regions .\nmany researchers found in their studies that patients were highly motivated to travel to a particular destination due to emotional attachment with doctor , hospitals or destination ( 6 , 50 ) .\nsuch as , many omani patients visit shiraz in iran for treatment due to religious and cultural familiarity ( 52 ) .\nconditional value can be considered as major factor pushes patients to travel abroad because medical needs are crucial and considered as unavoidable so have great conditional value .\nperceived risks is defined as perception of an individual about the probability that a particular action will lead them to a situation exposed with danger more than acceptable limit , and will lead to influence travel decision - making ( 53 ) . security and safety at the destination is major issue of concern by the potential travelers . in travel decision ,\nmaking perception of risks has utmost importance due to its tendency to alter destination selection ( 54 ) .\nresearchers argued in favor of conducting study on perceived risks and destination image together ( 55 ) . in tourism literature , authors considered safety and security at destination as one of the pull factors caused destination image formation ( 13 , 14 , 56 ) .\nhowever , in general cognitive image of destination does not engage with varied range of travel specific risks at destination and consider safety and risks as one of the many other attributes associated with destination ( 54 ) .\nin addition , at the same time perceived risks are considered as potential inhibitors of travel ( 57 ) .\nresearchers argued that using cognitive image to understand the dimensions of travel risks will be a conceptual mistake ( 58 ) .\nhence , perceived risks and cognitive image should consider individual variables for image related studies in travel .\ncredence goods as the quality of these good can not be assessed accurately even after consumption .\npatients may vulnerable to many risks if consider to take medical services at medical tourism destinations .\nresearchers described six dimension of risks associated with health travelers visited israel as  human - induced risks , \nfinancial risks ,  service quality risks ,  socio - psychological risk ,  natural disasters and car accident risk , and \nafter thorough literature review , authors categorized medical tourism destination perceived risks into three categories , as  physical - health related risks ,  service related risks , and  destination related risks. physical risks are considered as possibility of physical danger or injury detrimental to health where as health risks are considered as possibility to becoming sick while traveling or at destination ( 54 ) .\nin medical tourism , international patients can be exposed with different diseases , so risk of contracting with a different kind of disease is even higher such as blood borne infection and infection due to improper screening and storage of blood , deep - vein thrombosis ( dvt ) to those patients returning home after surgery , language related risks and lose of money can also be a matter of concern while involved in medical tourism .\nhealth risks for patients travel for organ transplant is even higher due to ignorance of standard protocol in donor selection ( 12 , 6062 ) .\nliterature revealed few american patients came in contact with non - tuberculous mycobecterial infection while taking treatment in hospitals abroad ( 63 , 64 ) .\nresearchers consider terrorism and kidnapping of rich patients and unstable economy of the destination as other risks associated with medical related travel .\napart from physical - health and service related risks , every destination have its own associated risks ; risks of terrorism , crime , and personal safety are associated with medical tourism destination due to falling in middle and lower middle - income countries in development status ( 63 ) . according to researchers , destination image is the total of ideas , beliefs , and impressions individuals possess about the attributes of destination and or activities available at a destination after processing information from various sources over a period of time ( 39 , 65 ) .\ndestination image as overall imagery picture individual obtains in his mind ( 66 ) . in the early studies on travel\n, researchers used the concept of stereotypic image of a travel destination ( 67 , 68 ) . later on , to understand the destination image formation process researchers developed an alternative framework and argued destination image consist of two components i.e. attribute based and holistic ( 66 ) .\nattribute based component refers to the perception of individual based on destination features and holistic component refers to imaginary mental image of destination .\nlater on , a bi - dimensional model was presented by researchers to represent destination image , consist of cognitive and affective image component ( 13 , 69 ) .\nthe cognitive component of destination image develops on knowledge and beliefs of destination based on tangible attributes , whereas affective component of image develops on emotions and feelings about the destination ( 70 , 71 ) .\nresearchers further studied affective image of destination and illustrate a four semantic differential scale to evaluate the affective component of destination image based on arousing \nfurthermore , cognitive component of destination image is an antecedent of affective component ( 72 ) .\nthus , a distinctive image of a destination forms in tourists mind based on strength and weakness of attributes of cognitive and affective components . image of destination formed in consumer s mind is defined as aggregate of attributes and beliefs ( 73 ) .\nit means if tourist has enough level of positive beliefs about attributes of destination it is expected that s / he has developed favorable attitude towards destination .\nthe process of destination image formation is described as mental construct of representation of destination based on information cues transmitted by image inducing agents chosen by individual ( 19 ) .\nafter thorough literature review authors identified four dimension of cognitive medical tourism destination image based of different attributes projected by different medical tourism destinations , as ;  medical amenities ,  general infra - structure ,  tourism attractions , and \nsocial environment. most of the hospitals websites are dominated with images stressing on sophistication , advanced technology , cleanliness and efficiency .\nmajority of these sites are in english highlight the variety of procedures , price , accreditation of hospitals , and affiliation of doctors , qualified and smart staff , lavishly furnished accommodations , and testimonials of past patients , and efficiency with different languages of staff .\ncommand on technology is rarely missed in any form of marketing ( 12 , 46 , 74 , 75 ) .\nbased on mentioned qualities , medical tourism destinations project themselves as most suited destination for potential travelers ( 28 , 32 , 76 ) . to nullify the quality related concerns of international patients hospitals and medical tourism facilitators / brokers emphasis on the markers of quality services .\nphysicians trainings in world reputed institutes like national institute for health , johns hopkins university , university of birmingham , and other reputed universities are highlighted in the profiles of physicians .\nprominent display of training and expertise of doctors achieve two goals ; established trustworthiness and mitigate concerns related to risk .\nthe accreditation awarded by jci is promoted by hospitals as mark of offering medical care of american standards ( 2 , 28 , 77 ) .\ncollaboration with prestigious hospitals in us and europe in also indicate seriousness towards providing quality services to patients by medical tourism hospitals at different destination ( 21 , 78 ) . distinguishing that major market drivers such as lack of health insurance and unaffordability are influencing patients to take procedures abroad , websites of brokerages predominantly display the comparative cost charts and price schedules .\nmost of the destinations claim providing significant cost services through different sources of promotion ( 5 , 79 , 80 ) .\nmost the promotions and advertisements show smiling , well - dressed and empathetic medical staff taking care of international patients .\nmany hospitals focus on multi - lingual staff providing services to patients speaking different major languages of the world .\nlanguage is also an influencing factor in decision making in selection of destination ( 11 , 37 ) .\nfacilities and quality of accommodation to international patients and their companions play important role in attracting the foreign patients .\nessential supportive services like local transportation services , food , communication , and others are also important in attracting the patients to a destination .\nthailand for example attracts more patients from developed countries because of already established quality tourism infrastructure offer excellent accommodation and hospitality services to international patients ( 81 ) . despite offering excellent medical care to international patients by hospitals in india most of the international patients visit india worry about accommodation quality , food hygiene , and personal safety ( 82 , 83 ) .\npotential tourists prefer to receive medical services to the places where they are also interested for holidaying ( 75 , 84 ) . after focusing on cost and reliability\nimage formation agents are the factors which control the perception and evaluation of image ( 13 ) . researchers addressed amount and diversity of information sources that expose individuals including information related to destination acquired through visiting particular place .\nvarious studies performed on destination selection behavior of tourists explored that with combination of other different factors , information sources explored by individuals determined certain destinations as possible alternatives ( 1317 ) .\nconsumer behavior studies have already established the effects of source of information on purchase behavior ( 18 ) .\namount and type of different information sources directly influence in development of cognitive image formation of destination ( 19 ) .\nsource of information is a vital antecedent of destination image formation and destination choice intention ( 20 ) .\nthere are four ( i ) professional advice ( tour operators , travel agents , airlines ) ( ii ) word of mouth ( friends , relatives , social media ) ( iii ) advertisement , and ( iv ) news / books / movies , different categories of type of information sources usually consider responsible for destination image formation ( 13 ) , this article use these four categories of source of information for medical tourism destinations image formation .\nmedical tourism facilitators are specialized in promotion of medical services abroad and offer supportive services such as assisting in selection of country and hospital , correspondence with doctors , travel arrangements , and arrangements of required paper work ( 21 , 22 ) .\njudgment of agent related to travel of their clients has high influence on decisions of clients ( 23 ) .\nthese facilitators serve as motivators also due to providing much - needed assistant to those unenthusiastic potential international patients who do not want to make their trip arrangements by their own .\nmany hospitals and clinics linked themselves with airlines to promote their services and offer discounts ( 2 , 5 , 2426 ) .\nliterature on medical tourism also reveals the role of practitioner in promotion of medical tourism mainly in underdeveloped countries due to various reasons such as lack of resources , unavailability of equipment , unavailability of infra - structure , unavailability of specialized manpower , and unavailability of medication ( 2730 ) .\nword of mouth and recommendation also has high influence in decision making of international patients in selection of destinations , hospitals , and doctors .\nstudies revealed large numbers of patients visit different countries for medical services were received recommendations from family members , friends , relatives , and colleagues ( 3134 ) .\nwebsites and online forums created by experienced international patients to share their experiences with medical tourism are also considered as decisive source of information for those planning to take medical services abroad ( 35 , 36 ) .\nprinted materials are also used to promote the services by hospitals and clinics , for example air mauritius in - flight magazine provides details about procedures and services provided by the hair grafting clinics in mauritius ( 2 ) .\nmajor medium of promotion of services by destination countries are trade fairs , travel markets / travel fairs , exhibitions , seminars and conferences to make potential patients informed about products and services offered by destinations .\nsome of these fairs and exhibitions are organized in collaboration with government agencies like tat , ministry of foreign affairs and department of export promotion but some providers organized these events by their own in cooperation with local institutes , medical schools and universities ( 37 ) .\nprint media play an important role in promotion and advertising medical tourism in major source countries , publish attractive and evidence based stories in their different segments related to health and travel .\nlos angeles time first examined about the growth of medical tourism and marked it as trend . later on new york times and los angeles times published stories of satisfied patients .\nfox , cbs s  60 minutes  and cnn aired their segments on patients traveling to medical services .\nmagazines like forbes and wall street journal analyzed the business aspect of medical tourism as  brokers assertively marketed medical tourism to consumers , employers , and insurers ( 38 ) .\nliterature revealed that not every physical attribute of a destination has influence on image formation process .\nthere is substantial inequality between descriptive dimensions of image and the attributes which are considered important for decision making within individuals ( 39 ) .\nit is generally presumed in marketing that products with similar characteristics will be equally preferred by the consumers , however , attributes , which make the product similar to other products , will not be necessarily same at the time of actual purchase . the importance of attributes will be change according to the need of consumer ( 40 ) . wish ( 1971 ) cited in ( 40 ) found that despite have many similarities individual like one country and dislike another one .\nthis is due to dimensions of liking may not be agree with the dimensions of similarity .\nliterature revealed that many researchers made distinction between physical and beneficial aspect of a product .\nfew researchers explained it as  characteristic and  benefits to the physical and beneficial aspect of product respectively ( 41 ) .\nthe typology of different attributes of product has been proven fruitful because by this a product s features can be segments into three groups as characteristic , beneficial , and imagery .\nthere are three components of vacation destination image formation ; ( i ) based on awareness : rely on the information sources , tourist believes about what a destination possesses , ( ii ) based on attitude : feelings and beliefs about destination , and ( iii ) based on expectations : expected benefits obtain from a tourist product ( 43 ) .\nthe above mention discussion clearly indicates that process of image formation is not just emphasis on physical attributes of destination but also depends on benefits or consumption values of product or service consumers hold in their minds .\nbenefits offered by a product or service are considered as consumption value of the same ( 44 ) .\nsheth , newman and gross ( 1991 ) developed a theory known as theory of consumption values , which focuses on consumption values of products and services ( 45 ) .\nconditional value. the decision making of consumer choice behaviour can be based on all five or any of the five consumption values .\nconsumption value model define the characteristics of  functional value as price , credibility , and durability .\nmedical tourism destinations offer very low price for medical services to international patients in comparison to developed countries , and most of the time price of a procedure in india and other asian destination is equal to 1/10 of price in us or european countries ( 4 , 4648 ) .\nquality of medical services is one of the aspects which drive medical tourism high towards success .\nmost of the hospitals in india provide medical care services to international patients are certified by jci which has reputation for hospital safety and regulatory management and recognized worldwide ( 49 ) .\nhigh procedure success rate also forms image as quality medical tourism destination of various destinations at south asian , african and latin america ( 48 , 49 ) .\nalthough availability of literature explain  social value in medical tourism is less , little available literature clearly define the  social value factor with - in the patient groups especially from less developed regions .\nsocial value aspect has been clearly observed in yemeni patients travel abroad for treatment ( 27 , 50 ) .\nsenior male members of the household consider it as opportunity to increase their reputation in society . availing expensive and prestigious medical care service in foreign countries and the associated sacrifices with it would make stories full of pride to tell to others ( 51 ) .\nmost of the citizens of yemen do not obtain resources to go for leisure travel at different parts of the world therefore traveling to foreign country for medical services provide chance to explore new territory , meet new people , and experience different social culture ( 27 , 50 ) .\nhowever , the concept of social value and epistemic value may not be associated with patients from developed regions .\nmany researchers found in their studies that patients were highly motivated to travel to a particular destination due to emotional attachment with doctor , hospitals or destination ( 6 , 50 ) . such as , many omani patients visit shiraz in iran for treatment due to religious and cultural familiarity ( 52 ) .\nconditional value can be considered as major factor pushes patients to travel abroad because medical needs are crucial and considered as unavoidable so have great conditional value .\nperceived risks is defined as perception of an individual about the probability that a particular action will lead them to a situation exposed with danger more than acceptable limit , and will lead to influence travel decision - making ( 53 ) . security and safety at the destination is major issue of concern by the potential travelers . in travel decision ,\nmaking perception of risks has utmost importance due to its tendency to alter destination selection ( 54 ) .\nresearchers argued in favor of conducting study on perceived risks and destination image together ( 55 ) . in tourism literature , authors considered safety and security at destination as one of the pull factors caused destination image formation ( 13 , 14 , 56 ) .\nhowever , in general cognitive image of destination does not engage with varied range of travel specific risks at destination and consider safety and risks as one of the many other attributes associated with destination ( 54 ) .\nin addition , at the same time perceived risks are considered as potential inhibitors of travel ( 57 ) .\nresearchers argued that using cognitive image to understand the dimensions of travel risks will be a conceptual mistake ( 58 ) .\nhence , perceived risks and cognitive image should consider individual variables for image related studies in travel .\ncredence goods as the quality of these good can not be assessed accurately even after consumption .\npatients may vulnerable to many risks if consider to take medical services at medical tourism destinations .\nresearchers described six dimension of risks associated with health travelers visited israel as  human - induced risks , \nfinancial risks ,  service quality risks ,  socio - psychological risk ,  natural disasters and car accident risk , and \nafter thorough literature review , authors categorized medical tourism destination perceived risks into three categories , as  physical - health related risks ,  service related risks , and \ndestination related risks. physical risks are considered as possibility of physical danger or injury detrimental to health where as health risks are considered as possibility to becoming sick while traveling or at destination ( 54 ) . in medical tourism ,\ninternational patients can be exposed with different diseases , so risk of contracting with a different kind of disease is even higher such as blood borne infection and infection due to improper screening and storage of blood , deep - vein thrombosis ( dvt ) to those patients returning home after surgery , language related risks and lose of money can also be a matter of concern while involved in medical tourism .\nhealth risks for patients travel for organ transplant is even higher due to ignorance of standard protocol in donor selection ( 12 , 6062 ) .\nliterature revealed few american patients came in contact with non - tuberculous mycobecterial infection while taking treatment in hospitals abroad ( 63 , 64 ) .\nresearchers consider terrorism and kidnapping of rich patients and unstable economy of the destination as other risks associated with medical related travel .\napart from physical - health and service related risks , every destination have its own associated risks ; risks of terrorism , crime , and personal safety are associated with medical tourism destination due to falling in middle and lower middle - income countries in development status ( 63 ) .\naccording to researchers , destination image is the total of ideas , beliefs , and impressions individuals possess about the attributes of destination and or activities available at a destination after processing information from various sources over a period of time ( 39 , 65 ) .\ndestination image as overall imagery picture individual obtains in his mind ( 66 ) . in the early studies on travel\n, researchers used the concept of stereotypic image of a travel destination ( 67 , 68 ) . later on , to understand the destination image formation process researchers developed an alternative framework and argued destination image consist of two components i.e. attribute based and holistic ( 66 ) .\nattribute based component refers to the perception of individual based on destination features and holistic component refers to imaginary mental image of destination . later on ,\na bi - dimensional model was presented by researchers to represent destination image , consist of cognitive and affective image component ( 13 , 69 ) .\nthe cognitive component of destination image develops on knowledge and beliefs of destination based on tangible attributes , whereas affective component of image develops on emotions and feelings about the destination ( 70 , 71 ) .\nresearchers further studied affective image of destination and illustrate a four semantic differential scale to evaluate the affective component of destination image based on arousing \nsleepy , pleasant  unpleasant , exciting gloomy , and relaxing  distressing ( 70 ) .\nfurthermore , cognitive component of destination image is an antecedent of affective component ( 72 ) .\nthus , a distinctive image of a destination forms in tourists mind based on strength and weakness of attributes of cognitive and affective components . image of destination formed in consumer s mind is defined as aggregate of attributes and beliefs ( 73 ) .\nit means if tourist has enough level of positive beliefs about attributes of destination it is expected that s / he has developed favorable attitude towards destination .\nthe process of destination image formation is described as mental construct of representation of destination based on information cues transmitted by image inducing agents chosen by individual ( 19 ) .\nafter thorough literature review authors identified four dimension of cognitive medical tourism destination image based of different attributes projected by different medical tourism destinations , as ;  medical amenities ,  general infra - structure , \nsocial environment. most of the hospitals websites are dominated with images stressing on sophistication , advanced technology , cleanliness and efficiency .\nmajority of these sites are in english highlight the variety of procedures , price , accreditation of hospitals , and affiliation of doctors , qualified and smart staff , lavishly furnished accommodations , and testimonials of past patients , and efficiency with different languages of staff .\ncommand on technology is rarely missed in any form of marketing ( 12 , 46 , 74 , 75 ) . based on mentioned qualities , medical tourism destinations project themselves as most suited destination for potential travelers ( 28 , 32 , 76 ) . to nullify the quality related concerns of international patients hospitals and medical tourism facilitators / brokers emphasis on the markers of quality services .\nphysicians trainings in world reputed institutes like national institute for health , johns hopkins university , university of birmingham , and other reputed universities are highlighted in the profiles of physicians .\nprominent display of training and expertise of doctors achieve two goals ; established trustworthiness and mitigate concerns related to risk .\nthe accreditation awarded by jci is promoted by hospitals as mark of offering medical care of american standards ( 2 , 28 , 77 ) .\ncollaboration with prestigious hospitals in us and europe in also indicate seriousness towards providing quality services to patients by medical tourism hospitals at different destination ( 21 , 78 ) . distinguishing that major market drivers such as lack of health insurance and unaffordability are influencing patients to take procedures abroad , websites of brokerages predominantly display the comparative cost charts and price schedules .\nmost of the destinations claim providing significant cost services through different sources of promotion ( 5 , 79 , 80 ) .\nmost the promotions and advertisements show smiling , well - dressed and empathetic medical staff taking care of international patients .\nmany hospitals focus on multi - lingual staff providing services to patients speaking different major languages of the world .\nlanguage is also an influencing factor in decision making in selection of destination ( 11 , 37 ) .\nfacilities and quality of accommodation to international patients and their companions play important role in attracting the foreign patients .\nessential supportive services like local transportation services , food , communication , and others are also important in attracting the patients to a destination .\nthailand for example attracts more patients from developed countries because of already established quality tourism infrastructure offer excellent accommodation and hospitality services to international patients ( 81 ) . despite offering excellent medical care to international patients by hospitals in india most of the international patients visit india worry about accommodation quality , food hygiene , and personal safety ( 82 , 83 ) .\npotential tourists prefer to receive medical services to the places where they are also interested for holidaying ( 75 , 84 ) . after focusing on cost and reliability\nprominent databases ( 2013 , 2014 , 2015 ) have been searched to obtain desire literature related to medical tourism including science direct , utmj.org , nih.gov , nchu.edu.tw , palgrave - journals , medretreat , biomedcentral and so on and the keywords used are medical tourism , information sources , medical travel , health travel and so on .\ngoogle search was performed to get latest data related to medical tourism . to know in detail about the variables used in the framework scientific research databases\nthe key words used to find out research variables as well as relationship between researches variables were destination image , destination information sources , beneficial image , perceived travel risks , cognitive image , affective image , consumption values and so on . to obtain data about medical tourism various types of available literature were reviewed such as industry reports , market research reports , media reports and internet sources , however for identification and explanation of variables scientific literature published in reputed journals only were included .\nthe theory of planned ( tpb ) is an established and comprehensively tested model details the relationship between beliefs , attitude , intention , and actual behavior of consumers ( 85 ) . the model is perfectly applied in a variety of studies including leisure and tourism travel , and hospitality ( 36 , 8688 ) .\nthese research studies emphases on the factors such as motivations , information sources , attitudes , and visit intentions , thus authors argue that attitudinal theory provides a sound foundation to understand travel intentions of international patients and underpin the conceptual model discussed in this article .\nstudies explained that consumers access more information in case of high association of risks or benefits or both in a particular act ( 89 , 90 ) and perform rigorous information search in case of planning first time trip ( 91 ) because first time trip is associated with unknown risks as well as unknown leisure activities .\nin general consumer behaviour practices risk - handling activity increases in case of high level of perceived risks .\nimportance of risk handling activity also determines by associated benefits gained after engaging with risk taking activity ( 92 ) .\nthe benefits of information search includes possibility of finding superior alternative to those already considered and the reduction in risk achieved from eliminating inferior , but a priori uncertain , alternatives ( 93 ) . with the discussion of above literature related to tourism\nit could be assumed that medical tourism information sources will have positive influence on perceived travel benefits of international patients . whereas , information sources of medical tourism will negatively influence perceived travel risks of international patients .\ndestination image is considered as perceptions or impressions of destination held by tourists with respect to the expected benefit or consumption values .\nthe benefits sought by the travelers are highly associated with the image of destination and the affective image of destination is largely highly influenced by the motivations / benefits sought by individuals ( 13 , 44 ) .\nthe affective image of a destination is more positive in individual s mind when emotions evoked by the place coincide with the benefits sought ( 95 ) .\nrisks and constraints associated with travel have significant impact on destination image formation at the time of early decision - making process ( 96 ) . according to researchers ,\ntwo dimensions significantly influence cognitive and affective image of destination ( 58 ) . on the basis of previous studies in tourism literature\nit can be assumed that perceived travel benefits of international patients will positively influence the destination image , whereas perceived travel risks of international patients will negatively influence the destination image .\nintention of visit related to travel is considered as tourists perceived likelihood to visit particular destination within a specific time period ( 97 ) .\nthus , to be closely correlated to the travel behaviour intention of visit believes as an important outcome variable in tourism research ( 16 , 97 ) .\nintention to visit a destination is highly influenced by cognitive / perceptual and affective evaluation ( 98 ) .\ndestination image is a direct antecedent of perceived quality , satisfaction and revisit intention and recommendation ( 99 ) . according to researchers\n, there is significant theoretical and empirical link between cognitive destination image and behavioral intention ( 100 ) .\nbased on above discussion it could be assumed that image of medical tourism destination will positively influence visit intention of international patients . conceptual framework  international patients travel decision making\nthe article is a sincere effort by authors to establish conceptual framework which explains decision - making process of international patients .\nthough , there has been advance in explaining different factors play important roles in international patients travel , however , there is scarcity of literature conceptualizing these factors into a framework and test it empirically .\nliterature reveals about associated benefits and risks related to travel abroad for medical purposes but do not conceptualize it in the process of decision - making .\nsources of information in medical tourism play significant role in development of attitude as well as intention , has already been established in consumer behavior .\nhowever , need is to test its significance in medical tourism decision - making process .\nthe proposed framework will encourage future researchers to test different variables empirically and establish the model of international patients travel behavior .\nethical issues ( including plagiarism , informed consent , misconduct , data fabrication and/or falsification , double publication and/or submission , redundancy , etc . ) have been completely observed by the authors ."}
{"lay_summary": " molecular therapeutics for treating epidermal growth factor receptor-(egfr- ) expressing cancers are a specific method for treating cancers compared to general cell loss with standard cytotoxic therapeutics .   \n however , the finding that resistance to such therapy is common in clinical trials now dampens the initial enthusiasm over this targeted treatment .   \n yet an improved molecular understanding of other receptor tyrosine kinases known to be active in cancer has revealed a rich network of cross - talk between receptor pathways with a key finding of common downstream signaling pathways . \n such cross talk may represent a key mechanism for resistance to egfr - directed therapy .   \n here we review the interplay between egfr and met and the type 1 insulin - like growth factor receptor ( igf-1r ) tyrosine kinases , as well as their contribution to anti - egfr therapeutic resistance in the context of squamous cell cancer of the head and neck , a tumor known to be primarily driven by egfr - related oncogenic signals . ", "article": "squamous cell carcinoma of the head and neck ( hnscc ) is a heterogeneous disease that includes tumors arising from the mucosal epithelial surface of the oral cavity , oropharynx , hypopharynx , and larynx . although these tumors originate within different anatomic sites within the upper aerodigestive tract , they are histologically identical ( 95% of hnscc are squamous cell carcinomas ) , share common etiologic risk factors and overlapping metastatic target site profiles ( reviewed in [ 13 ] ) .\nrecent genetic analysis of human head and neck tumors has revealed common molecular alterations including p53 mutation , p14arf , and p16 methylation , as well as cyclin d and egfr amplification [ 36 ] . despite these similarities ,\nthe distinct anatomic subsites are associated with differing rates of regional metastasis  for example , vocal cord lesions tend to metastasize less frequently than oropharyngeal or hypopharyngeal lesions . this variation may be attributed to differing densities of lymph draining vessels within each of the relevant subsites .\npatients who exhibit metastases into the regional nodal basin exhibit a 50% decrease in survival irrespective of treatment [ 715 ] .\ncurrently , it is the 5th leading cause of cancer by incidence and the 6th leading cause of cancer mortality in the world [ 16 , 17 ] .\nrecurrent and/or metastatic hnscc patients have a poor prognosis , with a median survival of less than 1 - 2 years [ 18 , 19 ] .\nseveral lines of evidence indicate that cancer is a disease resulting from dynamic changes in the genome that promote the progressive transformation of normal human cells into highly malignant derivatives [ 20 , 21 ] . during this process ,\ncancer cells acquire several unique capabilities including self - sufficiency in response to growth signals , insensitivity to antigrowth signals , evasion of programmed death ( apoptosis ) , limitless replicative potential , sustained angiogenesis as well as invasion and metastasis , reprogramming of energy metabolism , and avoiding immune destruction [ 21 , 22 ] .\ndetailed global genomic analyses of several human tumors has revealed that certain classes of signaling proteins appear to be targeted more frequently by oncogenic mutations .\nreceptor tyrosine kinases ( rtks ) are a good example . of the 59 transmembrane rtks identified to date ,\ndysregulation of ~30 rtks are associated with neoplastic transformation and cancer progression [ 2325 ] .\ninterestingly , ninety percent of primary head and neck squamous cell cancers , irrespective of subsite , have alterations in members of the epidermal growth factor ( egf ) family of receptor tyrosine kinases ( erbbs ) , in particular erbb1/egfr .\nten to fifteen percent of tumors will also have an alteration in another egfr family member , the erbb2/her2/neu receptor [ 27 , 28 ] .\nthese findings suggest a strong etiologic role for rtk dysregulation in this type of tumors . given this association , patients with head and neck squamous cell cancers are well positioned to benefit from existing and future molecular targeted agents directed against oncogenic rtks such as egfr ( reviewed in ) .     \nrtks are a family of transmembrane proteins that mediate many important physiological processes in both normal and cancerous cells .\nligand binding to the extracellular domain of rtks induces receptor dimerization and activation of rtk activity .\nsubsequent autophosphorylation of the receptor at specific tyrosine residues within the cytoplasmic domain generates binding sites for proteins that relay downstream biological signals to regulate protein function , protein - protein interactions , and gene expression . under physiological conditions ,\nrtk dysregulation can occur through several mechanisms including gene amplification or rtk overexpression , chromosomal translocation to produce constitutively active rtks , gain of function mutations or deletions that promote ligand - independent rtk activity , escape from negative regulatory mechanisms or local environmental changes , all of which lead to potent oncogenic signaling and hence neoplastic growth .\nthese complex signaling networks use multiple factors to drive the outcome of rtk signaling . although often depicted as linear pathways , they actually represent an integrated network with various modes of cross - talk , overlapping and distinct functions .\nknown signaling pathways involved in head and neck tumorigenesis include the phosphatidylinositol-3-kinase ( pi3k)-akt - mammalian target of rapamycin ( mtor ) , signal transducer and activator of transcription ( stats ) and raf kinase - mitogen - activated protein kinase kinase ( mek)-p42/p44 mitogen activated protein kinase ( mapk ) signaling pathways [ 1 , 30 ] .\nthis review highlights three rtk signaling pathways involved in head and neck squamous cell carcinoma ; egfr , the type 1 insulin - like growth factor receptor ( igf-1r ) and the hepatocyte growth factor ( hgf ) receptor ( met ) .\nthis short review will explore the relative contribution of each signaling axis to disease progression , potential modes of cross - talk , and targeted clinical approaches under investigation for disease management .\nthe egfr family of rtks is comprised of four different receptors known as erbb1 ( also referred to as egfr ) , erbb2 ( her2/neu in rodents ) , erbb3 ( her3 ) , and erbb4 ( her4 ) ( reviewed in [ 3133 ] ) . each receptor , with the exception of erbb3 , contain an intracellular tyrosine kinase domain that is activated by binding to extracellular egf - like ligands , which result in receptor dimerization and hence activation of downstream signaling cascades including mapk , pi3k / akt and stat signaling .\neleven egf - like ligands have been identified to date that can be categorized into four groups  those that bind egfr only ( egf , transforming growth factor alpha ( tgf ) , and amphiregulin ) , those that bind to egfr and her4 ( heparin binding - egf , betacellulin and epiregulin ) , those binding directly to either her3 and her4 ( neuregulin 1 and neuregulin 2 ) and her4 binding only ( neuregulin 3 and neuregulin 4 ) ( reviewed in ) .\nepigen , the most recently discovered member of the egf - like ligand family appears to be a low affinity and broad specificity ligand that effectively activates egfr .\nerbb2 is considered a ligand - less coreceptor as it does not have any known ligands that bind directly with high affinity , despite its established role as a potent oncogene in several cancer types including breast , colorectal , nonsmall cell lung carcinoma ( nsclc ) and hnscc [ 36 , 37 ] .  \naberrant egfr activity has been strongly linked to the etiology of 5890% of hnscc [ 26 , 38 ] .\nthese rates can vary due to the inclusion of cancers from different subsites within the head and neck , methods used to assess gene amplification and tumor scoring methods . in contrast to lung adenocarcinomas in which activating egfr mutations result in ligand - independent signaling [ 3943 ] , such activating egfr mutations are infrequent in hnscc [ 44 , 45 ] .\negfr gene amplification resulting in upwards of 12 copies per cell has been reported in hnscc patients compared to copy numbers detected in normal mucosa from noncancer patients .\nthis and other pathways of ligand - independent receptor activation that do not require egfr overexpression have been characterized as the likely drivers of egfr activity in hnscc .  \negfr gene amplification remains a strong indicator for poor patient survival , radioresistance , and locoregional failure [ 4749 ] .\negfr overexpression is detected in healthy mucosa in cancer patients ( field cancerization ) that will increase in proportion to observed histological abnormalities such as hyperplasia , carcinoma in situ and invasive carcinoma , indicating that it is an early event in hnscc .\naccordingly , significant effort has focused on egfr signaling as a therapeutic target for treating hnscc patients .\ncetuximab , matuzumab and nimotuzumab represent humanized antiegfr antibodies , whereas gefitinib and erlotinib are small tyrosine kinase inhibitors ( tkis ) ( figure 1 ) .\ncetuximab ( erbitux ) competitively inhibits endogenous ligand - binding to egfr and thereby inhibits subsequent receptor activation [ 5053 ] .\ncetuximab is a valuable treatment option in head and neck patients as it synergizes with current treatment modalities .\ncetuximab enhances the effects of many standard cytotoxic agents , including cisplatin ( the conventional platinum - fluorouracil chemotherapeutic ) , and in combination with chemotherapy it can elicit antitumor responses in tumors that previously failed to respond to that chemotherapy .\nnotably , cetuximab did not dramatically exacerbate the common toxic effects associated with radiotherapy of the head and neck , including mucositis , xerostomia , dysphagia , pain , weight loss , and performance status deterioration .\ncetuximab has been approved for use in combination with radiation for treating patients with locally advanced hnscc   and as monotherapy for patients with recurrent hnscc .\nmatuzumab ( formerly emd 72000 ) binds to egfr with high specificity and affinity to block receptor signaling , and also modulates antibody - dependent cellular cytotoxicity ( adcc ) when combined with cetuximab [ 5860 ] .\nphase i clinical trials report excellent antitumor activity of matuzumab against several human tumor types including head and neck cancers .\na randomized phase iib , four - arm , open - label study recently assessed the safety and efficacy of nimotuzumab in combination with radiation therapy ( rt ) or chemoradiation therapy ( crt ) in patients with advanced ( stage iii or iva ) hnscc .\nthe addition of nimotuzumab to both the radiation and chemoradiation regimens was reported to improve the overall response rate , survival rate at 30 months , median progression - free survival and median overall survival .\na combined group analysis of the nimotuzumab arms versus the non - nimotuzumab arms demonstrated a significant difference in overall survival favoring nimotuzumab .\nthis study is compelling as patient response rates compare favorably with studies combining cetuximab with radiotherapy , but with fewer side effects .\ngefitinib ( iressa ) is a small molecule tki - targeted to the intracellular active site for phosphorylation that has been tested in clinical trials involving hnscc patients , as a single agent or in combination with radiation treatment .\nunfortunately , gefitinib has shown limited clinical efficacy with response rates of 1015% [ 63 , 64 ] .\nerlotinib is a selective inhibitor of the egfr that also shows antitumor activity in hnscc comparable to standard combination chemotherapy .\nanother promising rtk under preclinical and clinical evaluation for head and neck cancers includes the igf-1r ( reviewed in [ 66 , 67 ] ) .\ntwo ligands , insulin - like growth factor 1 ( igf1 ) and igf2 bind to igf-1r .\nligand binding to the igf-1r stimulates its intrinsic tyrosine kinase activity , activating downstream signaling networks including ras - raf , mapk and erk , and pi3k ( figure 1 ) to drive cellular functions such as cell growth , survival and differentiation .\nit is widely accepted that the igf - axis activates antiapoptotic signaling , which in turn upregulates the pi3k - akt and mapk pathways in cancer cells .\nadditionally , igf - ir also regulates vascular endothelial growth factor ( vegf ) production , suggesting a role in tumor angiogenesis .\nseveral studies indicate that igf-1r is overexpressed and functional in 94% of hnscc patient samples [ 70 , 71 ] .\nconsistent with this , igf - ir signaling significantly enhances the proliferation , motility and tumorigenicity of human head and neck cancer cell lines . igf-1r\ndown regulation in a hnscc cell line using antisense oligonucleotides resulted in a dose - dependent decrease in cellular proliferation , induction of apoptosis , caspase activation and reduced expression of proangiogenic cytokines such as vegf .\ninterest in targeting the igf-1r in hnscc was bolstered by the observation that treatment of head and neck cancer cells with either igf or egf resulted in igf - ir and egfr heterodimerization [ 71 , 72 ] .\nhowever , only igf resulted in the phosphorylation of both receptors . using a mouse xenograft model for hnscc , treatment with antibodies against igf-1r , egfr or\nit remains to be determined whether cellular cross - talk between igf-1r and egfr has an important role in determining the biological aggressiveness of hnscc or resistance to egfr - targeted therapies .  \nseveral monoclonal antibodies and tkis for igf-1r have been tested in preclinical studies and early phase clinical studies .\nhowever , the efficacy of igf-1r - targeted therapy for treating patients with hnscc , particularly cross - talk with egfr , warrants further investigation . to date , the effect of blocking oncogenic igf-1r and egfr signaling have been studied more extensively in breast cancer cell lines [ 7375 ] .\ntreatment with gefitinib and ag1024 , a tki for igf-1r reduced cell proliferation when used as single agents and showed an additive effect when used in combination [ 76 , 77 ] . targeting igf-1r and egfr signaling is currently under evaluation in hormone - sensitive metastatic breast cancer using the igf-1r inhibitor osi-906 and the egfr tki erlotinib , although results are not yet available ( http://www.clinicaltrials.gov/ , identifier nct01205685 ) . similarly , an exploratory study to assess the modulation of biomarkers in hnscc patients treated preoperatively with cetuximab and/or imc - a12 , a humanized antiigf-1r monoclonal antibody is currently underway ( http://www.clinicaltrials.gov/ , identifier nct00617734 ) .\nthese studies will be critical for evaluating whether the use of anti - igf-1r and egfr - targeted treatments will be more effective than single - agent modalities for treating patients with hnscc .\nthe met receptor is a single pass transmembrane protein that upon binding its ligand hgf  also known as scatter factor - promotes increased cell proliferation , survival and motility ( reviewed in [ 78 , 79 ] ) .\nhgf is the only physiological ligand for met and is secreted as an inactive precursor polypeptide chain by mesenchymal cells .\nhgf is proteolytically cleaved to form an active / heterodimer by a number of serine proteases including urokinase plasminogen activator ( upa ) , tissue - type plasminogen activator ( tpa ) , coagulation factors x. xi and xii .\nmet is a disulphide - linked / heterodimer derived from the proteolytic cleavage of a 170  kda precursor .\nthe  chain and n - terminal region of the -chain form  sema domain , a seven -propeller structure in which blades 2 and 3 bind to hgf .\nthe sema domain is flanked by a cysteine - rich region followed by four immunoglobulin repeats .\nit is proposed that the cysteine - rich region and immunoglobulin repeat domains undergo a conformational change following hgf binding allowing for met dimerization [ 80 , 81 ] .\nbinding of hgf to met results in receptor autophosphorylation at key catalytic residues and subsequent recruitment of several cytosolic signaling molecules that are shared with the egfr and igf-1r signaling pathways , including the grb2/sos complex , the p85 regulatory subunit of pi3k , gab1 and jak / stat3 ( figure 1 ) .\nsubsequent activation of the mapk and jun - n - terminal kinase ( jnk ) pathways is responsible for the mitogenic and motogenic properties of met / hgf signaling resulting in  invasive growth  , depending on the physiological setting .\nincreased met signaling in human cancers can be the result of enhanced ligand - binding ( autocrine and paracrine ) , met overexpression or missense mutations that often induce constitutive kinase activity , failure of met down regulation and interactions with other cell surface receptors such as egfr ( reviewed in [ 8284 ] ) . met is overexpressed in 84% of hnscc patient samples .\ninterestingly , amplification of the met gene ( > 10 copies per cell ) is present only in 3 of 23 ( 13% ) tumor tissues .\nhgf overexpression is detected in 45% of hnsccs , suggesting that hgf functions predominantly in a paracrine manner to drive met signaling in these cancers .\nmoreover , high levels of hgf are detected in hnscc patient plasma samples   supporting the idea that ligand availability is not a limiting factor for met activation .\nmutations in the met ligand - binding domain ( t230m / e168d ) , transmembrane or jm domain ( r988c , t1010i ) and the tyrosine kinase domain ( t1275i , v14333i ) have also been identified in hnscc tumor samples , although their relative contribution to hnscc progression remains to be determined .\ntwo somatic met mutations have been detected in hnscc that result in constitutively active receptor signaling that confers an invasive phenotype when ectopically expressed in cell lines .\nthe y1230c mutation confers anchorage - independent growth and an invasive phenotype in transfected cells , whereas the y1235d met mutation stimulates epithelial cells to invade reconstituted basement membrane in the absence of hgf . in the case of the mety1235d mutation\n, genomic analyses of hnscc patient samples detected the presence of this mutant allele in 50% of metastatic tumors versus 26% in primary tumors , raising the possibility that this could be a critical genetic lesion for the acquisition of a metastatic phenotype .\nalternatively , increased met signaling could afford hnscc a selective advantage for growth and/or survival in metastatic sites , such as the lymph node and lung .\nindeed several studies indicate that met overexpression correlates highly with lymph node metastasis , pathologic stage , and disease reoccurrence [ 8891 ] .\nmoreover , patient survival was significantly reduced in biopsy samples with positive met expression relative to negative met expression , suggesting the association of met with hnscc disease progression .\nconsistent with these findings , treatment with the tki pf-2341066 caused a significant reduction in tumor growth , a high level of apoptosis and cellular debris within the tumor using a xenograft animal model for hnscc .\nselective inhibitors of met / hgf signaling include humanized monoclonal antibodies for hgf and met , and small - molecule tyrosine kinase inhibitors directed against met ( figure 1 ) .\nalthough their efficacy for treating a variety of solid tumors is increasingly recognized , we await results of preclinical and clinical trials for head and neck cancer that are ongoing .\nthe humanized antibody amg 102 shows high potency towards the mature and processed form of hgf with no detected effects on proteolytic activation of prohgf .\namg 102 interferes with met signaling , by competing with hgf for binding to the  chain of the met receptor . in phase\ni clinical studies in patients with advanced solid tumors , 70% of patients had a best response in terms of achieving stable disease [ 93 , 94 ] .\nimportantly , no antiamg 102 antibodies were detected and circulating hgf levels were dose dependent .\nanother promising clinical therapeutic is the one - armed 5d5 humanized antibody ( oa5d5/metmab ) directed against met .\nmetmab binds met with high affinity , preventing hgf binding , met phosphorylation , receptor internalization and downstream signaling events and has been shown to inhibit tumor growth in animal models by more than 95% [ 95 , 96 ] .\nmetmab is currently in phase i / ii human clinical trials in comparison with erlotinib in patients with nsclc ( http://www.clinicaltrials.gov/ , identifier nct00854308 ) .\nfuture clinical trials will be required to determine the suitability of amg102 and metmab as either single agents or combinatorial therapeutics for treating hnscc patients .\nforetinib ( formerly xl880 ) is a tki whose primary targets include met and vegf , and to a lesser extent the platelet - derived growth factor ( pdgf ) receptor , ron , kit and tie2 rtks .\nforetinib recently completed phase ii clinical trials in head and neck patients ( http://www.clinicaltrials.gov/ , identifier nct00725764 ) .\ninterim results suggest that after 12 months , 12 of 18 patients had stable disease .\na phase i dose - escalation study of the safety and pharmacokinetics of xl184 administered orally to patients with advanced malignancies ( showed that , on average , patients survived for more than 3 months with several up to 6 months while on treatment ) ( reviewed in ) . due to\nencouraging data from this study , a randomized phase iii trial of xl184 in hnscc patients was initiated to investigate xl184 as a first - line treatment ( compared with placebo ) for survival benefit to patients with hnscc ( http://www.clinicaltrials.gov/ , identifier nct00704730 ) .\narq197 ( arqule ) is a nonatp - site competitive , selective small molecule inhibitor of the met intracellular region .\nalthough the mechanism of arq197 is presently unknown , the results of phase i trials suggest potential antiinvasive activity for this compound .\noverall , met , and hgf - targeted therapies have been well tolerated in clinical trials with negligible toxicities .\nhowever , it remains to be determined whether met is a better therapeutic target than hgf .\nclearly , in patients where met is activated by autocrine hgf secretion , both hgf and met targeted therapies may prove to be more efficacious treatment options .\nacquired resistance is likely the result of several mechanisms including ( 1 ) egfr mutations initially present as well as those acquired during therapy , ( 2 ) receptor independent activation of downstream signaling cascades , ( 3 ) cross - talk with other rtks and converging signaling pathways and ( 4 ) environmental factors including inflammatory agents and viral infection .\nresistance to cetuximab has been associated with the coexpression of the truncated egfr mutant , egfrviii with wild - type egfr .\negfrviii is the result of an in frame deletion of exons 27 spanning the extracellular ligand - binding domain .\nthe deletion results in a truncated egfr receptor that signals in a ligand - independent manner .\negfrviii expression has been detected in 42% of hnscc patient samples , and closely correlates with increased hnscc cell proliferation in vitro and increased tumor growth using in vivo xenograft models .\negfrviii preferentially activates the pi3k pathway instead of the ras / raf / mek pathway , which is activated by wild - type egfr . of particular interest to the therapeutic treatment of hnscc ,\negfrviii expression decreases the proliferative response of egfr expressing tumor cells to cetuximab treatment relative to vector control cells . in a recent study ,\negfrviii cells were shown to be resistant to the antiinvasive effects of cetuximab due to an increase in phosphorylation of stat3 rather than increased pi3k signaling .\negf - induced expression of the stat3 target gene hif1 was abolished by cetuximab in hnscc cells expressing wild - type egfr under hypoxic conditions , but not in egfrviii - expressing hnscc cells [ 102 , 103 ] .\nthese data suggest a role for egfrviii in mediating hnscc resistance to cetuximab .   despite egfrs critical role in the development of hnscc\n, clinical data indicate modest clinical benefits for locoregional control and survival of head and neck cancer patients treated with egfr - targeted therapies .\nhnscc patients resistant to cetuximab , often succumb to local tumor recurrence as well as regional and distant metastasis .\nthe addition of cetuximab to radiation therapy was reported to show improved locoregional disease control , progression - free survival , and overall survival in patients with locally advanced hnscc .\nhowever the data revealed a disproportionate benefit of cetuximab with radiotherapy to oropharyngeal cancer patients when compared to patients treated with hyperfractionated radiotherapy .\naccumulating evidence suggests that human papilloma virus ( hpv ) 16 status ( hpv+ ) is an important prognostic factor associated with a favorable outcome in a subset of head and neck cancers , including oropharyngeal and tonsilar cancers .\nhpv+ tumors tend to have unique genetic aberrations including decreased egfr expression , whereas increased igf-1r levels characteristic of hnscc appear to be independent of hpv status .\nclinically , hpv+ tumors are characterized by more favorable patient prognosis regarding disease - free survival as well as overall survival [ 104 , 105 ] , possibly as a result of increased genomic stability associated with global gene hypermethylation in hpv+ tumors .\nthus it will be interesting to determine whether hpv+ status explains some of the benefits derived from the addition of cetuximab to radiotherapy in this subset of hnscc patients . at present\n, there are few clinical indicators of which hnscc patients will most likely respond to egfr - targeted therapies .\naccordingly , strategies to optimize egfr - targeted therapy remain an active area of research .\nadditional mechanisms that result in egfr activation include activating mutations in downstream signaling components or cross - talk between different rtk pathways . activating mutations in the pi3ka oncogene\noccurs in 10% of hnscc tumors   whereas elevated levels of phosphorylated stat3 correlates with lymph node metastasis and poor patient prognosis [ 108110 ] .\nconversely , h - ras mutations are infrequent in hnscc cases ( less than 5% ) , although a higher incidence has been detected in asian populations and correlates with areca nut chewing [ 111 , 112 ] .\nmet signaling has been shown to contribute to resistance in cell lines derived from multiple tumor types including breast , gastric and lung .\nin one key study , nsclc with activating mutations in the egfr acquire resistance to the tki gefitinib and erlotinib , by amplification of the met gene to maintain akt and her3 signaling .\nthese studies underscore the role of cross - talk between rtks to preferentially signal through the pi3k - akt survival pathway as a mechanism for acquired drug resistance .\nthe relevance of met as a mechanism for escape from egfr - targeted therapy in head and neck cancers remains to be determined .\nhypoxia results in the transcriptional upregulation of met gene expression via hif1 in a number of tumors including head and neck , often downstream of egfr signaling . in normoxia\n, hydroxylation of 2 prolines in hif1 enables its binding to the von hippel - lindau tumor suppressor protein ( pvhl ) linking hif1 to a ubiquitin ligase complex . during hypoxia , minimal or no hydroxylation occurs enabling hif1 to avoid proteasomal degradation and\ndimerize to other hif family members such as hif1   and coactivators , to form an active transcriptional hif complex on the hypoxia response element ( hre ) of target genes such as met .\nthe ubiquitin ligase catalyzes polyubiquitination of hif1 targeting it for proteasomal degradation . under hypoxic conditions ,\nincreased met signaling directs the invasive growth program , enabling cells to invade more oxygenated tissues .\nsince met has been reported to promote invasive and angiogenic effects in the tumor microenvironment , the use of hgf / met inhibitors may afford a means of impairing tissue colonization as well as tumor vascularization in head and neck cancer patients .     \nstudies on other solid tumor types , most notably glioblastoma , indicate a role for igf-1r upregulation in resistance to egfr - targeted therapies .\nigf-1r mediates resistance to anti - egfr therapy in primary glioblastoma through the continued activation of the pi3k / akt survival pathway .\nthe apparent cooperation between igf-1r and egfr in promoting hnscc pathogenesis as well as resistance to egfr - targeted therapy , suggests an advantage to cotargeting these signaling axes for the treatment of head and neck cancers . to date , the effect of blocking oncogenic igf-1r and egfr signaling have been studied more extensively in breast cancer lines .\ntreatment with gefitinib and ag1024 , a tki for igf-1r reduced cell proliferation when used as single agents and showed an additive effect when used in combination [ 76 , 77 ] .\ntargeting igf-1r and egfr signaling is currently under evaluation in hormone - sensitive metastatic breast cancer using the igf-1r inhibitor osi-906 and the egfr tki erlotinib , although results are not yet available ( http://www.clinicaltrials.gov/ , identifier nct01205685 ) .\nsimilarly , an exploratory study to assess the modulation of biomarkers in hnscc patients treated preoperatively with cetuximab and/or imc - a12 , a humanized antiigf-1r monoclonal antibody is currently underway ( http://www.clinicaltrials.gov/ , identifier nct00617734 ) .\nthese studies will be critical for evaluating whether the use of antiigf-1r and egfr - targeted treatments will be more effective than single - agent modalities for treating patients with hnscc .\ntargeted therapies that block egfr , met , and igf-1r signaling in head and neck cancers continue to show promising results in preclinical studies and clinical trials .\nhowever , it is difficult to predict which patients are most likely to benefit from these therapeutics and potential side effects during long - term in vivo use . given the interplay between these rtk signaling pathways and the mediocre results obtained with monotherapy regimens thus far , clinical trials will be required to determine how egfr- , met- , and igf-1r - targeted therapies can be used in combination in order to definitively abrogate their common downstream oncogenic signaling networks .\nalthough gaps in our knowledge concerning the role of met and igf-1r in head and neck tumorigenesis , as well as acquired resistance to antiegfr therapies remain to be addressed , efforts to translate current information towards clinical applications continue to be impressive ."}
{"lay_summary": " objectives : to investigate potential mechanisms mediating the neuroprotective effect of thymoquinone ( tq ) on dopaminergic neurons.methods:this study was conducted in the chemistry and biochemistry institute , university of veterinary medicine , vienna , austria between june and august 2013 . \n primary cultures were prepared from embryonic mouse mesencephala ( ofi / spf ) at gestation day 14 . \n four sets of cultures were kept untreated , treated with tq on the eighth day in vitro ( div ) for 4 days , treated with 1-methyl-4-phenylpyridinium ( mpp+ ) on the tenth div for 48 hours and co - treated with thymoquinone and mpp+ . on the twelfth div \n , cultures were subjected to immunohistochemistry against tyrosine hydroxylase and fluorescent staining using lysotracker deep red , 5,5,6,6-tetrachloro-1,1,3,3-tetraethyl benzimidazolylcarbocyanine ( jc-1 ) and 4,6-diamidino-2-phenylindole stains.results:the mpp+ decreased the number of dopaminergic neurons by 40% , and increased the release of lactate dehydrogenase ( ldh ) into the culture medium . \n the tq significantly rescued dopaminergic neurons and decreased the release of ldh at the concentrations of 0.1 and 1 m . the tq significantly shifted the red fluorescent intensity of the lysotracker deep red , increased the mitochondrial membrane potential as it increased the red : green florescent ratio of jc-1 , and decreased mpp+-induced apoptotic cell death.conclusion:the tq protects dopaminergic neurons in primary mesencephalic culture by enhancing lysosomal degradation that clears damaged mitochondria and inhibits mitochondria - mediated apoptotic cell death . ", "article": "this in vitro study was conducted in the chemistry and biochemistry institute , university of veterinary medicine , vienna , austria between june and august 2013 in accordance with the guidelines of the european union council ( 86/609/eu ) for the use of laboratory animals .\nthe work does not require approval from the ethics committee as it used mouse embryos under the fifteenth day of gestation .\nprimary mesencephalic cell cultures were prepared from c57/b16 embryos according to radad et al.10 to summarize , embryonic mouse mesencephala were dissected on the fourteenth day of gestation and cut into small pieces in a drop of dulbecco s phosphate - buffered saline ( dpbs ) ( invitrogen , darmstadt , germany ) , 2 ml of 0.2% trypsin solution ( invitrogen , darmstadt , germany ) and 2 ml of 0.02% dnase i solution ( roche , berlin , germany ) were added and the tissue was subsequently incubated in a water bath at 37c for 7 minutes ( min ) .\nthen , 2 ml of trypsin inhibitor ( 0.125mg / ml ) ( invitrogen , darmstadt , germany ) were added , the tissue was centrifuged at 100 g for 4 min and the supernatant was aspirated .\nthe tissue pellet was triturated 2 - 3 times with a fire - polished pasteur pipette , each time 0.02% dnase i ( invitrogen , darmstadt , germany ) was included in the medium .\ndissociated cells were plated at a density of 257,000 cells / cm in dulbecco s modified eagle s medium ( dmem ) ( sigma aldrich , hamburg , germany ) supplemented with 4 mm glutamine , 10 mm 4-(2-hydroxyethyl)-1-piperazineethanesulfonic acid ( hepes ) buffer , 30 mm glucose , 100 iu / ml penicillin , 0.1 mg / ml streptomycin , and 10% heat - inactivated fetal calf serum ( sigma aldrich , hamburg , germany ) .\nthe medium was exchanged on the first day in vitro ( div ) and on the third div . on the fifth div ,\nhalf of the medium was replaced by serum - free dmem containing 0.02 ml b-27/ml ( invitrogen , darmstadt , germany ) dmem .\nserum - free supplemented dmem was used for feeding from the sixth div , and subsequently replaced every second day . a stock solution of tq ( sigma aldrich , hamburg , germany ) ( 10 mm )\nfour sets of cultures were treated as follows : the first set of cultures was treated with dmso and kept as untreated controls .\nthe second set of cultures was treated with tq ( 0.01 , 0.1 , 1 , and 10 m ) on the eighth div for 4 consecutive days to investigate the effect of tq on the survival of dopaminergic neurons .\nthe third set of cultures was treated with 10 m of mpp on the tenth div for 48 hours ( h ) .\nthe fourth set of cultures was concomitantly treated with tq ( 0.01 , 0.1 , 1 , and 10  ) , and 10 m of mpp on the tenth div for 48 h. dopaminergic neurons were identified immunocytochemically by staining tyrosine hydroxylase .\ncultures were rinsed carefully with phosphate buffered saline ( pbs , ph 7.2 ) at the end of each treatment and fixed in 4% paraformaldehyde for 45 min at 4c . after washing with pbs , cells were permeabilized with 0.4% triton x-100 for 30 min at room temperature .\ncultures were washed 3 times with pbs and incubated with 5% horse serum ( vectastain abc elite kit , biozol diagnostica vertrieb gmbh , eching , germany ) for 90 min to block nonspecific binding sites . to determine the number of thir in cultures\n, cells were sequentially incubated with anti - th primary antibody overnight at 4c , biotinylated secondary antibody ( vectastain ) , and avidin - biotin - horseradish peroxidase complex ( vectastain ) for 90 min at room temperature and washed with pbs between stages .\nthe reaction product was developed in a solution of diaminobenzidine ( 1.4 mm ) in pbs containing 3.3 mm hydrogen peroxide and stained cells were counted with a nikon inverted microscope in 10 randomly selected fields per well at 10x magnification .\ncellular injury was quantitatively assessed by measuring the activity of lactate dehydrogenase ( ldh ) released from damaged cells into the culture medium .\nthe reaction was initiated by mixing 0.2 ml of cell - free supernatant ( diluted 1:1 with aqua dest . ) with potassium phosphate buffer containing  - nicotinamide adenine dinucleotide ( nadh ) and sodium pyruvate ( 0.18 and 0.62 mm in potassium phosphate buffer ) in a final volume of 0.5 ml in 1 ml cuvettes .\nthe decrease of nadh was spectrophotometrically ( novaspec ii , ge healthcare europe gmbh , freiburg , germany ) monitored .\nthe ldh activity was calculated from the slope of the decrease in optical density at 334 nm over a 3 min - time period .\nthe ldh release is proportional to the number of damaged or destroyed cells.11,12 lysotracker deep red ( life technologies , invitrogen , grand island , ny , usa ) is a red fluorescence dye used for labeling acidic organelles in live cells including autophagolysosomes .\ncultures were treated with 1 m of tq ( a concentration that significantly protected dopaminergic neurons in mpp - treated cultures ) on the eighth div and co - administered with mpp ( 10 m ) on the tenth div for 2 days . on the twelfth div ,\nculture medium was aspirated and cultured cells were incubated with a new medium containing 100 nm lysotracker deep red fluorescence dye ( life technologies , invitrogen , grand island , ny , usa ) for 15 - 30 min at 37c . after washing with dpbs\n, cultured cells were photographed on a nikon inverted microscope equipped with epifluorescence attachment using a rhodamine filter set ( 580/590 , g-2a ) and a coolpix 990 digital camera ( nikon , otawara , japan ) .\n5,5,6,6-tetrachloro-1,1,3,3-tetraethylbenzimidazolyl - carbocyanine ( jc-1 ) is a lipophilic cationic dye that selectively enters into mitochondria . in healthy cells with high mitochondrial membrane potential ( m )\nthe dye remains in the monomeric from with green fluorescence in case of apoptotic or damaged cells .\nthe jc-1 red : green ratio is used to estimate changes in m.13 the jc-1 was dissolved in dmso and further diluted in dmem ( 10 g / ml final concentration ) .\nafter removal of the culture medium , cells were loaded with jc-1 for 15 min at 37c , rinsed twice with pbs , and photographed on a nikon inverted microscope equipped with epifluorescence attachment using a rhodamine filter set ( 520 dm/520 ba , b-2a ) and a coolpix 990 digital camera ( nikon , otawara , japan ) .\nfluorescence intensity of the red : green ratio was determined semi quantitively by using adobe photoshop software .\ncells were fixed with 4% paraformaldehyde for 45 min at 4c . after washing with pbs ( ph 7.2 ) ,\nthe dapi solution ( 2 m final concentration ) was added to the cultures at room temperature for 5 min in the dark .\nafter washing with dpbs , 3 photos were taken randomly from each well with a coolpix 990 digital camera connected to an inverted microscope with epifluorescence attachment using an ultraviolet filter ( nikon , otawara , japan ) .\nnuclei with condensed and fragmented chromatin were counted when the photos were analyzed with adobe photoshop software .\ndata was obtained from 12 wells ( from 2 repeats ) for each treatment condition .\ncomparisons were made using anova and post - hoc duncan s test using the statistical analysis system program 1998 ( sas institute inc . ,\nthis in vitro study was conducted in the chemistry and biochemistry institute , university of veterinary medicine , vienna , austria between june and august 2013 in accordance with the guidelines of the european union council ( 86/609/eu ) for the use of laboratory animals .\nthe work does not require approval from the ethics committee as it used mouse embryos under the fifteenth day of gestation .\nprimary mesencephalic cell cultures were prepared from c57/b16 embryos according to radad et al.10 to summarize , embryonic mouse mesencephala were dissected on the fourteenth day of gestation and cut into small pieces in a drop of dulbecco s phosphate - buffered saline ( dpbs ) ( invitrogen , darmstadt , germany ) , 2 ml of 0.2% trypsin solution ( invitrogen , darmstadt , germany ) and 2 ml of 0.02% dnase i solution ( roche , berlin , germany ) were added and the tissue was subsequently incubated in a water bath at 37c for 7 minutes ( min ) .\nthen , 2 ml of trypsin inhibitor ( 0.125mg / ml ) ( invitrogen , darmstadt , germany ) were added , the tissue was centrifuged at 100 g for 4 min and the supernatant was aspirated .\nthe tissue pellet was triturated 2 - 3 times with a fire - polished pasteur pipette , each time 0.02% dnase i ( invitrogen , darmstadt , germany ) was included in the medium .\ndissociated cells were plated at a density of 257,000 cells / cm in dulbecco s modified eagle s medium ( dmem ) ( sigma aldrich , hamburg , germany ) supplemented with 4 mm glutamine , 10 mm 4-(2-hydroxyethyl)-1-piperazineethanesulfonic acid ( hepes ) buffer , 30 mm glucose , 100 iu / ml penicillin , 0.1 mg / ml streptomycin , and 10% heat - inactivated fetal calf serum ( sigma aldrich , hamburg , germany ) .\nthe medium was exchanged on the first day in vitro ( div ) and on the third div . on the fifth div ,\nhalf of the medium was replaced by serum - free dmem containing 0.02 ml b-27/ml ( invitrogen , darmstadt , germany ) dmem .\nserum - free supplemented dmem was used for feeding from the sixth div , and subsequently replaced every second day .\na stock solution of tq ( sigma aldrich , hamburg , germany ) ( 10 mm ) was prepared in dimethyl sulfoxide ( dmso ) .\nfour sets of cultures were treated as follows : the first set of cultures was treated with dmso and kept as untreated controls .\nthe second set of cultures was treated with tq ( 0.01 , 0.1 , 1 , and 10 m ) on the eighth div for 4 consecutive days to investigate the effect of tq on the survival of dopaminergic neurons .\nthe third set of cultures was treated with 10 m of mpp on the tenth div for 48 hours ( h ) .\nthe fourth set of cultures was concomitantly treated with tq ( 0.01 , 0.1 , 1 , and 10  ) , and 10 m of mpp on the tenth div for 48 h.\ncultures were rinsed carefully with phosphate buffered saline ( pbs , ph 7.2 ) at the end of each treatment and fixed in 4% paraformaldehyde for 45 min at 4c . after washing with pbs , cells were permeabilized with 0.4% triton x-100 for 30 min at room temperature .\ncultures were washed 3 times with pbs and incubated with 5% horse serum ( vectastain abc elite kit , biozol diagnostica vertrieb gmbh , eching , germany ) for 90 min to block nonspecific binding sites . to determine the number of thir in cultures\n, cells were sequentially incubated with anti - th primary antibody overnight at 4c , biotinylated secondary antibody ( vectastain ) , and avidin - biotin - horseradish peroxidase complex ( vectastain ) for 90 min at room temperature and washed with pbs between stages .\nthe reaction product was developed in a solution of diaminobenzidine ( 1.4 mm ) in pbs containing 3.3 mm hydrogen peroxide and stained cells were counted with a nikon inverted microscope in 10 randomly selected fields per well at 10x magnification .\ncellular injury was quantitatively assessed by measuring the activity of lactate dehydrogenase ( ldh ) released from damaged cells into the culture medium .\nthe reaction was initiated by mixing 0.2 ml of cell - free supernatant ( diluted 1:1 with aqua dest . ) with potassium phosphate buffer containing  - nicotinamide adenine dinucleotide ( nadh ) and sodium pyruvate ( 0.18 and 0.62 mm in potassium phosphate buffer ) in a final volume of 0.5 ml in 1 ml cuvettes .\nthe decrease of nadh was spectrophotometrically ( novaspec ii , ge healthcare europe gmbh , freiburg , germany ) monitored .\nthe ldh activity was calculated from the slope of the decrease in optical density at 334 nm over a 3 min - time period .\nlysotracker deep red ( life technologies , invitrogen , grand island , ny , usa ) is a red fluorescence dye used for labeling acidic organelles in live cells including autophagolysosomes .\ncultures were treated with 1 m of tq ( a concentration that significantly protected dopaminergic neurons in mpp - treated cultures ) on the eighth div and co - administered with mpp ( 10 m ) on the tenth div for 2 days . on the twelfth div ,\nculture medium was aspirated and cultured cells were incubated with a new medium containing 100 nm lysotracker deep red fluorescence dye ( life technologies , invitrogen , grand island , ny , usa ) for 15 - 30 min at 37c . after washing with dpbs ,\ncultured cells were photographed on a nikon inverted microscope equipped with epifluorescence attachment using a rhodamine filter set ( 580/590 , g-2a ) and a coolpix 990 digital camera ( nikon , otawara , japan ) .\n5,5,6,6-tetrachloro-1,1,3,3-tetraethylbenzimidazolyl - carbocyanine ( jc-1 ) is a lipophilic cationic dye that selectively enters into mitochondria . in healthy cells with high mitochondrial membrane potential ( m )\nthe dye remains in the monomeric from with green fluorescence in case of apoptotic or damaged cells .\nthe jc-1 red : green ratio is used to estimate changes in m.13 the jc-1 was dissolved in dmso and further diluted in dmem ( 10 g / ml final concentration ) .\nafter removal of the culture medium , cells were loaded with jc-1 for 15 min at 37c , rinsed twice with pbs , and photographed on a nikon inverted microscope equipped with epifluorescence attachment using a rhodamine filter set ( 520 dm/520 ba , b-2a ) and a coolpix 990 digital camera ( nikon , otawara , japan ) .\nfluorescence intensity of the red : green ratio was determined semi quantitively by using adobe photoshop software .\ncells were fixed with 4% paraformaldehyde for 45 min at 4c . after washing with pbs ( ph 7.2 ) ,\nthe dapi solution ( 2 m final concentration ) was added to the cultures at room temperature for 5 min in the dark . after washing with dpbs\n, 3 photos were taken randomly from each well with a coolpix 990 digital camera connected to an inverted microscope with epifluorescence attachment using an ultraviolet filter ( nikon , otawara , japan ) .\nnuclei with condensed and fragmented chromatin were counted when the photos were analyzed with adobe photoshop software .\ndata was obtained from 12 wells ( from 2 repeats ) for each treatment condition .\ncomparisons were made using anova and post - hoc duncan s test using the statistical analysis system program 1998 ( sas institute inc . ,\ntreatment of cultures with tq ( 0.01 , 0.1 , 1 , and 10 m ) on the eighth div for 4 consecutive days produced no significant effects on either the survival rate or the morphology of thir neurons ( data not shown ) .\ntreatment of cultures with mpp ( 10 m on the eighth div for 48 h ) decreased the number of dopaminergic neurons by around 40% compared with untreated control cultures ( figure 1a ) .\nsurviving neurons after mpp treatment showed fewer , shortened , and thickened neurites ( figure 1b ) .\nco - treatment of cultures with tq ( on the eighth div for 4 days ) and mpp ( 10 m on the tenth div for 48 h ) prevented dopaminergic cell loss by around 25% at 0.1 and 1 m ( figure 1a ) , and improved the morphology of surviving neurons compared to mpp - treated cultures ( figure 1b ) .\nanti - th immunohistochemical staining of cultured cells showing : a ) survival of dopaminergic neurons in primary mesencephalic cell cultures .\n100% corresponds to the total number of thir neurons after 12 div in untreated controls .\nvalues represent the meansem of 3 independent experiments with 4 wells in each treatment . in each well , 10 randomly selected fields were counted for th immunocytochemistry ( # p=0.001 , * p=0.008 , + p=0.009 ) .\nthe mpp - treated cultures showed thir neurons with few , shortened and thickened neuritis ( arrows ) .\ntreatment with tq improves the morphology of thir neurons compared to mpp - treated cultures .\nth - tryosine hydrolase , thir - tyrosine hydroxylase immunoreactive , div - day in vitro , sem - standard error of mean , mpp - 1-methyl-4-phenylpyridinium , tq - thymoquinone the tq attenuated mpp - induced ldh increase in primary mesencephalic cell culture .\nthe mpp ( 10 m from the tenth to twelfth div ) increased ldh release in the culture medium by 145% compared with untreated cultures ( figure 2 ) .\nthe tq significantly decreased ldh release in the culture medium by around 70% at 0.1 and 0.1 m concentrations compared with mpp - treated cultures ( figure 2 ) .\ndiv - day in vitro , sem - standard error of mean , mpp - 1-methyl-4-phenylpyridinium , tq - thymoquinone the tq increased lysotracker deep red fluorescence and the red : green fluorescence ratio of jc-1 , and decreased mpp - induced apoptotic cell death in primary mesencephalic cell culture .\nlysotracker deep red fluorescent intensity increased 3 folds ( 682% ) in the cultures co - treated with tq and mpp compared with the cultures treated with mpp alone ( 222% ) ( figure 3a ) . in parallel , cultures co - treated with mpp and tq showed higher red fluorescence than the cultures treated with mpp alone ( figure 3b ) .\nlysotracker deep red fluorescence staining of cultured cells showing : a ) lysotracker deep red fluorescence intensity in primary mesencephalic cell cultures .\n100% corresponds to the density of lysotracker deep red in primary mesencephalic cell cultures after 12 div .\nfluorescence intensity was determined densitometrically from 12 randomly selected micrographs in each experiment ( 3 photos from each well ) .\n( # p=0.05 , * p=0.0001 ) b ) representative micrographs showing that treatment of cultures with tq increased lysotracker deep red fluorescence intensity compared with mpp - treated cultures .\ndiv - day in vitro , sem - standard error of mean , tq - thymoquinone , mpp - 1-methyl-4-phenylpyridinium treatment of cultures with mpp ( 10 m on the tenth div for 48 h ) caused dissipation of m .\ncultures treated with mpp showed a significant decrease in red : green fluorescence ratio of jc-1 by around 17% compared with untreated controls ( figure 4a ) . however , co - treatment of mpp - treated cultures with 1 m tq from the eighth - twelfth div significantly increased m as it increased the red : green fluorescence ratio of jc-1 by around 24% compared with mpp - treated cultures ( figure 4a ) .\nas shown in figure 4b , mpp - treated cultures co - administered with tq displayed much higher red fluorescence than the cultures treated with mpp alone .\n5,5,6,6-tetrachloro-1,1,3,3-tetraethylbenzimidazolyl - carbocyanine ( jc-1 ) fluorescence staining of cultured cells showing : a ) red : green fluorescence ratio of jc-1 in primary mesencephalic cell cultures .\n100% corresponds to the red : green fluorescence ratio of jc-1 in primary mesencephalic cell cultures after 12 div .\nred : green fluorescence ratio of jc-1 was determined densitometrically from 12 randomly selected micrographs in each experiment ( 3 photos from each well ) .\n( # p=0.0001 , * p=0.0001 ) b ) representative micrographs showing that treatment of cultures with tq increased red fluorescence compared to mpp+-treated cultures which exhibits marked green fluorescence .\ntq - thymoquinone , mpp - 1-methyl-4-phenylpyridinium staining of cultured cells with the nuclear fluorescence dye , dapi revealed that mpp ( 10 m on the tenth div for 48 h ) increased the number of nuclei showing apoptotic features by 139% compared with untreated cultures ( figure 5a ) .\nagainst mpp , tq was shown to decrease the number of apoptotic nuclei by around 100% compared with mpp - treated cultures ( figure 5a ) .\n4,6-diamidino-2-phenylindole fluorescence staining of cultured cells showing : a ) number of nuclei showing apoptotic features with condensed and fragmented chromatin in primary mesencephalic cell cultures .\n100% corresponds to the number of apoptotic nuclei in untreated control cultures after 12 div .\n( # p=0.0001 , * p=0.0001 ) b ) representative micrographs showing that treatment of cultures with tq decreased the number of apoptotic nuclei compared to mpp - treated cultures .\ntq - thymoquinone , mpp - 1-methyl-4-phenylpyridinium summary of the neuroprotective effect of tq against mpp treatment in primary mesencephalic cell culture .\ntreatment of cultures with tq ( 0.01 , 0.1 , 1 , and 10 m ) on the eighth div for 4 consecutive days produced no significant effects on either the survival rate or the morphology of thir neurons ( data not shown ) .\ntreatment of cultures with mpp ( 10 m on the eighth div for 48 h ) decreased the number of dopaminergic neurons by around 40% compared with untreated control cultures ( figure 1a ) .\nsurviving neurons after mpp treatment showed fewer , shortened , and thickened neurites ( figure 1b ) .\nco - treatment of cultures with tq ( on the eighth div for 4 days ) and mpp ( 10 m on the tenth div for 48 h ) prevented dopaminergic cell loss by around 25% at 0.1 and 1 m ( figure 1a ) , and improved the morphology of surviving neurons compared to mpp - treated cultures ( figure 1b ) .\nanti - th immunohistochemical staining of cultured cells showing : a ) survival of dopaminergic neurons in primary mesencephalic cell cultures .\n100% corresponds to the total number of thir neurons after 12 div in untreated controls .\nvalues represent the meansem of 3 independent experiments with 4 wells in each treatment . in each well , 10 randomly selected fields were counted for th immunocytochemistry ( # p=0.001 , * p=0.008 , + p=0.009 ) .\nthe mpp - treated cultures showed thir neurons with few , shortened and thickened neuritis ( arrows ) .\ntreatment with tq improves the morphology of thir neurons compared to mpp - treated cultures .\nth - tryosine hydrolase , thir - tyrosine hydroxylase immunoreactive , div - day in vitro , sem - standard error of mean , mpp - 1-methyl-4-phenylpyridinium , tq - thymoquinone the tq attenuated mpp - induced ldh increase in primary mesencephalic cell culture .\nthe mpp ( 10 m from the tenth to twelfth div ) increased ldh release in the culture medium by 145% compared with untreated cultures ( figure 2 ) .\nthe tq significantly decreased ldh release in the culture medium by around 70% at 0.1 and 0.1 m concentrations compared with mpp - treated cultures ( figure 2 ) .\ndiv - day in vitro , sem - standard error of mean , mpp - 1-methyl-4-phenylpyridinium , tq - thymoquinone the tq increased lysotracker deep red fluorescence and the red : green fluorescence ratio of jc-1 , and decreased mpp - induced apoptotic cell death in primary mesencephalic cell culture .\nlysotracker deep red fluorescent intensity increased 3 folds ( 682% ) in the cultures co - treated with tq and mpp compared with the cultures treated with mpp alone ( 222% ) ( figure 3a ) . in parallel , cultures co - treated with mpp and tq showed higher red fluorescence than the cultures treated with mpp alone ( figure 3b ) .\nlysotracker deep red fluorescence staining of cultured cells showing : a ) lysotracker deep red fluorescence intensity in primary mesencephalic cell cultures .\n100% corresponds to the density of lysotracker deep red in primary mesencephalic cell cultures after 12 div .\nfluorescence intensity was determined densitometrically from 12 randomly selected micrographs in each experiment ( 3 photos from each well ) .\n( # p=0.05 , * p=0.0001 ) b ) representative micrographs showing that treatment of cultures with tq increased lysotracker deep red fluorescence intensity compared with mpp - treated cultures .\ndiv - day in vitro , sem - standard error of mean , tq - thymoquinone , mpp - 1-methyl-4-phenylpyridinium treatment of cultures with mpp ( 10 m on the tenth div for 48 h ) caused dissipation of m .\ncultures treated with mpp showed a significant decrease in red : green fluorescence ratio of jc-1 by around 17% compared with untreated controls ( figure 4a ) . however , co - treatment of mpp - treated cultures with 1 m tq from the eighth - twelfth div significantly increased m as it increased the red : green fluorescence ratio of jc-1 by around 24% compared with mpp - treated cultures ( figure 4a ) .\nas shown in figure 4b , mpp - treated cultures co - administered with tq displayed much higher red fluorescence than the cultures treated with mpp alone .\n5,5,6,6-tetrachloro-1,1,3,3-tetraethylbenzimidazolyl - carbocyanine ( jc-1 ) fluorescence staining of cultured cells showing : a ) red : green fluorescence ratio of jc-1 in primary mesencephalic cell cultures .\n100% corresponds to the red : green fluorescence ratio of jc-1 in primary mesencephalic cell cultures after 12 div .\nred : green fluorescence ratio of jc-1 was determined densitometrically from 12 randomly selected micrographs in each experiment ( 3 photos from each well ) .\n( # p=0.0001 , * p=0.0001 ) b ) representative micrographs showing that treatment of cultures with tq increased red fluorescence compared to mpp+-treated cultures which exhibits marked green fluorescence .\ntq - thymoquinone , mpp - 1-methyl-4-phenylpyridinium staining of cultured cells with the nuclear fluorescence dye , dapi revealed that mpp ( 10 m on the tenth div for 48 h ) increased the number of nuclei showing apoptotic features by 139% compared with untreated cultures ( figure 5a ) .\nagainst mpp , tq was shown to decrease the number of apoptotic nuclei by around 100% compared with mpp - treated cultures ( figure 5a ) .\n4,6-diamidino-2-phenylindole fluorescence staining of cultured cells showing : a ) number of nuclei showing apoptotic features with condensed and fragmented chromatin in primary mesencephalic cell cultures .\n100% corresponds to the number of apoptotic nuclei in untreated control cultures after 12 div .\n( # p=0.0001 , * p=0.0001 ) b ) representative micrographs showing that treatment of cultures with tq decreased the number of apoptotic nuclei compared to mpp - treated cultures .\ntq - thymoquinone , mpp - 1-methyl-4-phenylpyridinium summary of the neuroprotective effect of tq against mpp treatment in primary mesencephalic cell culture .\nin the present study , tq was investigated to ascertain whether it protected mesencephalic dopaminergic neurons against mpp - induced cell death through activation of enzymatic degradation , preservation of mitochondrial function , and inhibition of apoptotic cell death .\nclearly , mpp was found to significantly decrease the survival of dopaminergic neurons and increase the release of ldh into the culture medium .\nthe mpp toxicity involves its selective uptake by dopaminergic neurons through the dopamine transporter and inhibition of mitochondrial complex i activity with subsequent mitochondrial depolarization.14 in parallel , the use of jc-1 fluorescence dye in our current study showed that mpp significantly decreased the m of cultured cells as indicated by the decreasing red : green fluorescence ratio of jc-1 .\nsimilar mpp - induced reduction of m was reported in other in vitro disease models.15,16 mitochondrial damage has long been implicated in the death of nigrostriatal dopaminergic neurons in both pd patients and experimental models.17,18 staining of primary dopaminergic cultures with blue - fluorescent dapi nucleic acid stain showed that a significant number of the cells displayed features of apoptosis , most notably chromatin condensation , and fragmentation .\npreviously , tang et al19 and xu et al16 demonstrated that mpp caused apoptotic cell death in pc12 and sh - sy5y cells .\nthe mpp - induced apoptosis was reported to occur as the result of disruption of mitochondrial transmembrane potential and opening of the permeability transition pore.20 similar to our previous report,9 co - treatment of primary mesencephalic cell cultures with tq and mpp was found to protect dopaminergic neurons and decreased the release of ldh into the culture medium . since that time , no evidence in the literature has shown how tq protected dopaminergic neurons in the primary mesencephalic cell culture .\nstaining of cultures with lysotracker deep red showed that tq significantly increased the red fluorescence of the dye compared with mpp - treated cultures , indicating enhancement of the formation of many autophagolysosomes , the sites of lysosomal degradation , by tq .\nthis is supported by the findings of he and klionsky21 who correlated the fluorescent signals of lysotracker deep red to the upregulation of autophagy in zebrafish . increased red fluorescence of lysotracker deep red\nis attributed to the formation of many autophagosomes and autophagolysosomes that retain much dye as the result of increasing their acidification . using jc-1 fluorescent dye showed that tq significantly enhanced m as it increased the red : green fluorescence ratio of jc-1 compared with mpp - treated cultures .\nthe tq was similarly found to protect rat cortical neurons against ethanol- and a1 - 42-induced neurotoxicity through inhibition of mitochondrial membrane depolarization.22,23 counting of apoptotic nuclei using blue - fluorescent dapi nucleic acid stain indicated that tq decreased mpp - induced apoptotic cell death in primary mesencephalic cell cultures . in accordance ,\nullah et al22 reported that tq inhibited apoptotic cell death in ethanol - treated rat cortical neurons and attributed this effect of tq to the preservation of mitochondrial integrity .\nzhang et al24 reported that mitochondrial clearance protected cultured cortical neurons against ischemia - reperfusion - induced cell damage . in conclusion , correlating such results would therefore suggest that tq might activate a lysosomal degradative process in dopaminergic neurons , where clearance of damaged mitochondria results in reduced mitochondria - mediated apoptotic cell death .\nthis might raise the possibility of using tq as a potentially therapeutic intervention in pd patients .\nwhenever a manuscript contains material ( tables , figures , etc . ) which is protected by copyright ( previously published ) , it is the obligation of the author to obtain written permission from the holder of the copyright ( usually the publisher ) to reproduce the material in neurosciences .\nplease submit copies of the material from the source in which it was first published ."}
{"lay_summary": " fracture of the femoral neck continues to be a vexing clinical and therapeutic challenge for the orthopedic surgeon . \n the fracture has a propensity for non - union and avascular necrosis . \n it is a challenge for the orthopedic surgeon to decide when to intervene in a case with non - union where the implant continues to be in place . \n we present a case with persistent clinical and radiological non - union signs where the fracture eventually united after 32  months . \n the case bolsters the view that a continued conservative regime might entail good results in such situations . ", "article": "the femoral head often leads to healing complications , while the more predictable prosthetic replacements are associated with poorer function and significant complications .\nthe treatment of these fractures depends on the age of the patient , fracture displacement , bone quality , timing of surgery and activity level of the patient .\ndisplaced fractures in healthy , active patients are best treated by reduction and internal fixation .\nthere are however , complications unique to femoral neck fractures which are almost impossible to predict . non - union and avascular necrosis\nnon - union usually can definitely diagnosed within a year of fracture fixation with the same being achieved within 3  months at times . after non - union has been established , intervention is inevitable .\nthe decision to proceed in the management of failed fixation is based on the careful consideration of various factors . in young patients\nrevision internal fixation with cancellous or muscle pedicle bone grafting ( vascularised bone graft ) or an osteotomy results in useful outcome .\nwe report a case of non - union of the fracture of the neck of the femur , who refused additional procedures after his non - union had been established .\nthe study conforms to the declaration of helsinki and was approved by the institutional ethical board .\na 38-year old male businessman reported to the out door department of our hospital with a history of a fall from height .\nclinical and radiological examination revealed a displaced fracture of the neck of the femur which was graded as garden type 4 ( fig .\nthe patient was operated within 24  h. intraoperatively the garden alignment index was used as a yardstick of acceptable reduction .\nthe fracture was fixed with 3 ao 6.5  mm cannulated screws in an inverted triangle .\nonward the patient complained of persistent but mild groin pain on ambulation which was assisted .\nthe patients conservative line was continued till 1  year when his symptoms continued and radiologically there was no progress . at this point\ntwenty - six  months into the post operative followup the patients pain subsided and radiographs started showing signs of union . a radiograph taken 32  months after the fixation showed full union .\nnon - union after femoral neck fracture can be defined as a lack of radiographic evidence of union 6  months after the fracture .\ndelayed or non - union often manifests as continued pain with weight bearing beyond 3  months post fixation .\nincidence of non - union of femoral neck fractures has been reported to be between 2 and 22% and generally becomes apparent within 1  year [ 69 ] .\n3radiograph at 32  months depicting union garden 4 type fracture of the neck of the femur showing persistent non - union at 2  years radiograph at 32  months depicting union anatomical reduction and rigid internal fixation are the two important surgeon controlled factors that may contribute to outcome .\nthe preferred treatment for symptomatic non - unions in the elderly is prosthetic replacement . in the young active patients ,\nif failure is due to technical errors , revision open reduction and internal fixation may be adequate .\nour case demonstrates that as long as the implant is holding and the patient is regularly followed up good results might be expected in cases as far as 32  months into the post fixation period ."}
{"lay_summary": " granuloma faciale ( gf ) is a chronic condition characterized by red - brown plaques with follicular accentuation present usually on the face . \n we present a case of 35-year - old female with 5 year history of plaques over cheek and extra facial sites consistent with gf and its response to topical tacrolimus . \n this case supports previous reports of successful treatment of gf with topical tacrolimus . ", "article": "granuloma faciale ( gf ) is an uncommon , benign , inflammatory skin disorder of unknown etiology .\nit is characterized by single or multiple , grey - brown or violaceous nodules or plaques primarily occurring on the face and occasionally at extra - facial sites .\nthe disease is notoriously resistant to therapies and often tends to relapse when treatment is discontinued .\nwe present a patient with multiple lesions of gf and its response to topical tacrolimus .\na 35-year - old female presented to our department with a 5 year history of single , asymptomatic , grey - brown pigmented , nodule over the left cheek [ figure 1 ] .\nit started as a pin head sized papule which gradually increased to 2.5 cm  1.5 cm in size .\ntwo years later similar lesions appeared on the forehead , both arms and upper back .\npast and personal history was unremarkable . before treatment  single , grey - brown nodule with prominent follicular orifices over left cheek .\nafter treatment  residual lesion after three months of tacrolimus application general physical and systemic examination was normal .\ncutaneous examination revealed multiple , well - defined , grey - brown , indurated , non - tender plaques , varying in size from 0.5 cm  0.5 cm to 1.5 cm  2.5 cm , present on the left cheek , left forehead , both arms and upper back .\nmultiple grey - brown plaques over upper back routine hematological and biochemical investigations were normal .\nskin biopsy ( 4 mm ) from plaque revealed normal epidermis with clear sub epidermal \ngrenz zone and pan dermal dense infiltrate comprising of neutrophils , lymphocytes , histiocytes and plasma cells .\nsmall dermal vessels showed infiltration of neutrophils in the vessel wall along with peri - appendageal and peri - neural infiltrate in subcutaneous fat [ figure 3 ] .\n( h and e , 100  ) skin biopsy with normal epidermis and dense , mixed inflammatoey infiltrate beneath a narrow grenz zone in the dermis .\ninfiltrate is composed of mononuclear cells with neutrophils and eosinophils she was started on intralesional triamcilone acetonide 10 mg / ml injection monthly with tab .\nsix sessions of cryotherapy were performed once monthly after which she developed erythema and itching over the plaques and discontinued treatment .\nthe lesions showed 40 - 50% improvement after 3 months of therapy [ figure 1 ] .\nclassically , red - brown or violaceous nodules or plaques with associated telangiectasia and follicular accentuation are seen on the face over sun - exposed sites .\ndifferential diagnosis includes lupus pernio , lupus vulgaris , lymphoma , discoid lupus erythematosus and deep mycotic infection .\nskin biopsy is characterized by a mixed inflammatory infiltrate with a predominance of neutrophils and eosinophils in the dermis , in conjunction with small vessel vasculitis .\nthere is a grenz zone that separates the infiltrate from the epidermis and pilosebaceous units .\nthe disease is notoriously resistant to therapies and often tends to relapse once the treatment is discontinued .\nseveral medical and surgical modalities like topical and intralesional corticosteroids , cryotherapy , pulsed dye laser , puva , systemic corticosteroids , dapsone and antimalarials have been tried with variable success rates .\ncarbon dioxide laser has also been used in a case of recurrent gf . surgical excision has been performed with often unsatisfactory results .\nablative procedures may leave residual pigmentation and scarring , whereas long - term application of corticosteroids is associated with skin atrophy , telangiectasia and other possible adverse effects . in recent years successes with topical calcineurin inhibitors has been reported .\nseveral authors have reported complete or near - complete resolution of lesions after application of topical tacrolimus 0.1% ointment.[48 ] treatment regimens , duration and time to resolution of lesions have varied in these case reports [ table 1 ] .\nothers have found time to resolution to be between 4 and 6 months . in our patient ,\ntreatment with tacrolimus 0.1% ointment twice daily for 3 months has resulted in improvement . reported cases of successful treatment of granuloma faciale ( gf ) with topical tacrolimus tacrolimus\ninhibits t - cell proliferation , production and release of several pro - inflammatory cytokines like interleukin-2 ( il-2 ) , il-4 , tumor necrosis factor - alpha , and interferon - gamma ( ifn - gamma ) .\nalthough the pathogenesis is still unknown , it has been suggested that gf may be an ifn - gamma mediated disease .\nin addition , an increased production of il-5 , probably induced by the clonal expansion of a locally recruited t - cell population may enhance the attraction of eosinophils into the lesions of gf .\ntherefore , a possible mechanism of action of topical tacrolimus in this condition may be the inhibition of ifn - gamma and il-5 production and release , induced by the down - regulation of the t - cell activity , primarily involving the calcineurin binding and inactivation .\nhowever , we did observe eosinophils in skin biopsy in our case , probably since the biopsy was taken after one year of oral dapsone .\nour patient experienced a relevant improvement within 3 months of treatment with tacrolimus ointment after no response with intra lesional steroids , dapsone and cryo therapy . in conclusion\n, the previous reports and our observation suggest that topical tacrolimus may be a well - tolerated , efficacious therapy for gf ."}
{"lay_summary": " we report a case of chronic myelomonocytic leukaemia ( cmmol ) in a 68-year - old man who developed osteomyelitis of the mandible . at the initial visit \n , he reported uncontrolled gingival bleeding , despite self - administered haemostasis . \n he complained of severe pain in the socket , despite potent opioid analgesia . \n after consultation with the internal medicine specialists , we undertook a surgical anti - inflammatory approach that included sequestrectomy with massive blood transfusion . \n his physical condition was ameliorated after the surgical procedure , and he was discharged from the hospital . \n however , 3 months later , he died because of cardiac arrest after haemorrhagic shock and cardiovascular failure because his cmmol had developed to an acute blastic crisis . \n this experience demonstrates that the most important goal in such cases is to alleviate a patient 's discomfort by applying minimally invasive actions to eliminate infection and improve the quality of life without causing deterioration in the cmmol status . ", "article": "chronic myelomonocytic leukaemia ( cmmol ) is a rare disease with an incidence of 0.370.72 per 100 000 population . the median age at diagnosis varies between 65 years and 75 years [ 14 ] .\nthe radical treatment is allogeneic stem cell transplantation , although this treatment is unsuitable for most patients because of their advanced age [ 6 , 7 ] .\nthe median survival of patients with cmmol is 1520 months [ 5 , 6 , 8 ] .\nseveral case reports have indicated that excess surgical stress causes an acute blastic crisis , which contributes to a poor outcome [ 9 , 10 ] .\na 68-year - old man complained of having a reduced appetite for approximately 5 months and weight loss during the previous 4 months . on 12 may 2012\n, he visited a nearby general internal medicine clinic for the evaluation of left lower quadrant abdominal pain .\nhe was referred to the department of internal medicine at asahi general hospital ( asahi , japan ) for investigation and treatment .\nhe began taking oral hydroxyurea ( hydrea ; bristol - myers squibb , princeton , nj , usa ) .\nhe was unable to stop the gingival bleeding that had been ongoing for 5 hours .\nhe then visited the emergency department of asahi general hospital and was referred to the department of dentistry and oral surgery . at the initial visit\nthe right molar teeth ( 47 and 48 ) showed grade iii mobility , and their gingivae were painful with continuous bleeding .\n1a ) . the right molar teeth ( 46 and 47 ) showed class iii alveolar ridge deficiency on panoramic radiographs and were mobile teeth ( fig .\nwe packed an absorbable haemostat ( surgicel ; ethicon , somerville , nj , usa ) into the gingivae and sutured 30 silk threads above it . finally , we used surgical dressing packs ( coe - pak ; g.c .\nfigure 1:(a ) the oral photograph at the initial visit , immediately after the gauze with the astringent has been removed .\n( b ) the oral photograph after the extraction of teeth 47 and 48 . \n\n( a ) the oral photograph at the initial visit , immediately after the gauze with the astringent has been removed .\nthe internal medicine department assigned a clinical diagnosis of cmmol , based on the blood and bone marrow examinations conducted on 13 june 2012 .\ncomputed tomography on june 25 indicated that bone absorption had nearly reached the right inferior alveolar canal , and a ring of sequestrum was present under tooth 47 ( fig .\nwe diagnosed right mandibular osteomyelitis , based on these clinical features . on 11 july 2012 ,\nthe patient was hospitalized in the department of haematology ward because of significant anaemia and decreased platelet numbers . on the same day ,\nthe internal medicine specialist placed him on intravenous  piperacillin  tazobactam ( zosyn ; pfizer , new york , ny , usa ) .\nhe afterwards complained of severe pain in the socket ( 47 and 48 ) , despite receiving the potent opioid analgesic dihydrohydroxycodeinone ( fentanyl ; daiichi - sankyo , chiyoda - ku , tokyo , japan ) .\nhence , we decided to apply a surgical anti - inflammatory treatment in consideration of an acute blastic crisis .\na bone marrow examination on july 13 showed no signs of acute blastic crisis of his cmmol .\nafter we consulted an internal medicine specialist , we planned a surgical procedure to clean the inflamed region in his mouth . on the day before the surgery\n, he was administered a transfusion of platelet concentrate ( 20 units ) and piperacillin  tazobactam to prevent bleeding and further infection . on july 20 , with the patient under local anaesthesia , we surgically resected the right lower sequestrum and extracted molar 37 , which displayed severe caries .\nthe blood examination indicated improvement in the platelet count after the transfusion . after performing an inferior alveolar block\n, we removed the necrotic bone with ultrasonic bone surgery ( variosurg ; nsk , ashikaga , tochigi , japan ) until there was bleeding from the bone surface ( fig .\nwe placed gauze with tetracycline ointment in the socket and sutured 30 silk thread to compress it ( fig .\n( b ) we removed necrotic bone with ultrasonic bone surgery until there was bleeding from the bone surface .\n( b ) we removed necrotic bone with ultrasonic bone surgery until there was bleeding from the bone surface .\n( d ) we used 30 silk thread sutures to compress the gauze . on august 11\nthe formation of granulation tissue had nearly covered the surface of the bone , and all oral discomfort had disappeared ( fig .\nwe later placed a bridge in the upper anterior teeth and added a partial denture ( fig .\nwe placed a bridge for upper anterior teeth 12 , 11 , 22 and 23 , and a partial denture .\nwe placed a bridge for upper anterior teeth 12 , 11 , 22 and 23 , and a partial denture . on 3 january 2013\n, he admitted himself to the hospital in the haematology ward because of exertional dyspnoea .\nthe internal medicine specialists diagnosed cmmol that was undergoing acute leukaemic transformation by bone marrow examination .\nhe died on 10 february 2013 because of cardiac arrest , following haemorrhagic shock and cardiovascular failure due to cmmol .\nin all patients with cmmol , every effort must be made to use the least invasive procedure possible . in the present patient ,\nour deepest concerns were to have a proper balance between invasiveness and healing , and to avoid evoking an acute blastic crisis [ 9 , 10 ] .\nour most important goal was to alleviate the patient 's discomfort by using a minimally invasive procedure to eliminate infection . based on haematology results ,\nthe oral surgery did not trigger the acute blastic crisis of cmmol in this patient .\nthe surgery was necessary to improve his oral environment and to prevent further infection and more pain . because cmmol is associated with a risk of acute blastic crisis and a poor prognosis , any surgical procedure in these patients must be considered on a case - by - case basis ."}
{"lay_summary": " bivalirudin has been proposed as the sole anticoagulant in patients under extracorporeal membrane oxygenation ( ecmo ) or cardiopulmonary bypass . \n owing to the pharmacodynamic properties of bivalirudin , areas of blood stagnation should be carefully avoided in order to limit the risk of thrombosis . \n the ecmo circuit has no reservoir and is usually devoid of blood stagnation areas . \n conversely , under some circumstances , intracardiac blood stagnation areas may exist . in this case \n , there is a potential risk for the spontaneous formation of an intracardiac thrombus . \n we suggest that , under bivalirudin anticoagulation , a minimal degree of intracardiac blood flow with left heart valve movement is allowed . ", "article": "in a recent issue of critical care , we presented a series of 13 patients undergoing post - cardiotomy extracorporeal membrane oxygenation ( ecmo ) with bivalirudin - based anticoagulation .\nafter this series , we satisfactorily continued this experience , reaching about 20 patients treated .\nhowever , we think that a word of caution should be added to our recently published experience . owing to its pharmacological profile\n, bivalirudin is rapidly cleaved by proteolytic enzymes , and its half - life is about 25 minutes when the renal function is normal .\nthe use of bivalirudin for cardiopulmonary bypass ( cpb )   and ecmo   is a feasible option .\nhowever , it is recommended that , during cpb , blood stagnation in the circuit be avoided because the rapid cleavage of bivalirudin may result in thrombosis .\nthe ecmo circuit is devoid of a reservoir , and therefore blood stagnation is usually not a circuit- related problem .\nconversely , under some circumstances , the cardiac chambers may act as a ' natural reservoir ' , which entails blood stagnation and the risk for spontaneous intracardiac thrombosis .\nthis is particularly true in the case of a very large right or left atrium with insufficient venous drainage or the case of very poor ventricular systolic function with intraventricular blood stagnation . to avoid this condition\n, we think that maintaining a partial ecmo support , leaving a minimal degree of intracardiac blood flow , may be a reasonable choice .\nthis may be checked by echocardiographic view of heart valve movement or simply by the observation of some degree of pulsatile arterial blood pressure .\nwe think that , in the event of echocardiographic evidence of a ' smoke effect ' within one or more cardiac chambers , bivalirudin should be replaced by standard heparin anticoagulation .\nintracardiac thrombus formation during ecmo with heparin anticoagulation has been described as well , but the pharmacokinetic properties of heparin may limit the risk of thrombus formation due to blood stagnation ."}
{"lay_summary": " background : coronary computed tomography angiography ( ccta ) is a frequently performed examination for coronary artery disease . when performed with retrospective gating , there is an opportunity to derive functional parameters of left ventricle utilizing automated software . \n complementary information , if validated with established standards , will enhance the total value of study.objective:study evaluates the usefulness of fully automated software for the assessment of left ventricular ejection fraction ( lvef ) using 64-slice ccta data and to correlate ct results with echocardiography ( echo ) . \n role of ct derived lv function is reviewed in the light of emerging technologies and recent developments in multidetector ct ( mdct).materials and methods : a total of 113 patients referred for mdct ccta for evaluation of coronary artery disease . \n all patients were scanned on 64 slice ge - helical ct scanner and had an echo done within 1 week of the ct scan . retrospectively electrocardiogram ( \n ecg)-correlated image reconstruction was performed with the reconstruction at 10% r - r interval increment . \n axial image sets were analyzed with advanced workstation using a program - auto ejection fraction , circulation : ge medical solutions.results:the mean lvef calculated by clinical echo was 58.6  4.5% and by fully automated software based on cta data was 58.9  5.4% . \n the pearson 's regression analysis showed a large correlation , with a correlation coefficient of 0.503 ( p < 0.001 ) . \n bland - altman analysis showed a trend towards mdct resulting in slightly higher values for lvef when compared with echo.conclusion:the fully automated software is simple , reliable , and user - friendly , and can provide rapid assessment of lv functional parameters with good reproducibility . \n despite of good correlation , fewer patients are likely to benefit , in future , from this function due to smaller number of patients undergoing ccta with retrospective gating . ", "article": "global and regional left ventricular ( lv ) functions are well - known indicators of cardiac disease . quantitative values of ventricular volumes and of myocardial mass are independent predictors of morbidity and mortality in patients with coronary artery disease .\nclassically , echo has been used to evaluate lv volume and function because it is relatively inexpensive and noninvasive . however ,\na component of operator dependence and poor contrast between blood and myocardium are considerable limitations of this technique . cardiac magnetic resonance imaging ( mri )\nis considered the clinical  gold standard for lv function assessment , but it is expensive , of limited availability , and can not be performed in patients with implanted pacemakers or defibrillators . in recent years , multidetector ct ( mdct ) has gained acceptance as a promising imaging method for coronary arteries .\nmdct acquired in a single breath - hold with retrospective electrocardiogram ( ecg ) gating can cover the entire heart with 1-mm slice thickness with a temporal resolution of 125 - 250 ms .\nwhen performed for coronary imaging , this method provides excellent opportunity to create , image reformation in any desired plane , including anatomically optimized long axis , short axis , or four - chamber views .\ndiastolic and systolic images can easily be produced from the same data set with a retrospective ecg - gating technique , thus obtaining lv end - diastolic and end - systolic volumes ( edvs and esvs ) .\nmdct has a potential of being utilized as tool for the combined assessment of the coronary anatomy and lv function .\nin addition , ventricular wall motion can be assessed visually by the use of cine loop displays of multiple cardiac phases .\nrecently we observed increasing tendency for utilizing low radiation dose , prospective gating for coronary angiography , thus limiting possibility of volumetric assessment of ventricular function .\nhowever , a small number of patients may need a retrospective gating , thus providing possibility of reconstructions in various phases of cardiac activity . according to published reports ,\nmeasurements for various lv functional parameters with mdct were well - correlated and agree with measurements obtained with mri , two - dimensional transthoracic echocardiography ( 2d - tte ) , and ecg - gated single photon emission ct ( spect ) .\nexperience with 64-slice mdct for cardiac function assessment remains limited by small patient numbers and the inclusion of homogeneous patient populations .\nthe purpose of this study was to assess lv ejection fraction ( lvef ) using 64-slice as a byproduct of mdct coronary examination and to compare efficacy of technique with 2d - tte in a heterogeneous patient population . also , review the role of mdct lv function with a relation to evolution in the technology of coronary mdct imaging .\nstudy included 113 patients referred for 64-slice mdct coronary angiography for evaluation of coronary artery disease .\nall patients were scanned on 64 slice ge - helical ct ( ge high speed advantage ) scanner and had an echo done within 1 week of the ct scan .\nthis prospective study was approved by the institutional review board and written informed consent was obtained from all patients .\npatients with absolute contraindication to contrast or radiation were excluded from the study . in patients with relative contraindications such as atopy , asthma , and renal failure scan was performed if the benefit of examination outweighed the risk in such patients .\npatients with arrhythmias and ectopic heart beats were excluded as stable heart rate is required for ct coronary angiogram .\napart from the routine contraindications , patients with pacemaker and ventricular septal defect were excluded from the study as successful segmentation of the lv blood pool is not possible in these patients due to artifacts and incorrect segmentation by software .\nall patients undergoing ct coronary angiogram , who had heart rate of more than 60 bpm , were premedicated with 50 - 200 mg oral b adrenergic blocking agent : metoprolol , 1-h prior to the study . a 60 - 120 mg calcium channel blocker : diltiazem ,\ncta was performed with contrast volume of 1.2 ml / kg body weight of iohexol 350 .\nthe intravenous contrast agent was followed by 30 ml of saline chaser bolus at the same injection rate .\nscan parameters were 0.35 s rotation time , 120 kv tube voltage , 600 - 800 effective ma , 0.6 mm collimation , and a helical pitch of 0.22:1 .\nthe image acquisition was caudocranial for post - coronary artery bypass grafting ( cabg ) patients and craniocaudal for the rest of the patients .\nno complications encountered in any of the patients . retrospectively , ecg - correlated image reconstruction was performed .\nthe reconstruction was performed with the reconstruction window starting at 10% of r - r interval and up to 90% r - r interval with increment of 10% .\nthis included data sets reconstructed in systole , if diastolic data sets showed motion artifact .\ndiastolic and systolic axial image sets were then transferred to the scanner 's workstation - ge advanced workstation advantage windows 4.4 p. image data were evaluated with a prototype version of a commercially available program ( auto ejection fraction , circulation ; ge medical solutions ) that performs a fully automatic segmentation of the blood volume in the lv by defining the mitral valve plane and the lv .\nthe software uses this mitral valve plane as an upper boundary for the segmentation of the lv .\nthe software identifies the hinges of the mitral and aortic valve leaflets closest to the ventricle wall and selects these as defining points for the plane [ figure 1a ] .\nall ct scans were analyzed according to this method , which allowed for optimal segmentation of the lv .\npapillary muscles were automatically excluded from the blood pool , which allows for precise determination of blood volume in the lv .\nmultiplanar reformats are then performed by the software in long and short axes of left ventricle .\nthe long axis image is obtained parallel to the interventricular septum connecting the lv apex and the middle level of mitral valve .\nthe short axis images are obtained parallel to the plane of mitral valve [ figure 1b ] .\nlv = left ventricular ( b ) line perpendicular to long axis of left ventricle ( parallel to mitral valve ) \nplane for short axis images once the region of interest is finalized , the edv and esv are measured by this software using simpson 's method by summing the endocardial area of all lv ed and es short - axis slices multiplied by the slice thickness [ figure 2a and b ] .\nthe stroke volume ( sv ) and ef were automatically calculated from these values and displayed by the software [ figure 3a  d ] .\n( a ) lv short axis image in diastole ( b ) short axis image in systole 3d display of volumetric data in different patients . ( a ) patient 1 : left ventricular ejection fraction by ct  58.4% ( echo  58% ) . ( b )\npatient 2 : left ventricular ejection fraction by ct  55.7% ( echo  53% ) .\n( c ) patient 3 : left ventricular ejection fraction by ct  60.0% ( echo  60% ) .\n( d ) patient 4 : left ventricular ejection fraction by ct  38.3% ( echo  35% ) .\n3d = three - dimensional , echo = echocardiography , ct = computed tomography two - dimensional echo examination was performed either 1 week before or after coronary cta in either of two ultrasound units , an acuson sequoia ( siemens medical systems usa , mountain view , ca ) or a ge vivid 3 ( ge healthcare , milwaukee , wi ) .\nimages were obtained using a 3.5 mhz transducer and images were acquired in standard apical and parasternal two- and four - chamber views .\nthe chamber and wall dimensions were measured using standard recommendations for chamber quantification in consensus .\nresults on continuous measurements are presented on mean  sd ( min  max ) and results on categorical measurements are presented in number ( % ) . the mean  standard deviation ( sd ) lvef calculated by clinical echo\nsimilarly mean  sd of lvef calculated by fully automated software based on cta data was obtained [ table 2 ] .\nagreement for lvef was determined by the use of pearson 's regression analysis [ figure 4 ] and calculating correlation coefficient ( r ) .\nbland - altman analysis [ figure 5 ] was used to compare the lvef measured with mdct and that with 2d - tte .\nmountain plot [ figure 6 ] was used to see the relationship between two groups .\necho - ejection fraction ( ef ) mean  standard deviation ( sd ) : 58.67  4.53 , echo = echocardiography ct - ejection fraction ( ef ) mean  standard deviation ( sd ) : 58.93  5.43 , ct = computed tomography pearson regression analysis between echo - ef and ct - ef .\nr = pearson correlation coefficient , p = p - value , ef = ejection fraction bland and altman showing the correlation of echo - ef and ct - ef\nsd = standard deviation mountain plot showing the correlation of echo - ef and ct - ef .\nin our study , 86 ( 76.1% ) were males and 27 ( 23.9% ) were females .\nthe mean age of the patients was 51.19  10.10 years and majority of subjects belonged to age group between 51 and 60 years .\n28.3% were between 41 and 50 years , 15.9% subjects were between 61 and 70 years , and 12.4% subjects between 31 and 40 years .\nmost of the patients had at least one symptom , the commonest being chest pain in 88 ( 77.9% ) cases .\nthe most common coronary risk factor association was hypertension , accounting for 77.9% of the cases .\nthe mean heart rate of the patients at the time of scan was 61.5  8.6 bpm with maximum patients having a heart rate range of 61 - 70 bpm .\nthe mean lvef calculated by clinical echo was 58.67  4.53% with maximum number of patients having an ef range of 56 - 60% .\nthe mean lvef calculated by fully automated software based on cta data was 58.93  5.43% with maximum number of patients having an ef range of 61 - 65% . in our study using the fully automated software , the pearson 's regression analysis showed a good interstudy correlation , with a correlation coefficient of 0.503 ( p < 0.001 ) .\nbland - altman analysis showed a trend towards mdct resulting in slightly higher values for lvef when compared with echo ; however , this observation was not statistically significant .\nthe mountain plot analysis reinforced that ef measured by ct correlated well with that measured by echo .\nmdct coronary angiography has emerged as a valuable technique for the evaluation of coronary artery disease in patients with low to intermediate pretest probability of ischemic heart disease . utilizing analytic software ,\ngated volumetric ct data can be processed to provide quantitative functional analysis of the lv in patients with coronary artery disease .\nwe were able to obtain satisfactory artifact free datasets from 113 consecutive subjects who underwent coronary cta .\nall of our patients were either known cases of coronary artery disease or had suggestive clinical symptoms .\npatients with pacemaker , ventricular septal defect were excluded from the study as successful segmentation of the lv blood pool was not possible . achieving a stable heart rate for\nthe examination was variable component of the examination . however , no examination had to be postponed or cancelled due to this limitation .\nour study using automated software showed a good interstudy correlation , with a correlation coefficient of 0.503 ( p < 0.001 ) .\nthe bland - altman plot revealed a slight mean difference between ef measurements on ct and echo with most differences falling within two sds of the mean .\nhence , we found that software is user - friendly and capable of providing good reproducibility for ef measurements in comparison with echo . in a previous study by krishnam et al .\n, similar results were recorded , though the number of subjects was small . in a study by cury et al . , a trend of mdct slightly underestimating lvef compared with tte was observed .\nwe observed a trend towards mdct resulting in slightly higher values for lvef when compared with echo , contrary to expected mild reduction in beta blocked patients .\ntrend however was not statistically significant , could be due to recognized limitation of evaluation technique leading to over or underestimation .\nmean difference in ef measurements between cta and echo is small ; although standard deviation of the mean difference is quite high , leading to wide limits of agreement .\npossibly observation results from the fact that the ef measurements from echo were obtained in a clinical setting , on visual estimation and calculation of ef using simpson 's method based on geometrical assumptions .\nour observations are in accordance with the previous studies of 64-slice coronary ct , confirming that lvef estimation is feasible with the mdct data and may be regarded as a useful clinical index , correlating with results of echo .\nthere are studies with semiautomated software for quantitative functional analysis of lv with user defined mitral valve plane and an arbitrary point within the lv , with the option to expand or reduce the area of segmentation .\nmany earlier studies have compared the use of 4- , 8- , and 16-slice ct scanners for evaluation of lv volumes .\nlarger detector configuration in 64-slice ct scanner , has the advantage of being faster , capable of smaller slice thickness and higher temporal resolution .\nrelatively higher radiation dose results from the protocol optimized for thin slice high - resolution imaging of the coronary arteries .\nthe ecg - dependent tube current modulation is currently the most effective tool for dose reduction and may reduce patient dose by up to 50% .\nit is important to note that two points of the cardiac cycle ( end - systole and end - diastole ) with modulation of tube current were not used in our study because ecg - gated dose modulation was only applicable to 50 - 90% of the rr interval on ecg .\nif the aim is to evaluate coronary arteries only , it is recommended to use an ecg - dependent dose modulation technique or newer prospective gated techniques .\nnew developments in mdct technology is allowing examination of patients with higher heart rates and reducing the dose of beta - blockers . presently , mdct examination is possible which contains all the phases with a considerably lower dose of the order of 2 - 3.3 msv .\nthe software identifies the lv blood pool based on hounsfield unit values and continuity of adjacent voxels . in patients with a ventricular septal defect\n, there is contrast opacification in both ventricles and a bridge of contrast through the septal defect .\ntherefore , the software identifies the right and lv blood pools as a single chamber , resulting in incorrect segmentation and thus inaccurate assessment of lv functional parameters . in patient with pacemakers\n, software identifies a pacemaker wire as high - density contrast and segments the pacing wire as part of the ventricle , resulting in failed segmentation . the version of the software used for this study it was not able to segment the myocardium in order to quantify the lv myocardial mass , which may be important in certain cardiac diseases such as hypertrophic cardiomyopathy .\nit is important to note that cardiac mri is considered as a  gold standard for lv function assessment .\ncardiac mri ( cmri ) provides excellent temporal and spatial resolution , image acquisition in any desired plane , and a high degree of accuracy and reproducibility . concerning quantitative measurements\ncine mri technique is potentially the most comprehensive cardiac imaging modality available because of its excellent contrast between blood - filled ventricles and the surrounding myocardium .\nyamamuro et al . , have shown high linear correlation between ef measurements on ct and on mri .\nthe temporal resolution of many available mdct is still considerably lower than that of echo and cine mri .\nthis lower temporal resolution can make evaluation of isovolumetric ed and es phases of the cardiac cycle , and thus ef , less precise .\nthere is considerable improvement in temporal resolution of mdct with improvement in gantry rotation , multiple and partial segment processing techniques .\ntr of 80 - 250 ms has been achieved in state of the art units .\nthough it is short of fluoroscopic resolution , currently available options are more than sufficient for motion free systolic and diastolic cardiac imaging with heart rate below 100/min . additionally , the use of a b - blocker to reduce the heart rate to less than 65 bpm can influence the functional parameters that are to be measured . beta blocker do influence the lvef , lead to underestimation .\noverestimation or underestimation of the lv volume has been reported because of the different criteria for selecting the endocardial boundary or the inclusion / exclusion of papillary muscle .\nideally estimation of the real - ef from all 20 phases is more precise ; however , this significantly increases effort and processing time .\neffect of beta - blocker has to be factored in interpretation of ef by mdct .\nintroduction of new ct imaging methods , including dual source ct in clinical practice will overcome these two problems significantly owing to its two - fold increase in temporal resolution . also , newer options in mdct technology may partially obviate need for use of beta blockers .\nfunctional parameters derived from 2d - tte are compared with ct derived 3d volumetric data , which are not strictly comparable .\nour study design did not allow realistic comparison of mdct and echo lv volume data .\nit would be interesting to compare the same for assessment of accuracy of respective data .\nwith evolution of speckle - tracking 3d echography and new low radiation , high tr scanning such studies are possible .\nthe delay time between ct and echo and premedication with -blockers could have changed myocardial contraction and lv volumes as measured with the two methods . in the present\nset up , the number of patients referred to coronary angiography who will have volumetric data will be significantly smaller , limiting the application of this utility to a smaller offset of patients .\nthe radiation issue will certainly be an important consideration to use this technique in the larger group of patients .\nemerging new applications of echography in the form of 2d and 3d speckle - tracking echo certainly will have a greater role to play in the future noninvasive assessment of the myocardial function . in conclusion\nour study confirms useful complementary functional information in coronary cta datasets , using fully automated analysis software for rapid assessment of lvef .\nit is irrational to utilize mdct alone to assess lv function in clinical patients , given the radiation exposure involved .\nhowever , additional clinically useful information from a clinically indicated coronary ct examination with a lowest possible radiation dose is invaluable in patients known or suspected of ischemic heart disease .\nvalidating consistency of results with mri will further lend support to the use of mdct derived results .\ngoing forward with changing trends in ccta imaging , it is conceivable that number of patients undergoing cta with retrospective gating will substantially be reduced , thus limiting the functionality to a small group of patients ."}
{"lay_summary": " a bioassay - guided fractionation of methanol extract of aristolochia bracteolata whole plant was carried out in order to evaluate its antimicrobial activity and to identify the active compounds in this extract . \n antibacterial and antifungal activities of methanol extract against gram - positive , gram - negative , and fungal strains were investigated by the agar disk diffusion method . among the strains tested , moraxella catarrhalis and sea urchin - derived bacillus sp . \n showed the highest sensitivity towards the methanol extract and hence they are used as test organisms for the bioassay - guided fractionation . from this \n extract , aristolochic acid 1 ( aa-1 ) has been isolated and has showed the greatest antibacterial activity against both standard strain and clinical isolates of moraxella catarrhalis with equal minimum inhibitory concentration ( mic ) and minimum bactericidal concentration ( mbc ) values of 25 and 50  g / ml . modification of the aa-1 to aa-1 methyl ester completely abolished the antibacterial activity of the compound and the piperonylic acid moiety of aa-1 which suggested that the coexistence of phenanthrene ring and free carboxylic acid is essential for aa-1 antibacterial activity . ", "article": "\n moraxella catarrhalis is a gram - negative , aerobic diplococcus human mucosal pathogen which causes middle ear infections in infants and children [ 13 ] , and it is one of the three major causes of otitis media along with streptococcus pneumonia and haemophilus influenzae . although moraxella catarrhalis is frequently found as a commensal of the upper respiratory tract , recently it has emerged as a genuine pathogen and is now considered an important cause of upper respiratory tract infections in healthy children and elderly people , lower respiratory tract infections in adults with chronic obstructive pulmonary disease [ 1 , 5 ] , and hospital - acquired pneumonia .\namikacin , cefixime , fosfomycin , cefuroxime , cotrimoxazole , doxycycline , and erythromycin resistant strains of moraxella catarrhalis were isolated and the widespread production of a -1actamase enzyme renders the bacterium resistant to the penicillin [ 79 ] .\nthis has led to the search for new and effective therapeutic alternatives among natural compounds .\nplants remain an important source of diverse chemical entities which have been used as drugs or provide scaffolds from which new drugs have been derived .\nthe selection of a suitable candidate species for investigations can be done on the basis of long - term use by humans .\nthis approach is based on an assumption that the active compounds isolated from such plants are likely to be safer than those derived from plant species with no history of human use .\naristolochia is an important genus in the family of aristolochiaceae and is widespread across tropical asia , africa , and south america .\nit is used in traditional medicine as a gastric stimulant and in the treatment of cancer , lung inflammation , dysentery , and snakebites .\nit is also used in the treatment of tumors and malaria and for fevers , but its usage as an antimalarial is not recommended in its crude form .\naristolochia bracteolata showed a definite positive effect on wound healing , with significant increase in the level of powerful antioxidant enzymes .\nthe whole plant was used as a purgative , antipyretic , and anti - inflammatory .\norganic solvent extracts of the plant showed antibacterial activities while the water extract showed antifungal activity .\nalthough aristolochia has been used for thousands of years in many cultures for many indications due to its various pharmacological activities , it was later discovered that consuming these plants can certainly be dangerous .\nthe genus of aristolochia contains a naturally carcinogenic compound aa which has been shown to be the cause of so - called chinese herb nephropathy or aa nephropathy [ 19 , 20 ] , and mutations in the cells of people who consume it , causes more mutations than two of the best - known environmental carcinogens : tobacco smoke and uv light [ 21 , 22 ] .\nthere are many cases of nephropathy reported in the literature caused by the systemic and long term application of chinese snakeroot ( aristolochia fangchi ) ; this highlighted the risk of using preparations which contain aristolochic acids .\nalthough aristolochia is being known in many countries that is containing a toxic compound aa , but this has not stopped it from being a popular herbal remedy for thousands of years .\nit is still extensively used in india and in traditional chinese medicine for slimming , menstrual symptoms , and rheumatism .\nit is also widespread used in sudan and other african countries as one of the most effective herbal remedies for infectious diseases .\ntherefore , it was our objective to assess the potential antimicrobial activity of aristolochia bracteolata using a bioassay - guided fractionation , in order to produce pure compound that can act as the lead compound in developing new , safe , and effective drug to replace the use of the harmful crude plant material .\nsephadex lh-20 ( pharmacia fine chemical co. ltd ) was used for column chromatography . precoated silica gel plates ( merck , kieselgel 60 f254 , 0.25  mm ) and precoated rp-18 f254s plates ( merck ) were used for thin - layer chromatography ( tlc ) analysis .\nhigh resolution fab - ms and esi - ms were recorded on jeol jms700n and jms-100td , respectively .\nh- and c - nmr , h - h cosy , noesy , hsqc , and hmbc spectra were recorded with a unity plus 500 spectrometer ( varian inc . , u.s.a . ) operating at 500  mhz for h and 125  mhz for c , respectively .\nh - nmr chemicals shifts are expressed in  values referring to the solvent peak h 2.49 for dmso and coupling constants are expressed in hz .\nc - nmr chemical shifts are expressed in  values referring to the solvent peak c 39.5 for dmso .\npiperonylic acid was purchased from commercial sources ( tci ) and used without further purification . the plant material ( whole )\nwas collected in the period from ( october to december 2012 ) from khartoum state in sudan .\nstandard strains : moraxella catarrhalis ( gtc 01544 ) , klebsiella pneumoniae ( atcc 13883 ) , escherichia coli ( k12 ) , salmonella typhimurium ( atcc 14028 ) , streptococcus pyogenes ( atcc 19615 ) , streptococcus agalactiae ( atcc 13813 ) , staphylococcus epidermidis ( atcc 12228 ) , neisseria lactamicus ( atcc 23970 ) , enterobacter cloacae , ( atcc 23355 ) , bacillus subtilis ( atcc 6633 ) , staphylococcus aureus ( 209p ) , and pseudomonas aeruginosa ( ifo 3445).clinical strains : moraxella catarrhalis , bacillus cereus , aeromonas hydrophila , salmonella typhi , vibrio cholerae , and yersinia enterocolitica . \n  standard strains : moraxella catarrhalis ( gtc 01544 ) , klebsiella pneumoniae ( atcc 13883 ) , escherichia coli ( k12 ) , salmonella typhimurium ( atcc 14028 ) , streptococcus pyogenes ( atcc 19615 ) , streptococcus agalactiae ( atcc 13813 ) , staphylococcus epidermidis ( atcc 12228 ) , neisseria lactamicus ( atcc 23970 ) , enterobacter cloacae , ( atcc 23355 ) , bacillus subtilis ( atcc 6633 ) , staphylococcus aureus ( 209p ) , and pseudomonas aeruginosa ( ifo 3445 ) . clinical strains : moraxella catarrhalis , bacillus cereus , aeromonas hydrophila , salmonella typhi , vibrio cholerae , and yersinia enterocolitica .\nin addition to a sea urchin ( anthocidaris crassispina ) derived bacillus sp . which obtained from the laboratory in medical plants garden , nagasaki university.(c)fungal strains : the fungal strains used were aspergillus niger ( nbrc 33023 ) , penicillium crustosum ( nbrc 33015 ) , schizophyllum commune ( nbrc 30749 ) , trichophyton concentricum ( nbrc 31068 ) , and candida albicans ( nbrc 10108 ) .\nfungal strains : the fungal strains used were aspergillus niger ( nbrc 33023 ) , penicillium crustosum ( nbrc 33015 ) , schizophyllum commune ( nbrc 30749 ) , trichophyton concentricum ( nbrc 31068 ) , and candida albicans ( nbrc 10108 ) .\nthe air - dried powdered whole plant ( 200  g ) was exhaustively extracted with cold maceration method with sufficient quantity of 70% methanol for 7 days at room temperature .\nthe methanolic extract was passed through whatman number 1 filter paper ( whatman england ) and the concentrated extract ( 40  g ) was digested with 100  ml distilled water and successively partitioned with n - hexane ( 4  400  ml ) , chloroform ( 3  400  ml ) , ethyl acetate ( 5  400  ml ) , and n - butanol ( 2  400  ml ) .\neach fraction was concentrated under reduced pressure to a constant weight to give the corresponding n - hexane fraction ( 0.4  g ) , chloroform fraction ( 2  g ) , ethyl acetate fraction ( 0.7  g ) , n - butanol fraction ( 6  g ) , and aqueous fraction ( 30  g ) . the most active fraction against bacillus sp . and\nm. catarrhalis ( chloroform fraction ) was subjected to sephadex lh20 column chromatography to give three subfractions ( a - c ) .\nfraction ( b ) was resubjected again to sephadex lh20 to afford very active and pure compound aa-1 ( 150  mg ) . to the solution of aa-1 ( 50  mg ; 0.23  mmol ) in dimethylformamide ( dmf )\n, 1  ml potassium carbonate was added ( 95  mg ; 0.69  mmol ) . to the resulting suspension iodomethane\nwas added ( 72  l ; 1.15  mmol ) and stirred for 8 hours .\nthe reaction mixture was poured onto water ( 10  ml ) and ethyl acetate ( 20  ml ) .\nthe organic layer was washed with 1  m hcl ( 10  ml ) three times and then with brine ( 10  ml ) once .\nafter removal of solvent under reduced pressure , the residue was purified by silica - gel chromatography ( chloroform - methanol ) to afford the titled ester ( 88% ) .\nh - nmr ( 400  mhz , cdcl3 , tms , r.t . )  ( ppm ) : 3.88 ( 3h , s ) , 4.06 ( 3hs ) , 6.38 ( 2h , s ) , 7.11 ( 1h , d , j = 7.8  hz ) , 7.72 ( 1h , dd , j = 7.8  hz , 8.0  hz ) , 7.77 ( 1h , s ) , 8.70 ( 1h , d , j = 8.0  hz ) , and 8.83 ( 1h , s ) .\nsuspension of the tested bacteria ( 100  l of 10  cfu / ml ) was spread onto solid media plates .\nthe sterile paper discs ( 6  mm in diameter ) which were impregnated with the plant extract ( 14  mg ) and pure compound ( 10100  g ) were placed aseptically over the bacterial culture on nutrient agar plates .\nafter incubation at 37c for 24 hours , the zone of inhibition around the discs was measured by millimeter scale .\nsterile , blank paper discs impregnated with only sterile solvents served as negative control each time .\nthe sterile paper discs ( 6  mm in diameter ) which were impregnated with individual extract were placed on the inoculated plates .\nthese plates were incubated for 2472  h at 2528c and the growth was evaluated visually by comparing a particular plate with the negative control plates ( having only test fungi ) .\nthe antifungal activity was evaluated by measuring the inhibition zone diameter ( in millimeter ) observed .\nthe mic and mbc values were determined by broth dilution method in accordance with clsi methodology .\nbacterial strains were cultured for 24  h at 37c on nutrient broth and then suspended in sterile distilled water to give a final inoculum concentration of 1.5  1.0  10  cfu / ml .\ndilutions ranging from 1.56 to 400  g / ml of the compound were prepared in tubes including broth and dmso 10% ( v / v ) , in addition to one negative control ( broth + dmso 10% v / v + test microorganism ) to ensure that the final concentration of dmso in the assays did not interfere with the bacterial growth and one sterility control ( broth + dmso 10% v / v + test compound ) .\na 100  l suspension of test microorganism was added to individual tubes and incubated at 37c for 24  h. the mic of the compound was defined as the lowest concentration that inhibited the visible bacterial growth and the mbc was defined as the lowest concentration that prevented the growth of the organism after subculture onto antibiotic - free plates .\ninitial steps in new drug discovery involve identification of new chemical entities , which can be either sourced through chemical synthesis or can be isolated from natural products through biological activity guided fractionation .\nbioassay - guided fractionation of the identified plant may lead to standardized extract or isolated bioactive lead compounds as the new drug .\nthe whole plant of aristolochia bracteolata was extracted successively with meoh and subjected to liquid - liquid fractionation with n - hexane , chloroform , ethyl acetate , and n - butanol .\nthe resulting fractions were tested for antibacterial and antifungal activities . the crude extract and chloroform fraction were significantly active against sea urchin - derived bacillus sp . and both standard strain and clinical isolates of moraxella catarrhalis and were moderately active against s. aureus , b. subtilis , and ps .\nthe n - hexane fraction had moderate activity against s. aureus and b. subtilis while ethyl acetate fraction showed moderate activity against ps .\nthe crude extract failed to inhibit the growth of all test fungi in addition to the following bacterial strains : klebsiella pneumoniae , escherichia coli , salmonella typhimurium , streptococcus pyogenes , streptococcus agalactiae , staphylococcus epidermidis , neisseria lactamicus , enterobacter cloacae , bacillus cereus , aeromonas hydrophila , salmonella typhi , vibrio cholerae , and yersinia enterocolitica .  \nthe chloroform soluble fraction was therefore selected for further chromatographic separations and resulted in the isolation of known compound aa-1 ( figure 1 ) .\naa-1 showed strong activity against moraxella catarrhalis ( standard strain and clinical isolates ) and sea urchin - derived bacillus sp .\n( table 2 ) , with equal mic and mbc values of 25 and 50  g / ml . both the piperonylic acid moiety of aa-1 ( figure 1 ) and aa-1-methyl ester showed no activity against bacteria ( table 2 ) , which suggests that the coexistence of phenanthrene ring and free carboxylic acid is essential for aa-1 antibacterial activity .\nbioguided fractionation of methanolic extract of aristolochia bracteolata led to isolation of aa-1 and its structure was elucidated by interpretation of its nmr and ms data and by comparison with those reported in the literature .\nelectrospray ionization mass spectrometry ( esims ) showed pseudomolecular ion signal at m / z 364.03 [ m + na ] and high resolution fast atom bombardment mass spectrometry ( hr - fabms ) afforded m+1 ion signal at m / z 342.0620 which was corresponding to the molecular formula c17h12no7 ( calculated for 342.06138 ) .\nh nmr and c - nmr spectra were matched with those of aa-1 which were previously reported .\ntwo weak signals which did not show any correlation with proton in hsqc and hmbc spectroscopy were considered as quaternary carbons at positions 5 (  124.3  ppm ) and 6 (  143.5  ppm ) , respectively .\nlaboratories of the world have found literally thousands of phytochemicals which have inhibitory effects on all types of microorganisms in vitro .\nmore of these compounds should be subjected to animal and human studies to determine their effectiveness in whole - organism systems , including in particular toxicity studies and an examination of their effects on beneficial normal microbiota . in spite of\nthe fact that herbal remedy is a mixture of many chemicals in unknown doses and might result in unpleasant side effects , many people believe that treatments that are natural are somehow magically safe and effective . \n aristolochia is used in traditional medicine for the treatment of various diseases [ 13 , 15 ] , including those associated with bacteria .\nthis study showed clearly that the excellent effect of aristolochia in treating such diseases is due to the toxic compound aa-1 .\nalthough aa-1 is highly effective in killing m. catarrhalis , it is ineffective against the other microorganisms tested .\nthis highlights the importance of m. catarrhalis in discovering the cellular target of aa-1 and the mechanism of aa-1 toxicity .\nthe widespread use of aristolochia is not sufficient to ensure that it is effective or even that it is safe .\ntherefore , hit - to - lead exploration is necessary to identify related compounds with low toxicity , low cost , and improved potency that can replace the use of the harmful crude plant material .\nit is impossible to ban the use of these remedies , especially in the rural areas in sudan and other african countries ; therefore , we strongly recommend educating the public of the risks versus the benefits of aristolochia and gradually replacing them with either economical new drugs or standardized extracts and homogenous batches of other plant material with known levels of safe active constituents .\nusing bioassay - guided fractionation technique , the present study directly linked the antibacterial activity of aristolochia bracteolata to the aa-1 .\nalthough aa-1 had strong activity against m. catarrhalis , it had a narrow spectrum of activity than expected based on the activity of the crude extract from which it was isolated or from its traditional usage .\nthis may be the result of synergism between different compounds in the complex extracts or may be due to placebo effect ."}
{"lay_summary": " we herein report an unusual case of an infected descending aortic pseudoaneurysm with luminal pathognomonic oscillating vegetation with serological findings and clinical features mimicking anti - proteinase 3-antineutrophil cytoplasmic antibody - associated vasculitis . the positive blood cultures and imaging findings , including a pseudoaneurysm and vegetations in the aorta , suggested the presence of an infected aortic aneurysm . \n the patient was successfully treated with antibiotics and endovascular aortic repair . \n a precise diagnosis is crucial in order to avoid inappropriate therapy such as immunosuppressive treatment , which could result in life - threatening consequences in a patient with an infected aortic aneurysm . ", "article": "anti - neutrophil cytoplasmic antibodies ( ancas ) correlate well with a wide spectrum of vasculitis manifestations , including wegener 's granulomatosis , microscopic polyangiitis , and churg - strauss syndrome , all of which are commonly referred to as anca - associated vasculitis ( 1 ) .\nseveral infections , particularly infective endocarditis , have been reported to show positive findings on anca tests ; furthermore , their clinical features have been acknowledged to mimic anca - associated vasculitis , which may lead to a misdiagnosis and inappropriate treatment ( 2,3 ) .\nhowever , to our knowledge , infected aortic aneurysms have not been reported to show positive findings on anca tests .\nwe herein report a patient with an infected thoracic aortic aneurysm mimicking anti - proteinase 3-antineutrophil cytoplasmic antibody ( pr3-anca)-associated vasculitis .\nvegetations in the descending aorta , which were detected using transesophageal echocardiography , contributed to the diagnosis in this case .\na woman in her 60s was admitted to the nagoya city university hospital complaining of a fever , which had persisted for three weeks , along with a loss of appetite , proteinuria , hematuria , and renal dysfunction .\nher renal function test values had been in the normal range three months prior to the admission .\nshe also had a history of orbital mucosa - associated lymphoid tissue lymphoma , which was in remission after treatment with only radiation therapy .\na physical examination at the time of admission revealed a body temperature of 38.1 , pulse rate 109 beats / min , and blood pressure 104/53 mmhg .\nthe laboratory tests revealed a white blood cell count of 18,900/mm , hemoglobin 6.6 g / dl , blood urea nitrogen 30.8 mg / dl , serum creatinine 2.24 mg / dl , and c - reactive protein ( crp ) 9.44 mg / dl ( table ) .\nthe pr3-anca titer was 47.4 iu / ml ( normal range < 10 iu / ml ) , although her myeloperoxidase - antineutrophil cytoplasmic antibody ( mpo - anca ) titer was not elevated .\na urinalysis gave results of 2 + for protein and 3 + for occult blood in a dipstick examination , and a microscopic examination detected more than 100 red blood cells per high - power field .\nalt : alanine aminotransferase , ana : antinuclear antibodies , ast : aspartate transaminase , c3 : compliment 3 , c4 : compliment 4 , ch50 : 50% hemolytic unit of complement , crp : c - reactive protein , dna : deoxyribonucleic acid , ldh : lactate dehydrogenase , mpo - anca : myeloperoxidase - antineutrophil cytoplasmic antibody , rf : rheumatic factor , pr3-anca : anti - proteinase 3-antineutrophil cytoplasmic antibody she was initially diagnosed with pr3-anca - associated vasculitis and was thereafter treated with methylprednisolone pulse therapy ( 500 mg / day ) for three days ( fig .\nhowever , streptococcus sanguis was serially detected in blood cultures ; therefore , the administration of steroids was stopped .\ntransesophageal echocardiography also revealed no vegetation in the heart ; however , it showed many oscillating masses attached to the intima in the descending aorta ( fig .\n2 ) . contrast - enhanced computed tomography ( ct ) revealed a new descending aortic aneurysm ( fig .\neffects of antibiotics on fever and c - reactive protein during hospitalization . the patient finally became afebrile and has c - reactive protein levels within the normal range after receiving antibiotics .\ncrp : c - reactive protein , dap : daptomycin , pcg : penicillin g , taz / pipc : tazobactam / piperacillin , tx : therapy transesophageal echocardiographic images of the descending aorta , with sectioning planes at 90 ( a ) and 0 ( b ) .\nmany oscillating masses attached to the intima were seen in the lumen of the descending aorta .\ncontrast - enhanced computed tomographic images in the axial ( a ) and frontal ( b ) sections .\nthese images show a descending aortic pseudoaneurysm and a contrast defect ( arrow ) beside the aneurysm that is compatible with echo - documented vegetation .\nbased on the results of microbiological testing , antibiotic treatment with intravenous penicillin g ( 24,000,000 unit / day ) was started , after which she became afebrile .\nwe added intravenous daptomycin ( 300 mg every 24 hours ) and tazobactam / piperacillin ( 2.25 g every 6 hours ) to the penicillin g because recurrent fever was observed two weeks later .\nthis additional antibiotic treatment made her afebrile again , and her renal function was recovered ( fig .\n, she developed a janeway lesion , which was confirmed by the pathological finding of a skin biopsy specimen ( fig .\n4 ) . transesophageal echocardiography finally demonstrated that the vegetation had disappeared after the antibiotic treatment ( fig .\n5 ) , but contrast - enhanced ct revealed that the aneurysm remained unchanged in form . a nontender hemorrhagic macular on the sole of the foot ( a ) .\nphotomicrograph of the macular lesion shows microembolization with fibrin and infiltration of neutrophilic cells hematoxylin and eosin staining ( b , c ) .\na transesophageal echocardiographic image of the descending aorta after the antibiotic treatment , with the sectioning plane at 90. many oscillating masses have disappeared . on the 54th hospital day , she underwent endovascular aortic repair ( evar ) of the aneurysm ( fig .\n6 ) after confirmation that her crp level was in the normal range and once blood cultures were consistently negative .\none year after the procedure , she continues to take oral antibiotics ; no complications related to stent - graft deployment or recurrent infections have been encountered .\nher pr3-anca titer has normalized . a contrast - enhanced computed tomographic image after endovascular stent graft repair .\nin this case , an infected aortic aneurysm exhibited elevated the patient 's pr3-anca level , and its clinical course mimicked pr3-anca - associated vasculitis .\nthe detection of ancas is highly specific for a diagnosis of anca - associated vasculitis ( 4 ) ; however , a number of infections can result in a positive anca test .\nthere are several reports of infective endocarditis with the presence of ancas that mimic the clinical manifestations of an anca - associated vasculitis such as glomerulonephritis ( 2,3 ) . in the present case , based on the finding of positive blood cultures\n, we suspected that the patient was experiencing not anca - associated vasculitis but infective endocarditis .\nhowever , no vegetations were detected in the cardiac chambers using transthoracic echocardiography or transesophageal echocardiography .\ninstead , contrast - enhanced ct revealed a pseudoaneurysm in the descending aorta , which suggested that the patient had an infected aneurysm .\nher renal dysfunction and elevated pr3-anca levels normalized with clinical resolution of the infected aneurysm after the administration of appropriate antibiotic therapy and evar .\nthe patient has remained free of any evidence of systemic vasculitis during follow - up .\nthe presence of pr3-anca may have been falsely positive in the present patient . to our knowledge , this is the first report of an infected aortic aneurysm with a positive pr3-anca test and clinical features mimicking anca - associated vasculitis .\nthe presence of vegetations in the heart is one of the most characteristic findings of infective endocarditis .\nthese vegetations are composed of bacteria , platelets , and inflammatory cells interspersed with fibrin mesh , either on damaged endocardium , including native cardiac valves , or prosthetic valves ( 5 ) . in the present case ,\nbecause these masses disappeared after antibiotic treatment , they were considered to be vegetations . a pathological examination of the macular hemorrhages on the patient 's sole indicated not a cholesterol embolization but rather a janeway lesion , which was the consequence of septic embolic events .\nwe therefore suspected that these masses were not mobile plaques but bacterial vegetations . to our knowledge ,\nfew cases of infected native aortic aneurysm manifesting vegetations in the aneurysm have been reported ( 6 - 8 ) .\nseveral mechanisms have been proposed regarding how ancas are formed during the course of infection , such as autoantigen complementarity , molecular mimicry , epigenetics , neutrophil extracellular traps , and microbial - sensing proteins called toll - like receptors ( 9 ) . there may be a great degree of overlap in the clinical and laboratory manifestations between anca - associated vasculitis and anca - positive infected aortic aneurysm , potentially leading to a misdiagnosis .\nit is important to correctly diagnose these cases in order to avoid administering inappropriate therapy , such as immunosuppressive treatment , which might have life - threatening consequences in a patient with an infected aortic aneurysm .\npositive blood cultures and imaging findings , such as a pseudoaneurysm and/or vegetations in the aorta , suggest the presence of an infected aortic aneurysm . a combination of conventional surgical treatment with resection of the aneurysm , extensive local debridement , and revascularization by in situ reconstruction or extra - anatomic bypass may be the gold standard , but such a treatment strategy is accompanied by a high mortality and morbidity . in the present case ,\nit was recently reported that evar of an infected aortic aneurysm is feasible and , for most patients , a durable treatment option ( 10 ) .\ngiven that the continuous administration of antibiotics for the infected aneurysm should prevent a recurrence of local infection , we continued using antibiotics until the infection was controlled and carefully monitored the shape of the pseudoaneurysm on contrast - enhanced ct .\nwe were ready to perform an emergency surgical correction at any point during this patient 's treatment course . in conclusion\n, we herein reported an unusual case of infected descending aortic pseudoaneurysm with luminal pathognomonic oscillating vegetation and with serological findings and clinical features mimicking pr3-anca - associated vasculitis ."}
{"lay_summary": " backgroundendometriosis is a disabling disease of reproductive - age women . \n dysmenorrhea , dyspareunia , and pelvic pain are the main symptoms of endometriosis . \n its etiology is not clear . \n endometriosis may have various causes , including vitamin d deficiency , but its effect is controversial.material/methodsin this double - blind clinical trial , we enrolled patients with endometriosis diagnosed and treated by laparoscopy , with scores of at least 3 for of dysmenorrhea and/or pelvic pain at 8 weeks after surgical treatment . \n they were randomly prescribed vitamin d ( 50 000 iu weekly for 12 weeks ) or placebo . \n severity of pain in the 2 groups ( placebo and treatment ) was compared by vas test at 24 weeks after surgical treatment.resultsthere were 19 patients in the vitamin d group and 20 in the placebo group . \n baseline characteristics in the 2 groups were similar . \n following the treatment with vitamin d or placebo , we did not find significant differences in severity of pelvic pain ( p=0.24 ) and dysmenorrhea ( p=0.45 ) between the 2 groups . \n mean pelvic pain at 24 weeks after laparoscopy in the vitamin d group was 0.841.74 and in placebo group it was 0.681.70 ( p=0.513 ) . \n mean dysmenorrhea was 2.102.33 in the vitamin d group and 2.732.84 in the placebo group ( p=0.45).conclusionsafter ablative surgery for endometriosis , vitamin d treatment did not have a significant effect in reducing dysmenorrhea and/or pelvic pain . ", "article": "endometriosis is a prevalent cause of infertility , pelvic pain , dysmenorrhea , and dyspareunia in reproductive - age women .\nits diagnosis is by inspection of the pelvis during laparoscopy . in women with pelvic pain and infertility ,\nendometriosis mimics some autoimmune and malignant diseases , including familial occurrence and immunological abnormalities in b and t cells , increased angiogenesis , invasion of endometrial cells to adjacent organs ( e.g. , bladder and bowels ) , and need for repeat surgeries due to recurrence [ 1,57 ] .\nmultiple mechanisms for etiology and improvement of endometriosis are suggested and the treatments are based on these unclear mechanisms . therefore , progestin , gnrh agonists and antagonists , and drugs related to lipid metabolism ( e.g. , simvastatin ) are used for treatment .\nit has been shown that inflammation is important in the pathogenesis of endometriosis , so endometriosis treatment should not be different from that of other inflammatory disorders\n. there may be a correlation between vitamin d levels and the risk of polycystic ovarian disease , endometriosis , breast and ovarian cancer , increased arterial stiffness in older patients , and myasthenia gravis [ 1218 ] .\nit has been found that vitamin d has a role in normal cellular growth regulation .\nvitamin d increases anti - inflammatory cytokines production and decreases pro - inflammatory cytokines [ 1922 ] .\nvitamin d induces apoptosis and suppression of angiogenesis in vitro and in vivo [ 2528 ] .\nalthough an indirect relationship between vitamin d and endometriosis has been reported in multiple studies , here has been no published randomized clinical trial on endometriosis and vitamin d treatment in women .\nwe explored the relationship between vitamin d and endometriosis in a double - blind , randomized clinical trial looking at the effect of vitamin d supplementation on cessation of pain in proven endometriosis after laparoscopic diagnosis and treatment .\nthis randomized , double - blind clinical trial was performed in a single tertiary university hospital from nov 2014 to feb 2016 . to find patients with endometriosis , we did laparoscopy for various indications , including ovarian cyst , infertility , pelvic pain , and dysmenorrhea .\nusing laparoscopy , the surgeons diagnosed patients with endometriosis and tried to excise or ablate all diseased tissue . the day before laparoscopy\n, a data collection form was completed by a physician , including the reason for laparoscopy , and the severity of pelvic pain and dysmenorrhea were estimated using a visual analogue scale test ( vas test ) , with a score of 0 being no pain and a score 10 being the worst pain ever experienced .\nthe laparoscopies were done by 2 gynecologic laparoscopic surgeons ; both were involved in each operation and they recorded the severity of endometriosis according to the revised american society for reproductive medicine ( asrm ) classification . in the patients with endometriosis in the second menses after laparoscopic diagnosis and treatment , the vas test was repeated .\npatients with vas scores of at least 3 for dysmenorrhea and/or pelvic pain were invited to participate in this clinical trial , and after consultation we asked them to sign the informed consent .\nthe dyspareunia score was not a criterion for entering the study because some of the patients were not married and had not had intercourse .\nwomen aged 1540 years with proven endometriosis by laparoscopy and a vas test score of 3 or more for dysmenorrhea and/or pelvic pain at second menses after operative laparoscopy .\npatients with vitamin d treatment in the last 6 months prior to surgery ; patients with known systemic diseases ( e.g. , hypertension , diabetes , coronary , renal , and hepatic diseases ) ; patients with known malignancy ; patients with hormonal treatment , including oral contraceptive pills , in the last 6 months . after authorization by the university ethics committee ,\neligible patients were assigned by simple randomization to receive either vitamin d or placebo . in the vitamin d group ( d group ) , we prescribed oral vitamin d 50 000 iu / weekly for 12 weeks ( capsule d - vigel , vitamin d3 50 000 iu , daana pharma co. tabriz - iran ) and in the placebo group ( p group ) we prescribed 1 capsule of placebo ( daana pharma co. tabriz - iran ) weekly for 12 weeks .\nfour weeks after the end of the intervention ( 24 weeks after surgical treatment ) , the vas test was repeated for the 2 groups .\nwe used the ks test ( one - sample kolmogorov - smirnov test ) for normality of data distribution , levine s test for equality of variances and independent samples , and the t test for equality of means for comparing quantitative normal data between the 2 groups .\nwe used the paired - samples t test for comparing quantitative normal data between before and after treatment in each group and the pearson chi - square test for matching and comparing categorical variables between the 2 groups . due to the small sample size\n, we conducted mann - whitney non - parametric analysis between the 2 groups and wilcoxon signed ranks test for comparing before and after treatment data in each group .\nthis study was funded and supported by iran university of medical sciences ( iums ) , grant no .\nwomen aged 1540 years with proven endometriosis by laparoscopy and a vas test score of 3 or more for dysmenorrhea and/or pelvic pain at second menses after operative laparoscopy .\npatients with vitamin d treatment in the last 6 months prior to surgery ; patients with known systemic diseases ( e.g. , hypertension , diabetes , coronary , renal , and hepatic diseases ) ; patients with known malignancy ; patients with hormonal treatment , including oral contraceptive pills , in the last 6 months . after authorization by the university ethics committee ,\neligible patients were assigned by simple randomization to receive either vitamin d or placebo . in the vitamin d group ( d group ) , we prescribed oral vitamin d 50 000 iu / weekly for 12 weeks ( capsule d - vigel , vitamin d3 50 000 iu , daana pharma co. tabriz - iran ) and in the placebo group ( p group ) we prescribed 1 capsule of placebo ( daana pharma co. tabriz - iran ) weekly for 12 weeks .\nfour weeks after the end of the intervention ( 24 weeks after surgical treatment ) , the vas test was repeated for the 2 groups .\nwe used the ks test ( one - sample kolmogorov - smirnov test ) for normality of data distribution , levine s test for equality of variances and independent samples , and the t test for equality of means for comparing quantitative normal data between the 2 groups .\nwe used the paired - samples t test for comparing quantitative normal data between before and after treatment in each group and the pearson chi - square test for matching and comparing categorical variables between the 2 groups . due to the small sample size\n, we conducted mann - whitney non - parametric analysis between the 2 groups and wilcoxon signed ranks test for comparing before and after treatment data in each group .\nthis study was funded and supported by iran university of medical sciences ( iums ) , grant no .\nwe did 146 laparoscopies for different indications in gynecologic patients , and endometriosis was diagnosed in 75 . at the second menses after diagnostic and therapeutic laparoscopy , 40 cases met the inclusion criteria for our study .\nthe remaining 39 cases were randomly assigned in vitamin d ( n=19 ) or placebo treatment ( n=20 ) groups .\none patient in the placebo group became pregnant at the third month after the operation and discontinued placebo treatment . at the end of the study , we had 19 patients in each group ( figure 1 ) .\ntable 1 shows a baseline comparison between the 2 study groups for general characteristics , reason for laparoscopy , severity of endometriosis , and severity of dysmenorrhea and pelvic pain .\ncauses of laparoscopy in women with endometriosis diagnosed by laparoscopy were dysmenorrhea ( n=28 ) , ovarian cyst ( n=23 ) , chronic pelvic pain ( n=19 ) , and infertility ( n=9 ) . in some patients , there was more than 1 reason for laparoscopy .\nseverity of endometriosis in 45% was moderate ( n=17 ) and 47% had severe endometriosis ( n=18 ) . before laparoscopy ,\nthe mean pelvic pain score in the vitamin d group was 4.053.45 and 4.824.1(p=0.513 ) in the placebo group . before laparoscopy , the mean dysmenorrhea pain score in the vitamin d group was 7.372.61 and in placebo group it was 6.423.04 ( p=0.325 ) . table 2 shows a comparison between the 2 groups for severity of pelvic pain and/or dysmenorrhea at different time points ( before laparoscopy , in second menses after laparoscopy , and at 24 weeks after laparoscopy ) . at the second menses after laparoscopy , there was no significant difference between the 2 groups for pelvic pain ( p=0.583 ) and dysmenorrhea ( p=0.365 ) , and at 24 weeks after laparoscopy there was no significant difference between mean pain scores in the 2 groups . mean pelvic pain at 24 weeks after laparoscopy in the vitamin d group was 0.841.74 and in placebo group it was 0.681.70 ( p=0.513 ) .\nmean dysmenorrhea was 2.102.33 in the vitamin d group and 2.732.84 in the placebo group ( p=0.45 ) .\nall of the patients had good cooperation for follow - up and continued their treatment until the end of the study .\nin this double - blind , randomized clinical trial , at 24 weeks after laparoscopic treatment of endometriosis there was no significant difference between effect of vitamin d3 ( cholecalciferol ) and placebo on severity of dysmenorrhea and/or pelvic pain .\nthis is the first clinical trial on women with endometriosis to explore the possible relationship between vitamin d treatment and relief of endometriosis - related pain .\nour literature search found only studies that were indirectly related to vitamin d and endometriosis [ 2743 ] .\nthe etiology of endometriosis is poorly understood , and many etiologic factors have been suggested , including the serum level of 1 , 25-dihydroxy vitamin d3 .\n1 , 25-dihydroxy vitamin d3 is a fat - soluble vitamin with an unclear role in endometriosis .\nit is suggested that nuclear vitamin d receptors can have a regulatory role in inflammation and can be used as an index of cellular metabolic health . a study on vitamin d receptor gene polymorphism in endometriosis compared 132 infertile women with endometriosis with 132 fertile women , reporting no significant difference and suggesting that vitamin d receptor gene polymorphism does not play an important role in the pathogenesis of endometriosis . in some studies ,\nhigher plasma levels of 1 , 25-dihydroxy vitamin d3 and higher intake of dairy foods was associated with lower risk of endometriosis .\nconversely , another study compared serum vitamin d levels of 87 women with endometriosis with 53 women without endometriosis ; the mean serum levels of 1 , 25-dihydroxy vitamin d3 in women with and without endometriosis were 24.914.8 ng / ml and 20.411.8 , respectively ( p=0.05 ) and the study concluded that endometriosis is associated with higher serum levels of vitamin d .\na systematic review of 10 case - control studies and 1 cohort study on women s diet found that women with endometriosis had lower consumption of vegetables and omega-3 , and reported a significant association between diet and endometriosis .\nvitamin d binding protein ( dbp ) is a plasma glycoprotein that modulates immune and inflammatory responses and also controls transport of vitamin d metabolites and bone development . in a study\ncomparing 13 ectopic endometrial tissues and 6 normal endometrial tissues , vitamin d binding protein was significantly higher in the ectopic endometrial tissues ( p<0.05 ) .\na systematic review of research from 1946 to 2013 on vitamin d and endometriosis reported that women with endometriosis had higher serum levels of vitamin d binding protein .\nanother study compared serum and peritoneal levels of dbp in 26 women with endometriosis and 17 women with other benign gynecological conditions and reported that women with endometriosis had higher serum levels of dbp than in the control group .\na study comparing urinary levels of dbp in 57 women with endometriosis with levels in 38 controls found that the urinary level of dbp was significantly higher in patients with endometriosis .\na study using a rat model of endometriosis reported that treatment with vitamin d3 produced fibrosis and apoptosis in the stroma of tissues with endometriosis . a study on induced endometriosis in adult balb female mice reported that administration of 100 g / kg / day elocalcitol ( a vitamin d receptor agonist ) for 3 weeks reduced total lesion weight . because a relationship between vitamin d and endometriosis has been suggested by multiple studies , and since there has been no randomized clinical trial on endometriosis and vitamin d treatment in women , we decided to explore this relationship . in the present study on endometriosis - related pain\n, we found no significant difference in results of vitamin d treatment vs. placebo at 24 weeks after surgical diagnosis and treatment .\nvitamin d is a fat - soluble vitamin mainly produced in the body from food and supplements and cutaneous sun exposure .\nvitamin d deficiency is defined as serum 1.25-dihydroxy vitamin d3 levels under 20 ng / ml .\nit is reported in 52% of black and hispanic adolescents in boston and in 48% of girls in maine , and it is seen in 40100% of elderly men and women in the usa and europe . a study in germany found that 57% of people\n1879 years old were vitamin d deficient . the prevalence of vitamin d deficiency was reported to be 90% in healthy subjects in delhi , india . in a systematic review of 195 studies in 44 countries found that 37.3% of studies found that the mean serum vitamin d levels were less than 20 ng / ml .\nthe prevalence in pregnant turkish women was 81.4% . in a study of high school students in iran ,\nthe serum mean vitamin d level was 14.79.4 ng / ml . in another study in university students in shiraz , iran , 51.2% of female students had low serum levels of vitamin d . because the incidence of vitamin d deficiency in iran is high and we did not check the serum vitamin d levels in samples before intervention , it is possible that this dose and duration of vitamin d prescription was beneficial only for treatment of vitamin d deficiency and not endometriosis . in 1072 women attending an infertility center ,\nan in vitro study compared the effect of vitamin d3 on 25 human endometriosis stromal cell cultures ( ovarian endometrioma ) with the effect of vitamin d3 on culture of 20 endometrial samples of non - endometriosis women ; vitamin d3 inhibited proliferation , invasion , and pro - inflammatory cytokine production in endometriosis and reduced production of interleukin 6 and other inflammatory cytokines that stimulate adhesion of endometrial cells to the peritoneal cavity . a study on in vitro effects of vitamin d3 on human endometriosis stromal cells found that vitamin d3 significantly reduced interleukin 1 and tumor necrotizing factor- inflammatory responses , and also reported fewer endometrial stromal cells and reduced dna synthesis .\nthe study found significantly lower serum vitamin d3 levels in severe endometriosis compared to normal controls and patients with mild endometriosis . a study in italy investigated the effect of vitamin d on primary dysmenorrhea .\nthe samples were 40 women aged 1840 years old with 4 consecutive painful periods in the past 6 months .\nthey measured the serum levels of 25 hydroxy vitamin d with high - performance liquid chromatography .\nthen the women were randomized into a group of 20 women who received a single oral dose of 300 000 iu vitamin d ( cholecalciferol ) at 5 days before their next menstrual cycle and another group of 20 women received placebo .\nthere was a negative correlation between the baseline dysmenorrhea pain score and the level of 25 hydroxy vitamin d3 ( r=0.36 , p=0.2 ) .\nthe researchers found a significant reduction of dysmenorrhea pain in the vitamin d group in comparison with the placebo group in the next 2 menstruations ( p<0.01 ) .\nthey suggested this significant reduction of dysmenorrhea pain in vitamin d prescription group was due to decreased levels of pro - inflammatory cytokines and decreased the biological activity of prostaglandins .\nthe samples were not assessed for existing endometriosis . because low levels of serum vitamin d are common in healthy italian pre - menopausal women , these results only show that vitamin d was effective in relieving dysmenorrhea at least for 2 months after treatment in women with or without endometriosis and also in women with or without vitamin d deficiency .\nthere may be a relationship between vitamin d and pathogenesis of endometriosis , but in our study vitamin d was not effective in treatment of endometriosis - related pain .\nlarger clinical trials are needed to determine the possible effects of vitamin d supplementation in endometriosis treatment .\nthe first limitation of this study is the high prevalence of vitamin d deficiency in our country and worldwide , meaning that a high percentage of our samples may have had vitamin d deficiency , which may have affected the results of our research .\nfurther clinical trials are needed on the role of vitamin d treatment for endometriosis - related pain .\nfuture studies should assess the serum levels of vitamin d before enrolling study subjects , and those with vitamin d deficiency should be excluded .\nthe first limitation of this study is the high prevalence of vitamin d deficiency in our country and worldwide , meaning that a high percentage of our samples may have had vitamin d deficiency , which may have affected the results of our research .\nfurther clinical trials are needed on the role of vitamin d treatment for endometriosis - related pain .\nfuture studies should assess the serum levels of vitamin d before enrolling study subjects , and those with vitamin d deficiency should be excluded ."}
{"lay_summary": " objectivethe aim of this study was to compare the correspondence between gap formation and \n apical microleakage in root canals filled with epoxy resin - based ( ah plus ) \n combined or not with resinous primer or with a dimethacrylate - based root canal \n sealer ( epiphany ) . \n material and methodsthirty - nine lower single - rooted human premolars were filled by the lateral \n condensation technique ( lc ) and immersed in a 50-wt% aqueous silver nitrate \n solution at 37c ( 24 h ) . \n after longitudinal sectioning , epoxy resin \n replicas were made from the tooth specimens . \n both the replicas and the specimens \n were prepared for scanning electron microscopy ( sem ) . \n the gaps were observed in \n the replicas . \n apical microleakage was detected in the specimens by sem / energy \n dispersive spectroscopy ( sem / eds ) . \n the data were analyzed statistically using an \n ordinal logistic regression model and analysis of correspondence ( =0.05 ) . \n \n resultsepiphany presented more regions containing gaps between dentin and sealer \n ( p<0.05 ) . \n there was correspondence between the presence of gaps and \n microleakage ( p<0.05 ) . \n microleakage was similar among the root - filling \n materials ( p>0.05 ) . \n conclusionsthe resinous primer did not improve the sealing ability of ah plus sealer and the \n presence of gaps had an effect on apical microleakage for all materials . ", "article": "it is generally accepted that microleakage between the filling materials and root canal \n walls might adversely affect the outcome of root canal treatment .\ntherefore , it is critical the complete \n sealing of the root canal system after cleaning and shaping in order to avoid the \n bacterial penetration and re - infection of the root and periapical tissues .\nthe association of gutta - percha cones \n and root canal sealer has been traditionally used for this purpose . however , in the last \n decade , the dentin adhesive technology has been incorporated into the root canal filling \n techniques to reduce apical and coronal leakage by bonding to root canal walls .\netch - and - rinse adhesives have been \n tested with resin cements and the \n combination of a dentin - bonding agent and an epoxy resin - based root canal sealer \n significantly reduced apical leakage . in restorative dentistry , the self - etch adhesive systems have shown less technique \n sensitivity , with reliable long - term performance of a two - step mild self - etch \n adhesive . following this trend ,\npentron clinical technologies \n ( wallingford , ct , usa ) has developed the epiphany system , which contains a self - etch \n primer , a dual - cured composite resin sealer and a polyester - based thermoplastic \n root - filling material ( resilon ; resilon research llc , madison , ct , usa ) . \n according to shipper , et al .\n( 2004 ) \n this material has been shown to be more resistant to bacterial leakage than epoxy \n resin - based sealers for filling root canals . in endodontics ,\nthe controversy about the performance of adhesive systems inside the \n root canal remains . despite that , \n other possibility is combining epiphany primer with ah plus in an attempt to add the \n hybridization capacity to the gold standard endodontic sealer .\nthe reason for this is \n that the removal of the smear layer with ethylenediamine tetraacetic acid ( edta ) does \n not provide the same etching pattern usually associated with the hybrid layer , which is \n considered an important factor for dentin bonding .\nthe majority of studies have evaluated apical or coronal microleakage , and few have \n focused gap formation at the dentin / sealer interface .\nso far , no correlation between microleakage and gap \n formation has been established in the literature .\nthus , it is reasonable to believe that \n the association of both methods would provide a more precise evaluation of the adhesive \n interface .\nthe aim of this study was to compare the apical sealing and gap formation of ah \n plus / gutta - percha with epiphany system .\nin addition , the opportunity was taken to assess \n the effect of the association of epiphany primer and ah plus / gutta - percha on apical \n sealing and gap formation .\nthe null hypotheses tested were as follows : ( 1 ) there is no \n difference in apical microleakage or ( 2 ) apical gap formation among the experimental \n groups and ( 3 ) there is no correspondence between apical microleakage and the presence \n of gaps .\nthirty - nine lower single - rooted human premolars with straight root canals and fully \n developed apices ( local ethics committee approval 177/05 ) were cleaned and submitted \n to 18.5 kgy gamacell radiation ( nuclear energy research institute , so paulo , \n sp , brazil ) , and stored in saline solution at 4c .\nafter endodontic access , \n the real working length ( rwl ) was established 1 mm short of the apical foramen .\na \n crown - down technique was used ( up to k - file # 50 ) under constant irrigation with 0.5% \n naocl .\nthe smear layer was removed with 17% edta ( 5 ml ) and 0.5% naocl ( 5 \n ml ) followed by saline \n solution ( 15 ml ) .\nthree coats of nail polish were applied to \n external root surfaces except for the apical 2 mm .\nthe teeth were randomly ( http://www.random.org ) divided into \n 3 experimental groups ( n=11 ) .\nthe endodontic sealers were \n prepared according to the manufacturer 's instructions and the cold lateral \n condensation filling technique ( lc ) was used according with the following \n description : an iso # 50 master gutta - percha cone was lightly coated with ah plus sealer ( ah \n plus ; dentsply detrey , konstanz , germany ) and placed into the \n canal to rwl .\na size b finger spreader ( dentsply maillefer , ballaigues , switzerland ) \n was then inserted into the canal to a level approximately 1 mm short of rwl .\nlc with \n accessory gutta - percha cones was performed until the entirely filled root canal .\nthe \n excess gutta - percha was removed with a heated plugger and then compacted \n vertically .\nadhesive - modified technique was used for bonding ah plus to intraradicular dentin . a \n paper point soaked with epiphany primer\nwas used to etch dentin ( 30 s ) and the excess \n was removed with paper points .\nthe coronal surface of the root filling was \n light - cured for 40 s ( 600 mw / cm ) .  \nthe positive controls ( n=3 ) were left unfilled and coated as described earlier . the \n negative controls ( n=3 ) were filled and totally coated , including the apical \n foramina .\nthe openings were sealed ( cavit w , 3 m espe , st paul , mn , usa ) , and \n stored in a chamber held at 100% humidity and 37c for 7 days .\nnext , all teeth \n were immersed in a 50-wt% aqueous silver nitrate solution ( agno3 , ph7.0 ) \n in the darkness that was buffered using naoh 0.1 n for 24 h at 37c .\nthe silver - impregnated teeth \n were rinsed and placed in photodeveloper ( 8 h ) in fluorescence light to reduce the \n silver ions into metallic silver . \n\nlake bluff , \n il , usa ) , longitudinally sectioned in an isomet 1000 precision saw ( buehler ) at low \n speed ( 200 rpm ) with a water - cooled diamond blade .\nthe interfaces were etched with a \n 35% phosphoric acid solution ( 5 s ) , rinsed with distilled water ( 30 s ) and gently \n air - dried .\nthen , specimen preparation followed the protocol 1 for apical microleakage \n analysis using scanning electron microscopy / energy dispersive spectroscopy ( sem / eds ) ; \n or the protocol 2 for gaps analysis using sem according to the following \n description : specimens were fixed , dehydrated in ascending grades of ethanol and final chemical \n drying in hmds ( hexamethyldisilazane , sigma - aldrich inc . ,\nlouis , mo , usa ) for 10 \n min , and covered with \n carbon ( sputter coater scd 050 , bal - tec ag , balzers , liechtenstein ) .\nthe apical 5 mm \n of the root canal filling were divided into 5 regions of 1 mm to evaluate \n microleakage by sem leo stereoscan 440 ( leo electron microscopy ltd . ,\ncambridge , \n england ) using back scattered electrons ( bse ) mode ( figure 1a ) .\nthe eds ( inca software , oxford , uk , england ) was performed in \n lower magnification within a pre - determined area ( 300 m ) ( figure 1b ) , and in a higher magnification , the \n identification of silver was made punctually to determine its exact location ( figure 1c ) .\neach 1 mm region was classified \n according to the following scores : 0 ( absence of leakage in both interfaces ) and 1 \n ( presence of leakage in at least one of the interfaces ) . in figures 1d and 1e\nscanning electron microscopy ( sem ) micrographs using back scattered electrons \n ( bse ) mode and corresponding energy dispersive spectroscopy ( eds ) spectrum of \n agno3 leakage : ( a ) - the apical 5 mm of the root canal filling \n divided into 1 mm - regions .\npointer at the detected metallic silver ; ( b )  area \n ( 300 m ) scanned for the existence of silver and \n respective eds spectrum ( arrow ) and ( c ) - in detail , punctual eds confirmation \n of its exact location .\ngp = gutta - percha ; d = dentin impressions of polyvinyl siloxane ( aquasil , ulv , dentsply detrey ) were \n made of the interfaces and the surfaces replicated with epoxy resin \n ( epon - thin , buhler ) .\nthe replicas were covered with carbon to \n investigate the presence of gaps at the dentin / sealer and sealer / cone interfaces , as \n described previously , using secondary electrons ( se ) mode .\nas the gaps were not \n continuous , for each 1 mm - region , two interfaces were analyzed ( figure 2a ) and classified as : type 0 : both interfaces were \n gap - free , type 1 : gap at dentin / sealer interface ( figure 2b ) , type 2 : gap at sealer / cone interface ( figure 2c ) , and type 3 : both types of gaps present .\ntherefore , \n for each experimental group , 11 replicas were prepared ; 55 regions were evaluated and \n accordingly classified .\nscanning electron microscopy ( sem ) micrographs using secondary electrons ( se ) \n and back scattered electrons ( bse ) mode of the replica and the section of the \n same specimen , respectively .\n( a ) - the apical 5 mm of the root canal filling \n divided into 1 mmregions .\nclassification of the types of gaps : ( b )  type 1 : \n gap between dentin / sealer ( pointer ) ; air voids were present within the sealer \n ( open arrow ) ; ( b ' ) - silver penetration was evident along the dentin / sealer \n interface , into dentinal tubules in a reticular form and granular aspect on the \n dentin surface ( arrowhead ) ; ( c )  type 2 : gap between sealer / cone ( pointer ) - \n cohesive fracture of the sealer ( open arrow ) ; ( c ' ) - the area marked in figure \n c at higher magnification : silver deposition into the dentinal tubules in a \n reticular form and granular aspect within the sealer layer ( arrowhead ) could be \n seen ; ( the sealer thickness was indicated between black / white arrowheads . \n\ngp = gutta - percha ; d = dentin ; r = resilon ) the data obtained for apical microleakage and types of gaps were statistically \n analyzed ( =0.05 ) using the ordinal logistic regression model and correspondence analysis in the minitab statistical software \n program ( minitab inc .\nthe counting of regions analyzed for gaps was also computed and adjusted in a \n generalized linear model with poisson distribution and logarithmic link function .\nthe \n sealers groups ( ah plus , ah primer and epiphany ) and the type of gap were considered \n as explanatory variables and ah plus and the type 0 as references .\nthirty - nine lower single - rooted human premolars with straight root canals and fully \n developed apices ( local ethics committee approval 177/05 ) were cleaned and submitted \n to 18.5 kgy gamacell radiation ( nuclear energy research institute , so paulo , \n sp , brazil ) , and stored in saline solution at 4c .\nafter endodontic access , \n the real working length ( rwl ) was established 1 mm short of the apical foramen .\na \n crown - down technique was used ( up to k - file # 50 ) under constant irrigation with 0.5% \n naocl .\nthe smear layer was removed with 17% edta ( 5 ml ) and 0.5% naocl ( 5 \n ml ) followed by saline \n solution ( 15 ml ) .\nthree coats of nail polish were applied to \n external root surfaces except for the apical 2 mm .\nthe teeth were randomly ( http://www.random.org ) divided into \n 3 experimental groups ( n=11 ) .\nthe endodontic sealers were \n prepared according to the manufacturer 's instructions and the cold lateral \n condensation filling technique ( lc ) was used according with the following \n description :\nan iso # 50 master gutta - percha cone was lightly coated with ah plus sealer ( ah \n plus ; dentsply detrey , konstanz , germany ) and placed into the \n canal to rwl .\na size b finger spreader ( dentsply maillefer , ballaigues , switzerland ) \n was then inserted into the canal to a level approximately 1 mm short of rwl .\nlc with \n accessory gutta - percha cones was performed until the entirely filled root canal .\nthe \n excess gutta - percha was removed with a heated plugger and then compacted \n vertically .\nadhesive - modified technique was used for bonding ah plus to intraradicular dentin . a \n paper point soaked with epiphany primer\nwas used to etch dentin ( 30 s ) and the excess \n was removed with paper points .\nthe coronal surface of the root filling was \n light - cured for 40 s ( 600 mw / cm ) .\nthe positive controls ( n=3 ) were left unfilled and coated as described earlier . the \n negative controls ( n=3 ) were filled and totally coated , including the apical \n foramina .\nthe openings were sealed ( cavit w , 3 m espe , st paul , mn , usa ) , and \n stored in a chamber held at 100% humidity and 37c for 7 days .\nnext , all teeth \n were immersed in a 50-wt% aqueous silver nitrate solution ( agno3 , ph7.0 ) \n in the darkness that was buffered using naoh 0.1 n for 24 h at 37c .\nthe silver - impregnated teeth \n were rinsed and placed in photodeveloper ( 8 h ) in fluorescence light to reduce the \n silver ions into metallic silver . \n\nlake bluff , \n il , usa ) , longitudinally sectioned in an isomet 1000 precision saw ( buehler ) at low \n speed ( 200 rpm ) with a water - cooled diamond blade .\nthe interfaces were etched with a \n 35% phosphoric acid solution ( 5 s ) , rinsed with distilled water ( 30 s ) and gently \n air - dried .\nthen , specimen preparation followed the protocol 1 for apical microleakage \n analysis using scanning electron microscopy / energy dispersive spectroscopy ( sem / eds ) ; \n or the protocol 2 for gaps analysis using sem according to the following \n description :\nspecimens were fixed , dehydrated in ascending grades of ethanol and final chemical \n drying in hmds ( hexamethyldisilazane , sigma - aldrich inc . , st .\nlouis , mo , usa ) for 10 \n min , and covered with \n carbon ( sputter coater scd 050 , bal - tec ag , balzers , liechtenstein ) .\nthe apical 5 mm \n of the root canal filling were divided into 5 regions of 1 mm to evaluate \n microleakage by sem leo stereoscan 440 ( leo electron microscopy ltd . ,\ncambridge , \n england ) using back scattered electrons ( bse ) mode ( figure 1a ) .\nthe eds ( inca software , oxford , uk , england ) was performed in \n lower magnification within a pre - determined area ( 300 m ) ( figure 1b ) , and in a higher magnification , the \n identification of silver was made punctually to determine its exact location ( figure 1c ) .\neach 1 mm region was classified \n according to the following scores : 0 ( absence of leakage in both interfaces ) and 1 \n ( presence of leakage in at least one of the interfaces ) . in figures 1d and 1e\nscanning electron microscopy ( sem ) micrographs using back scattered electrons \n ( bse ) mode and corresponding energy dispersive spectroscopy ( eds ) spectrum of \n agno3 leakage : ( a ) - the apical 5 mm of the root canal filling \n divided into 1 mm - regions .\npointer at the detected metallic silver ; ( b )  area \n ( 300 m ) scanned for the existence of silver and \n respective eds spectrum ( arrow ) and ( c ) - in detail , punctual eds confirmation \n of its exact location .\nimpressions of polyvinyl siloxane ( aquasil , ulv , dentsply detrey ) were \n made of the interfaces and the surfaces replicated with epoxy resin \n ( epon - thin , buhler ) .\nthe replicas were covered with carbon to \n investigate the presence of gaps at the dentin / sealer and sealer / cone interfaces , as \n described previously , using secondary electrons ( se ) mode .\nas the gaps were not \n continuous , for each 1 mm - region , two interfaces were analyzed ( figure 2a ) and classified as : type 0 : both interfaces were \n gap - free , type 1 : gap at dentin / sealer interface ( figure 2b ) , type 2 : gap at sealer / cone interface ( figure 2c ) , and type 3 : both types of gaps present .\ntherefore , \n for each experimental group , 11 replicas were prepared ; 55 regions were evaluated and \n accordingly classified .\nscanning electron microscopy ( sem ) micrographs using secondary electrons ( se ) \n and back scattered electrons ( bse ) mode of the replica and the section of the \n same specimen , respectively .\n( a ) - the apical 5 mm of the root canal filling \n divided into 1 mmregions .\nclassification of the types of gaps : ( b )  type 1 : \n gap between dentin / sealer ( pointer ) ; air voids were present within the sealer \n ( open arrow ) ; ( b ' ) - silver penetration was evident along the dentin / sealer \n interface , into dentinal tubules in a reticular form and granular aspect on the \n dentin surface ( arrowhead ) ; ( c )  type 2 : gap between sealer / cone ( pointer ) - \n cohesive fracture of the sealer ( open arrow ) ; ( c ' ) - the area marked in figure \n c at higher magnification : silver deposition into the dentinal tubules in a \n reticular form and granular aspect within the sealer layer ( arrowhead ) could be \n seen ; ( the sealer thickness was indicated between black / white arrowheads . \n\ngp = gutta - percha ; d = dentin ; r = resilon ) the data obtained for apical microleakage and types of gaps were statistically \n analyzed ( =0.05 ) using the ordinal logistic regression model and correspondence analysis in the minitab statistical software \n program ( minitab inc .\nthe counting of regions analyzed for gaps was also computed and adjusted in a \n generalized linear model with poisson distribution and logarithmic link function .\nthe \n sealers groups ( ah plus , ah primer and epiphany ) and the type of gap were considered \n as explanatory variables and ah plus and the type 0 as references .\nthe ordinal logistic regression analysis demonstrated that there was no statistically \n significant difference ( p>0.05 ) among the groups tested and types of gaps over \n the logit of microleakage .\nthe model was adjusted to identify the \n effect of the type of gap on microleakage .\nthe type 3 data were not considered isolated \n in the analysis ( very few regions ) but joined with type 2 data ( figure 2c ; table 1 ) .\nthe \n adjustment tests of the model presented high p - values for pearson 's test ( p=0.900 ) and \n deviance ( p=0.852 ) .\nthe adjusted model demonstrated that the effect of the type of gap \n on the logit of microleakage is significant when compared to the \n presence of types 1 and 2 ( figure 2b and 2c , respectively ) of gap with the absence of gap \n ( p=0.047 ) .\nthe correspondence analysis also showed the association between microleakage \n and both types of apical gaps ( figure 3 ) .\ncorrespondence analysis of microleakage vs. type of gap : ( inf.0 ) - absence of \n leakage ; ( inf.1 ) - leakage up to the 1 millimeter ; ( inf.2 ) \nleakage \n up to the 2 mm ; ( inf.3 )  leakage up to the 3 \n millimeter ; ( inf.5 )  leakage up to the 5 millimeter ; ( f.0 )  absence \n of gaps ; ( f.1 )  gaps type 1 ; ( f.2 ) - gaps types 1 and 2 .\nthe absence of leakage \n is associated with the absence of gap ; leakage up to the 1 millimeter \n is associated with type 1 ; and more extensive leakage is associated with types 1 \n and 2 frequency and type of gaps in the apical 5 mm of root canal fillings percentage of regions with gaps .\ntype 0 : absence of gaps ; type 1 : gaps between \n dentin and sealer ; type 2 gaps between sealer and cone the generalized linear model with poisson distribution ( table 1 ) found no difference between ah plus and ah primer ( p=0.497 ) in \n distribution of each type of gap , but they presented more type 0 regions \n ( p<0.001 ) .\nthere was a significant interaction between epiphany and the type of \n gap ( p<0.003 ) and for this group , there were more type 1 regions .\nbased on the findings of this study , the first null hypothesis could not be rejected . \n\nrecently some studies have shown similar results between ah plus and epiphany on apical \n sealing ability using the fluid filtration method .\nconsistent with these \n studies , our results indicate that the epiphany system is as effective as ah \n plus / gutta - percha in preventing microleakage based on the chemical tracer penetration \n analysis by sem and the use of epiphany primer does not reduce the microleakage of ah \n plus . nevertheless , other researches pointed out that the epiphany system provided the \n greatest resistance to the movement of fluids or dye leakage \n test , when compared to epoxy \n resin - based root canal sealers , but others have just indicated the opposite .\nthese apparent discrepancies can perhaps be explained by the \n methodology used and their variables .  \nthese results agree with those of previous studies in which , microleakage markers were \n used to evaluate apical sealing of the same endodontic sealers .\nthe tracer \n selected was agno3 , which may penetrate into dentinal tubules due to their \n physical and chemical characteristics including : concentration , smaller molecular size , \n its neutral ph , diffusion coefficient and service life up to 168 h post - preparation time of \n solution .\nanother reason for \n this choice is that metallic silver deposits may be observed by sem using back scattered \n electrons ( bse ) mode . on the other hand ,\nthe results of the current study disagree with the findings of \n shipper , et al .  \nan \n explanation for this would be that their studies have evaluated coronal and not apical \n bacterial leakage . indeed , coronal seal might be favorably influenced by photoactivation \n of the material which is unlikely to occur in the apical third .\nfurthermore , it is speculated that in in \n vivo studies ( dogs ) , the high release of calcium hydroxide ( 41.46 mg / l ) that \n would occur during the process of epiphany sealer solubilization , would make the medium \n alkaline , resulting in acceleration of the periapical tissue repair process .\nthis study has shown that the presence of apical gaps at the sealer / dentin or \n sealer / cone interfaces had an effect on apical microleakage .\nthe epiphany group \n presented more type 1 gaps than the other groups ( table \n 1 ) , rejecting the second null hypothesis .\nthese results corroborate with \n previous observation of gaps in the apical 4 mm of epiphany or ah plus - filled root \n canals .\nstress generated \n during the polymerization shrinkage of epiphany sealer has probably influenced the \n integrity loss at the sealer / dentin interface .\nin addition , the cavity configuration factor ( c - factor ) is \n highly unfavorable for adhesion inside root canals .\nmoreover , it is known that analysis of gap formation of \n vertically sectioned root filled teeth hides the risk of artifacts during sectioning . \n\ntherefore , in this study , the sections were made at low speed under water cooling .\nthe \n resin - epoxy replicas at the dentin / sealer and sealer / cone interfaces were made before \n the specimens had been prepared for sem examination in order to differentiate genuine \n gaps from artifactual gaps created after vacuum desiccation in conventional scanning \n electron microscopes .\nfew studies have focused on apical sealing from two separate perspectives , such as \n microleakage and apical gap formation .\nsem was used to evaluate these perspectives , but it was restricted to a descriptive \n approach .\na systematization of the observations , complemented by a statistical analysis , such as \n the one performed in this study , could provide greater methodological accuracy and \n impartiality for comparing the experimental groups .\nthe correspondence of analysis \n between the types of gaps and linear extent of agno3 leakage ( fig .\n3 ) confirms the effect of gaps on apical \n microleakage , expressed by the silver deposition into gaps that extended deeply inside \n dentinal tubules ( fig .\nregarding to statistical analysis , the ordinal logistic regression analysis model was \n used due to microleakage was considered categorized ordinal response variable ( ranging \n from 0 - no leakage to 5 - leakage up to the fifth millimeter ) .\nthe correspondence \n analysis is a method that leads to visualize the association between two categorical \n variables , in this case microleakage and the type of gap .\nthe generalized linear model \n with poisson which is an extension of usual regression model was performed to quantify \n the distribution of types of gaps .\nthis result could be explained by two hypotheses : ( 1 ) \n the low degree of conversion of the epiphany sealer and ( 2 ) the formation of hydrogel at the bond interface resulting \n from the incomplete evaporation of the epiphany primer solvent .\nthe second hypothesis could also explain the inefficacy \n of epiphany primer in improving the sealing capacity of ah plus .\nmoreover , there is a \n chemical incompatibility between these two materials , since the epoxy resin sealers do \n not copolymerize with methacrylate resin - based adhesives .\nother studies should be carried out to clarify the \n sealing ability of the root - filled materials studied .\nit may be concluded that none of the tested materials completely sealed the apical 5 mm . \n\nthe presence \n of gaps had an effect on apical microleakage for all materials . comparing the materials , \n epiphany system presented more regions containing gaps between the dentin and the sealer \n ( type 1 ) . in view of these findings ,\nclinically , it can be suggested that ah plus would \n provide a better apical seal .\nthis study was partially supported by capes ( coordenao de \n aperfeioamento de pessoal de nvel superior)/institutional \n qualification program ( pqi n : 0090/03 - 4 ) ."}
{"lay_summary": " permanent neonatal diabetes mellitus refers to diabetes that occurs before the age of 6 months and persists through life . \n it is a rare disorder affecting one in 0.2 - 0.5 million live births . \n mutations in the gene kcnj11 , encoding the subunit kir6.2 , and abcc8 , encoding sur1 of the atp - sensitive potassium ( katp ) channel , are the most common causes of permanent neonatal diabetes mellitus . \n sulfonylureas close the katp channel and increase insulin secretion . kcnj11 and abcc8 mutations have important therapeutic implications because sulfonylurea therapy can be effective in treating patients with mutations in the potassium channel subunits . \n the mutation type , the presence of neurological features , and the duration of diabetes are known to be the major factors affecting the treatment outcome after switching to sulfonylurea therapy . \n more than 30 mutations in the kcnj11 gene have been identified . here , \n we present our experience with a patient carrying a novel p.h186d heterozygous mutation in the kcnj11 gene who was successfully treated with oral sulfonylurea . ", "article": "neonatal diabetes mellitus ( ndm ) presenting within the first 6 months of life includes permanent neonatal diabetes mellitus ( pndm ) , which require lifelong therapy , and transient neonatal diabetes mellitus ( tndm ) where the condition shows remission during infancy but relapses in adolescence .\nalmost all cases of neonatal diabetes have monogenic etiology in contrast to the autoimmune diabetes presenting in children beyond 6 months of age .\npndm is associated with defects in pancreatic beta cell development and function . activating mutations in the kcnj11 gene , encoding the subunit kir6.2 , and abcc8 gene ,\nencoding the sulfonylurea receptor 1 ( sur1 ) of atp - sensitive potassium ( katp ) channel , which has a key role in insulin secretion in glucose metabolism , are the most common causes and account for approximately 40% of all cases of pndm12 ) .\nmutations in the glucokinase ( gck ) and insulin ( ins ) genes have also been reported in patients with pndm .\nsulfonylureas close the katp channel by an atp - independent route , leading to increase insulin secretion4 ) .\ntherefore , in many patients with pndm with kir6.2 and sur1 mutations , insulin therapy can be replaced by oral sulfonylureas which offer more improvement in glycemic control and better quality of life35 ) .\nwe report a case of pndm caused by a novel p.h186d heterozygous mutation in the kcnj11 gene whose treatment was successfully transitioned from insulin to oral sulfonylurea .\nher parents were unrelated , and her family was healthy and had no history of diabetes .\nlaboratory results at diagnosis were : blood glucose , 1,041 mg / dl ; ph , 7.025 ; hco3 , 5.1\nmmol / l ; pco2 , 19.8 mmhg ; sodium , 147 mmol / l ; potassium , 5.6 mmol / l ; chloride , 113 mmol / l ; blood urea nitrogen , 31 mg / dl ; creatinine , 1.2 mg / dl ; urine ketone , + + + ; glycosylated hemoglobin ( hba1c ) , 7.7% ; and c - peptide , 0.2 ng / ml . after recovery from diabetic ketoacidosis , she had injections of neutral protamine hagedorn ( nph ) insulin two times a day and regular insulin ( ri ) four times a day .\nher maximal daily insulin dose was at 1.5 u / kg . her insulin requirement was gradually decreased to 0.44 u / kg / day by 4 months of age .\nalthough there were several hypoglycemic events , insulin injection for glucose control after the infancy period could not be stopped .\ngenetic study for neonatal diabetes using genomic dna extracted from peripheral lymphocyte was done at 4.5 years of age , and a novel heterozygous mutation of the kcnj11 gene located on chromosome 11p15.1 and encoding kir6.2 , c.556c > g ( p.his186asp ) , was found ( fig .\ntransition of treatment from insulin to sulfonylurea was attempted at the age of 4.8 . before the trial ,\nlaboratory findings were as follows : hba1c , 6.9% ; fasting glucose , 205 mg / dl ; c - peptide , 0.84 ng / ml ; 24-hour urine c - peptide , 2.2 g ; negative for islet cell antibody ; anti - insulin antibody ; and anti - gad antibody .\nshe was 103.2 cm in height ( 25th-50th percentile ) , 17 kg in weight ( 50th-75th percentile ) and did not have any specific neurological deficit .\noral sulfonylurea ( glibenclamide ) was initiated at a dose of 0.1 mg / kg / day divided into two equal doses .\nthe glibenclamide dose was gradually increased to 0.4 mg / kg / day over 1 week and the insulin was stopped .\noral glucose tolerance test ( glucose , 1.75 g / kg ) was done at 6 months and 1 year after completion of the sulfonylurea transition .\ninsulinogenic index [ insulin ( 30 min-0 min)/glucose ( 30 min-0 min ) ] , a marker of beta cell function , became increased from 0.10 to 0.18 , and acute c - peptide response [ c - peptide ( 30 min-0 min)1,000/glucose ( 30 min-0 min ) ] became increased from 6.48 to 8.29 ( table 1 ) .\nthe patient is now 7.5 years of age with a height of 121.4 cm ( 50th percentile ) and weight of 23.4 kg ( 50th percentile ) .\nblood glucose was well controlled without episodes of hypoglycemia and the hba1c has been lower than during insulin injection ( fig .\nndm is a monogenic form of diabetes that presents within the first 6 months of life .\nheterozygous activating mutations in the kcnj11 and abcc8 gene encoding the subunits kir6.2 and sur1 of katp channel in pancreatic beta cells are the most common and account for nearly half of all cases of pndm12 ) .\nmutations in the glucokinase ( gck ) , insulin ( ins ) genes have also been reported in patients with pndm .\nthe causes of rare syndromic pndm includes recessive mutations in several genes , such as pdx1 , eif2ak3 , gck , ptf1a , foxp3 , neurog3 , neurod1 , rfx6 , ier3ip1 , hnf1b , glis3 , pax6 , slc19a2 , slc2a2 , and wfs167 ) . in tndm\n, imprinted locus at chromosome 6q24 seen in more than half of cases8 ) , and kcnj11 and abcc8 gene mutations are also found in some cases .\nglucose increases intracellular atp level and it induces the closure of katp channels that lead to insulin secretion by pancreatic beta cells . activating mutations in the kcnj11 or abcc8 gene of katp channel lead to katp channels remaining open despite the presence of glucose , thus , insulin secretion can not be increased1 ) . on the contrary , loss of function mutations cause congenital hyperinsulinemia due to the closure of the katp channel and lead to increased insulin secretion\n. sulfonylureas ( su ) can close the katp channel and increase insulin secretion4 ) .\ntreatment response is not expected in patients with mutations in other genes , such as glucokinase gene , foxp3 , and ipf1 .\ntherefore , molecular diagnosis in neonatal diabetes may help identify patients that are likely to respond to oral sulfonylureas .\npearson et al.3 ) reported the responses to sulfonylurea according to mutation types in diabetic patients caused by kcnj11 mutation .\nthere were no differences in blood insulin , c - peptide level , and insulin injection dose between the successful group and unsuccessful group .\nv59 m , r201c , f35v , h46y , r50q , g53r , r201l , e322k , y330s , f333i mutations also belong to the successful group .\nswitching to su was unsuccessful in patients with q52r , i296l , and l164p mutations .\nin addition , failure of switching to su was more related with the presence of neurologic features ( 14% in successful group and 80% in unsuccessful group ) and older age at initiation of su .\nmedian age was 6 years old ( intraquartile range , 3 - 12 years ) in the successful group and 18 years old ( intraquartile range , 6 - 35 years ) in the unsuccessful group3 ) .\nthe report about a mother and daughter carrying the same kcnj11 mutation showed that the daughter could be switched from insulin to su at age 8.5 years , but her mother had an imcomplete response9 ) .\nthe trial of su switching in a poorly controlled diabetic 19 years old patient with r201h mutation , a mutation type expected to respond successfully , failed10 ) .\nthese observations suggest that factors that can affect the success of switching to su include ; mutation type , severity of mutation , and duration of the diabetes .\na long - standing diabetes may lead to islet beta cell exhaustion resulting in nonresponse to su9 ) .\nndm caused by kcnj11 gene mutations is inherited in autosomal dominant pattern , but most of these cases result from new mutations without family history . the patient in this case has a novel mutation ( p.h186d ) in the kcnj11 gene and presented with a mild form of pndm .\nswitching to su with an initial dose 0.4 mg / kg / day was successful at 4.8 years of age .\noral glucose tolerance test in index patient showed improvement in insulin secretion during the treatment at 6 months and 12 months after the use of su .\nalthough she had hypoglycemia every 2 or 3 weeks and experienced a few episodes of hypoglycemia with mental change during insulin treatment , there was no more hypoglycemia after changing to su treatment . oral sulfonylurea therapy is both safe and better than insulin for metabolic control .\nreported side effects of oral su are transitory diarrhea and tooth discoloration in a few patients311 ) .\nmean hba1c was 8.1% in patients with insulin injection and 6.4% in patients with su therapy312 ) .\nchronic su treatment seems to develop no beta cell desensitisation in pndm patients with kcnj11 mutation13 ) .\nearly su therapy at disease onset can permit insulin hypersensitivity and maintained basal insulin secretion , then provide long - term remission in animal subset14 ) . allowing for the potential beneficial effect on neurodevelopmental outcome and glycemic control , empiric tiral of su before genetic testing in neonatal diabetes patients can be considered15 ) . in conclusion , as the mutation type , severity of mutation , and duration of the diabetes are the major factors affecting the success of switching to su , early genetic analysis and trial of sulfonylurea is important in the management of neonatal diabetes .\nfurther studies looking at the result of su treatment and long term follow in pndm patients are needed ."}
{"lay_summary": " radiocontrast administration is an important cause of acute renal failure . in this study , \n compared the plasma creatinine levels with spot urine il-18 levels following radiocontrast administration . \n twenty patients ( 11 males , 9 females ) underwent radiocontrast diagnostic and therapeutic - enhanced examinations . \n the rin mehran risk score was low ( 5 ) . \n the radiocontrast agents used were 623 mg / ml iopromid ( 1.5 ml / kg ) , and 100 ml of 650 mg / ml meglumine diatrizoate as three - way oral and rectal contrast material for abdominal computed tomography ( ct ) scans . \n serum blood urea nitrogen , creatinine , na , k , cl , ca , p , creatinine clearance , and spot urine il-18 levels were analyzed before and repeated at 24 , 48 , and 72 h after radiocontrast administration . \n six and 24-h urinary il-18 levels were measured with a human il-18 elisa kit following radiocontrast administration . \n an increase in plasma creatinine 24 and 48 h following radiocontrast administration was observed compared with precontrast values , but it was not statistically significant ( p=0.052 and p=0.285 , respectively ) . a statistically significant increase in il-18 levels was observed at 6 and 24 h , compared with precontrast values ( p=0.048 and p=0.028 , respectively ) . \n a tendency for postcontrast 24-h urinary il-18 levels to increase was observed compared with 6 h , but the increase was not statistically significant ( p=0.808 ) . \n our results show that plasma creatinine starts to increase at 24th hour ; however , spot urine il-18 levels go up at 6th hour following radiocontrast administration implying urine il-18 to be an earlier parameter for kidney injury . ", "article": "radiocontrast - induced nephropathy ( rin ) can lead to acute renal failure ( arf ) , which may require dialysis therapy .\narf increases treatment cost due to sepsis , hemorrhage , respiratory failure , and a long hospitalization.[13 ] rin is an important cause of hospital - acquired arf and is responsible for 12% of cases .\nrenal medullary hypoxia and the direct toxic effects of iodinated contrast agents on renal tubules are possible mechanisms responsible for the pathophysiology of rin\n. identified specific risk factors for rin are current renal insufficiency , diabetes mellitus , and high contrast volume , dehydration , advanced age ( > 70 years ) , congestive heart failure ( chf ) , and nephrotoxic drug use ( angiotensin converting enzyme inhibitor and nonsteroidal antiinflammatory drugs ) .\npatients at risk for radiocontrast nephropathy are recommended to use nonionic iso - osmolar or nonionic low osmolar contrast agents .\nincreases in serum creatinine levels are useful for detecting rin . in the majority of patients ,\nplasma creatinine levels rise within the first 2448 h after administering the radiocontrast agent , reach a peak within 35 days , and return to normal after 13 weeks .\nrecent studies have reported that urine levels of il-18 ( a pro - inflammatory cytokine ) , kidney injury molecule-1 , and neutrophil gelatinase - associated lipocalin ( ngal ) levels are important for early detection of rin .\nsome reports have shown that il-18 levels start to increase within 46 h and peak at 12 h in patients with acute renal injury . in this study\n, we aimed to compare the plasma creatinine levels with spot urine il-18 levels following radiocontrast administration .\ntwenty patients ( 11 males and 9 females ) underwent diagnostic and therapeutic contrast - enhanced examinations at the department of internal medicine from january 2009 to march 2009 .\nthe study was approved by the institute ethics committee and written consent was obtained from the selected patients based on a low mehran risk score ( 5 ) .\npatient demographic characteristics a precontrast - enhanced examination of serum blood urea nitrogen ( bun ) , creatinine , na , k , cl , ca , p , creatinine clearance was analyzed and they were repeated at 24 , 48 , and 72 h following contrast administration .\nspot urine il-18 levels were measured before and 6 and 24 h after radiocontrast administration with a human il-18 elisa kit ( biosource invitrogen human il-18 , california ) .\nintravenous iopromid ( 623 mg / ml , 1.5 ml / kg ; ultravist 300 ) , a three - way oral and rectal contrast material for abdominal ct scans , and 650 mg / ml meglumine diatrizoate ( urovist , 100 ml ) were used for every patient . glomerular filtration rate was calculated using the cockcroft \n1 h before the procedure , 8.4% nahco3 plus 5% dextrose ( 3 ml / kg / h ) with 1200 mg / day n - acetylcysteine was given to all patients prophylactically .\nafter radiocontrast agent administration , the same prophylactic treatment was continued ( 1 ml / kg / h ) for 6 h. during this time , hydration and urine output were followed by monitoring the intake and release of fluids .\npatients with no history of kidney disease , plasma creatinine values < 1.2 mg / dl , gfr60 ml / min , nondiabetic , no urinary infection , and no decompensated heart failure were included .\nurinary il-18 levels were measured with a human il-18 elisa kit ( biosource invitrogen human il-18 , carlsbad , ca , usa ) .\nthe statistical analysis was performed with the ncss pass 2007 and 2008 statistical software ( kaysville , ut , usa ) .\nserum creatinine levels increased after radiocontrast administration compared with precontrast levels , although the result was not statistically significant [ table 2 ] .\na slight increase in creatinine levels occurred at 48 h after radiocontrast administration but they fell to precontrast values at 72 h. a slight increase in plasma creatinine levels at 24 and 48 h following radiocontrast administration was observed compared with precontrast values , but it was not statistically significant ( p=0.052 and p=0.285 , respectively ) [ table 2 ] .\nplasma creatinine levels in patients before and after radiocontrast agent administration compared with precontrast urine spot il-18 levels , postcontrast 6 and 24 h urinary levels of il-18 increased significantly ( p=0.048 and p=0.028 , respectively ; table 3 ) . a tendency for postcontrast 24-h urinary il-18 levels to increase\nwas observed compared with 6 h , but the increase was not statistically significant ( p=0.808 ; table 3 ) .\nspot urine il-18 levels in patients before and after radiocontrast agent administration plasma creatinine levels and spot urine il-18 were weakly but positively correlated with those during the precontrast period , although this finding was not statistically significant ( r=0.246 , p=0.126 ) .\nsimilarly , postcontrast 24-h plasma creatinine levels and spot urine il-18 levels were weakly but positively correlated , although this result was also not statistically significant ( r=0.254 , p=0.276 ) .\nthere was no difference between pre- and postcontrast values of serum blood urea nitrogen ( bun ) , creatinine , na , k , cl , ca , p , and creatinine clearance .\nthe most common definition of rin is plasma creatinine levels of 0.5 mg / dl or higher 72 h after contrast administration or 25% higher than the basal plasma creatinine level .\nplasma creatinine levels began to rise within 24 h in 80% of the patients with rin , peaking at 4872 h , and returning to baseline after 2 weeks .\nthe first 24 h remains unclear in patients with acute renal injury , but il-18 levels start to increase within 46 h , peaking at 12 h. additionally , plasma creatinine is affected by age , body weight , total body volume , gender , race , drug use , muscle mass , and protein intake so researchers are looking for a diagnostic marker for rin that can be measured easily and is not affected by nonrenal factors .\nmost studies related to these parameters include serum and urine cystatin c , serum and urine ngal , and urine il-18 in the analysis .\nas proinflammatory cytokine il-18 levels increase in urine , tubular inflammation , such as ischemia , reperfusion injury , allograft rejection , cisplatin toxicity , and endotoxemia occur .\nparikh et al . , found that 72 patients with acute tubular necrosis and delayed graft reaction have significantly higher il-18 levels than other kidney diseases ( urinary tract infection , chronic renal failure , nephrotic syndrome , or prerenal azotemia ) .\nreported that il-18 generally showed a low sensitivity but high specificity , respectively , for assessing an acute kidney injury diagnosis and risk classification . in our study , we examined spot urinary il-18 levels in comparison with plasma creatinine levels .\na weak positive correlation was found between precontrast creatinine and urine il-18 levels , although it was not statistically significant . furthermore , we also found a weak positive correlation between postcontrast 24 h creatinine and urine il-18 levels , although this was not statistically significant either .\na slight increase in plasma creatinine levels at 24 h and 48 h following radiocontrast administration was observed compared with precontrast values , but it was not statistically significant which was regressed to precontrast values at 72 h. a statistically significant increase in the level of spot urinary il-18 levels at 6 and 24 h postcontrast was observed , compared with precontrast spot urine il-18 levels and difference between 6 and 24 hour levels were not statistically significant .\none of the limitations of this study is that there are other early biomarkers of acute kidney injury such as ngal and kim-1 .\nanother limitation is that urine il-18 measurement was indexed to serum creatinine instead of urine creatinine since serum creatinine is considered to be a better and commonly used marker in the diagnosis of acute kidney injury . in conclusion ,\nspot urine il-18 levels at sixth hour following radiocontrast administration suggesting that it may be an earlier parameter for identifying kidney injury ."}
{"lay_summary": " living in biofilms is probably the most common condition for bacteria and fungi and biofilm - related infections account for the majority of bacterial infectious diseases worldwide.among others biofilm - related infections , those associated with implanted biomaterials have an enormous and still largely underestimated impact in orthopaedics and trauma , cardio - surgery and several other surgical disciplines.given the limited efficacy of existing antibiotics in the prevention and treatment of bacterial biofilms , new strategies are needed to protect implants and host tissues , overcoming the striking ability of the microorganisms to adhere on different surfaces and to immediately protect themselves by forming the biofilm matrix.adhesion is a necessary first step in microbial colonization and pathogenesis and provides a potential target for new preventive and treatment approach.among various polymers , tested as antibacterial coatings , hyaluronic acid and some of its composites do offer a well - established long - term safety profile and a proven ability to reduce bacterial adhesion and biofilm formation.aim of the present review is to summarize the available evidence concerning the antiadhesion / antibiofilm activity of hyaluronic acid and some of its derivatives to reduce / prevent bacterial adhesion and biofilm formation in various experimental and clinical settings . ", "article": "according to the u.s . national institutes of health , up to 80% of human bacterial infections involve biofilm - associated microorganisms 1 . among these , implant - related infections\ndo still have a tremendous impact in orthopaedics and trauma 2 , with high social and economic costs 3 , 4 , posing challenging diagnostic and therapeutic dilemmas 5 .\nin fact , peri - prosthetic joint infection ( pji ) remains one of the most feared complications in orthopaedic surgery and among the first reasons for implant failure 6 .\nmoreover , given the increasing number of hip and knee arthroplasties performed , the prevalence of this complication is rising , with increasing costs for national health systems and increasing biological costs for the patients , such as loss or reduced joint function and deterioration in their physical and psychological health 7 . according to the widely accepted model of the ' race for the surface ' for pji development ,\nhost and bacterial cells compete for surface colonization , with a low probability of bacterial attachment if host cells adhere to implant first , and vice versa . in the event of bacterial adhesion to an implant ,\nin addition , the matrix protects the biofilm cells from various microbicidal agents and stresses , including dehydration , toxins , ultraviolet light , chemical disinfectants , temperature and osmotic shock , and lead them to increased resistance against antimicrobials 9 , 10 . to address the limited efficacy of existing antibiotics in the treatment of established bacterial biofilms , novel approaches are required to prevent bacterial adhesion and biofilm formation 11 .\nadhesion is a necessary first step in microbial colonization and pathogenesis and provides a good theoretical target for new preventive and treatment strategies 12 .\nbacterial adhesion to surfaces can be divided into a first , reversible phase and a second , irreversible phase .\nonce an implant is inserted into the body , it is covered by a conditional protein layer composed of host proteins , such as albumin and complement , that act as a reservoir of several receptors for bacterial adhesive ligands , mediating adhesion of free - floating bacteria to the surface of the biomaterials 14 , 15 ; these first adhesions are , however mechanically and biologically unstable .\nfew minutes after this first , reversible phase , bacterial clusters attached to the surface starts to express biofilm related genes , produce glycocalyx and form mature biofilm , thus transforming the adhesion from reversible to irreversible 16 .\nfull - formed biofilm can be found few hours after the first bacterial adhesion 17 .\nantimicrobial surface coatings can be based on an anti - adhesive principle that prevents bacteria to adhere and form biofilms 18 .\nin fact , some polymer coatings , like the hydrophilic polymethacrylic acid , polyethylene oxide or protein - resistant polyethylene glycol can be applied to the surface of titanium implants and result in significant inhibition of bacterial adhesion 19 - 22 .\nhydrophobic and superhydrophobic surface treatment technologies have also shown a great repellent antibacterial effect in preclinical studies 23 - 25 .\nhowever , clinical application of completely novel coating technologies and compounds , not otherwise previously tested in humans , appears particularly challenging 26 .\nbacterial colonization can also be blocked by an inhibitor interfering with ligand - receptor interaction for bacterial attachment .\none of these inhibitors could be hyaluronic acid ( ha ) , a glycosaminoglycan made up of glucuronic acid and n - acetylglucosamine disaccharide units .\nit is a uniform , linear and unbranched molecule , with highly variable length and molecular weight ( up to 106 da ) .\nit is abundant in skin ( up to 56% ) and in connective tissues , with a turnover ranging from several hours to a few days depending on tissues .\nhyaluronic acid constitutes one of the main components of extracellular matrices . because of its biological properties , ha has several clinical applications ( aesthetic surgery , dermatology , dentistry , orthopedics and opthalmology ) 27 .\nextensive studies on the chemical and physicochemical properties of ha and its physiological role in humans , together with its versatile properties , such as its biocompatibility , non - immunogenicity , biodegradability , and viscoelasticity , have proved that it is an ideal biomaterial for medical and pharmaceutical applications 28 , 29 . among its various properties ,\nseveral studies have recently shown the ability of ha to protect against various infectious agents 30 , depending on ha concentration and molecular weight 31 , 32 , while more recently ha interference on bacterial adhesion and biofilm formation has been extensively investigated 33 .\ngiven its high biocompatibility and well known safety profile and the anti - adhesive capabilities , ha and its composites represent an attractive , non - antibiotic , option to mitigate the impact of biofilm - related infections in various clinical settings including implant - related infections . aim of this review is to provide an update of the current evidence concerning ha ability to reduce / prevent bacterial adhesion and biofilm formation .\nnearly two decades ago , pavesio et al . 34 were probably the first to describe the ability of ha to resist bacterial adhesion , with particular reference to staphylococcus epidermidis , and its non - fouling properties 35 , proposing coated polymeric medical devices ( e.g. , intraocular lenses , stents and catheters ) to reduce implant - related infections .\nin particular , a hydrophilic ha overlayer , linked to the surface of polymethylmethacrylate intraocular lenses ( iols ) , was shown to be able to prevent fibroblasts adhesion and to greatly reduce staphyloccous epidermidis adhesion to the implant surface 36 .\nthe impact of slime dispersants and anti - adhesives on in vitro biofilm formation on iols was further investigated by kadry and co - workers 37 , using a staphyloccous epidermidis wild strain , isolated from a patient with endophtalmitis ; the authors reported the ability of hyaluronan to reduce bacterial adhesion to iols to 30% , compared with untreated control cells .\nthe authors suggested the use of adjuvant therapy such as dispersants or anti - adhesives , in addition to the antibiotics in irrigating solutions for bacterial ocular infections .\nmore recently , the in vitro antiadhesive and antibiofilm activity of hyaluronic acid towards bacterial species commonly isolated from respiratory infections was investigated by drago et al .\n33 . in this study , the interference exerted on bacterial adhesion was evaluated by using hep-2 cells , while the antibiofilm activity was assessed by means of spectrophotometry after incubation of biofilm with hyaluronic acid and staining with crystal violet .\nthe experimental findings clearly demonstrated how hyaluronic acid is able to interfere with bacterial adhesion to a cellular substrate in a concentration - dependent manner .\nmoreover , staphylococcus aureus biofilm was found to be more sensitive to the action of ha , compared to that produced by haemophilus influenzae and moraxella catarrhalis . concerning more specifically the antimicrobial activity , ha\nhas also been shown to exert varied bacteriostatic , but not bactericidal , dose - dependent effects on different microorganisms in the planktonic phase 31 , 38 . in this\nregard , radaeva et al . reported the inhibiting activity of ha with respect to some pseudomonas species 39 , while ardizzoni and co - workers 30 investigated the effects of ha on 15 atcc bacterial strains , representative of clinically relevant bacterial and fungal species .\ntheir results showed that different microbial species and , sometimes , different strains belonging to the same species , are differently affected by ha . in particular , staphylococci , enterococci , streptococcus mutans , two escherichia coli strains , pseudomonas aeruginosa , candida glabrata and c. parapsilosis displayed a ha dose - dependent growth inhibition , while no ha effects were detected in e. coli atcc 13768 and c. albicans and s. sanguinis was favoured by the highest ha dose . comparing the potential bacteriostatic effect of some of the most commonly used biomatrix materials ( collagen type i , hyaluronic acid , hydroxyapatite , polylactic acid and polyglycolic acid ) on the growth over the first 12h of exposure of some of the most common orthopaedic bacterial pathogens ( staphylococcus aureus , staphylococcus epidermidis , -hemolytic streptococcus , pseudomonas aeruginosa ) , carlson and co - workers 38 found that ha had the most significant bacteriostatic properties on the studied organisms .\n31 investigated the potential bacteriostatic effect of hyaluronic acid in different concentrations and molecular weight on oral and non - oral microorganisms ( staphylococcus aureus , propionibacterium acnes , actinobacillus actinomycetemcomitans , pavotella oris and porphyromonas gingivalis ) with potential application in dentistry surgery ; the results showed that different hyaluronan solutions exerted varied bacteriostatic effects on all the bacterial strains .\nthe authors concluded that the clinical application of hyaluronan in form of membranes , gels , or sponges during surgical therapy may reduce bacterial contamination of the surgical wound , thereby lessening the risk of postsurgical infection and promoting more predictable regeneration .\nconcerning possible orthopaedic applications , in 2004 harris and richards 40 showed the visualization and quantification of s. aureus adhering to a variety of different treated / coated titanium surfaces . in their study ,\ncoating titanium with sodium hyaluronate significantly decreased the density of s. aureus adhering to the surfaces and its potential use in osteosynthesis , orthopaedics or dental applications was suggested out . in a very recent review on polysaccharide - based coatings , that have been proposed over the last ten years to impede biofilm formation on material surfaces exposed to bacterial contamination ,\nhyaluronic acid was discussed as one of the most studied , with demonstrated non - fouling properties on glass surfaces 41 ; displaying hydrophilic characteristics ( contact angle of 22 ) , this coating was in fact reported to reduce adhesion of s. epidermidis and e. coli by several orders of magnitude compared to the unmodified glass slide .\nsimilarly , adhesion of s. aureus on ti foils functionalized with hyaluronic acid - catechol was lower than on pristine substrates .\nbased on ha antiadhesive properties , a novel ha - based hydrogel has been recently proposed , in order to protect implanted biomaterials in orthopaedics , trauma and dental surgery from bacterial colonization 42 ; this fast - resorbable hydrogel coating , composed of covalently linked hyaluronan and poly - d , l - lactide (  defensive antibacterial coating  , dac , novagenit srl , mezzolombardo , italy ) , has been found to have a synergistic antibiofilm activity with various antibacterials and able to be effectively manually spread onto the surface of various biomaterials commonly used in orthopaedics , trauma and dental surgery 43 ( fig .\n1 ) . the ability to completely cover even sand - blasted titanium surface and resist scraping has in fact been confirmed by scanning electron microscopy ( sem ) analysis ( cf .\nthis is an important requirement in order to reduce the exposed surface of a biomaterial , thus creating a uniform coating of the surface and leaving no pores or cracks that could eventually be colonized by planktonic bacteria . in unpublished experiments ( novagenit srl , data on file ) , in order to evaluate dac ability to prevent bacterial adhesion , 200 mg of hydrogel were homogenously spread on the surface of sterile titanium discs .\nhydrogel - coated substrates and uncoated substrates ( controls ) were then placed into sterile 6-wells polystyrene plates and overlaid with a standardized inoculum ( 10 cfu / ml ) of bacterial cells for 15 , 30 , 60 and 120 minutes .\nthe remaining adhered cells were detached by adding a solution of 0.1% w / v dithiothreitol ( dtt ) ( sigma - aldrich , milan , italy ) to each well and stirring for 15 minutes at room temperature .\nthen , 100 l of each sample were plated onto tryptic soy agar ( tsa ; merck , darmstadt , germany ) and incubated at 37c for 24 hours for cfu counts .\nthe results showed that the adhesion density of s. aureus on titanium discs pre - treated with dac , was significantly lower than adhesion on untreated controls at each time point ( fig .\n2 ) . in particular , reductions of adhered bacteria equal to 86.8% , 80.4% ,\n74.6% and 66.7% vs untreated discs were observed after 15 , 30 , 60 and 120 minutes of incubation , respectively , while an increase of adhesion density during time was observed for both control and pre - treated discs ( fig .\nfurther analyses were conducted to show the ability to dislodge previously adhered bacteria ; to this aim , titanium discs were placed into sterile 6-wells polystyrene plates and overlaid with a standardized inoculum ( 10 cfu / ml ) of bacterial cells in order to allow the adhesion of bacterial cells .\nafterwards , 200 mg of hydrogel were spread on the surface of contaminated titanium discs in order to remove previously adhered bacteria .\nnon - adherent bacteria were removed by rinsing with sterile saline , while the remaining adhered cells were detached by adding 0.1% dtt as previously described .\nthen , 100 l of each sample were plated onto tsa and incubated at 37c for 24 hours for cfu counts .\nthe results showed that dac hydrogel treatment of discs reduced the amount of adhered bacteria in respect to control discs after 15 , 30 , 60 and 120 minutes of 84.0% , 72.8% , 72.3% and 64.3% , respectively ( fig.4 ) .\nonce again , an increase of adhesion density during time was observed for both control and treated discs ( fig .\ndac hydrogel showed similar or superior in vitro activity , compared to various antibacterials and a synergistic activity when used in combination ( fig .\nwere grown on chrome - cobalt devices in 6-wells polystyrene plates containing tsb for 24 hours at 37c .\nthen , growth medium was removed together with non - adherent bacteria and new broth added .\nthe plates were incubated at 37c in ambient air , until a visible biofilm was obtained .\ngentamycin and vancomycin were tested at a final concentration of 20 mg / ml . similarly , when mixed with the hydrogel , 60 mg of gel powder were reconstituted with 1 ml of water for injections containing gentamicin or vancomycin at 20 mg / ml concentration .\namount of biofilm at each time was determined before hydrogel and antibiotic agents addition and after 0.5 , 1 , 2 , 4 , 6 , 24 and 48 hours of incubation by a spectrophotometric assay .\nin particular , at each time , broth was removed and biofilm stained with crystal violet .\nafter elution of the stain from implants with absolute ethanol , the amount of biofilm was quantified by reading optical density ( o.d . ) at a wavelength of 595 nm against blank ( consisting of ethanol ) .\namount of biofilm at each time was compared with that formed on the same type of implant before treatment .\neach assay was performed in duplicate and repeated for three times . at each time point , both for gentamycin and vancomycin showed only a partial inhibition of biofilm formation ( ca .\n40 - 50% for vancomycin ) , with minor difference between the two studied microorganisms . on the other side ,\n50% in comparison to the untreated controls , while a combination of the hydrogel with either antibacterial resulted in a larger reduction of biofilm formation ( approximately 75 to 80% in comparison with untreated controls ) .\nboth these experimental studies show the ability of the dac hydrogel to significantly reduce bacterial adhesion and biofilm formation of common bacterial pathogens , thus potentially providing an effective protection of the implant ; however , these data also point out how , in the clinical setting , in the absence of an adequate immune response from the host and/or of sufficient local levels of antibiotics , a passive antiadhesive coating 18 like ha can be overcome by the remaining bacteria in a time - dependent manner .\nfor this reason , any passive antiadhesive coating of implants 44 should probably better be seen as a tool to reduce and delay bacterial adhesion and biofilm formation to a variable degree , also depending on the local environment , the contaminating bacterial species and initial bacterial load ; this may still provide an additional advantage to the host 's cells to first colonize the implanted biomaterial and win the competition with the microorganisms that may eventually be present , thus contributing to reduce the occurrence of implant - related infections .\nseveral clinical local applications of ha to reduce the impact of biofilm - related infections have been reported , in different clinical settings , with favourable results and no adverse events .\n45 recently described topical administration of hyaluronic acid in children with recurrent or chronic middle ear inflammations and chronic adenoiditis . in this prospective , single - blind , randomised controlled study , otoscopy , tympanometry and pure - tone audiometry in children which received the daily topical administration of normal 0.9% sodium chloride saline solution ( control group ) or 9 mg of sodium hyaluronate in 3 ml of a 0.9% sodium saline solution was performed .\nthe final analysis was based on 116 children ( 49.1% boys ; mean age , 62.9  17.9 months ) : 58 in the control group and 58 in the study group . at the end of follow - up ,\nthe prevalence of patients with impaired otoscopy was significantly lower in the study group ( p value = 0.024 ) compared to baseline but not in the control group . in comparison with baseline ,\nthe prevalence of patients with impaired tympanometry at the end of the follow - up period was significantly lower in the study group ( p value = 0.047 ) but not in the control group .\nthe reduction in the prevalence of patients with conductive hearing loss ( chl ) ( p value = 0.008 ) and those with moderate chl ( p value = 0.048 ) was significant in the study group , but not in the control group .\nthe mean auditory threshold had also significantly improved by the end of treatment in the study group ( p value = 0.004 ) but not in the control group .\nseveral studies have also reported the beneficial effect of topical ha in chronic urinary tract infections ( uti ) .\nin contrast to traditional antibiotic therapy , which aims at eradicating pathogens , treatment with ha targets bacterial adherence to the bladder mucosa with the presumption that a damaged glycosaminoglycan mucous layer facilitates bacterial adherence and therefore recurrent uti 46 . among others 47 , 48 ,\nlipovac and colleagues evaluated the efficacy of nine ha bladder instillations over 6 months in 20 women with a history of recurrent uti .\ntheir status was assessed prospectively but compared with a retrospective review of patients ' charts .\nthe number of infections per year per patient was significantly reduced ( from 4.990.92 to 0.560.82 , p>0.001 ) and the mean time to recurrence ( from 76.724.6 to 178.325.5 days , p>0.001 ) was prolonged significantly .\nnevertheless 65% of treated patients were free of recurrences until the end of study ( 47.6 weeks ) 49 .\nwere able to provide a higher level of evidence by reporting a prospective , randomized , double - blind , placebo - controlled study , in which a significant reduction of 77% ( p<0.0002 ) in the uti rate per patient per year versus placebo was observed at the end of the study .\nmoreover , mean time to uti recurrence was significantly prolonged ( 185.278.7 versus 52.733.4 days , p<0.001 ) after treatment compared with placebo .\noverall urinary symptoms and quality of life measured by questionnaires significantly improved compared with placebo 50 .\nvery recently a multicentre european study confirmed the efficacy of intravesical administration of combined hyaluronic acid and chondroitin sulphate ( cs ) for the treatment of female recurrent urinary tract infections 51 .\na total of 276 adult women received intravesical administration of ha+cs or standard of care ( antimicrobial/ immunoactive prophylaxis/ probiotics / cranberry ) . at follow - up ,\n181 patients treated with ha+cs and 95 patients treated with standard of care from 7 centres were available .\nthe crude and adjusted ors ( 95% ci ) for bacteriologically confirmed recurrence within 12 months were 0.77 ( 0.46 to 1.28 ) and 0.51 ( 0.27 to 0.96 ) , respectively .\nstudies were also undertaken to determine the effect on clinical variables , sub - gingival bacteria and local immune response brought about by application of hyaluronan - containing gels in early wound healing after scaling and root planing ( srp ) in dentistry 52 , 53 . in the study reported from eick et al .\nthe exclusion criteria were : antibiotics intake in the 6 months before the study , periodontal treatment received during the previous year , pregnancy , nursing , smoking , chronic diseases such as diabetes mellitus or rheumatoid arthritis , and allergy to ingredients in the drug . in the test group ( n=17 ) , a 0.8% hyaluronan - containing gels ( ha ) was introduced into all periodontal pockets during srp and a 0.2% ha gel was applied by the patients onto the gingival margin twice daily during the following 2 weeks while the control group ( n=17 ) was treated with srp only ; no placebo was used . probing depth ( pd ) and clinical attachment level ( cal )\nwere recorded at baseline and after 3 and 6 months , and subgingival plaque and sulcus fluid samples were taken for microbiologic and biochemical analysis . in both groups , pd and cal\nthe changes in pd and the reduction of the number of pockets with pd5 mm were significantly higher in the test group after 3 ( p=0.014 and 0.021 ) and 6 ( p=0.046 and 0.045 ) months .\nsix months after srp , the counts of treponema denticola were significantly reduced in both groups ( both p=0.043 ) , as were those of campylobacter rectus in the test group only ( p=0.028 ) .\nalthough to date no surface modification has been reported to be able to fully prevent bacterial adhesion and biofilm formation 55 , available data show that hyaluronic acid has a proven in vitro antiadhesive / antibiofilm effect against some of the most common pathogens and it has been used safely , alone or in combination with other polymers , with satisfactory results in different conditions associated with biofilm - related chronic infections .\nclinical data in various applications , including dentistry , urology , wound management , dermatology and orthopedics , allow to consider the potential use of ha as a protective coating barrier of implants particularly safe and feasible on a large scale basis .\nwhile antibacterial coatings to mitigate the occurrence of implant- and biofilm - related infections are regarded as one of the most needed technology , currently only few and insufficient options are available for clinical use in orthopedics and trauma surgery 18 .\nconsidering the pathogenesis of implant - related infections , any protection offered by a fully biocompatible antiadhesive barrier , like ha and some of its derivatives , could be extremely useful to reduce the tremendous burden of implant - related infections .\non the other hand , it should be noted that hyaluronic acid as a passive protective barrier has some limits . among others ,\nthe antiadhesive / antibiofilm effect is limited and may vary , depending on the type of the microorganism , the bacterial load , the local environment , etc .\n; moreover , ha protection may be neutralized by the possible ability of some bacteria to produce hyaluronidase , an enzyme that catalyzes the degradation of hyaluronic acid 56 , while collagen and hyaluronan may even become possible ligands for microbial attachment in particular situations 57 , 58 .\nto overcome at least some of these limits , possible loading of hyaluronic - based hydrogels with antibiotics is technically feasible and has been proposed by different authors 59 - 62 , being a possible option for future developments and large scale clinical applications , provided that regulatory requirements can be met ."}
{"lay_summary": " \n background and objective . \n antimicrobial resistance is now a major challenge to clinicians for treating patients . \n hence , this short term study was undertaken to detect the incidence of multidrug - resistant ( mdr ) , extensively drug - resistant ( xdr ) , and pandrug - resistant ( pdr ) bacterial isolates in a tertiary care hospital . \n material and methods . \n the clinical samples were cultured and bacterial strains were identified in the department of microbiology . \n the antibiotic susceptibility profile of different bacterial isolates was studied to detect mdr , xdr , and pdr bacteria . \n results . the antibiotic susceptibility profile of 1060 bacterial strains was studied . \n 393 ( 37.1% ) bacterial strains were mdr , 146 ( 13.8% ) strains were xdr , and no pdr was isolated . \n all ( 100% ) gram negative bacterial strains were sensitive to colistin whereas all ( 100% ) gram positive bacterial strains were sensitive to vancomycin . \n conclusion . \n close monitoring of mdr , xdr , or even pdr must be done by all clinical microbiology laboratories to implement effective measures to reduce the menace of antimicrobial resistance . ", "article": "in 2011 , who declared  combat drug resistance : no action today , no cure tomorrow .  . in recent years\npresently , antimicrobial resistance ( amr ) poses a major threat to patient 's treatment as it leads to increased morbidity and mortality , increased hospital stay , and severe economic loss to the patient and nation [ 3 , 4 ] .\nthe clinical isolates such as pseudomonas aeruginosa , methicillin resistant staphylococcus aureus ( mrsa ) , enterococci especially vancomycin resistant enterococci ( vre ) , and members of family enterobacteriaceae , for example , klebsiella pneumoniae , e. coli , and proteus sp .\n in the last two decades , there were so much increase of infectious diseases that the standard of public health in many parts of the world is equivalent to preantibiotic era .\nas per standardized international terminology created by european centre for disease control ( ecdc ) and centre for disease control & prevention ( cdc ) , atlanta , the multidrug - resistant ( mdr ) , extensively drug - resistant ( xdr ) , and pandrug - resistant ( pdr ) bacteria have been well defined .\nmultidrug resistant ( mdr ) was defined as acquired nonsusceptibility to at least one agent in three or more antimicrobial categories . extensively drug\nresistant ( xdr ) was defined as nonsusceptibility to at least one agent in all but two or fewer antimicrobial categories ( i.e. , bacterial isolates remain susceptible to only one or two antimicrobial categories ) .\npandrug resistant ( pdr ) was defined as nonsusceptibility to all agents in all antimicrobial categories .\nhence , this short term study was undertaken to detect the incidence of mdr , xdr , and pdr bacterial isolates in a tertiary care hospital of central india .\nthis short term cross - sectional study was conducted in the department of microbiology from 15th of april to 15th of july , 2014 .\nthe bacterial strains were isolated from different clinical samples and were identified by conventional methods .\nthe clinical specimens from indoor patient departments ( ipd ) only were included in the study .\nantibiotic susceptibility test of bacterial strains was done by kirby bauer disc diffusion method   as per clinical laboratory standard institute ( clsi ) guidelines .\nantibiotics used for gram positive cocci ( gpc ) were penicillin , erythromycin , ciprofloxacin , tetracycline , amikacin , vancomycin , and linezolid and for gram negative bacilli ( gnb ) were amikacin , ceftazidime , ceftazidime - clavulanic acid , ciprofloxacin , imipenem , and colistin , respectively .\nlinezolid and colistin were used as supplemental drugs . for urine sample , instead of ciprofloxacin and tetracycline ,\nfor routine quality control of antibiotic susceptibility test , s. aureus atcc 25923 , e. coli atcc 25922 , and pseudomonas aeruginosa atcc 27853 were used .\nmdr , xdr , and pdr strains were detected as per criteria described by ecdc and cdc .\nmethicillin resistant staphylococcus aureus ( mrsa ) strains were detected by meca - mediated oxacillin resistance using cefoxitin disk ( 30  g ) on mueller hinton ( mh ) agar plate inoculated with test strains as per standard disk diffusion recommendations and incubated at 3335c for 1618 hours .\ninhibition zone 21  mm with cefoxitin disk was interpreted as meca positive according to clsi guidelines .\nextended spectrum -lactamases ( esbl ) producing strains were detected by combined disk method using ceftazidime ( 30  g ) and ceftazidime plus clavulanic acid ( 30  g plus 10  g ) .\nan increase in diameter of 5  mm with ceftazidime plus clavulanic acid as compared to ceftazidime disk alone was considered positive for esbl detection .\n138 clinical samples were received from intensive care unit ( icu ) and 742 clinical samples were received from wards of different clinical specialities .\n698 clinical samples had single bacterial growth and 182 had mixed bacterial growth . out of these 182 clinical samples , 172 samples had 2 bacterial isolates , 4 samples had 3 bacterial isolates , and 6 samples had 1 bacterial isolate along with candida albicans .\nfigure 1 shows that 314 ( 29.6% ) bacterial strains were gram positive cocci ( gpc ) and 746 ( 70.4% ) were gram negative bacilli ( gnb ) .\nout of 314 gpc , 252 ( 80.3% ) were coagulase positive staphylococci . amongst 746 gnb , 261 ( 35% ) were e. coli , followed by pseudomonas aeruginosa 212 ( 28.4% ) . during the study period ,\nfigure 2 shows the incidence of mdr and xdr strains isolated . out of total 1060 bacterial strains\nstudied , 393 ( 37.1% ) bacterial strains were mdr and 146 ( 13.8% ) strains were xdr .\namongst 314 gpc strains isolated , 143 ( 45.5% ) and 56 ( 17.8% ) were mdr and xdr , respectively .\nout of 746 gnb isolates , 250 ( 33.5% ) strains were mdr and 90 ( 12.1% ) were xdr .\nout of total 9304 patients admitted , 393 ( 4.2% ) and 146 ( 1.6% ) were positive for mdr and xdr strains , respectively . \n\nfigure 3 shows the incidence of mdr and xdr gram positive cocci isolated . out of total 252 coagulase positive staphylococci\nisolated , 125 ( 49.6% ) were mdr and 38 ( 15.1% ) were xdr .\n10 coagulase negative staphylococci were isolated and 5 ( 50% ) were mdr , whereas 2 ( 20% ) were xdr .\n79 ( 31.3% ) coagulase positive staphylococci strains were mrsa and 2 ( 20% ) coagulase negative staphylococci were mrcons . out of total 45 enterococci isolated , 13 ( 28.9% ) were mdr and 16 ( 35.6% ) were xdr .\nno vancomycin intermediate staphylococcus aureus ( visa ) , vancomycin resistant staphylococcus aureus ( vrsa ) , or vancomycin resistant enterococci ( vre ) were isolated .\nall streptococcus species including group a , nongroup a , and pneumococcus were sensitive to penicillin .\nno mdr or xdr strain was isolated from streptococcus sp . all ( 100% ) gram positive cocci were sensitive to vancomycin and linezolid . \n\nfigure 4 shows incidence of mdr and xdr strains isolated from each species of gram negative bacilli . in the present study ,\ne. coli was the commonest isolate 261 ( 35% ) , followed by pseudomonas aeruginosa 212 ( 28.4% ) .\n79 ( 30.3% ) and 22 ( 8.4% ) e. coli strains were mdr and xdr , respectively .\nout of 200 klebsiella pneumoniae strains isolated , 75 ( 37.5% ) and 25 ( 12.5% ) were detected as mdr and xdr , respectively . out of 42 acinetobacter and other nonfermenter species isolated , 19 ( 45.2% ) and 8 ( 19% ) were mdr and xdr strains , respectively . amongst 250 gnb - mdr strains isolated ,\nthe commonest mdr strains were detected from e. coli 79/250 ( 31.6% ) , followed by klebsiella pneumoniae 75/250 ( 30% ) .\nsimilarly , out of 90 gnb - xdr strains isolated , the commonest xdr strains were detected from pseudomonas aeruginosa 29/90 ( 32.2% ) , followed by klebsiella pneumoniae 25/90 ( 27.8% ) . in the present study , 137 ( 18.4% )\nothers include wards like dermatology , pulmonary medicine , orthopedics , and cardiovascular and thoracic surgery ( cvts ) .\nthe different icus include neonatal icu ( nicu ) , medicine icu ( micu ) , operation theatre icu ( ot icu ) , and paediatric icu ( picu ) .\nout of total 393 mdr strains detected , 127 ( 32.3% ) ( the highest number ) mdr strains were isolated from surgery wards followed by 72 ( 18.3% ) mdr strains from different icus .\namongst total 146 xdr strains isolated , 41 ( 28.1% ) ( the highest number ) were isolated from surgery wards also .\nout of 72 mdr strains detected from different icus , 29 ( 40.3% ) ( the highest number ) mdr strains were isolated from nicu , followed by 20 ( 27.8% ) and 18 ( 25% ) from ot icu , and only 5 ( 6.9% ) from picu . even in the total 26 xdr strains isolated from different icus , 10 ( 38.5% ) ( the highest number )\nthe percentage of mdr and xdr strains isolated from different icus was 72/138 ( 52.2% ) and 26/138 ( 18.8% ) , respectively , which were again much more than mdr and xdr strains isolated from wards 321/742 ( 43.3% ) and 120/742 ( 16.2% ) , respectively .\n275 patients were admitted to nicu , of whom 29 ( 10.5% ) were positive for mdr strains and 10 ( 3.6% ) were positive for xdr strains . out of total 1907\npatients admitted to surgery ward , 127 ( 6.7% ) were positive for mdr strains whereas 41 ( 2.1% ) were positive for xdr strains . in micu ,\n545 patients were admitted and 20 ( 3.7% ) were positive for mdr strains and 8 ( 1.5% ) were positive for xdr strains .\nthe clinical and financial burden to patients and health care providers for mdros is really challenging .\nbarbara soule , joint commission resources practice leader , infection prevention and control services , has told , \npatients who are infected with mdros often have an increased risk of prolonged illness and mortality .\nthe cost of care for these patients can be more than double as compared to those without mdro infection  . since the year 2000 , only 4 new classes of antibiotics have been approved by food and drug administration ( fda ) , us , for example , linezolid , streptogramins , daptomycin , and tigecycline .\nthe problem is that the bacteria are developing resistance at a much faster pace than the new drug development . regarding public health attention , mdros are described as superbugs having very limited treatment options . for some mdros\n, only 1 or 2 antibiotics can be effective with toxic side effects . in 2009 , boucher et al .\nhave reported eskape organisms as  bad bugs ,  where e stands for enterococcus faecium , s for staphylococcus aureus , k for klebsiella pneumoniae , a for acinetobacter baumannii , p for pseudomonas aeruginosa , and e for enterobacter species . in the year 2009 only\n, peterson has reported the escape group of organism , which was the same as the above list but k was replaced by c , that is , clostridium difficile , and the last e stands for enterobacteriaceae . in the present study , amongst 250 gnb - mdr strains isolated , the commonest mdr strains were detected from e. coli 79/250 ( 31.6% ) , followed by klebsiella pneumoniae 75/250 ( 30% ) .\nsimilarly , out of 90 gnb - xdr strains isolated , the commonest xdr strains were detected from pseudomonas aeruginosa 29/90 ( 32.2% ) , followed by klebsiella pneumoniae 25/90 ( 27.8% ) .\naly and balkhy reported that most prevalent mdro in their study was e. coli followed by klebsiella pneumoniae . in another study , carried out in a tertiary care hospital in riyadh\n, it has been reported that most frequent mdr pathogens were pseudomonas aeruginosa followed by e. coli .\nthe percentage of mdr e. coli strains was more than klebsiella pneumoniae and even pseudomonas aeruginosa in our study probably because a total number of e. coli strains isolated ( 261 ) were also higher .\nthe slightly increased incidence of drug resistant strains observed in our study may be because our hospital is a tertiary care center in a rural setup and patients from adjoining districts and even villages are admitted for treatment . before attending the hospital , most of the patients get different antibiotics from general practitioners or due to over - the - counter sell of antibiotics often in improper dose .\nthe limitation of this study is that this is a single center study for only three - month period in a tertiary care hospital in central india . to reflect the trend of infections caused by mdr and xdr strains of bacteria in the region , a multicenter study involving all types of healthcare setups for a minimum period of one year\nthere is paucity of data regarding mdros in health care setup not only in india but also worldwide .\nunless and until multidrug resistant organisms are detected and their incidence is known , the strategies for their control can not be adopted properly in healthcare setup . hence , detection , prevention of transmission of mdros by following infection control practices , antimicrobial surveillance , and stewardship are need of the hour .\nmisuse and overuse of antibiotics , over - the - counter selling of antibiotics without prescription to common people , must be stopped by strict implementations of rules and regulations .\nwe hereby conclude that early detection and close monitoring of mdr , xdr , or even pdr bacterial strains must be started by all clinical microbiology laboratories to reduce the menace of antimicrobial resistance which is now a global problem ."}
{"lay_summary": " ureterocele is a common ureteric anomaly detected in pediatric population . \n ureterocele diagnosis and evaluation need a variety of radiological methods . \n we report a case of 5-year - old female child sent for 99mtc - diethylene triamine pentaacetic acid scan for evaluation of glomerular filtration rate and excretory function of kidneys in view of right - sided hydroureteronephrosis and pyonephrosis with percutaneous tube in situ . \n incidental photopenia was noted in the urinary bladder . \n on ultrasonography of abdomen cause of this photopenia was found to be an intravesical ureterocele . ", "article": "ureterocele is a congenital urinary abnormality characterized by the presence of an intrabladder hernia or cystic ballooning of the lower end of a ureter lying between the mucosa and muscle of the bladder .\nthe abnormality leads to urinary retention and recurrent urinary tract infection ( uti ) , which can cause irreversible damage to the kidney .\nthis abnormality can be suspected in the fetus by antenatal ultrasonography ( usg ) and confirmed by other x - ray investigations after birth .\nthe incidence of ureterocele is variable with the highest rate of 1:500 and it is generally found in females with duplex system association ( 95% ) .\nureteroceles can have different clinical presentations , such as antenatal hydronephrosis , uti , vesicoureteral reflux ( vur ) , bladder outlet obstruction , prolapsed urethral mass , etc .\nusg and voiding cystourethrography ( vcug ) are essential initial procedures for a child suspected of having a ureteral anomaly .\na 5-year - old female child was referred to our department for tc - diethylene triamine pentaacetic acid ( dtpa ) scan .\nshe was a follow - up case of right - sided hydroureteronephrosis with pyonephrosis with percutaneous tube ( pcn ) insertion done on the right side .\npatient 's blood urea and serum creatinine were 29 and 1.3 mg / dl , respectively .\nusg of the abdomen revealed left - sided mild hydroureteronephrosis and gross enlargement of the right kidney , reaching up to lower abdomen with dilated pelvis and ureter .\nthe child was referred for evaluation of glomerular filtration rate and excretory function of kidneys .\ntc - dtpa scan was done in our department with right pcn tube in situ .\npcn tube was clamped during the acquisition of dynamic and prevoid static image and clamp released thereafter . on tc - dtpa scan , left kidney showed good perfusion and adequate cortical radiotracer concentration followed by good drainage into dilated ureter .\nright ureter and right pelvicalyceal system ( pcs ) were visualized in the postvoid image ( indirect evidence of vur ) [ figure 2b , thin arrow ] .\nretention of radiotracer was noted in dilated pcs and dilated ureter in delayed static images acquired till 4 h [ figure 2c and d ] .\nfaint visualization of radiotracer was noted through the pcn tube after removal of clamp [ figure 2b , bold arrow ] .\na large photopenia was noted in the suprapubic region in the urinary bladder ( ub ) during dynamic [ figure 1 ] as well as delayed static images acquired till 4 h [ figure 2a  d ] .\nan usg of the abdomen was done in the radiology department of our hospital to find out the cause of this persistent photopenia in the ub .\nusg of the abdomen showed evidence of left - sided mild hydroureteronephrosis and grossly enlarged hydronephrotic right kidney with dilated right ureter and an intracystic ureterocele arising from the right side [ figure 3a and b ] .\nperfusion and dynamic images of 99mtc - diethylene triamine pentaacetic acid scan scintigraphy , posterior view with percutaneous clamp in situ , showing good perfusion and adequate cortical function and good drainage of left kidney .\nphotopenia noted in the urinary bladder ( bold arrow ) ( a ) prevoid static image with right pcn clamp in situ .\nright ureter and right pelvicalyceal system visualization is noted suggesting indirect evidence of vesico - ureteric reflux ( thin arrow ) .\n( c and d ) 3 and 4 h delayed static images showing persistent photopenia in the urinary bladder ( arrow marked ) ( a and b ) ultrasonography images depicting right ureterocele within the urinary bladder ( ub ) and dilated distal right ureter\naccording to literature , 90% of the patients with ureterocele are diagnosed before the age of 3 years .\nmost of the patients with ureterocele are classically diagnosed during the investigation for uti , asymptomatic hydronephrosis , and abdominal mass .\nalthough the age of diagnosis is decreasing , uti is still the most common clinical presentation of ureterocele in 50% of the patients promoting physician to make the thorough evaluation of the urinary system .\nthe whole nephronourinary system could have already been negatively affected at the time of diagnosis . in our case ,\nusg is an easy method to perform , noninvasive , and probably the best imaging modality for making the diagnosis .\nreflux can occur in the ipsilateral lower pole in almost half of the patients , but the contralateral system is also affected at a rate of 25% . the tc - dimercapto succinic acid ( dmsa ) scan should be undertaken routinely to assess the distribution of function in the duplex kidney and for detecting and follow - up of scarred tissue and nonfunctioning upper poles in cases of ureterocele .\ndid a study on pediatric ureteroceles in 19 patients , on the diagnosis , management and treatment options .\nvcug was able to detect vur in 13 out of 17 patients ( 33% ) .\ndmsa scintigraphy showed ipsilateral renal scarring and nonfunctioning upper pole images in 7 out of 13 patients . computed tomography and mag3 scintigraphy\ndid a study on the management of 36 patients with varied presentation of complicated ureteroceles .\nusg , micturating cystourethrogram , isotope renogram were done preoperatively in all the babies . in one of the cases ,\ninitial usg was unable to detect ureterocele in most of the cases in this study .\nthey said that unless the usg is done in well - hydrated , cooperative patient , ureterocele is likely to be missed on usg .\nhence , an intravenous pyelogram , radioisotope renogram , and micturating cystourethrogram are invaluable in the complete understanding of ureterocele . in our patient also , the diagnosis of ureterocele was missed on initial usg .\nphotopenia was noted in the ub on our scan , and this prompted us to investigate the patient further .\npossible causes for photopenic defects in the ub on nuclear scintigraphic studies include bladder papilloma , bladder polyp , carcinoma bladder , bladder calculus , foreign body in ub , intravesical ureterocele , etc .\nrepeat usg revealed the cause of photopenia in ub in our case to be an intravesical ureterocele . on reviewing the literature we found that tc - dtpa scan is useful in the evaluation of renal function in patient with known ureteroceles .\nhowever , in our case on finding the photopenia in the ub on tc - dtpa scan , intravesical ureterocele was detected on usg ."}
{"lay_summary": " objectives : the aim of this study was to investigate the impact of asymptomatic vertebral fractures on the quality of life in older women as part of the sao paulo ageing & health study.methods:this study was a cross - sectional study with a random sample of 180 women 65 years of age or older with or without vertebral fractures . \n the quality of life questionnaire of the european foundation for osteoporosis was administered to all subjects . \n anthropometric data were obtained by physical examination , and the body mass index was calculated . \n lateral thoracic and lumbar spine x - ray scans were obtained to identify asymptomatic vertebral fractures using a semi - quantitative method.results:women with asymptomatic vertebral fractures had lower total scores [ 61.4(15.3 ) vs. 67.1(14.2 ) , p  =  0.03 ] and worse physical function domain scores [ 69.5(20.1 ) vs. 77.3(17.1 ) , p  =  0.02 ] for the quality of life questionnaire of the european foundation for osteoporosis compared with women without fractures . \n the total score of this questionnaire was also worse in women classified as obese than in women classified as overweight or normal . \n high physical activity was related to a better total score for this questionnaire ( p  =  0.01 ) . likewise , lower physical function scores were observed in women with higher body mass index values ( p<0.05 ) and lower physical activity levels ( p<0.05 ) . \n generalized linear models with gamma distributions and logarithmic link functions , adjusted for age , showed that lower total scores and physical function domain scores for the quality of life questionnaire of the european foundation for osteoporosis were related to a high body mass index , lower physical activity , and the presence of vertebral fractures ( p<0.05).conclusion : vertebral fractures are associated with decreased quality of life mainly physical functioning in older community - dwelling women regardless of age , body mass index , and physical activity . \n therefore , the results highlight the importance of preventing and controlling asymptomatic vertebral fractures to reduce their impact on quality of life among older women . ", "article": "health - related quality of life ( hrqol ) is a multidimensional concept that defines a person 's health based on specific aspects , such as physical , emotional , and social functioning and general welfare ( 1 ) .\nthe assessment of hrqol consists of an evaluation of the degree to which these aspects are decreased by symptoms , incapacities , and limitations caused by disease ( 2 ) .\nthe assessment of hrqol has been used as a measure complementary to bone mineral density to evaluate and monitor the burden of osteoporosis on a patient 's daily life ( 3 ) .\nthere are several instruments that can be used to assess the quality of life of individuals with osteoporosis , including the osteoporosis assessment questionnaire , the quality of life questionnaire for osteoporosis ( optqol ) , the osteoporosis quality of life questionnaire , and the questionnaire of the european foundation for osteoporosis ( qualeffo ) ( 4 - 7 ) .\nthe qualeffo , a specific tool used to evaluate subjects with vertebral fractures and that includes questions on pain , physical functioning , social functioning , general health perception and mental functioning , has been shown to be repeatable and consistent ( 7 - 8 ) .\nvertebral fractures are the most frequent osteoporotic fractures , occurring in at least 30% of the elderly population ( 9 ) , and have important clinical implications ( 10 - 14 ) .\nthese fractures are associated with increased risks of new osteoporotic fractures and mortality , especially in older women ( 10 - 11 ) .\nonly one - third of vertebral fractures are symptomatic ; therefore , patients may be unaware of their presence .\nindeed , in studies based on the radiographic screening of populations , the incidence of all vertebral fractures has been estimated to be three times higher than the incidence of hip fractures , and only 30% of people with vertebral fractures were found to have received medical attention ( 12 ) . women with vertebral fractures can also experience decreased hrqol due to physical limitations and psychosocial disabilities ( 13 - 14 ) .\nsome studies have assessed the impact of vertebral fractures on hrqol in older women in many countries ( 15,16 ) , but few such epidemiological studies have been conducted in brazil .\nmoreover , most of the studies conducted in this country have been performed in ambulatory or institutionalized individuals ( 17,18 ) .\ntherefore , this study evaluated the impact of vertebral fractures on the quality of life of healthy , community - dwelling women aged 65 years or older using the qualeffo .\nthis study was performed using the framework of the so paulo ageing & health study ( spah ) , which was a population - based , cross - sectional study ( 9 ) .\nthe inclusion and exclusion criteria were the same as those of the core study ( 9 ) .\nall of the individuals were apparently healthy and showed no evidence of malabsorption , chronic diarrhea , hepatic disease , severe chronic diseases , or cancer .\ncurrent or previous bisphosphonate use was also an exclusion criterion ( 9 ) . quality of life was assessed through individual interviews using the validated qualeffo with 41 questions covering five domains : pain ( 5 questions ) , physical functioning ( 17 questions ) , social functioning ( sevn questions ) , general health perception ( three questions ) , and mental functioning ( nine questions ) ( 7 ) .\nthe total score for each domain was obtained by summing the scores of all questions for that domain and submitting this sum to a linear transformation to a scale ranging from 0 to 100 , where 0 corresponds to the worst hrqol and 100 to the best hrqol .\nradiographs of the lumbar and thoracic spine centered on l2 and t7 , respectively , were obtained for all participants , with 40 \" between the tube and the film .\nthe identification of vertebral fractures was performed by two individuals with experience in the field of analyzing vertebral fractures .\nthey were blinded to each other 's assessments , and when the results conflicted , a consensus between the two individuals was reached .\nthe agreement between the assessments of the two individuals was 96% , and the kappa coefficient was 0.82 .\neach identified fractured vertebra was assigned a grade based on the genant sq scale , where mild ( grade 1 ) corresponds to a 20 - 25% reduction in the anterior , middle , and/or posterior height ; moderate ( grade 2 ) corresponds to a 26 - 40% reduction in any height ; and severe ( grade 3 ) corresponds to a reduction of over 40% in any height .\nthe height ( without shoes ) of each participant was measured to the nearest 0.1 cm with a wall - mounted stadiometer .\nthe weight of each participant ( without shoes and wearing only light clothing ) was measured to the nearest 0.25 kg using a double - beam balance scale .\nthe body mass index ( bmi ) was calculated by dividing the participant 's weight ( kilograms ) by her height squared ( square meters ) , and the subjects were categorized using the following cutoff points proposed by the world health organization ( who ) : normal weight  =  bmi<25 ; overweight  =  25bmi<30 ; and obese  =  bmi30 ( 20 ) .\ninformation regarding health , lifestyle and risk factors for osteoporosis / fractures was obtained through individual interviews .\nwomen who had had two or more falls in the last 12 months were defined as chronic fallers ( 21 ) .\nphysical activity was classified as ( a ) low , does not even perform housework ; ( b ) moderate , performs regular housework , walks irregularly , and gardens ; and ( c ) high , performs regular physical activity aside from her daily routine at least twice a week for 30 min ( 22 ) .\nregarding concomitant diseases , those mentioned at the time of the interview were noted , as well as those diagnosed during the physical examination . systemic arterial hypertension ( sah ) was defined as a history of hypertension with the use of antihypertensive drugs or a systolic blood pressure>140 mmhg and/or diastolic blood pressure>90 mmhg , which was measured with a standard sphygmomanometer with the subject seated for at least 5 minutes prior to the measurement ( 23 ) .\nparticipants taking oral hypoglycemic agents or insulin or those with fasting blood glucose levels126 mg / dl were considered to be diabetic ( 24 ) .\nthe bmd was measured by dual x - ray absorptiometry ( dxa ) using hologic densitometry equipment ( hologic inc .\nbedford , ma , usa , discovery model ) in the following regions : lumbar spine , femoral neck , and total femur .\nanatomically abnormal vertebrae were excluded from the analysis of the lumbar spine only if they were clearly abnormal and were not assessable within the resolution of the system or if there was a difference in the t - score of more than 1.0 between the vertebra in question and adjacent vertebrae , as recommended by the international society for clinical densitometry ( iscd ) ( 25 ) .\nthe precision of the bmd measurements was determined based on standard iscd protocols ( 26 ) .\nwe calculated the least significant change with 95% confidence to be 0.033 g / cm for the spine , 0.047 g / cm for the femoral neck , and 0.039 g / cm for the total femur . according to the classification criteria of the iscd ( international society of clinical densitometry ) , the lowest t - score among the three sites ( lumbar spine , femoral neck , and total femur ) was used to classify each participant as having osteoporosis , osteopenia , or normal bone density .\nthus , the individuals with t - scores that were 2.5 standard deviations or more below the scores for healthy controls for the peak bone mass were diagnosed with osteoporosis , individuals with t - scores between 2.5 and 1.0 standard deviations below the scores for healthy controls were diagnosed with osteopenia , and individuals with t - scores greater than 1.0 standard deviation below the scores for healthy controls were classified as normal ( 26 ) .\nthe sample size of 180 was based on a standard deviation of 15% ( 27 ) for the total qualeffo score and a two - sided 5% significance level .\nthe study had 95% power to detect a difference of 10 points in the total qualeffo score .\nthe results for the quantitative variables are expressed as the mean ( standard deviation ) , and results for the qualitative variables are described by the absolute and relative ( % ) frequencies .\ndemographic characteristics and the qualeffo results were compared between women with and without fractures using the mann - whitney - wilcoxon test for quantitative variables and the chi - square test for qualitative variables .\nthe associations between the qualeffo scores and potential determinants of quality of life were assessed using the wilcoxon rank - sum test or the kruskal - wallis test .\ncorrelations between continuous variables and the qualeffo questionnaire data were tested using the spearman correlation coefficient ( rs ) .\ngeneralized linear models with gamma distributions and logarithmic link functions were performed to determine the influence of the vertebral fractures on the qualeffo score .\nvariables with a statistical significance better than 0.1 ( p<0.1 ) in the bivariate tests were included in these models , and statistically significant variables ( p<0.05 ) were retained in the final model .\nthis study was conducted in compliance with the ethical principles of the helsinki declaration ( 2008 ) and local applicable laws and regulations .\nthis study was approved by the local ethics and research committee ( research protocol 1110/07 ) .\nthis study was performed using the framework of the so paulo ageing & health study ( spah ) , which was a population - based , cross - sectional study ( 9 ) .\nthe inclusion and exclusion criteria were the same as those of the core study ( 9 ) .\nall of the individuals were apparently healthy and showed no evidence of malabsorption , chronic diarrhea , hepatic disease , severe chronic diseases , or cancer .\nquality of life was assessed through individual interviews using the validated qualeffo with 41 questions covering five domains : pain ( 5 questions ) , physical functioning ( 17 questions ) , social functioning ( sevn questions ) , general health perception ( three questions ) , and mental functioning ( nine questions ) ( 7 ) .\nthe total score for each domain was obtained by summing the scores of all questions for that domain and submitting this sum to a linear transformation to a scale ranging from 0 to 100 , where 0 corresponds to the worst hrqol and 100 to the best hrqol .\nradiographs of the lumbar and thoracic spine centered on l2 and t7 , respectively , were obtained for all participants , with 40 \" between the tube and the film .\nthe identification of vertebral fractures was performed by two individuals with experience in the field of analyzing vertebral fractures .\nthey were blinded to each other 's assessments , and when the results conflicted , a consensus between the two individuals was reached .\nthe agreement between the assessments of the two individuals was 96% , and the kappa coefficient was 0.82 .\neach identified fractured vertebra was assigned a grade based on the genant sq scale , where mild ( grade 1 ) corresponds to a 20 - 25% reduction in the anterior , middle , and/or posterior height ; moderate ( grade 2 ) corresponds to a 26 - 40% reduction in any height ; and severe ( grade 3 ) corresponds to a reduction of over 40% in any height .\nthe height ( without shoes ) of each participant was measured to the nearest 0.1 cm with a wall - mounted stadiometer .\nthe weight of each participant ( without shoes and wearing only light clothing ) was measured to the nearest 0.25 kg using a double - beam balance scale .\nthe body mass index ( bmi ) was calculated by dividing the participant 's weight ( kilograms ) by her height squared ( square meters ) , and the subjects were categorized using the following cutoff points proposed by the world health organization ( who ) : normal weight  =  bmi<25 ; overweight  =  25bmi<30 ; and obese  =  bmi30 ( 20 ) .\ninformation regarding health , lifestyle and risk factors for osteoporosis / fractures was obtained through individual interviews .\nwomen who had had two or more falls in the last 12 months were defined as chronic fallers ( 21 ) .\nphysical activity was classified as ( a ) low , does not even perform housework ; ( b ) moderate , performs regular housework , walks irregularly , and gardens ; and ( c ) high , performs regular physical activity aside from her daily routine at least twice a week for 30 min ( 22 ) . regarding concomitant diseases ,\nthose mentioned at the time of the interview were noted , as well as those diagnosed during the physical examination .\nsystemic arterial hypertension ( sah ) was defined as a history of hypertension with the use of antihypertensive drugs or a systolic blood pressure>140 mmhg and/or diastolic blood pressure>90 mmhg , which was measured with a standard sphygmomanometer with the subject seated for at least 5 minutes prior to the measurement ( 23 ) .\nparticipants taking oral hypoglycemic agents or insulin or those with fasting blood glucose levels126 mg / dl were considered to be diabetic ( 24 ) .\nthe bmd was measured by dual x - ray absorptiometry ( dxa ) using hologic densitometry equipment ( hologic inc .\nbedford , ma , usa , discovery model ) in the following regions : lumbar spine , femoral neck , and total femur .\nanatomically abnormal vertebrae were excluded from the analysis of the lumbar spine only if they were clearly abnormal and were not assessable within the resolution of the system or if there was a difference in the t - score of more than 1.0 between the vertebra in question and adjacent vertebrae , as recommended by the international society for clinical densitometry ( iscd ) ( 25 ) .\nthe precision of the bmd measurements was determined based on standard iscd protocols ( 26 ) .\nwe calculated the least significant change with 95% confidence to be 0.033 g / cm for the spine , 0.047 g / cm for the femoral neck , and 0.039 g / cm for the total femur . according to the classification criteria of the iscd ( international society of clinical densitometry ) , the lowest t - score among the three sites ( lumbar spine , femoral neck , and total femur ) was used to classify each participant as having osteoporosis , osteopenia , or normal bone density .\nthus , the individuals with t - scores that were 2.5 standard deviations or more below the scores for healthy controls for the peak bone mass were diagnosed with osteoporosis , individuals with t - scores between 2.5 and 1.0 standard deviations below the scores for healthy controls were diagnosed with osteopenia , and individuals with t - scores greater than 1.0 standard deviation below the scores for healthy controls were classified as normal ( 26 ) .\nthe sample size of 180 was based on a standard deviation of 15% ( 27 ) for the total qualeffo score and a two - sided 5% significance level .\nthe study had 95% power to detect a difference of 10 points in the total qualeffo score .\nthe results for the quantitative variables are expressed as the mean ( standard deviation ) , and results for the qualitative variables are described by the absolute and relative ( % ) frequencies .\ndemographic characteristics and the qualeffo results were compared between women with and without fractures using the mann - whitney - wilcoxon test for quantitative variables and the chi - square test for qualitative variables .\nthe associations between the qualeffo scores and potential determinants of quality of life were assessed using the wilcoxon rank - sum test or the kruskal - wallis test .\ncorrelations between continuous variables and the qualeffo questionnaire data were tested using the spearman correlation coefficient ( rs ) .\ngeneralized linear models with gamma distributions and logarithmic link functions were performed to determine the influence of the vertebral fractures on the qualeffo score .\nvariables with a statistical significance better than 0.1 ( p<0.1 ) in the bivariate tests were included in these models , and statistically significant variables ( p<0.05 ) were retained in the final model .\nthis study was conducted in compliance with the ethical principles of the helsinki declaration ( 2008 ) and local applicable laws and regulations .\nthis study was approved by the local ethics and research committee ( research protocol 1110/07 ) .\nthe demographic , anthropometric and clinical data for all participants in the study , grouped based on the presence ( vertebral fracture ) or absence of vertebral fractures ( no vertebral fracture ) , are shown in table 1 .\nthere were no significant differences with respect to the mean bmi or the percentage of caucasian individuals between the groups ( p>0.05 ) ( table 1 ) .\nregarding the bmi classification , 22.8% and approximately 38% of the subjects were classified as normal and obese , respectively , with no significant difference between the two groups ( p>0.05 ) .\na tendency of older age in the vertebral fracture group was observed ( p  =  0.057 ) .\nthe frequencies of hypertension ( p  =  0.224 ) , diabetes ( p  =  0.672 ) , hypothyroidism ( p  =  0.723 ) , and two or more concomitant diseases ( p  =  0.216 ) and the average number of medications used ( p  =  0.497 ) were comparable between the groups .\ninterestingly , the vertebral fracture group contained a higher frequency of women defined as chronic fallers than the no vertebral fracture group ( 64.7 vs. 32.1% , p  =  0.017 ) .\nas expected , the vertebral fracture group had a higher frequency of osteoporosis ( 73.2 vs. 51.1% , p  =  0.012 ) and a lower frequency of osteopenia ( 19.5 vs. 38.1% , p  =  0.027 ) than the no vertebral fracture group .\nthe results for each domain of the qualeffo and the total qualeffo score in both groups are shown in table 2 .\nthe total qualeffo score was lower in the vertebral fracture group than in the no vertebral fracture group [ 61.4 ( 15.4 ) vs. 67.1 ( 14.2 ) , p  =  0.031 ] .\nlikewise , the physical function domain score of the qualeffo was worse in the vertebral fracture group compared with the no vertebral fracture group [ 69.5 ( 20.1 ) vs. 77.3 ( 17.1 ) , p  =  0.018 ] .\nno difference was observed regarding the other qualeffo domains ( pain , social functioning , health perception , and mental functioning ) ( table 2 ) .\nthe total qualeffo score was inversely related to bmi ( rs  =  -0.21 ,\np  =  0.005 ) and weight ( rs  =  -0.22 , p  =  0.009 ) .\nthe total qualeffo score was worse in women classified as obese than in those classified as overweight or normal [ 61.7 ( 15.4 ) vs. 66.4 ( 13.8 ) vs. 70.8 ( 13.5 ) , respectively , p  =  0.008 ] .\na lower total qualeffo score was also observed in women with low physical activity than in those with moderate or high activity [ 51.8 ( 19.1 ) vs. 64.8 ( 14.3 ) vs. 70.3 ( 13.2 ) , respectively , p  =  0.010 ] ( table 3 ) .\nsimilarly , the physical function domain of the qualeffo was inversely related to the bmi ( rs  =  -0.24 , p  =  0.001 ) . in this domain , women classified as obese were found to have lower scores than women classified as overweight or normal [ 70.7 ( 19.3 ) vs. 76.1 ( 16.1 ) vs. 81.4 ( 17.4 ) , respectively , p  =  0.002 ] . finally , lower scores for the physical function domain were found among women with low physical activity compared with those with moderate or high activity [ 49.6(24.9 ) vs. 75.1(18.1 ) vs. 80.7(12.6 ) , respectively , p  =  0.002 ] ( table 3 ) . a generalized linear model with gamma distributions and logarithmic link functions was developed to identify patient characteristics that were related to the total and physical function domain scores of the qualeffo .\nvariables with a p<0.10 in the univariate analysis ( age , bmi classification , physical activity , diabetes , presence of at least one fracture ) were included as independent variables .\nthe presence of obesity was negatively associated with the total qualeffo score ( p  =  0.001 ) .\na high physical activity level was positively associated with the total qualeffo score ( p  =  0.001 ) .\nthe presence of at least one fracture was associated with a worse total qualeffo score , independent of age , bmi classification and physical activity level ( p  =  0.030 ) .\nlikewise , the presence of at least one fracture was negatively associated with the physical function domain , independent of these same variables ( p  =  0.041 ) ( table 4 ) .\nthis study was the first study conducted in brazil that specifically assessed the impact of vertebral fractures on the quality of life in older , community - dwelling women using a specific questionnaire . in this study\n, we demonstrated that the presence of vertebral fractures in this population is related to worse hrqol , particularly with respect to physical functioning .\nthe major advantage of the present study is the homogenous selection of community - dwelling women , unlike previous studies in which individuals were recruited from clinics or from populations included in clinical trials .\nstudies showing worse hrqol in patients with vertebral fractures have been published in several countries ( 15,16 ) .\nthere are only two studies evaluating the hrqol in patients with vertebral fractures in brazil , but neither was specific to older community - dwelling individuals ( 17,18 ) .\nthe first of these two other studies was performed in 55 outpatient women divided into three groups : 1- women without osteoporosis , 2- women without osteoporosis and no vertebral fractures , 3- women with osteoporosis and vertebral fractures . in that study ,\nthe quality of life was assessed with the sf-36 , and no difference was found among the three groups .\none of the reasons for this finding was the inclusion of only women who were able to perform the spirometric tests , resulting in the exclusion of women in worse conditions who would most likely belong to the fracture group ( 17 ) .\nlater , de oliveira et al . evaluated the quality of life in ambulatory women with osteoporosis and found similar results for those who had vertebral fractures and those who did not .\nhowever , that study was not designed to assess the impact of vertebral fractures on quality of life , and the number of women with fractures was too small to enable an accurate assessment ( 18 ) .\nthe assessment of quality of life in relation to the qualeffo pain domain was similar in women with and without vertebral fractures in our study .\nsome studies have found that the pain domain is worse in women with fractures ; however , the patients included in those studies were recruited based on clinical symptoms related to fractures and were compared with those without back pain ( 28 ) .\nvertebral fractures do not always manifest with symptoms and are often diagnosed based on radiographs taken for other reasons .\nevaluated the chest radiographs of older women who had been hospitalized for several causes , and they found that only a few of the vertebral fractures present had been previously identified by clinicians ( 29 ) .\nindeed , in our previous study performed in brazil , 29.4% subjects had vertebral fractures , and none of these patients had prior knowledge of their vertebral fractures ( 9 ) .\nas observed in other studies , the mental function , social function , and health perception domains were not significantly different between women with and without fractures ( 30 ) .\nthe relatively small differences between the groups with and without fractures may be the result of the acceptance of poor health conditions due to the natural expectation of physical decline in older women ( 13 ) . in our study\n, we found that obesity and low physical activity were associated with lower quality of life .\nother authors have reported that higher bmi and a sedentary lifestyle are factors that influence the quality of life in patients with osteoporosis ( 18,31 - 32 ) .\nit is important to highlight the fact that both obesity and a sedentary lifestyle are preventable factors and can be controlled by a change in lifestyle .\nsome authors observed that physical exercise is associated with a better quality of life ( 33 ) and have demonstrated that a home exercise program for women with vertebral fractures ( 60 min / d , 3x / week for 12 months ) significantly improves the hrqol ( 34 ) . a study performed at our institution in osteoporosis patients showed that an exercise program improved the quality of life in these women ( 35 ) .\ntherefore , our data reinforce the need for all older women to be advised about the benefits of exercise .\nthese women should be encouraged to exercise regularly to reduce their bmi and improve their general welfare .\nour study is the first in brazil to conduct a thorough assessment of the relationship between quality of life and vertebral fractures .\nan important characteristic of this study was the use of standardized and reliable instruments for both the vertebral fracture assessment ( genant semi - quantitative method ) and the hrqol assessment ( qualeffo ) .\nalthough the qualeffo has not been validated in brazil , which is a limitation of the present study , this tool is the most frequently used for assessing quality of life in osteoporosis and was recommended for the investigation of vertebral fracture subjects in multicentric studies that included centers in brazil ( 36 ) .\nthis questionnaire is more sensitive in detecting differences between groups , and it provides a better discrimination between individuals with and without vertebral fractures compared with generic hrqol instruments , such as the sf-36 , particularly with respect to physical functioning , which is significantly affected in these patients ( 8) . in conclusion , this study demonstrated the negative impact of vertebral fractures on the quality of life in older women , independent of other factors such as bmi and physical activity .\nalthough the clinical relevance of vertebral fractures is well established , these results are important for assessing the burden of this disease and reinforce the need to reduce the underdiagnosis and undertreatment of these fractures . the results of this study also highlight the need for awareness of the importance of maintaining proper weight and promoting changes in lifestyle through physical activity and dietary control .\nthis study was supported by fundao de amparo e pesquisa do estado de so paulo ( fapesp ) # 03/09313 - 0 ; conselho nacional de cincia e tecnologia ( cnpq ) # 305691/2006 - 6 ( rmrp ) and # 119601/2009 - 5 ( lf ) ; federico foundation grants ( rmrp ) ; and coordenao de aperfeioamento de pessoal de nvel superior ( capes ) ( jbl , cpf ) ."}
{"lay_summary": " \n aims . our aim is to compare the adequacy and diagnostic yield of samples obtained by the endometrial explora sampler i - mx120 with endometrial specimens obtained by conventional dilatation and curettage ( d&c ) \n . methods . a total of 1270 endometrial samples \n were received in the histopathology laboratories at the king khalid university hospital , riyadh , saudi arabia , between 2007 and 2010 . in the outpatient clinic , \n the uterine explora model i was used to obtain 996 samples . \n the remaining 274 samples were obtained by conventional d&c . \n sample adequacy and the clustering of inadequate specimens according to age groups by the two different techniques were compared and statistically analyzed . results . out of 1270 endometrial samples , 253 ( 19.9% ) were inadequate . \n the uterine explora was used in 88.5% of these inadequate samples ( 253 samples ) , and the remaining 11.5% were obtained by d&c . \n the insufficient tissue incidence was higher with the explora ( 17.6% ) than with the d&c ( 2.2% ) and the difference was statistically significant ( p < 0.0001 ) . \n the ages of the patients , as well as the clinical indications for the procedures , were recorded . conclusion . \n this retrospective study demonstrated better specimen adequacy when d&c was used compared to the higher rate of sample insufficiency obtained with the explora . ", "article": "the majority of women with menorrhagia , postcoital bleeding , intermenstrual bleeding , or postmenopausal bleeding ultimately undergo diagnostic hysteroscopy with endometrial sampling as part of their assessment , particularly if symptoms persist or pelvic imaging suggests a uterine abnormality .\ndilatation and curettage ( d&c ) has been widely considered to be the method of choice for obtaining endometrial samples for histopathological evaluation\n. however , the needs for admission and general anesthesia and their associated costs have made this option less favorable . in the outpatient setting , endometrial sampling is an effective and acceptable method for obtaining endometrial samples for histopathological assessment [ 3 , 4 ] .\ninadequate sampling is more problematic in postmenopausal women , for whom up to 68% of endometrial samples are reported to be inadequate . in our institution , the only sampling tool available to perform the outpatient sampling procedure is the uterine explora model i - mx120 ( http://www.coopersurgical.com/ ) ( figure 1 ) .\nin addition , the device is sterile and disposable ( one - time use ) .\nthe advantages of using explora rather than d&c as a sampling device include a reduction in hospitalization costs , extra convenience for the patient and physician , and the minimal complications of the procedure .\nthe purpose of this study is to compare the effectiveness of the explora model i tool with the conventional d&c technique for obtaining adequate endometrial samples that are capable of providing specific and informative histopathologic diagnoses .\nafter obtaining the approval of our institutional review board , all endometrial samples received at the histopathology department in king khalid university hospital ( kkuh , riyadh , ksa ) between january 2007 and december 2010 were included in this study . a total of 1270 endometrial samples were included ( table 1 ) .\ntwo hundred seventy - four samples ( 21.6% ) were obtained by conventional d&c in the surgical theater , while the remaining 996 samples ( 78.4% ) were obtained by senior obstetrics and gynecology residents who used a standardized biopsy technique in the outpatient procedure rooms . during the usage of the explora model\ni , the syringe provided with the instrument was used to create a negative pressure , and the explora was rotated as it was withdrawn . after withdrawal , the tip was cut off , and the tissue was placed in 10% buffered formalin saline fixative and was sent for pathological examination .\nthe pathologists who interpreted the endometrial samples were blinded to the instrument or method used to obtain the samples .\nan inadequate sample was defined as consisting of only blood , cervical mucus , endocervical epithelium , or blood with fragments of endometrial glands or stroma insufficient for histopathological assessment and diagnosis .\nthe age , gravidity , parity , menstrual history , uterine size , hysteroscopy findings ( when available ) , and the presence or absence of any cervical abnormality were recorded on the request forms , which were reviewed by the investigators . for each of the two methods used ( explora model i and d&c ) , the numbers and percentages of inadequate samples and age group clustering were calculated and statistically analyzed .\nof the 1270 endometrial samples obtained , 253 samples ( 19.9% ) were scored as inadequate . of these samples ,\nthe explora sampler was used to collect 224 samples ( 88.5% ) , whereas 29 samples ( 11.5% ) were obtained by d&c ( figure 2 ) .\nthus , the insufficient tissue percentage was higher with the explora ( 17.6% ) than with d&c ( 2.2% ) , which was a statistically significant difference ( p < 0.0001 )\n. age group clustering ( i.e. , numbers of premenopausal and postmenopausal women ) of inadequate sample results was also calculated ( figure 3 ) . of the 253 inadequate samples ,\n82.6% were from women 45 years of age and older ( i.e. , postmenopausal ) compared to 17.4% in premenopausal women ; the age difference was significant ( p < 0.0001 ) .\nthe detection rates of endometrial hyperplasia and carcinoma using both methods were assessed and calculated .\nof the 73 samples with a diagnosis of endometrial hyperplasia , 50 ( 68.5% ) were diagnosed by d&c , and 23 ( 31.5% ) were diagnosed using the explora sampler .\nhowever , of the 18 samples with a diagnosis of endometrial cancer , the rates of detection were similar between the two methods .\nendometrial sampling for the evaluation of dysfunctional uterine bleeding and the diagnosis of endometrial hyperplasia and carcinoma and other indications remains one of the most commonly performed gynecological procedures [ 14 ] . in recent years\n, less hazardous and more inexpensive and convenient outpatient sampling methods have replaced the traditional , in - hospital , endometrial curettage .\nthe advantages of outpatient endometrial biopsy include reduced cost and less risk for the patient , as no anesthesia is required .\nfurthermore , the discomfort and pain produced by sampling have been reported to be minimal .\nhowever , it is essential to ensure that outpatient endometrial sampling is quantitatively adequate and comparably accurate to conventional dilatation and curettage .\na sample is judged as adequate if a specific diagnosis can be given from the histological examination of the endometrial fragments obtained .\nadequacy can be measured by comparison of either outpatient biopsy with curettage histological evaluation or outpatient biopsy with the results of pathological examination of hysterectomy specimens [ 3 , 4 ] .\nmany techniques for obtaining an endometrial sample without the need for curettage have been described in the literature .\nchicago , il , usa ) and the novak biopsy curette with a 10  ml syringe functioning as an aspiratory device , which have been shown to be equally effective compared to d&c in detecting an endometrial pathology [ 69 ] .\nhowever , the vabra aspirator and novak biopsy curette , although widely available and relatively inexpensive , have several disadvantages , including the need for an electric vacuum pump to perform the aspiration in the former technique and the pain caused by both methods . as a result of these drawbacks , smaller inexpensive and\nself - contained instruments have been developed and the prototype of this class of endometrial samplers is the pipelle . the pipelle has been shown to have a diagnostic accuracy comparable to that of vabra aspiration and the novak curettage while causing less pain [ 911 ] .\nall of these instruments ( i.e. , the vabra aspirator , the novak biopsy curette , and the pipelle ) have low rates of false - negative and insufficient tissue results for the detection of endometrial abnormalities , as determined by comparison to hysterectomy specimens [ 1113 ] .\nit was found that pipelle biopsy had a sensitivity of 99.2% in pinpointing high grade cancer and a sensitivity of 93% in detecting low grade malignancies ; the sensitivities defined for d&c were 100% and 97% , respectively . while \nexcellent agreement  was generally noted between preoperative histology and grade and the final pathology , pre - operative endometrial sampling more commonly provided underestimates of final grade ( low grade versus high grade ) than overestimates .\nthe explora is somewhat similar in its design to the pipelle , but clinical studies on its effectiveness are scarce , with the effectiveness ranging between 14.6 and 15% according to various studies [ 6 , 15 ] .\nour own findings revealed that the rate of obtaining inadequate samples using the explora was much higher ( 17.6% ) than the rates reported in the literature .\nhowever , most of these cases ( 82.6% ) were obtained from postmenopausal women with atrophic endometrial status .\nthis finding is in keeping with the rates reported by other investigators [ 58 , 16 ] .\nthis retrospective study suggests that traditional d&c produces better endometrial sample adequacy than the explora technique .\nthis finding indicates that clinicians performing endometrial sampling would benefit from more experience and training using the explora technique .\nadditional studies comparing the adequacy of samples obtained with different endometrial sampling techniques and devices are warranted .\nfurthermore , we recommend using the d&c procedure when the explora - obtained samples are inconclusive or when the use of the explora sampler is accompanied by ultrasound findings that are suspicious of endometrial hyperplasia or carcinoma ."}
{"lay_summary": " in miocene times a vast wetland existed in western amazonia . \n whereas the general development of this amazing ecosystem is well established , many questions remain open on sedimentary environments , stratigraphical correlations as well as its palaeogeographical configuration . \n several outcrops located in a barely studied region around eirunep ( sw amazonas state , brazil ) were investigated to obtain basic sedimentological data . \n the observed deposits belong to the upper part of the solimes formation and are biostratigraphically dated to the late miocene . \n vertically as well as laterally highly variable fine - grained clastic successions were recorded . \n based on the lithofacies assemblages , these sediments represent fluvial deposits , possibly of an anastomosing river system . \n sand bodies formed within active channels and dominant overbank fines are described ( levees , crevasse splays / channels / deltas , abandoned channels , backswamps , floodplain paleosols ) . \n lacustrine environments are restricted to local floodplain ponds / lakes . \n the mollusc and ostracod content as well as very light 18o and 13c values , measured on ostracod valves , refer to exclusively freshwater conditions . based on palaeontological and geological results the existence of a long - lived lake (  lake pebas  ) or \n any influx of marine waters can be excluded for that region during the late miocene . ", "article": "the geological and ( palaeo-)biological evolution of lowland amazonia during neogene and quaternary times remains fascinating since the early days of natural sciences ( for summaries of research history see e.g. , loczy , 1963 and wesselingh , 2008 ) .\nmany , but partly highly controversial models have been introduced to explain its historical development ( for recent compilations see e.g. , lundberg et  al . , 1998 ;\n, 2006 ; wesselingh and salo , 2006 ; rossetti and mann de toledo , 2007 ; haffer , 2008 ; hoorn and wesselingh , 2010 ; hoorn et  al . , 2010 ;\ngenerally , it is widely accepted that around the onset of the miocene ( 23  ma ) a mega - wetland (  pebas system  , also called  lake pebas  ) developed in western amazonia due to the subsiding subandean foreland ( e.g. , hoorn , 1994 , 2006 ; wesselingh et  al . , 2002 ; wesselingh and salo , 2006 ; shephard et  al . , 2010 ) .\nshort - lived marine incursions or even a transcontinental seaway from the caribbean sea through the venezuelan / columbian llanos basin southwards to the argentinean paran basin are proposed ( e.g. , rsnen et  al . , 1995 ;\n2009 ) but heavily disputed ( e.g. , campbell et  al . , 2006 ; cozzuol , 2006 ; westaway , 2006 ; latrubesse et  al . , 2007 , 2010 ;\n, 2003 ; hoorn and vonhof , 2006 ; wesselingh , 2006 ) . in the late miocene this mega - wetland disintegrated due to enhanced uplift of the northern / central andes .\nthe drainage pattern of northern south america started to reverse completely to today s easterly course and the modern  amazon system  became established during the early pliocene ( hoorn , 2006 ; figueiredo et  al .\n, 2009 ; hoorn et  al . , 2010 ; latrubesse et  al . ,\n2010 ) . beside the vast size of amazonia and the still fragmentary regional coverage with field surveys ,\nthere are considerable inconsistencies in palaeoenvironmental reconstructions and , in particular , in the chronology and correlation of scattered outcrops .\nwesselingh ( 2008 , p. 5 ) stated :  the lack of geological data has led to the emergence of many grand theories about the origin of present - day amazon system and its highly diversity , often based on dubious interpretations of the little data available  .\nthe present paper aims to contribute basic sedimentological data from a barely studied region ( eirunep , 2.000  km sw manaus ; fig . \n1a ) , which is supposed to be placed at the south - eastern margin of the  pebas system  ( wesselingh and ramos , 2010 ) .\nwe demonstrate that there is no evidence for a long - lived lake ( sensu gorthner , 1994 ) or any marine influx .\nconversely , we document a well - structured , aggrading fluvial system of late miocene age , which is in agreement with the sedimentation model and chronology proposed by latrubesse et  al .\nthe studied sections are located along the juru and tarauac river , ne respectively se of the city eirunep ( state of amazonia , western brazil ; 245  km  s of benjamin constant ; fig . \ndelineations and subdivisions of basins in western amazonia diverge notably and several authors attribute the region of eirunep to the solimes basin ( eirunep subbasin ; e.g. , caputo , 1991 ; roddaz et  al . , 2005 ; ramos , 2006 ; wesselingh and salo , 2006 ; wesselingh et  al . ,\nhowever , based on subsurface information , obtained by extensive hydrocarbon and coal exploration campaigns during the 1970 s , this region is situated west of a basement high ( miura , 1972 ;  iquitos arch  ; corresponds to the  carauari arch  of caputo , 1991 ) on the eastern margin of the acre basin ( e.g. , del arco et  al . , 1977 ; maia et  al . , 1977 ; latrubesse et  al . , 2010 ; fig . \nbeside quaternary deposits ( terraces , alluvium ) , the scattered outcrops along river banks expose sediments of the upper parts of the solimes formation ( del arco et  al . , 1977 ;\nmaia et  al . , 1977 ; paz et  al . , in press ) . the solimes fm .\ncomprises more than 1000  m thick , largely pelitic  sandy alternations with lignitic intercalations and covers a huge part of western amazonia ( fig . \n. uncertainties in its definition , its stratigraphical and geographical extent as well as its depositional environments basically reflect the ongoing debate about amazonia s history through neogene times .\n( 1977 ) , hoorn ( 1993 , 1994 ) , latrubesse et  al .\nthe sections were vertically logged by visual inspection of the lithofacies ( including colour , grain size , bedding planes , sedimentary structures , macrofossil content ) . for lithofacies coding the scheme of miall ( 1996 )\nwas used : capital letters  =  dominant grain size ( g , gravel ; s , sand ; f , fine sand  clay ) followed by a lowercase letter  =  sedimentary structures and/or biogenic features ( c , clast - supported ; m , massive / faint lamination ; h , horizontal bedding / lamination ; t and p , trough and planar cross bedding ; r , ripple bedding ; s , scour fill ; l , lamination ; r , rooted ; c , coal ; p , pedogenic overprint ) .\nadditionally the outcrops were mapped laterally as far as possible . due to poor outcrop conditions\nan application of the  architectural element concept ( miall , 1996 ) was only loosely possible .\nfor micropalaeontological investigations bulk samples ( 12  kg ) were taken from all outcrops .\n500  g of dried sediment ( 40  c , 24  h ) were washed by using diluted hydrogen superoxide for disintegration through standard sieves ( h2o2 : h2o  =  1 : 5 ; 63/125/250/500  m ) .\nwet sieve residuals were washed with ethanol prior to drying ( 40  c , 24  h ) .\nan in - depth taxonomic examination of the obtained microfossils ( including the sieve fractions < 250  m ) will be subject of further studies .\nfor preliminary stable isotope analyses ( o , c ; 18 samples ) two or three ostracod valves ( 4060  g ; cyprideis spp . ) from earlier sampling campaigns were used ( collected by m.i.r ) . for analyses\na thermo - finnigan kiel ii automated reaction system and a thermo - finnigan delta plus isotope - ratio mass spectrometer were used ( university of graz ; standard deviation  =  0.1 relative to nbs-19 ; results in per mille relative to vpdb ) .\nmore detailed investigations are in preparation ( m. fonseca / belm , m. caporaletti / graz ) .\nlocation : 12.6  km ne eirunep ( s 063355.5/w 0694611.7  , altitude : 108  m ) , left cutbank of the juru river ( fig .  2 ) .\ndescription : the basal 1.8  m ( layers 19 ) of the section consists of partly ripple bedded sands and laminated silts ; some cm - thick clay intercalations were observed . above\nfollows a 0.65  m thick alternation of clay with incorporated calcareous nodules and laminated silty sand or ripple bedded sand ( 1017 ; fig . \nthe top is rich in vertebrate remains ( crocodiles , turtles ; 17 ; fig . \nmassive to finely laminated , occasionally bivalves - bearing ( silty ) clay with coaly and sandy layers forms the next 1.14  m ( 1823 ; fig . \nbeds 2425 ( 1.85  m thick ) comprise massive , horizontally or trough cross bedded sand and finely laminated or massive ( sandy  silty ) clay / fine sand ( fig . \ngrey mottled , rooted and massive clay ( paleosol ) with a calcareous horizon on its top ( 26 ) .\nup - section , a 4.2  m ( 2739 ) thick alternation of massive or laminated clay , silt and partly ripple bedded fine sand is developed ( a slight coarsening - upward trend is anticipated ) .\nbed 32 displays a slightly erosive base with intraclasts in the lower part ( mud pebbles ) .\nlayers 3139 are cut by a channel ( 40 ) with a multiphase fill . large scale cross bedded sands ( -cross stratification ) with sporadic intraclasts ( mud pebbles ) on reactivation surfaces and trough cross bedded and ripple bedded fine \nmicrofossil contents : samples from the basal part of the section ( pd2 ) yielded only scarce valves of cyprideis spp . and rare fish elements .\ninterpretation : the lithofacies of the basal part of the outcrop ( 117 ) refers to a deposition in a fluvial overbank environment .\nthe diffuse layers of calcareous nodules ( 17 ) are supposed to be largely a diagenetic feature ( groundwater caliche ) .\nhowever , it may also hint to soil - forming processes at seasonally dry floodplain areas ( retallack , 2001 ) .\nup - section the sediments become finer and contain several ( sandy  silty ) coal - rich layers ( 1823 ) .\nthese beds are assigned to the formation of a floodplain pond , which was inhabited by opportunistic ostracods , freshwater bivalves and fishes .\nhowever , crevasse splays influenced episodically that shallow lacustrine environment ( sandy and organic matter - rich layers ) .\nlater ( layers 2425 ) , the influx of crevasse splays into the pond , which is still populated by ostracod faunas and fishes increased ( more prominent sandy beds , partly scour - fills ) .\npedogenic processes are indicated by incipient soil formation in layer 26 ( mottled , roots ) .\nfloodplain pond conditions ended above ( beds 2739 ) due to enhanced clastic input from an approaching channel\n. finally ( bed 40 ) , the overbank fines were intersected by a channel of at least 23  m in depth , which was filled up by large scale cross bedded sand .\nmore or less perpendicular to the main accretion surfaces oriented ripple bedding indicates deposition by lateral accretion of a point bar .\nlocation : 17.9  km ne eirunep ( s 063251.1/w 0694239.4  , altitude : 107  m ) , left cutbank of the juru river ( fig .  4 ) .\ndescription : the lower 5  m of the outcrop are formed by ( section 1 ) : ( 1 ) greenish  grey , mottled clay with ferran cutans and cm - sized carbonate nodules ( fig . \n5a ) ; ( 2 ) dark grey , massive or indistinctly laminated clay with cm - sized carbonate concretions ( fig . \n5b ) , thin , pyrite - rich coaly layers , plant fragments , root traces and vertebrate remains ( crocodiles , turtles ) ; ( 3 ) greenish  yellowish , mottled clay with ferran cutans ( passes gradually into bed 4 ) ; ( 4 ) violet - red  green - grey , mottled clay / paleosol ( fig . \n5c ) ; and ( 5 ) green  grey , mottled clay with vertebrate remains ( reptiles ) on top .\na trough cross bedded sandy layer with coaly interlayers in the se part of the site mentioned by paz et  al .\n( in press ) was not exposed during our observation ( section 4 ) . in the nw part ( section 1 ) , above layer 5 , ripple bedded fine sand with intraclasts ( mud pebbles ) at its base is recorded , which contains bivalves and coalified wood remains ( 6 ) .\nlaminated sand alternations ( 7 ) and massive sandy clay , which is rich in molluscs in its lower and upper part ( 8) . up - section ( 9 ) , an alternation of clay and coal layers , rich in molluscs ( i.e. , mycetopoda sp . ) , as well as a thinly bedded succession of laminated sand and thin clay interlayers ( 10 ) follow . towards the se ( section 24 )\nan up to 2  m thick , large scale cross bedded sandy unit is developed ( fig . \noccasionally , intraclasts and vertebrate fragments are found at the base of this element or on accretion surfaces , which dip around ne .\nthe dip of ripple foresets is approximately perpendicular oriented to these surfaces ( sw ) .\nthis unit is overlain by a layer of calcareous nodules ( 11 ; section 3 ) and laminated clay ( silt)coal alternations with bivalve and vertebrate remains ( 13 and 14  =  equivalent to 9 ) .\nbed 12 ( plastic , strongly weathered clay ) is an equivalent of layer 10 .\nmicrofossil contents : samples mn1 and mn2 lack microfossils , in mn8a and mn8b only scattered valves of cypria sp . and heterocypris ?\nmn9 and mn 14 yielded many fish , gastropod and bivalve ( sphaeriids ) remains as well as abundant ostracod valves ( cyprideis spp . ) .\nearlier reports on fossil material : celestino and ramos ( 2007 ; see also wesselingh and ramos , 2010 ) documented the following ostracod taxa : cyprideis graciosa , cyprideis lacrimata , cyprideis longispina , cyprideis machadoi , cyprideis pebasae , cyprideis olivencai , cyprideis sp . 1 and 2 .\nfurther findings ( plants , fishes , reptiles ) are mentioned in del arco et  al .\nthe later authors also reported the occurrence of cyathecidites annulatus , echitricolporites spinosus and grimsdalea magnaclavata pollen .\ngreenish to yellowish and dark grey colouration might indicate more or less water - logged conditions , whereas reddish colours may hint to rather well - drained , oxidizing environments .\nhowever , diagenetic alteration can hamper such an interpretation significantly ( retallack , 2001 ) .\nlayer 2 is less affected by pedogenic processes ( faint lamination , coaly layers , plant and reptile fragments ) and perhaps represents floodplain lake / backswamp deposits .\nthe paleosols ( overbank fines ; 15 ) are overlain by a sandy channel fill ( point bar ) with lag deposits at its base and repeatedly occurring intraclasts at its lateral accretion surfaces ( channel depth > 2  m based on the preserved height of this unit ) . in the nw part of morada nova layers\n68 represent an abandoned channel fill , which could be the fill of a subordinate channel or the fill of a chute channel .\nup - section , the influx of the active channel decreased and a floodplain lake developed ( 9 , 13 , 14 ) , which enabled the establishment of plentiful ostracod and aquatic molluscs faunas .\nthe pond itself or its surroundings were richly vegetated ( coaly layers ) and settled by semi - aquatic reptiles . finally , enhanced input of sandy matter points to an increasing influence of the channel , probably due to crevasse splays .\n( s 063140.8/w 0693952.0  ; altitude : 106  m ) , left cutbank of the juru river ( fig . \ndescription : section 1 ( w part ) starts with a 1.6  m thick succession of laminated , ripple and cross bedded silty sand with coaly intercalations ( layers 16/1 ) .\nup - section ( 714/1 ) , a 2.5  m thick sequence of ripple bedded silty fine sand layers with commonly erosive basal boundaries ( incl .\nconvolute bedding and m - thick concretions are frequent in its upper part ( 1114/1 ) .\nsilty clay ; 1520/1 ) and comprise coal and mollusc - rich pelitic ( 16/1 , 19/1 ) and coaly layers ( 18/1 ) as well as carbonate - cemented clay ( 20/1 ) .\nlayer 21/1 ( 0.75  m thick ) is composed of greenish  violet , mottled or poorly laminated clay with scattered bivalve shells .\nintercalated are several layers ( 10  cm - thick ) , which consist of 12  mm large , rounded clay clasts ( fig . \nit is overlain by 1  m of massive clay with abundant mollusc ( e.g. , sheppardiconcha septencincta ; fig . \nleaves ; 22/1 ) and a > 0.5  m thick ( weathered ) coaly layer ( 23/1 ) with mollusc fragments ( e.g. , anodontites ?\nsection 2 ( e part ; 120  m downstream of section 2 ) starts with > 0.35  m thick , laminated fine sand with coaly interlayers ( layer 1/2 ) .\nit is cut by a 4  m wide and 0.8  m deep channel fill ( 25/2 ; fining - upward , from base to top : laminated , coal - rich fine sand with rare mollusc and plant remains ; ripple bedded fine sand , rich in plant fragments ; massive clay , rich in bivalves ( sphaeriids ) , several wood remains ; fig . \nthis channel fill is topped by a 0.5  m thick , massive  poorly laminated clay with thin fine sand interlayers ( 6/2 ) and 0.2  m of massive , partly indurated ( cemented ) clay ( 7/2 ) .\ncoalified wood remains are rare ; bivalves ( sphaeriids ) are abundant ( especially upper part of 6/2 ) .\nlayer 6/2 and 7/2 taper off towards the w. up - section ( 1  m thickness ) , follow massive , silty  sandy clays ( 89/2 ) and ripple bedded silty fine sand with silt interlayers ( 1014/2 ) .\nespecially layer 8/2 is rich in molluscs ( sphaeriids ) , 1314/2 contain coaly fragments ; clay intraclasts are observed at the base of 13/2 .\nthese beds are topped by 2.7  m of mottled silty fine sand with coaly fragments in the lower 0.3  m ( 15/2 ) .\n. layer 16/2 ( > 1.2  m thick ) comprises coal  coaly fine sand  finely laminated clay alternations ( fig . \n7f ) and is rich in bivalves ( sphaeriids ) in the lowermost 57  cm .\nwhereas samples aq5/1 and aq6/1 contain only rare ostracod remains , aq16/1 yields , beside fish fragments , some valves of cytheridella sp . and darwinulids , accompanied by rare specimens of cypria sp . , cyprideis spp . and\n, darwinulids , cypria sp . , ilyocypridids ) and fish bones . several ( aq22a/1 ) respectively rare ( aq22b/1 ) cyprideis spp .\nvalves are recorded in the samples of section 1 above , together with fish remains and gastropods ( aq22b/1 ) .\nsample aq3/2 of section 2 delivered only rarely cyprideis spp . and some fish remains . in the samples aq 5 - 6 - 8 - 13/2 plentiful ostracod faunas ( cytheridella sp . , ilyocyprinids , darwinulids , cyprideis spp .\nare documented along with fish remains and sphaeriid bivalve shells ( aq8/2 and aq13/2 ) . aq15/2 and aq16/2 are almost barren of ostracods but contain fish and bivalve ( sphaeriids ) fossils . earlier reports on fossil material : celestino and ramos ( 2007 ; see also wesselingh and ramos , 2010 ) recorded the following ostracod taxa : alicenula ( darwinula ) fragilis , cypria aqualica , c.  longispina , c.  pebasae , cyprideis sp . 3 , cytheridella purperae , heterocypris ?\n( 2006b ) re - examined mollusc material studied by roxo ( 1937 ) from aquidab and described : ampullariidae sp .\nsheppardiconcha septemcincta . additional findings ( including vertebrates and plants ) are mentioned by del arco et  al .\nthe basal , sandy  silty layers ( 16/1  =  1/2 ) possibly represent crevasse splay deposits , which are followed by a series of crevasse splay and/or crevasse channel sediments ( 714/1 respectively 25/2 ) .\nalternatively , these layers could represent channel deposits of an avulsive river arm . in section 2 a subordinate abandoned channel fill ( floodplain pond ; 67/2 ) is developed .\nafterwards ( 1523/1 and 816/2 ) the influx of crevassing respectively the active channel successively decreased and led to the formation of a floodplain lake , which was only influenced by flash floods in more proximal settings ( section 2 ; e.g. , 12/2 ) . aquatic faunas ( bivalves , ostracods ,\nfishes ) and semi - aquatic crocodilians inhabited that lake , which was surrounded by a densely vegetated backswamp .\nthese beds display a mottled appearance and contain ( 21/1 ) layers of crumb peds ( clast - supported layers of rounded but not interlocked tiny mud balls ) , which indicate bioturbation due to invertebrate activity ( retallack , 2001 ) .\nfinally , the lake became replaced by a swampy environment ( 23/1 and 16/2 ) .\nlocation : 27.4  km ne eirunep ( s 063122.0/w 0693542.8  ; altitude : 105  m ) , left cutbank of the juru river ( fig . \ndescription : at the base > 2  m of slightly southwards inclined ( < 10 ) rippled bedded silty fine sand ( layer 1 ) are followed by 2.7  m thick violet - brown ( 2 ) and yellowish ( 3 ) mottled paleosols with calcareous nodules ( between 2 and 3 a pedogenically overprinted clay plug is intercalated ) .\nlayers 13 are cut by a channel , whose fill starts ( 4 ) with > 1.5  m thick , massive  poorly laminated silty clay with gastropods , rare bivalves and plant ( leaves ) remains .\nbed 4 grades into a 0.8  m thick , brownish - grey , blocky structured silty clay ( 5 ) with a calcareous crust on its top .\nit is overlain by 2.4  m of violet - brown , mottled clay ( 6 ) with intercalated layers of calcareous nodules .\nstrata 13 as well as the channel fill ( 46 ) are topped by a 0.4  m thick alternation of laminated silty clay and laminated or rippled bedded fine \nmedium sand with a high amount of plant detritus ( also wood remains ) and abundant vertebrates ( turtles ; 7 ) .\nthe badly exposed , 7.2  m thick beds up - section ( 8) consist of cross and ripple bedded fine sand with intercalations of clayey lenses ( 2  m lateral extension , 20  cm thickness ) , which are formed by clay intraclasts ( mud pebbles , 1  cm diameter ) .\nrepeatedly coaly layers are intercalated and rarely vertebrate ( crocodiles ) remains were found in the intraclast conglomerate .\nlayer 9 represents a 1.2  m thick alternation of horizontally or ripple bedded fine \nthe topmost 1.2  m thick layer 10 consists of ripple bedded silty fine sand and silty clay alternations , which form cm - thick , fining - upward couplets .\nmicrofossil contents : sample re4 yielded only a few valves of cyprideis spp . as well as some fish and gastropod remains .\ninterpretation : layer 1 could represent a crevasse splay or levee deposit , which is overlain by pedogenically altered floodplain fines ( 23 ) with intercalated minor channel fills .\nthese overbank deposits are cut by a channel ( ? 20  m wide and 5  m deep ) , which became filled by pelitic , afterwards pedogenically overprinted sediments .\nthe rare ( a matter of preservation ? ) mollusc and ostracod record indicates at least at the beginning ( 4 ) aquatic life in the abandoned channel . above , a crevasse splay ( 7 ) points to rising proximity of the active channel .\nlarge wood remains and vertebrate fragments were accumulated by this splay . the sandy succession up - section (\n8) can only be attributed to a sandy bedform sensu miall ( 1996 ) due to insufficient outcrop conditions .\nintercalated shallow scours , filled up with mud balls indicate deposition of reworked material and variations of the flow regime .\nthe more or less rhythmically stratified , sandy - pelitic alternations at the top of remanso ( 910 ) mark a shift towards overbank environment and might represent a bar - top assemblage . location : 17.5  km se eirunep ( s 064923/w 0694704  , altitude : 117  m ) , left cutbank of the tarauac river ( fig . \ndescription : the basal 1.7  m ( layers 13 ) consist of massive or laminated pelite- and fine sand with rare bivalve remains .\nthey are topped by 0.2  m of reddish - brown , massive clay ( 4 ) .\nthe sandy  silty layers 59 display a general coarsening - upward trend and contain only rarely bivalve fragments .\nup - section ( 10 ) , a 0.25  m thick intraclast conglomerate ( mudstone pebbles ) with abundant mollusc ( e.g. , ampullariidae ?\nthis stratum is overlain by thin sand and clay layers ( 1117 ) with abundant mollusc remains ( 12 , 14 , 16 , lower part of 17 ) .\nlayer 14 is rich in coal fragments ( wood , leaves ) at its top .\nthe 2.57  m thick succession above ( 1823 ) starts with thin , ripple bedded fine sand beds ( 1819 ) , followed by massive silty / sandy clay with coaly fragments ( 20 ) and cm - thick alternations of fine sandy silt and silty fine sand ( 21 ; forming couplets of small - scale fining - upward cycles ) .\nbeds 22 and 23 comprise alternations of massive , fine sandy silt and ripple bedded , silty fine sand .\n24 consists of 10  cm - thick alternations of indistinctly ripple bedded silty fine sand and massive or poorly laminated pelite . the upper part ( 1.5  m ) is mottled and primary sedimentary structures are obscured due to pedogenic processes .\nthese samples contain several fish remains and in to12 rare characean gyrogonites were found additionally . the samples to20 and to 23 delivered only rare ostracod ( cypria sp .\nearlier reports of fossil material and facies : ramos ( 2006 ) mentioned the following ostracod taxa : c.  aqualica , c.  graciosa , c.  lacrimata , c.  longispina , c.  pebasae , c.  purperae , cytheridella sp . , darwinula fragilis as well as additional vertebrate and crab findings .\ninterpretation : the lowermost sandy - pelitic layers ( 14 ) might be deposited in a floodplain pond / lake , which was influenced by crevasse splays .\nthe coarsening - upward trend of layers 59 hints to a progressive influx of a crevasse channel ( layer 10 ) .\nit remains unclear if the ostracods of this layer are allochthonous or if they are incorporated in that layer due to subaquatic inflow of the crevasse splay ( crevasse delta ) into a floodplain pond / lake .\nup - section ( 1124 ) , plentiful ostracod and mollusc faunas ( especially in the lower part : 1117 ; compare ramos , 2006 ) indicate the return to an aquatic environment and the abandonment of the crevasse channel .\nsmall - scale fining - upward alternations of ripple bedded sand and pelite document individual flooding events or surges .\nlocation : 22.1  km sse eirunep ( s 065218.3/w 0694705.1  ; altitude : 120  m ) , left cutbank of the tarauac river ( fig . \ndescription : layers 16 represent a 3.2  m thick succession of greenish ( 1 ) , reddish ( 2 ) , yellowish ( 3 , 5 , 6 ) or violet grey ( 4 ) coloured , mottled , frequently calcareous nodules - bearing paleosols . in layer 6 vertebrate remains ( crocodile teeth ) and gastropods were found .\nabove follows a 1.1  m thick , indistinctly bedded clay to fine sand ( 7 ) , which contains in its lower half coaly plant fragments and becomes towards the top and laterally progressively mottled ( paleosol ) .\nthe 0.65  m thick sediment column up - section ( 811 ) is composed of massive clay ( 8) , ripple bedded fine sand ( 9 ) , laminated silty fine sand to silt ( 10 ) and fine sand ( 11 ) .\neach of these layers displays a slightly erosive base and an internal fining - upward trend .\nthe beds 8 , 9 and 11 each start with a basal layer of concretionary mud clasts in which ( layer 8 and 11 ) abundant vertebrate remains were found .\nlayer 12 is formed by 1.2  m thick , ripple bedded fine sand with cm - thick , laminated silty clay interlayers .\nup - section a 0.7  m thick , orange - grey , mottled paleosol with mud clasts and rare vertebrate remains at its base ( 13 ) as well as a > 1.5  m thick , violet - purple coloured , mottled paleosol are developed ( 14 ) .\nmicrofossil contents : the samples ba7a and ba7b contained several ostracod valves ( mainly cyprideis spp . , some specimens of cypria sp .\ninterpretation : the basal layers ( 16 ) represent a succession of paleosols , which could be seriously altered floodplain deposits . due to the occurrence of ostracods , probably bed 7 was deposited in a floodplain lake environment .\nafterwards , a series of crevasse splay ( maybe partly also crevasse channel ) deposits follows ( 813 ) , which is topped by pedogenically overprinted floodplain fines ( 14 ) .\nthe sedimentary record of the investigated outcrops documents vertically as well as laterally highly variable fine - grained clastic successions ( predominantly clay  fine sand , along with fine  medium sand ) . based on the lithofacies and , as far as possible , lateral observations , these sediments represent fluvial deposition within active channels as well as in overbank environments .\nmacroforms , generated within the active channel include lateral accretion deposits ( sandy point bars ; figs .  2 and 4 ) and undifferentiated sandy bedforms ( stacked dune fields ? ; fig . \n8) , which are probably partly intersected by chute channels or are overlain by overbank fines .\nthese comprise pelite  sand - alternations of levee , crevasse splay and crevasse channel deposits .\nfrequently , a lag of mud pebbles and vertebrate fragments is found at the base of crevasse channels / splays . in part\n, some splays may have entered floodplain ponds / lakes via crevasse deltas ( e.g. , figs .  6 and 9 ) .\nabandoned , fine - grained channel fills ( mud plugs ) were observed ( fig . \ndecimetre - thick , clay  silt beds with rich ostracod and mollusc faunas indicate the presence of short - lived , shallow ponds or lakes within the floodplain ( floodbasin ; e.g. , fig . \n6 ) point to partly swampy , poorly - drained conditions and a densely vegetated floodplain , which is , however , influenced by high clastic input .\nintensively mottled paleosols with root casts and calcareous nodules are ubiquitous ( e.g. , fig . \ndifferences in colour and occasional calcic horizons may reflect diverging water - logging due to e.g. , local topography and/or seasonal fluctuations in discharge or climate ( kaandorp et  al .\nnevertheless , diagenesis may have altered significantly primary features and more  specific investigations are required ( retallack , 2001 ) .\nwe are aware that restricted outcrop conditions and the limited areal and stratigraphical extent ( 30  m stratigraphical thickness ) of the current investigation hamper conclusions about the nature of fluvial style .\nreconstructions of fluvial geomorphology , based solely on lithofacies assemblages and fragmentary known fluvial elements , remain to some degree tentative ( miall , 1996 ; bridge , 2003 )\n. however , it seems obvious that we are dealing with a suspended load river system due to the high amount of overbank fines , probably within a tropical to subtropical wet  dry climate ( kaandorp et  al . , 2005 ; latrubesse et  al .\nwe observed : ( a ) a large proportion of overbank deposits , ( b ) laterally extensive , heterogeneous , fine - grained avulsion deposits ( including crevasse splays ) , ( c ) predominantly sandy channel deposits , which change laterally and vertically rapidly into overbank deposits as well as ( d ) lacustrine and coaly deposits . some sandy point bars ( of secondary channels ? ) indicate subordinate lateral sediment accretion .\nthese features are not exclusive to anastomosing river deposits , however , they largely coincide with the  standard  model of an anastomosing river sensu miall ( 1996 ) as well as with characteristics of such a system as reviewed by makaske ( 2001 ; compare also smith , 1983 ) .\nthe general setting ( subsiding foreland basin , extensive sediment input from the andes , possibly incompletely framed by tectonically active basement highs towards the east ) as well as a wet  dry seasonal climate ( seasonal floods , channel banks stabilized by vegetation ) would provide the conditions for anastomosing river systems ( smith , 1983 ; nanson and knighton , 1996 ; makaske , 2001 ; latrubesse et  al .\n( late miocene ) in the state of acre ( sw brazil ) led to similar assumptions ( latrubesse et  al .\nthese authors proposed a megafan system , which originates in the andes and encompass a complex mosaic of avulsive rivers and associated wetlands ( including abandoned channels , floodplain lakes , floodbasin deltas , backswamps and well - drained floodplains ; see also wilkinson et  al .\nthis system is suggested to reach to the east at least as far as 67 w ( iquitos arch  sensu del arco et  al . , 1977 ) and probably also beyond (  purus arch  ; latrubesse et  al . , 1997 , 2010 ; fig\naccording to that , the sections around eirunep were located in a more distal position , which could be the reason for a more pronounced anastomosing - anabranching pattern due to a lower gradient ( compare also interpretations of the late miocene tariquia formation , southern bolivia ; uba et  al .\n( 2007 , 2010 ) compared the depositional environment of the late miocene solimes fm . in acre with i.e. , the quaternary megafans of the chaco plain and the pantanal wetland ( iriondo , 1993 ; horton and decelles , 2001\nthe mollusc fauna , recorded from floodplain pond / lake deposits , is dominated by sphaeriids and the pachychilid sheppardiconcha ( fig . \n7b ) and indicates freshwater conditions within a fluvio - lacustrine environment ( wesselingh et  al . , 2006b ; wesselingh and ramos , 2010 ) .\ntypical freshwater ostracods ( darwinulids , ilyocyprinids , cypria , cytheridella ) are associated with diverse species of cyprideis .\nthis genus is a holoeuryhaline taxon , able to cope with fluctuating salinities , aberrant water chemistries , variable temperatures and oxygenation ( e.g. , meisch , 2000 ; keyser , 2005 ) . as it could adapt to freshwater conditions ( e.g. , lake tanganyika ; wouters and martens , 2001 ) and co - occurs here with exclusively freshwater taxa\n, there is no constraint to conclude a brackish water environment ( ramos , 2006 ) .\npreliminary stable isotope data ( o , c ) measured on cyprideis valves from aquidab , morada nova and torre da lua , yielded very negative values ( o :  5.7 to  9.7 , c :  10.3 to  12.5 ) , which exclude any marine influx .\nthere is still intensive debate on definition and timing of palynological biozonation concepts ( e.g. , hoorn , 1993 , 1994 ; latrubesse et  al . , 2007 , 2010 ; jaramillo et  al . , 2010 ; silva - caminha et  al . ,\nhowever , palynostratigraphy remains a cornerstone for correlation across amazonia up to now and provides at least a rough stratigraphical framework .\n( 2006a ) are highly linked to the concept established by hoorn ( 1993 ) .\nbased on the presence of some index taxa ( c.  annulatus , e.  spinosus , g.  magnaclavata ) a late miocene age ( probably asteraceae zone sensu lorente , 1986 ) is proposed by paz et  al .\n( in press ) for the outcrops morada nova and torre da lua recently . the vertebrate fauna from torre da lua ( ramos , 2006 ) is related to the so - called  acre fauna  , which is one of the best documented faunas of northern south america ( cozzuol , 2006 ; latrubesse et  al .\nthe acre vertebrate assemblage displays significant affinities with the  mesopotamian  faunas of argentina and uruguay as well as with the urumaco assemblages ( venezuela ) and is dated to the late miocene ( huayquerian south american land mammal age ; cozzuol , 2006 ; latrubesse et  al .\nis still poor and has to be extended by later works ( wesselingh and ramos , 2010 ; see roxo , 1937 ; wesselingh et  al .\n, 2006b ; wesselingh , 2008 , and outcrop descriptions herein ) . from a stratigraphical point of view the mollusc faunas of aquidab and torre da lua\n( 2006b ) to be of late miocene origin and post - date the  pebas fauna \n( compare celestino and ramos , 2007 ; wesselingh , 2008 ; wesselingh and ramos , 2010 , which suggested a late middle miocene age based on the ostracod record ) .\na late miocene age seems to be in agreement with the lack of typical endemic pebasian molluscs ( wesselingh and ramos , 2010 ) . the recorded cyprideis - species from aquidab , morada nova and torre da lua ( ramos , 2006 ; celestino and ramos , 2007 ; wesselingh and ramos , 2010 ) have generally long ranges according to muoz - torres et  al .\n( 1998 , 2006 ; see also whatley et  al . , 1998 ) .\nthe occurrence of c.  lacrimata and c.  pebasae might be indicative for an age not younger than the ( early ) late miocene .\nnonetheless , due to some contradictions ( e.g. , c.  lacrimata is supposed to appear first after the last appearance of c.  longispina but both are co - occurring at morada nova and torre da lua ) and the lack of key taxa , the current ostracod zonation needs some adjustment and is not further stressed here .\nhowever , to date , a late miocene age seems most plausible for all outcrops described herein by considering the palaeontological record .\nmoreover , this fits well to the palaeogeographic context of this region as proposed by latrubesse et  al .\nsedimentological observations derived from outcrops around eirunep ( south - western part of the state of amazonia ) document various subenvironments of a fluvial system ( upper part of the solimes formation , late miocene ) . beside sandy channel deposits ,\nthe main part comprises overbank sediments of levees , crevasse splays / channels / deltas , abandoned channels , backswamps and floodplain paleosols .\nbased on the lithofacies and the general geological setting , this system can be possibly related to an anastomosing river style .\nthere is not any indication for a long - lived lake (  lake pebas  ) or any marine influx in this region during the late miocene .\n( 1997 , 2007 , 2010 ; compare also cozzuol , 2006 ; westaway , 2006 ) ."}
{"lay_summary": " \n aim . to investigate incidental adrenal enlargement clinical characteristics and functional status and analyze functional lesion risk factors . materials and methods . \n this retrospective study included 578 patients with adrenal imaging features showing enlargement . \n incidental adrenal enlargement cases ( 78 ) were considered eligible . \n demographics , functional diagnosis , adrenal imaging features , and concomitant diseases were analyzed . \n results . \n the number of adrenal enlargements and proportion of incidental adrenal enlargement increased each year . \n mean patient age was 50.32 years . \n thirty - nine cases had unilateral enlargement on the left side and 3 on the right side ; 36 had bilateral enlargement . \n routine medical checkup was found to have the greatest chance ( 43.59% ) of revealing clinical onsets leading to discovery . \n biochemical and functional evaluation revealed 54 ( 69.23% ) cases of nonfunctional lesions , 12 ( 15.38% ) of subclinical cushing syndrome , 6 ( 7.69% ) of primary hyperaldosteronism , 1 ( 1.28% ) of metastasis , and 5 ( 6.41% ) of unknown functional status . \n nodular adrenal enlargement ( or , 7.306 ; 95% ci , 1.72728.667 ; \n p = 0.006 ) was a risk factor for functional lesions . \n age and lesion location were not significant factors . \n conclusion . \n incidental adrenal enlargement is a frequent radiographic finding and is accompanied by diverse clinical factors that require proper evaluation and management . \n nodular adrenal enlargement was a risk factor . ", "article": "with increasing availability , widened indications , and technical refinements of computed tomography ( ct ) and magnetic resonance imaging ( mri ) , the number of incidentally discovered adrenal lesions , such as adrenal incidentalomas and incidental adrenal enlargement , is increasing . in a recent study by tang et al .\n, among a total of 564 eligible ct studies ( patients undergoing ct without prior known malignancy , trauma , or endocrine disease ) , adrenal hyperplasia was detected in 64 cases , giving a prevalence of 11.3% .\nthis indicated that incidental adrenal enlargement had a significant prevalence and has become a common clinical problem .\nit should be emphasized that the term incidental adrenal enlargement represents the way the lesion was detected ( incidentally ) , rather than the etiology or diagnosis .\nit is a common term for a variety of adrenal disorders , but its cause must be properly assessed so that patients needing treatment , such as those with hormone hypersecretion or malignant disease , can receive appropriate care . however , there is a lack of literature on functional status and its follow - up to provide comprehensive insight to these findings .\npatients with incidental adrenal enlargement were evaluated in a tertiary referral hospital with endocrinological departments in china .\nthis study aimed to determine the primary clinical presentation that most frequently leads to the discovery of adrenal enlargement , to evaluate clinical characteristics and functional status of these patients , and to analyze risk factors for functional lesions .\nthis retrospective study included 578 patients with adrenal imaging features showing adrenal enlargement who were hospitalized at the department of endocrinology in pla general hospital ( beijing , china ) between january 1993 and july 2013 .\ndata retrieved included patient demographics , final functional diagnosis , adrenal imaging features , and concomitant diseases .\npatients were classified as having incidental adrenal enlargement when abdominal imaging was performed for indications unrelated to adrenal disease .\npatients with diseases known to cause adrenal enlargement , such as known endocrine disorders which could affect adrenal size , trauma , and underlying malignancy , were excluded . among all enrolled patients , 78 presented with incidental adrenal enlargement .\nthe ct imaging technique used was not standardized due to the various clinical indications . however , to be included in their entirety on a maximum of 5  mm section thickness , the upper limit of normal was set as 10  mm for the body of the gland and 5  mm for each limb as documented by vincent et al . .\nthe type of enlargement , based on subjective evaluation of the adrenal glands , was recorded as either smooth or nodular .\nnodular enlargement was diagnosed if the adrenal gland had an irregular contour , contained nodules , and had normal adrenal tissue interspersed between the nodules .\nsmooth enlargement was defined as enlargement of the gland with a smooth contour and no measureable or diffuse nodules . after obtaining patient history and physical examination , all patients underwent biochemical evaluation to assess their functional status .\npatients with elevated 24-hour urine - free cortisol level ( 2 times ) or those in whom plasma cortisol levels did not decrease after an overnight low - dose dexamethasone test ( 1  mg dst ; cutoff 50 \npatients with an aldosterone - rennin ratio ( arr ) > 20 underwent any 1 of 3 confirmatory tests ( saline infusion , captopril challenge , or postural stimulation ) to confirm or exclude definitively primary hyperaldosteronism ( pa ) .\ncategorical data such as gender and clinical / radiologic features were compared using -test or fisher 's exact test .\nvariables that resulted in a p < 0.05 in the univariate analyses were entered into logistic regression analysis to assess the risk factors of functional lesions .\nthe hospital ethics committee approved this study , and written informed consent was obtained from all patients or their parents .\nof 578 patients with adrenal enlargement , 78 cases ( 13.49% ) were detected incidentally .\nevery 2 years , the numbers of total cases were 17 , 11 , 14 , 24 , 33 , 31 , 54 , 55 , 114 , and 225 , respectively .\nthe numbers of incidental adrenal enlargement cases were 0 , 0 , 0 , 1 , 1 , 2 , 5 , 4 , 16 , and 49 , respectively .\nin addition , the proportion of incidental adrenal enlargement gradually increased ( 0 , 0 , 0 , 4.17% , 3.03% , 7.32% , 9.26% , 7.27% , 14.04% , and 21.33% ) .\n39 cases had unilateral enlargement on the left side and 3 on the right side , and the remaining 36 were bilateral enlargement .\nas shown in table 1 , routine medical checkup was found to have the greatest chance ( 43.59% ) of revealing clinical onsets leading to the discovery of adrenal enlargement .\npredominant complaints included low back pain ( 10.26% ) and abdominal pain ( 3.85% ) . in addition , there were 30 ( 38.46% ) cases in which the lesions were incidentally detected during hospitalization for underlying diseases , such as diabetes mellitus , hypertension , and coronary heart disease , among others . biochemical and functional evaluation revealed that 54 ( 69.23% ) cases were nonfunctional and 12 ( 15.38% ) were subclinical cushing syndrome ( scs ) ; among these patients , 10 cases were diagnosed as aimah , the other 2 were diagnosed as adenomas , and they were all confirmed by pathology results .\nprimary hyperaldosteronism 6 ( 7.69% ) , metastatic 1 ( 1.28% ) , the primary cancer was gastric cancer .\nthere were 5 patients ( 6.41% ) whose functional status remained unclear because of failure to finish the functional evaluation ( figure 2 ) .\nnodular adrenal enlargement ( or 7.306 ; 95% ci , 1.72728.667 ; p = 0.006 ) was the risk factor for functional lesions .\nas outlined above , incidental adrenal enlargement is detected with increasing frequency , most likely due to widespread increase in cross - sectional imaging , and is gradually emerging as a common clinical problem .\nour study shows that the proportion of incidental adrenal enlargement has gradually increased by year .\nmean age at diagnosis was 50.32 years , which is in line with other incidentally detected adrenal findings , namely , adrenal incidentaloma .\nthe increasing age of the general population and a research trend towards more advanced investigations in the elderly population may be contributing to the high detection rate in this age group .\nour results indicate that , for the elderly patients , it is essential to place emphasis on these incidental findings .\n's study   indicated that , of the total 64 patients , of which 40 ( 63% ) were men and 24 ( 37% ) were women , 43 ( 67% ) cases were bilateral enlargement and 21 ( 33% ) cases were unilateral .\nin addition , smooth enlargement was more common , in 53 ( 83% ) cases , and together these statistics reflect the likelihood that adrenal enlargement will be bilateral , smooth , and found in men .\nhowever , our study did not show this tendency , likely because the research goals and thus , study populations , differed between the 2 studies .\n's study aimed to explore prevalence , while the present study aimed to evaluate functional status .\nin addition , patients enrolled in our study were hospitalized at the department of endocrinology . it should be noted that admitting was more or less selective , especially in tertiary referral hospitals , and that economic considerations in parts of china were still a problem .\nclinically , upon discovery of incidental adrenal enlargement , 2 issues arise : functionality and malignancy . in the relevant literature [ 48 ] , adrenal enlargement can result from endocrine disorders , such as adrenocorticotropic hormone- ( acth- ) dependent or independent cushing syndrome , pa , multiple endocrine neoplasia type 1 ( men-1 ) , and congenital adrenal hyperplasia .\nother potential causes include nonfunctional lesions , defined as a radiographic adrenal enlargement without clinical or biochemical manifestations , inflammation , neoplastic processes , obesity , or depression .\n12 patients were found to have subclinical cushing syndrome ( originated from the adrenal gland ) and 6 patients were diagnosed with pa . however , the variety of disease spectrum in the study was only moderate , perhaps due , in part , to the limited number of included cases .\nit is important to note that even though reported prevalence was up to 11.3% , patient referrals to endocrinologists are relatively rare .\nthis is likely related to the poor radiological awareness of this issue and its potential clinical significance .\nthe clinical significance of lesion location and patient gender is smaller . in the present study ,\nacth - independent macronodular hyperplasia ( aimah ) and primary pigmented nodular adrenal hyperplasia often manifest as adrenal hyperplasia . the clinical features of aimah tended to be atypical .\nnodules usually distorted and completely obscured the normal adrenal glands and were characteristically  ginger - like  .\nas for pa , adrenal glands affected by idiopathic hyperaldosteronism ( iha ) may be normal on the ct scan or show nodular changes , and small aldosterone producing adenoma ( apas ) may be interpreted incorrectly by the radiologists as \niha  on the basis of ct findings of bilateral nodularity or normal - appearing adrenal glands [ 1013 ] .\nthus , it is a simple matter to explain why nodular enlargement could be a predictive factor of functional lesions .\nmeanwhile , this also suggests that if incidentally detected lesions were nodular enlargements , evaluating its functional status should be a priority .\nin addition , the present study suggests that lesions on the left side were likely to be nonfunctional .\nin addition , there was only one patient with malignant lesion in the present study , and thus we were unable to analyze incidence of malignancy .\nincidental adrenal enlargement is a frequent radiographic finding and it is accompanied by diverse clinical factors that require proper diagnostic evaluation and management . in functional evaluation ,"}
{"lay_summary": " objectivethe purpose of this study is to propose an innovative method of knowledge transfer that aims to improve health literacy about pediatric infectious diseases prevention in families . \n children have an appreciable role in this scheme.methodsthis study is a before and after trial that has been conducted in hamedan in 2009 . after changing seven infectious disease topics into childish poems , we selected five kindergartens randomly and taught these poetries to the children . teaching process held after a pretest containing 24 questions that examined 103 of parents about mentioned topics . \n the same post - test was given after 4 months of teaching process.findingsthe mean of correct answers to the pretest was 59.22% comparable with 81.00% for post - test ( p<0.00 ) . \n gender and knowledge degree could not change the results significantly . \n assuming one 's correct answers to the questions as his / her knowledge mark , the mean of this variable increased to 5.32 by this method.conclusionthis cost - effective and joyful method had successful results in promoting health knowledge . \n children are able to play an active role in family 's health situation . \n learning within family atmosphere without any obligations makes our scheme a solution for paving the knowledge transferring way . ", "article": "pursuing the goal of improved health literacy requires more alliances between health and education sectors to improve literacy levels in the population .\nit is important for health educators to know about knowledge transfer to meet their needs in transferring their knowledge to public\n. knowledge transfer , which means the synthesis , exchange and ethically application of knowledge within a complex system of relationship among researchers and users , has become one of the recent priorities in research centers . the word \nthe method of knowledge transfer , apart from its characteristics , requires active interactions between researchers and users .\ncaplan proposes the two- communities theory indicating a gap between researchers and policymakers , whereas these days another gap has been formed between researchers and other users .\nin addition to illiteracy in developing countries that hampers effective health education , there are multitudes of non - medical specialists who do not have enough information about daily health affairs , and this lack is more remarkable in countries that welcome immigrants .\nimmigrants often have significant language and health literacy difficulties , which are further exacerbated by cultural barriers .\nalongside with sophisticated methods like computer and internet , using simple methods help us bring to achieve our health goals[68 ] . also , the lack of health literacy needs more attention when it is manifested in caregivers .\nit is believed that some of the undesirable health outcomes in children are because of inadequate health knowledge among caregivers . in the usa ,\ntherefore researchers have considered different methods to come up with this deficiency by having children to cooperate in their health programs .\na research group in india endeavored to transfer knowledge on leprosy in cooperation with children and informed their parents through them .\njacob et al ( 1994 ) started conducting a similar research that yields promising results .\nrimal and flora ( 1998 ) express that parental dietary behavior is partially affected by children .\nthe findings from studies in this field have encouraged other experts to apply similar methods to conduct their research projects , allahverdipour and bashirian , onyango - ouma and mwangagain from the influence of children in order to teach different parts of their society[1316 ] . despite the researcher 's trends in using novel methods in this field ,\nnone of them have used childish poem as a medium for knowledge transferring . in this study\n, we try to raise families health knowledge about infectious diseases by a method that uses children as health agents .\ninfectious diseases are still the leading cause of mortality in children less than 60 months in developing countries .\njuvenile age is accompanied by learning childish poems , which can be sung contnuously at home and potentially become as part of both children 's and parents memories .\nwe decided to transfer health knowledge to families through altering this information to childish poems and teaching children at kindergartens . in this method\nthe outcome of transferring health knowledge through childish poems has been assessed in this study .\nin this study , we use the method of interventional pre and post series to conduct our research .\nthe proposal of this non - invasive project was approved by the research committee of hamadan medical university in january 2009 .\nit was also accepted by hamadan welfare organization , which is the responsible organization of kindergartens in hamadan .\nour methodology is briefly explained as follows . at first , a sub specialist in pediatric infectious diseases provides seven short texts about health and common pediatric infectious diseases prevention .\nthen , a poet transfers these conceptions to childish poems for the first time ( appendix 1&2 ) . in the process of preparing an accurate questionnaire , at first 30 questions with three choices of \n,  false  and  do not know  were made , but 24 items of those are confirmed as valid questions by two experts of health education and infectious diseases . to assess\nthe reliability of the questionnaire a pilot study on a 40 participant sample was performed and cronbach 's alpha of the questionnaire was determined as 83 percent .\nin addition , we defined knowledge mark ( km ) as a parent mark in both the pre - test and/or post - tests . among 35 kindergartens in hamadan , we selected 7 kindergartens by simple random method .\nthe parents ( either father or mother , the one who is responsible to take her / his child ) of all five to six year old children of the selected kindergartens are asked to participate in the survey and a verbal consent is obtained from those who accepted .\nwe excluded the following children from our sample : those whose parents are physicians , nurses , health - care workers , and those children whose parents work at the kindergarten ( exclusion criteria ) .\nwe asked the parents of the sample survey to participate in a pretest by answering to a questionnaire when they are in the kindergartens .\nalso , they were asked to come to the kindergartens personally one more time when it is required ( to answer to the post test ) . then , we asked our kindergarten tutors to teach children seven musical poems about hydatid cyst , antibiotic misuse , botulinum toxin in home - canned foods , dysentery , the importance of sixth tooth , brucellosis and tetanus . in this step , children were not allowed to take home these texts , but they were asked to sing the poems at home and want their parents to re - write the poems on a paper and give them the papers to take to the kindergarten .\nthe teaching stage took between three to four months . during the next stage , parents took a post - test survey with the same 24 questions .\nparents of 115 kids participated in the pre - test and 103 of them completed the post - test .\nstatistical analysis is done on 103 who completed both tests by paired t - test .\nthe sample data consists of 103 parents who provided solutions to both the pre- and post - test question survey . of the participants 77 were female and 26 male . from the level of education point of view\n, 19 were below high school diploma , 45 had high school diploma , 8 had associate degree , 27 had ba , 3 had ma , and 1 had phd .\nthe results of the survey show a significant difference between the correct answers in both pre - test and post - test stages ( fig .\n1 ) . the frequency of correct answers to the tests \n table 1 shows the mean of the correct answers in the pre - test stage is 59.22 while the same figure for the post - test step is 81 ( p < 0.001 ) .\nin addition , we define knowledge mark ( km ) as a parent mark in both the pre - test and/or post - test stages . the mean km shows a significant increase ( 5.01 ) from 13.62 in the pre - test to 18.63 in the post - test ( table 2 ) . \n \nmean percent of correct answers to pre - test and post - test categories \n  analyzed by paired t - test sd : standard deviation mean of knowledge mark in pre - test and post test analysed by paired t - test the difference of km promotion among females and males was not significant ( 21.6120.17 in males and 20.331.61 in females , p=0.8 ) . the km was increased to 19.9325.06 among parents who at most had high school diploma and 23.4720.84 among parents with upper educational levels ( p=0.5 ) .\nhealth has been the concern of poets such as fiona sampson for years , however , these poems never had educational purposes . the results of this study\nconfirm our hypothesis about the role of children in raising family 's knowledge on health .\nthe results show that neither gender nor the grade of knowledge degree ( below and upper high school diploma or below and upper ba ) affect answers .\ntherefore , people with different educational status have received the information similarly implying that this method can be extended to general cases in a straightforward manner . \n\n1 shows that the percentage of correct answers has increased in 23 out of 24 questions .\nthe percent - age of correct answer to post - test has decreased only in one item ( item 11 ) which compares the risk of brucellosis transmission via unpasteurized milk and yogurt . although the term yogurt has not been mentioned directly in the related poem , but there is a hint about boiling mechanism and we expect that the audience discover the answer by logical thinking about the necessitation of boiling milk for preparing yogurt .\nthe decrease in answering is 2 percent which is not significant ; however , it shows that it would be better to mention the conceptions directly in these types of poems in order to avoid any misconceptions .\nmoreover , the percentage of correct answers to the questions of selected topics in pre - test and post - test has been compared ( table 1 ) and shows that parents have done better in post - test about all topics except one .\nthe difference of correct answers to the questions about brucellosis does not show a significant increase in post - test .\nthis finding is probably due to higher basic knowledge about brucellosis among parents . in other words , parents have had acceptable information about brucellosis even without our educational program , so we observe lower contrast between pre - test and post - test about brucellosis\n. it should be taken into consideration that brucellosis is an endemic disease in hamadan and people have been educated in different ways about this disease in recent years . although the lowest contrast between pre - test and post - test correct answers belongs to a question about botulism , the overall assessment shows that parent 's knowledge about this topic has been promoted significantly ( p<0.001 , table 1 ) . the significant difference between the pre - test and post - test km , based on the results of table 2 , is the sign of successful knowledge transfer through childish poems .\nthe researcher 's method is impressively successful ; however , the fact that he mentions that some mothers can not distinguish the semantic difference between information and advice , needs serious attention .\nin addition , since daughters may misunderstand the information , it would be probable to transfer the misconceived information to their mothers and this fact threats the successfulness of study in applying . while , in our study ; firstly , childish poems do not imply sententious , secondly , if the poem is sung wrong , the disturbance in rhythm will be appeared , so the information which is transferred through poems is not at risk of alteration . in evans research ,\nparents get familiar with educated topics with the help of their children in homework assignments designed for asthma management , and are taught about asthma indirectly .\nthe advantage of our study in comparison with evans is that in evans method knowledge transfer brings to bear via homework assignment , while in our study there is no obligation for doing home works , and parents are educated while enjoying their child 's singing . on account of the fact that making communication with younger children is not as difficult as with adolescents for parents , we are sure that knowledge transfers within a family through a continuous and friendly communication will work .\nchristensen expressed the importance of children 's role in promoting the family health status . in his article , he emphasized on the activities that children can perform to enhance their health and promote their family health situation via the health efforts for themselves .\nwe showed that children , additionally to what christensen mentioned , are able to affect their family 's health status directly . they can improve their family 's health as little teachers in health .\nit should be taken into consideration that the limitations of this study was the impact of other media on participant 's knowledge , which was not preventable .\none of the acceptable results of this survey was publishing the poems as a book for children which was republished and welcomed by public .\nthis study 's results suggest that health knowledge transfer to families through childish poems is an applicable method that has many advantages . by applying this joyful , cost - effective and easy - to - use method\nhowever , it should be taken into consideration that this method is applicable for families with trainable children , for teaching in larger scales more general ways should be added to this method .\nmoreover , the simplicity of poems and expressing the topics in a less elaborative form are the key factors that affect the successfulness of this way ."}
{"lay_summary": " introduction : septic arthritis of the shoulder is uncommon in adults . it is a surgical emergency as joint destruction occurs rapidly and can lead to significant morbidity and mortality . \n accurate diagnosis can be particularly challenging in patients with underlying liver disease . \n mri is a useful adjunct in early detection of atypical causes of shoulder pain.case report : a 43 years old male came to our outpatient department with complaints of pain and stiffness of his left shoulder . on examination , \n his shoulder movements were severely restricted . further evaluation with mri revealed septic arthritis of left gleno - humeral joint for which emergency arthroscopic debridement was done.conclusion:septic arthritis of shoulder may not present with classical clinical features . \n hence , a through clinical and radiological evaluation will help us prognosticate and treat accordingly thereby preventing complications like septic shock , osteomyelitis . ", "article": "septic arthritis of the shoulder is uncommon in adults . it is a surgical emergency as joint destruction occurs rapidly and can lead to significant morbidity and mortality .\na 43 years old male came to our outpatient department with complaints of pain and stiffness of his left shoulder . on examination , his shoulder movements were severely restricted .\nfurther evaluation with mri revealed septic arthritis of left gleno - humeral joint for which emergency arthroscopic debridement was done .\nseptic arthritis of shoulder may not present with classical clinical features . hence , a through clinical and radiological evaluation will help us prognosticate and treat accordingly thereby preventing complications like septic shock , osteomyelitis .\npatients with septic arthritis usually develop moderate to severe joint pain , warmth , tenderness , effusion , restricted active and passive motion , and sometimes redness .\nwe report an unusual presentation of shoulder septic arthritis in a 43 years old man with no other clinical signs and symptoms of classical septic arthritis .\na 43-year - old man presented to the orthopaedic outpatient clinic with 2 months history of pain and limited range of motion in his left shoulder .\nhis pain was insidious in onset , mild to moderate in intensity , aggravated by activities and associated with moderate rest and night pain .\npatient was diagnosed as frozen shoulder at an outside facility and had been given intraarticular depomedrol 40 mg injection for the same 40 days ago with no improvement in his symptoms .\nhe is diabetic and has liver cirrhosis and is on treatment . on physical examination ,\nthe skin colour and temperature of the left shoulder were normal , but the shoulder was tender to touch over the anterior joint line .\nmri was obtained [ fig 2 ] which showed extraosseous soft tissue enhancements around left shoulder with soft tissue abscess in inter muscular planes of supraspinatous , infraspinatous , subscapularis .\nblood test revealed normal white cell count with normal differential count , crp-13.4 mg / l ( normal<5.0 mg\nthe erythrocyte sedimentation rate was raised , at 88 mm / hour ( normal range , 0 - 20 mm / hour ) aspiration of shoulder joint was performed and fluid was sent for aerobic and anaerobic culture , afb staining , mycobacterium culture , and mycobacterium genetic testing .\narthroscopic lavage of the joint was done and articular fluid sent for repeat aerobic and anaerobic culture .\njoint visualization was markedly limited because of severe inflammation and fibrinous changes of the joint .\nthe articular cartilages of glenoid and humeral head were completely eroded down to the bone .\nsusceptibility of the isolate was determined with the disk diffusion method and it was susceptible only to colistin .\n3 ) fibrocollagenous and fibrovascular inflammed connective tissue containing proliferated blood vessels and perivascular mixed inflammatory cells and lymphoplasmacytoid cells .\nbased on preoperative and intraoperative culture report , a definitive diagnosis of polymicrobial septic arthritis of the shoulder was established and patient was treated with combination antimicrobial treatment .\nour patient had muted inflammatory response probably due to immunocompromised state ( cirrhosis and diabetes ) which is not uncommon .\nmost often it is hematogenous seeding of shoulder joint , however it can also happen after intraarticular steroid injections .\nseptic arthritis of the shoulder is more common in immunocompromised patients and intravenous drug abusers . in this case report , the patient had atypical clinical symptoms and is immunocompromised and his primary source of infection seems to be hematogenous .\nour experience with this patient highlights the importance of maintaining high index of suspicion for septic arthritis in immunocompromised patients presenting with atypical shoulder pain associated with stiffness . in the setting of suspected septic arthritis ,\nour initial pre - investigation diagnosis was atypical shoulder pain and stiffness of non specific etiology in an immunocompromised patient and infection was part of the differential diagnosis not the only diagnosis .\nesenwein et al in his report highlighted the importance of early intervention to prevent chondral damage , osteomyelitis and also to prevent systemic spread .\nvarious authors have highlighted the importance of early diagnosis and management of septic arthritis failing which could lead to osteomyelitis and septic shock . in our patient\n, the diagnosis was delayed due to atypical presentation and over reliance on clinical findings at an outside center .\nwe strongly recommend early imaging studies in immunocompromised patients presenting with shoulder pain and practitioners should avoid loosely diagnosing as shoulder pain with associated stiffness as frozen shoulders .\nklinger et al . did a retrospective study on 21 patients who underwent surgical treatment for septic arthritis of the shoulder joint between 2000 and 2007 , and he concluded that patients with symptoms for less than 2 weeks did well with arthroscopic approach and early infection can be managed arthroscopically .\nour reports show that arthroscopic washout can give good result even after 2 weeks of clinical symptoms if there is no evidence of osteomyelitis .\nseptic arthritis of the shoulder is very often due to hematogenous spread and diagnosis is often clinical .\nlaboratory investigations and imaging studies like mri and usg may be useful in establishing the diagnosis but confirmation is usually by joint aspiration .\npatients who are immunocompromised and have insidious onset of moderate to severe pain and which fails to respond to trial of conservative treatment should be subjected to either ultrasound or mri instead of x - ray because very often in these group of patients it is primarily a soft tissue pathology like impingement , rc tear , calcific tendinitis or rarely infections and malignancies .\nwe recommend that moderate pain of more than 4 weeks duration with severe stiffness in immunocompromised patient ( liver cirrhosis , renal failure , steroid treatment ) should be further evaluated with mri or ultrasound in the setting of normal x - ray and should not be loosely diagnosed as frozen shoulder .\ngoldenberg in his report emphasized the role of local as well as systemic factors that predispose patients with cirrhosis to gram - negative bacterial joint infections .\nmalnick also reported a case of spontaneous septic arthritis in a cirhottic patient that was due to e.coli .\nour study as well as other studies by goldenberg and malnick highlight the importance of including broad spectrum antibiotics with gram negative cover whilst waiting for final culture sensitivity .\nseptic arthritis of shoulder may not present with classic clinical features . a through clinical and radiological evaluation should be executed and treatment initiated promptly to prevent complications like septic shock and osteomyelitis .\nthe case highlights the importance of establishing anatomical and pathological diagnosis using mri in patients with shoulder pain instead of loosely diagnosing them as impingement or frozen shoulder .\nthe case also challenges the practice of routine shoulder depomedrol steroid injection , in the setting of secondary frozen shoulder , atleast in immunocompromised individuals .\nprimary idiopathic frozen shoulder is a rare condition and secondary frozen shoulder cases are often due to underlying shoulder pathology ."}
{"lay_summary": " biliary complications continue to be a major cause of morbidity after split - liver transplantation ( slt ) . in this report \n we describe an uncommon late biliary complication . \n one year after slt the patient showed an intrahepatic bile dicy dilatation with severe cholangitis episodes . \n the segmentary bile duct of hepatic segment vi - vii draining in the left duct was unidentified and tied at the time of the in situ split - liver procedure . \n we perform a permanent obliteration of the dilated intrahepatic ducts by a percutaneous embolization using an n - butyl cyanoacrylate ( nabc ) . the management of biliary complications after slt requires a multidisciplinary approach . \n the use of   nbca in obliteration of a dilated bile duct seems to be a safe procedure with good results providing a less invasive option than hepatic resection and decreasing the morbidity associated with chronic external biliary drainage . \n further studies are needed to determine   whether this approach is effective and safe and whether it could reduce hospital stay and cost . ", "article": "split - liver   transplantation ( slt ) is an   attractive alternative procedure to expand the donor pool in patients waiting for liver transplantation .\nthe standard split - liver procedure for a child and an adult ( adult / pediatric split liver ttransplantation , a / p slt ) , by splitting segment ii - iii for pediatric recipient and segment i - iv - v - vi - vii - viii for an adult , is an accepted surgical option with good results both for the adult and for pediatric recipient .\nbiliary complications continue to be the major cause of morbidity after slt with a reported high incidence ranging between 10% and 32% [ 1 , 2 ] . as a consequence of bile duct anatomic variations\n, slt requires a precise knowledge of the liver anatomy [ 3 , 4 ] .\nthe challenge of this procedure is represented by a preoperative radiological assessment of the biliary anatomy often unavailable at the donor 's hospital .\nthus the risk of biliary duct injury during the splitting procedure is usually considered higher than during living donor procedure .   in this report\nwe describe an uncommon late biliary complication that occurred after slt and was successfully treated by a multidisciplinary approach .  \na 63-year - old male with hepatitis c - related cirrhosis was referred for liver transplantation to our institution .\nwe performed a conventional a / p slt with in situ technique providing the left lateral segment for a child ( segments ii - iii ) and leaving the right lobe graft ( segment i - iv - v - vi - vii - viii ) for an adult recipient .\nthe celiac trunk was left on the left graft while the right hepatic artery remained on the right graft .\nthe patient was transplanted using the piggy - back technique without a veno - venous bypass .\nthe biliary tract was reconstructed performing a duct - to - duct anastomosis using a t - tube by our standard technique previously described .\na cholangiography through the t - tube was performed on postoperative day 14 , and the t - tube was clamped before patient discharge .\nthree months after a / pslt the t - tube was removed after a cholangiography with normal findings .\none year after transplant the patient showed abnormal liver function tests , hyperbilirubinemia , leukocytosis , and elevated g - glutamyl transpeptidase ( ggt ) , and mild elevation in alanine transaminase ( alt ) .  \nthe patient underwent a doppler ultrasound that showed ( a patent hepatic artery )   an intrahepatic bile duct dilatation and an anastomotic biliary stricture .\nthe anastomotic stricture was treated by stenting the main biliary duct during an endoscopic retrograde cholangiopancreatoghaphy ( ercp ) without any evidence of intrahepatic biliary dilatation .\nafter this procedure the patient was submitted to a percutaneous transhepatic cholangiography ( ptc ) showing a complete obstruction of segments vi and vii biliary branches near the duct - to - duct biliary anastomosis ( figure 1 ) .  \nthe patient was discharged leaving the external biliary drain open allowing bile drainage and an easy access for repeated radiologic treatment and an internal stent in the common bile duct .\nthree months later the patient underwent a surgical revision because of repeated episodes of cholangitis . during surgery\nan intraoperative cholangiography was performed through the biliary drain   confirming a bile duct dilatation at the level of segments vi and vii .  \nit was impossible to cross the biliary stricture by a torque catheter and by hydrophilic guide wire ( figure 2 ) .\nwe supposed that the segmentary bile duct branch of   posterior segments vi and vii draining in the left bile duct was unidentified and tied at the time of the in situ split - liver procedure during the parenchymal transection .\na primary biliary reconstruction by biliary repair or biliodigestive anastomosis was considered at high risk because of the presence of postsurgical   adhesions   sand due to fibrotic tissue replacing   the parenchymal transected area . a liver resection of the dilated segments vi and vii was considered at high risk of leaving an inadequate liver mass .  \nwe decided to perform a permanent intraoperative obliteration of the dilated intrahepatic ducts by a percutaneous embolization using a nonresorbable agent . with a fluoroscopic guidance through the transhepatic access we positioned a 5-french polyethylene catheter inside the ducts , preliminary flushed by a nonionic dextrose solution .\nwe then injected the tissue adhesive agent n - butyl cyanoacrylate ( nbca , glubran 2 , gem , viareggio , italy ) mixed with ionized oil ( lipiodol , guebert , aulnay - sous - bois , france )   for opacization in a ratio of 1:5 .\nthis solution completely filled the biliary duct , and the occlusion was totally accomplished in a few seconds ( figure 3 ) . during the first 3 days after the chemical bile duct embolization , the patient had a low fever with a slightly abnormal liver function test .\na computed tomography ( ct ) scan performed 6 months later showed no sign of hepatic abscesses , and the bile duct dilatation was completely occupied by the nbca - lipiodol mixture .\none year after the procedure patient showed normal liver function tests without no episodes of cholangitis .\nchemical bile duct embolization treatment could represent a valuable   solution to treat uncommon biliary complications .\nthese tissue adhesive glues are low - viscosity liquid monomers that undergo rapid polymerization and solidification when they come into contact with organic fluids such as bile .\nnbca is a permanent liquid embolic material that produces long - term occlusion in vessels of various size through an inflammatory tissue response resulting in vessel thrombosis or tissue   atrophy .\nlittle is known about the use of cyanoacrylate compounds , and unlike european countries   the use of glubran has not been approved by the food and drug administration yet .  \nother authors have described the efficacy of biliary duct ablation by nbca in patients with persistent postsurgical bile leaks after lobectomy or cholecystectomy .\nvu et al . treated six patients with persistent postsurgical bile leaks as a complication after hepatic lobectomy or cholecistectomy using nbca glue for the obliteration of isolated segmental bile ducts in four cases .\nendoscopic treatment of biliary leakage by nbca has been described by seewald in nine patients in whom primary stent placement or nasobiliary drain was unsuccessful .\ndescribed the use of a cyanoacrlylate in the treatment of a pancreatic fistula after distal pancreatectomy .\nthe percutaneous interventional technique represents an effective valuable approach to reduce mortality and morbidity in the treatment of biliary complications after liver transplantation .\nthe use of nbca in obliteration of a dilated bile duct seems to be a safe procedure with good results providing a less invasive option than hepatic resection above all in high - risk patients with posttransplant bile duct injuries , decreasing the morbidity associated with chronic external biliary drainage .\nfuther studies are needed to determine whether this approach is effective and safe and whether it could reduce hospital stay and costs ."}
{"lay_summary": " ribonucleotide reductase ( rr ) , the rate limiting enzyme in the synthesis and repair of dna , has been studied as a target for inhibition in the treatment of cancer for many years . \n while some researchers have focused on rr inhibitors as chemotherapeutic agents , particularly in hematologic malignancies , some of the most promising data has been generated in the field of radiosensitization . \n early pre - clinical studies demonstrated that the addition of the first of these drugs , hydroxyurea , to ionizing radiation ( ir ) produced a synergistic effect in vitro , leading to a large number of clinical studies in the 19701980s . \n these studies , mainly in cervical cancer , initially produced a great deal of interest , leading to the incorporation of hydroxyurea in the treatment protocols of many institutions . \n however , over time , the conclusions from these studies have been called into question and hydroxyurea has been replaced in the standard of care of cervical cancer . over the last 10  years \n , a number of well - done pre - clinical studies have greatly advanced our understanding of rr as a target . \n those advances include the elucidation of the role of p53r2 and our understanding of the temporal relationship between the delivery of ir and the response of rr . at the same time \n , new inhibitors with increased potency and improved binding characteristics have been discovered , and pre - clinical and early clinical data look promising . here \n we present a comprehensive review of the pre - clinical and clinical data in the field to date and provide some discussion of future areas of research . ", "article": "ribonucleotide reductase ( rr ) inhibitors have been studied as radiation sensitizers for over 30  years in both the lab and the clinic .\nthe first of these , hydroxyurea , has been studied in both cervical and head and neck cancers , among others .\nalthough initially promising , many of the clinical trials produced negative results , or those that were difficult to interpret . there has recently been a significant advance in our understanding of this pathway from a number of well - done pre - clinical studies .\nin addition , the discovery of new rr inhibitors with increased potency and improved binding characteristics has produced a significant increase in interest in this area .\nthis review will synthesize the data detailing the response of rr to ionizing radiation ( ir ) and will provide a perspective on the use of rr inhibitors as radiosensitizers in the treatment of human cancers . over the years , many groups have explored the use of rr inhibitors as chemotherapeutics in their own right , or as adjuncts to dna damaging molecules , particularly in hematologic malignancies . while this area looks promising , this subject will not be reviewed here .\nribonucleotide reductase is the rate limiting enzyme in the synthesis and repair of dna and is the only enzyme responsible for the conversion of ribonucleoside diphosphates to deoxyribonucleotide diphosphates , the fundamental building blocks of dna synthesis and repair .\nr1 ( also called rrm1 or m1 ) is the larger , regulatory subunit that is constitutively expressed throughout the cell cycle .\nit binds allosteric modulators , ribonucleoside diphosphates , and the nucleoside analogs gemcitabine and fludarabine .\nthere are currently two known smaller subunits that bind r1 to form the active enzyme ; r2 ( also called rrm2 or m2 ) and a more recently discovered p53 inducible homolog of the r2 subunit , known as p53r2 .\nboth contain a tyrosine free radical stabilized by a non - heme iron complex that is critical in the reduction of ribonucleotides .\nr2 is known to be cell cycle regulated , with the highest levels during s phase , however the precise roles of the r2 and p53r2 subunit in the response to ir are an area of active debate , as outlined below ( figure 1 ) .\ngiven the pivotal role of rr in dna synthesis and repair , many studies have investigated the effect of dna damaging agents , including ir , on rr and its subunits .\neven so , there is currently still a great deal of controversy surrounding the exact mechanism of rr response to ir .\nthe first is that the small subunit r2 is up - regulated and provides dntps for dna repair in addition to its usual role in dna synthesis during s phase .\nthis is supported by a number of studies , including one by kuo et al . , who characterized the response of rr in the human cervical cancer cell line , caski .\nthey demonstrated an increase in r2 protein levels after treating cells with ir , which was correlated with an increase in rr activity .\nhowever , there was no increase in the transcription of r2 , implying that the protein increase was due to post - transcriptional regulation ( kuo and kinsella , 1998 ) .\nthis finding was reinforced by studies that demonstrated dna damage dependent stabilization of the r2 protein without any change in mrna after ir exposure in mouse balb/3t3 cells ( chabes and thelander , 2000 ) ; however it was in contrast to earlier work showing transcriptional activation of the r1 and r2 promoters after exposure to ir in the same cell line ( filatov et al . , 1996 ) . even though the precise mechanism of r2 response to ir damage is unclear , work has shown that human nasopharyngeal cancer cells overexpressing r2 demonstrate a significant increase in radioresistance and fewer dna double strand breaks ( dsb ) after exposure to ir ( kuo et al . , 2003 ) , confirming the concept that r2 is important in the cellular response to ir\nthe second theory involves the p53 inducible subunit , p53r2 , first reported by tanaka et al .\nthey showed that p53r2 was not cell cycle regulated ( unlike r2 ) , but was significantly induced after exposure of normal fibroblasts to ir ( tanaka et al . , 2000 ) and was found to translocate to the nucleus , the proposed site of most important dntp production ( r2 did not ) . in cells that lacked wild - type ( wt ) p53 ,\nthere was no induction , indicating that functional p53 was necessary for p53r2 up - regulation .\ncells transfected with p53r2 were resistant to dna damage induced cell death . in agreement with other studies , they found no increase in r2 mrna , but did not measure protein levels .\nadditional studies have subsequently shown that p53r2 forms an active complex with r1 ( guitett et al . , 2001 ) and\nrr activity increased in correlation with the increase in p53r2 , however the response of r2 was variable , with decrease in some lines and a moderate increase in the others ( yamaguchi et al . , 2001 ) .\nfinally , other models are possible , including one described by xue and colleagues . in their study , both subunits were found to bind p53 in human oropharyngeal carcinoma cells , and in response to ir , were released to bind r1 in the nucleus ( xue et al . , 2003 ) , highlighting a third possibility in contrast to those previously presented .\nclearly , there is still work to be done in elucidating the response of rr to ir .\nmany of the differences seen in the studies discussed can likely be attributed to the use of different techniques , materials , and especially cell lines .\nwhat should be clear is that rr is involved in the cellular response to ir and targeting it is both rational and likely desirable in enhancing the treatment of cancers with ir .\nit is likely that both r2 and p53r2 are involved to a different degree in different cancers , with cellular phenotype likely playing a key role in determining their relative significance .\nhydroxyurea ( hu ) is a hydroxylated analog of urea and was the first rr inhibitor to be extensively studied .\nit has directed activity at the tyrosine radical moiety of r2 and was first found to be active against cancer cells in 1963 ( stearns et al . , 1963 ) .\nsubsequent experiments in vitro showed that in addition to its direct inhibition of dna synthesis , it was also a sensitizer of cell killing by x - rays , particularly if given before or after ir ( sinclair , 1968 ) .\nlater experiments showed that this was also the case in in vivo animal tumor models using isotransplants of spontaneous c3h / he mouse mammary carcinomas ( piver et al . , 1972 ) .\nthe total dose of ir to cure 50% of tumors was reduced when hu was combined with fractionated ir , although this effect was nt seen with single fraction ir treatments . given these encouraging pre - clinical results during the 19601970s ,\nhu was subsequently examined in a number of clinical trials in a variety of human cancers .\nthe majority of these trials have occurred in cervical cancer , most commonly in locally advanced disease . in particular , there were a number of prospective randomized controlled trials in the 1970s and 1980s that examined the effect of hu plus radiotherapy vs. radiotherapy alone .\nand the gynecologic oncology group ( gog ) enrolled 190 women with figo stage iiib or iva cervical carcinoma .\nhu was administered orally at 80  mg / kg starting on the first day of irradiation and every 3  days thereafter for 12  weeks .\npatients received at least 50  gy minimum tumor dose to the whole pelvis followed by a single brachytherapy treatment of 20  gy to point a. in spite of the large number of patients enrolled , only 90 were eligible for assessment of response .\nthis was due to ineligibility ( wrong stage , wrong cell type , etc . ) and those that were inevaluable ( refused treatment , periaortic node irradiation , improper field , etc . ) .\nthe data were impressive , with a complete response ( cr ) of 68.1% in the hu group vs. 48.8% in the placebo ( p  =  <  0.05 ) , and a median progression free survival ( pfs ) of 13.6 vs. 7.6  months ( hreshchyshyn et al . , 1979 ) . however , myelosuppression was more common in the hu group , with seven grade iii or iv myelotoxicities .\nthey recruited 148 women with figo iib or iiib cervical carcinoma and again compared hu to placebo in the setting of conventional radiotherapy , with hu given every 3  days for 12  weeks .\nof the stage iib patients , 74% receiving hu had no evidence of disease at the completion of therapy compared with 43.5% of the placebo ( p  =  <  0.01 ) .\nof the stage iiib patients , the cr rates were 52.5 vs. 33% ( p  =  0.22 ; piver et al . , 1977 ) .\nagain , 78% of patients in the hu group developed leucopenia vs. 11% in the placebo group indicating a significant toxicity in addition to the improved clinical effect . at the time these studies were published\n, it was felt that hu added significant benefit to the treatment of locally advanced cervical carcinoma , and hu plus radiotherapy became the standard of care for the gog .\nhowever , over time , much of the data in these studies has been challenged , particularly in a systematic review by symonds et al .\nthey found a number of methodological problems with the studies such as small sample size , large numbers of exclusions post randomization , subgroup analyses of already small groups and questionable censoring .\nthey concluded that hu  appears to add to acute toxicity and probably increases late complications  and that  there is no convincing evidence of sufficient quality to suggest a therapeutic effect of this drug \nalthough the gog initially used hu as its standard of care in the treatment of locally advanced cervical cancer , it was nt long before this combination was supplanted by a new adjunct to radiation therapy . one of the most important studies prompting this paradigm shift was the gog 120 trial , first reported in 1999 ( rose et al . , 1999 ) and recently updated ( rose et al . , 2007 ) .\ngog 120 was a randomized phase iii study comparing cisplatin alone vs. cisplatin , fluorouracil , and hu vs. hu alone , in conjunction with pelvic irradiation for patients with locally advanced cervical cancer and pathologically negative para - aortic nodes .\nthey reported a significant improvement in pfs and overall survival ( os ) in both cisplatin containing arms ( p  <  0.001 ) , with relative risks for progression of disease or death of 0.57 and 0.51 for cisplatin alone and cisplatin , fluorouracil and hu , respectively , when compared with hu alone . in addition , toxicities were similar in all groups .\nfurther , a similar study by whitney et al . compared the efficacy of standard radiotherapy ( rt ) plus hu with standard rt plus fluorouracil ( 5-fu ) and cisplatin in a randomized controlled trial . in 368 women with figo stage iib , iii , or iva cancer of the uterine cervix , there were significant improvements in pfs and os with the 5-fu and cisplatin combination ( whitney et al . , 1999 ) .\nadverse effects included leucopenia : 4% of 5-fu / cisplatin patients and 24% of hu patients experienced grade iii or iv toxicity .\ngiven the findings of these studies , concurrent cisplatin and radiotherapy became the standard of care in locally advanced cervical cancer , spelling the end of hu use in the treatment of cervical cancer .\nin addition to its study in cervical carcinoma , hu has also been extensively investigated in other cancers , particularly head and neck .\nwhile early studies had significant flaws in methodology , a phase i study showed a 90% response rate in patients treated with hu , 5-fu , and palliative dose fractionated ir ( vokes et al .\n, 1989 ) , prompting a series of trials by the same group and others .\nthis included work by mantz et al . , who examined the benefit of hu when added to a more extensive chemoradiation protocol including cisplatin , 5-fu , leucovorin , and interferon-2b induction chemotherapy followed by 5-fu and hu with fractionated radiotherapy in 32 laryngeal cancer patients .\nmedian follow up was 44.5  months , and , after completion of all therapy , the cr rate was 94% .\nmedian os was 44.5  months , and median pfs was 86 , 78 , and 78% at 1 , 3 , and 5  years , respectively , which compared favorably with other published data and for the first time saw patients with stage iv head and neck cancer failing distantly more often than locally ( mantz et al .\nthe increased local control , unfortunately , was associated with increased toxicity , which has also been seen in other studies .\none phase i study with prolonged infusion of hu with hyperfractionated , accelerated , external radiation in patients with advanced squamous cell cancer of the head and neck showed an increase in the severity of swallowing toxicity compared with previous trials , with severe edema , and reductions in motility and mobility of pharyngeal and laryngeal structures ( beitler et al . , 1998 ) .\nthe same group later published a study examining the long term impact on swallowing that showed persistent , severe swallowing dysfunction ( smith et al . , 2000 ) .\ninterestingly , these studies examined continuous hu infusions based on pre - clinical data that suggested that hu should always be given concurrently with ir to maximize effect . even though local control was excellent , with just 4 of 26 patients experiencing recurrence ,\nquality of life is of great importance in these patients , and the late follow up reported esophageal strictures for the first time after chemoradiotherapy , suggesting that this particular regimen may be too aggressive .\nthe state of hu in head and neck cancer is well reviewed by argiris et al .\n( 2003 ) and while the authors are optimistic about the future of chemoradiation in head and neck cancer , it remains to be seen where hu and other rr inhibitors will fit in the future treatment of this disease site . even as hu has slowly progressed in the clinic\n, work has continued on examining the mechanism by which it sensitizes cells to the effects of ir . in particular , work by kuo et al .\nhas shown that the sequence with which cells are treated with hu plays an important role .\nthey demonstrated that in the caski cervical cancer cell line , clinically relevant concentrations of hu had a significant interaction with ir , with post - ir exposure  >  pre - ir ( kuo et al . , 1997 ) .\nthis was associated with increased g2 delay , suggesting a decrease in the repair of damaged dna .\nin addition , in cells overexpressing the r2 subunit , hu is able to return ir sensitivity to baseline ( kuo et al . , 2003 ) , demonstrating that r2 inhibition is the likely mechanism for hu radiosensitization in these cells .\nthese findings are potentially informative about the failure of hu to become established as a radiosensitizer in cervical cancer . in the majority of the early trials ,\ngiven that hu works best in vitro when dosed immediately after ir exposure , one could conclude that these trials were not optimized for best effect .\nin addition , hu has recently been shown to have a significant effect on the mechanism of dna dsb repair employed by cells after exposure to ir .\nburkhalter et al . showed that cells pre - incubated with hu were unable to use homologous recombination ( hr ) to repair dsb , and instead relied on non - homologous end joining ( nhej ) .\nin addition , cells that were nhej deficient had significantly more dsb after hu treatment ( burkhalter et al . , 2009 ) .\ngiven that nhej is thought to be the dominant dsb repair mechanism in cells treated with hu , rr inhibitors are likely to have enhanced activity in tumors that are nhej deficient .\neven with new studies on its mechanism of action , hu will likely remain consigned to history due to the many inadequacies it has as a drug molecule .\nwhile its oral absorption is almost complete and it is completely distributed in the water compartments of the body , hu has a short half - life ( between 1.6 and 4.45  h ; gwilt and tracewell , 1998 ) and its effectiveness is limited by relatively low affinity for rr and by the development of resistance .\none area where it could potentially find use in the future is in cns neoplasms , as it does cross the blood \nrecent studies have examined its use in progressive meningioma in combination with 3d - conformal radiotherapy and adjuvant chemotherapy . in one trial ,\npfs at 1 and 2  years was 84 and 77% , which is similar to other adjuvant studies ( hahn et al .\nin spite of the mixed clinical data for hu , there is sufficient proof of concept to suggest that a rr inhibitor can be efficacious as a radiosensitizer in human cancers .\nthus , there has been a concerted effort to discover more potent molecules with more favorable pharmacokinetics and pharmacodynamics for this purpose .\none of the more promising of these is triapine , a thiosemicarbazone that destroys the tyrosyl radical in r2/p53r2 by forming a redox active complex with iron , producing reactive oxygen species . in studies comparing it with hu in vitro\n, triapine was shown to have significantly higher potency in both enzyme and cell assays .\nin addition , it was fully active against hu and gemcitabine resistant cells and was equally potent against r2 and p53r2 , whereas hu was approximately threefold less potent at binding p53r2 ( zhu et al . , 2009 ) .\nin addition , in in vivo models , triapine was active against hu resistant l1210 and kb cell lines and caused significant inhibition of solid tumor growth in mouse xenograft models ( finch et al .\nfurther studies have examined the radiosensitizing properties of triapine in a number of human cell lines .\nused a panel of three human tumor cell lines , including glioma , pancreatic , and prostate cancer cells , with triapine enhancing radiosensitivity when delivered 16  h before or immediately after ir by 1.5- to 2-fold .\nir interaction was associated with a reduction in the repair of dna dsb as evidenced by a persistence of h2ax foci at 24  h ( barker et al . , 2006 ) .\na similar effect was seen in mouse tumor xenografts , again , with greater effect if triapine was dosed just after ir .\nthe most effective temporal relationship between triapine dosing and ir is similar to that seen with hu in earlier pre - clinical studies .\ninterestingly , normal human fibroblasts were only sensitized when triapine was given before , not after ir , suggesting a potential for an improved therapeutic index for ir  triapine sequencing that may be incorporated into future clinical studies .\nare ic50 ( concentration of compounds producing 50% inhibition of recombinant rr activity ) values for both compounds in an in vitro rr activity assay with r2 or p53r2 bound to r1 ( zhu et al . , 2009 ) .\nalso shown are elimination half - lives ( t1/2 ) for both compounds ( gwilt and tracewell , 1998 ; kunos et al . ,\n2010b ) . of note , many cancers have virally or mutationally silenced p53 that allows rr activity to continue unchecked . in these cancers , it is potentially of increased importance to inhibit the r2 and p53r2 subunits that have lost p53 regulatory control .\nthis is the case in cervical cancer , where the vast majority have dysfunctional p53 due to hpv infection . in one study , three cervical cancer cell lines with mutated or dysfunctional p53\nwere irradiated 6  h after triapine exposure . in all cases , the cell lines were sensitized to ir and sustained dna damage as measured by persistence of h2ax foci . in addition , by measuring dctp levels , the investigators were able to show reduced rr activity in cells with and without functional p53 , demonstrating that the inhibition of rr is p53 independent ( kunos et al . , 2009 ) .\nthese findings were reinforced by further work of the same group that also showed a synergistic effect when cisplatin was added in addition to triapine and ir ( kunos et al . , 2010a ) .\nthese promising pre - clinical data have prompted the initiation of a number of clinical trials .\nindeed , triapine has so far been studied in 27 clinical trials in the usa at various stages of recruitment ( www.clinicaltrials.gov ) , including those in both solid and hematologic malignancies .\nin particular there are three trials investigating the radiosensitizing potential of triapine , with data from one phase i study being published by kunos et al .\nthe purpose of their study was to assess the safety / tolerability , pharmacokinetics , and clinical activity of triapine three times weekly in concert with once weekly cisplatin and pelvic radiation in 11 patients with gynecologic malignancies .\ntriapine was dosed in 2  h infusions and the half - life was found to be 2  h. all 10 patients with advanced stage ib to ivb cervical cancer achieved complete clinical response , with a median 18  month follow up showing no disease progression in any of the patients .\nfive of the 10 patients had pet / ct evident pelvic or para - aortic lymphadenopathy before treatment , with complete resolution on follow up imaging after treatment ( kunos et al .\nin addition to the clinical data , the authors also examined objective markers of disease response .\nlate responders had a significantly higher rr activity on day 10 vs. day 1 and there was no temporal change in rr activity in the early responders , indicating that the expected spike in rr activity after ir was suppressed by triapine .\nthe fact that the late responders experienced durable responses in spite of elevated rr activity at day 10 suggests that there may be other mechanisms of triapine activity that require further study .\nthe promising results from this phase i trial prompted a phase ii trial which is now underway .\nover the last 10  years , there have been a number of major leaps forward in the field of radiation oncology that allow us to deliver higher doses of radiation in ever more specific ways to our patients .\nstill , in the vast majority of cases , we are constrained by dose limiting toxicities that must be accounted for when designing treatment plans and balanced against the therapeutic benefit realized .\ntherefore , the field of radio modulation and specifically radiosensitization will continue to grow in importance in the coming years as we search for ways to maximize the therapeutic index of our treatments .\nwhile there are many different radiosensitizers currently being studied , the rr inhibitors are among the oldest of targets , and are getting a new lease of life in recent times with the development of more modern drug molecules .\nas outlined in the review above , the story began with the study of hu in combination with ir in a number of pre - clinical trials in the 1960s , leading to a large amount of interest in the clinic , culminating with the gog adopting hu and ir as its standard of care in locally advanced cervical cancer . while its success in this arena was short\nlived , many parallel studies investigating the mechanism of action of hu were carried out , resulting in a far clearer understanding of the biological interactions between ir and rr inhibitors .\neven as hu was fading from view , investigators were working on successors including the intriguing molecule , triapine .\nas shown above , this drug works in a similar fashion to hu , but has significantly improved potency , pharmacokinetics , and pharmacodynamics .\nthe phase i study in cervical cancers that was recently published includes some very encouraging data , and the field waits in anticipation for the publication of further trials .\nit remains to be seen what the best dosing regimen for triapine will be , however the weight of pre - clinical data , including that with hu , suggests that daily dosing shortly after radiation therapy will be most effective and provide the greatest therapeutic window .\nthese authors would encourage studies incorporating this type of dosing schedule in the clinic , although this must obviously be weighed carefully against the potential for increased toxicity .\nin addition to triapine , there are other new rr inhibitors being tested at various stages , including trimidox and motexafin gadolinium .\n( 1994 ) , in a paper that reported 100-fold more potency at rr than hu in a cell based assay .\nsubsequent in vitro studies have demonstrated that while it acts as a radiosensitizer in panc-1 human pancreatic cancer cells ( ahmed and hassan , 2000 ) , it is less potent than hu and further work is ongoing to fully assess its potential .\nmotexafin gadolinium is a texaphyrin molecule that targets thioredoxin reductase in addition to rr . in in vitro experiments , it was shown to inhibit rr with an ic50 of 26  m ( hashemy et al . , 2006 ) , although given that it has a number of other cellular effects , it is unclear how much of its potency as a radiosensitizer is due to rr inhibition alone .\nit is likely that the coming years will continue to see the emergence of new rr inhibitors with unique properties .\nthe recent advances in the understanding of rr biology and the development of new inhibitors places us at an important crossroads in the story of rr inhibitors .\nthere are sufficient data to provide proof of concept for the target from a biological standpoint , however clinical trials to this point have not been wholly convincing .\nit will be interesting to follow the development of the field in the next 510  years , particularly with the clinical trials of triapine in cervical cancer , and hopefully at least one of the many rr inhibitors being studied will eventually bring additional therapeutic benefit to patients in the near future .\nthe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest ."}
{"lay_summary": " investigation of the bone and the bone marrow is critical in many research fields including basic bone biology , immunology , hematology , cancer metastasis , biomechanics , and stem cell biology . despite the importance of the bone in healthy and pathologic states , however , it is a largely under - researched organ due to lack of specialized knowledge of bone dissection and bone marrow isolation . \n mice are a common model organism to study effects on bone and bone marrow , necessitating a standardized and efficient method for long bone dissection and bone marrow isolation for processing of large experimental cohorts . \n we describe a straightforward dissection procedure for the removal of the femur and tibia that is suitable for downstream applications , including but not limited to histomorphologic analysis and strength testing . \n in addition , we outline a rapid procedure for isolation of bone marrow from the long bones via centrifugation with limited handling time , ideal for cell sorting , primary cell culture , or dna , rna , and protein extraction . \n the protocol is streamlined for rapid processing of samples to limit experimental error , and is standardized to minimize user - to - user variability . ", "article": "the study of long bones and the cells of the bone marrow is central to a myriad of research disciplines , including , but not limited to , bone biology , cancer biology , immunology , hematology , and biomechanics .\nthe bone is a highly dynamic organ that together with the cartilage forms the skeleton to provide mechanical support against loading and protection of the internal organs .\nin addition , the mineral components of bone are a storage sink for the critical signaling molecules calcium and phosphorus , as well as other factors .\nfinally , bones house the bone marrow and , together with metabolically active bone forming osteoblasts and bone resorbing osteoclasts , provide the stem cell niche necessary for the maintenance of hematopoietic and lymphoid cell populations .\nbone and bone marrow are affected in many disorders , often leading to bone marrow dysfunction , severe bone pain , and pathologic fracture .\nbone is a common site of metastasis in many solid tumors , most notably breast cancer and prostate cancer , where tumor cells directly engage the bone marrow niche to initiate the vicious cycle of bone metastasis and displace hematopoietic stem cells .\nhematopoietic malignancies including myeloma and leukemia are characterized by bone marrow dysfunction as well as deregulation of healthy bone remodeling .\nother non - malignant skeletal disorders are also active areas of research , such as osteoarthritis , osteoporosis , scoliosis , and rickets . even in an otherwise healthy individual , biomechanical failure in a bone\nall of these disorders represent active areas of research with the goal of identifying new preventative measures and treatment regimens to reduce morbidity and mortality . to research the plethora of roles of the bone and the bone marrow , both under physiologic and pathologic conditions\n, it is critical for researchers to have a simple and efficient standardized method for dissection of the mouse long bones for rapid processing of large in vivo experiments .\nthe dissection protocol outlined here is suitable for all long bone analyses including ex vivo imaging , histology , histomorphometry , and strength testing , among others .\nsimilarly , a standardized bone marrow isolation method with high bone marrow cell recovery and low inter - user variability is important for experimental analysis such as fluorescence - activated cell sorting ( facs ) or quantitative pcr ( qpcr ) as well as downstream applications such as primary cell culture of bone marrow cells .\nall animal work was approved by the institutional animal care and use committee in accordance with the recommendations outlined in the guide for the care and use of laboratory animals of the national institutes of health .\nposition the mouse in a supine position and affix by pinning all four legs through the mouse paw pads below the ankle joint . spray the mouse with 70% ethanol , thoroughly dousing the legs . make a small incision to the right of midline in the lower abdomen , just above the hip .\npull back the skin and cut the quadriceps muscle anchored to proximal end of the femur to expose the anterior side of the femur and pin out from the leg , placing the pin at a 45-degree angle from the board . with the blade of the scissors against the posterior side of the femur , cut the hamstrings away from the knee joint . pull back the skin and the hamstring muscles anchored to proximal end of the femur to expose the posterior side of the femur and pin out from the leg , placing the pin at a 45-degree angle from the board . with the forceps , hold the distal end of the femur , just above the knee joint . guide the blades of the scissors on either side of the femoral shaft towards the hip joint , being careful not to cut into the femur itself . after reaching the femoral head , indicated by the scissors opening slightly ,\ntwist the scissors with the top blade of the scissors moving directly over the femoral head to dislocate the femur , being careful not to snap the bone below the femoral head .\ngrasp the top of the femoral shaft with the forceps , cut the soft tissue away from the femoral head to release it from the acetabulum .\npull the entire leg bone , including femur , knee , and tibia , up and away from the body , carefully cutting away the connective tissue and muscle connecting the leg to the skin .\noverextend the ankle joint and again use the scissors in a twisting motion to dislocate the tibia . grasping the distal end of the tibia , taking care not to sever the tendons , pull the tibia up and away from the body and the pin board .\ncut any remaining connective tissue attaching the long bone to the mouse at the knee . remove any additional muscle or connective tissue attached to the femur and the tibia .\nfor any applications that require the bone to remain intact ( histology , histomorphometry , biomechanical testing , etc . ) , proceed with standard in - house protocols ( as in ) . to isolate bone marrow , proceed to section 2 . using the forceps ,\ngrasp the femur with the patella facing away and the proximal end ( femoral head ) down .\noverextend the knee joint and use the scissors in a twisting motion to dislocate the tibia and femur .\ngrasp the femur with the anterior side facing away and the proximal end ( femoral head end ) down .\nrotate the scissors back and forth to remove the condyles , the patella , and the epiphysis to expose the metaphysis .\nremove any additional muscle or connective tissue attached to the femur using forceps , scissors , and kimwipes . using the forceps ,\ngrasp the tibia with the anterior side facing away and the distal end ( ankle end ) down .\nif the tibial epiphysis is intact , guide the scissors up the tibia shaft to the condyles . gently rotate the scissors back and forth to remove the condyles and epiphysis to expose the metaphysis .\nremove any additional muscle or connective tissue attached to the tibia using forceps , scissors , and kimwipes .\npush an 18 g needle through the bottom of a 0.5 ml  microcentrifuge tube . place the long bones ( maximum of 2 femurs and 2 tibiae ) into the tube , knee - end\nverify that the bone marrow has been spun out of the bones by visual inspection .\nthe bones should appear white and there should be a large visual pellet in the larger tube .\nsuspend the bone marrow in appropriate solution ( e.g. , pbs , culture media , facs buffer ) and proceed with experimental protocol ( dna , rna , or protein isolation , facs analysis , or primary cell culture ) .\neuthanize the mouse in accordance with institutional guidelines . position the mouse in a supine position and affix by pinning all four legs through the mouse paw pads below the ankle joint . spray the mouse with 70% ethanol , thoroughly dousing the legs . make a small incision to the right of midline in the lower abdomen , just above the hip .\npull back the skin and cut the quadriceps muscle anchored to proximal end of the femur to expose the anterior side of the femur and pin out from the leg , placing the pin at a 45-degree angle from the board . with the blade of the scissors against the posterior side of the femur , cut the hamstrings away from the knee joint .\npull back the skin and the hamstring muscles anchored to proximal end of the femur to expose the posterior side of the femur and pin out from the leg , placing the pin at a 45-degree angle from the board . with the forceps , hold the distal end of the femur , just above the knee joint .\nguide the blades of the scissors on either side of the femoral shaft towards the hip joint , being careful not to cut into the femur itself . after reaching the femoral head , indicated by the scissors opening slightly ,\ntwist the scissors with the top blade of the scissors moving directly over the femoral head to dislocate the femur , being careful not to snap the bone below the femoral head . grasp the top of the femoral shaft with the forceps , cut the soft tissue away from the femoral head to release it from the acetabulum . pull the entire leg bone , including femur , knee , and tibia , up and away from the body , carefully cutting away the connective tissue and muscle connecting the leg to the skin .\noverextend the ankle joint and again use the scissors in a twisting motion to dislocate the tibia . grasping the distal end of the tibia , taking care not to sever the tendons , pull the tibia up and away from the body and the pin board .\ncut any remaining connective tissue attaching the long bone to the mouse at the knee . remove any additional muscle or connective tissue attached to the femur and the tibia .\nfor any applications that require the bone to remain intact ( histology , histomorphometry , biomechanical testing , etc . ) , proceed with standard in - house protocols ( as in ) . to isolate bone marrow , proceed to section 2 .\nusing the forceps , grasp the femur with the patella facing away and the proximal end ( femoral head ) down .\noverextend the knee joint and use the scissors in a twisting motion to dislocate the tibia and femur .\ngrasp the femur with the anterior side facing away and the proximal end ( femoral head end ) down .\nrotate the scissors back and forth to remove the condyles , the patella , and the epiphysis to expose the metaphysis .\nremove any additional muscle or connective tissue attached to the femur using forceps , scissors , and kimwipes . using the forceps ,\ngrasp the tibia with the anterior side facing away and the distal end ( ankle end ) down .\nif the tibial epiphysis is intact , guide the scissors up the tibia shaft to the condyles . gently\nrotate the scissors back and forth to remove the condyles and epiphysis to expose the metaphysis .\nremove any additional muscle or connective tissue attached to the tibia using forceps , scissors , and kimwipes .\npush an 18 g needle through the bottom of a 0.5 ml  microcentrifuge tube . place the long bones ( maximum of 2 femurs and 2 tibiae ) into the tube , knee - end\nverify that the bone marrow has been spun out of the bones by visual inspection .\nthe bones should appear white and there should be a large visual pellet in the larger tube .\nsuspend the bone marrow in appropriate solution ( e.g. , pbs , culture media , facs buffer ) and proceed with experimental protocol ( dna , rna , or protein isolation , facs analysis , or primary cell culture ) .\nthe protocol described here is optimized for rapid dissection of the mouse femur and tibia with a minimum of damage to the bone tissue .\nthis technique is suitable for a number of downstream analyses , including biomechanics studies , histomorphometry ( figure 1a - b ) , and histology ( figure 1c ) .\nthe representative histomophometric micoct 3d reconstruction ( figure 1a - b ) demonstrates that both the cancellous bone and cortical shell are maintained that allows for accurate quantitation of the standardized structural parameters for bone histomorphometry , including trabecular number , thickness , and spacing ;  bone volume ;  and cortical thickness , among other measures .\nthe representative histologic section shows an h&e stained formalin - fixed and decalcified tibia ( figure 1c ) .\nthe image demonstrates the integrity of both the calcified bone and cellular bone marrow for histologic analysis .\nthe bone marrow isolation procedure preserves the sterility of the bone marrow space , has low handling to reduce contamination , and does not require cutting of the long bone , thus reducing loss of bone marrow yield .\nthis bone marrow is suitable for many downstream applications , including flow cytometry and pcr analyses . in addition\n, this procedure can be used to isolate bone marrow for primary cell culture of bone marrow cells , including osteoclasts and osteoblasts ( figure 2a - b ) .\nthree - dimensional microct reconstruction of a mouse tibia showing ( a ) the outer cortical shell and ( b ) trabecular bone ( scale bar = 0.5 mm ) .\n( c ) histological h&e stain of a decalcified and sectioned tibia ( 4x ) .\n( a ) trap staining for multinucleated osteoclasts after 7 days in osteoclastogenic media ( 4x ) .\n( b ) alkaline phosphatase ( purple color ) for osteoblasts and alizarin red ( red color ) stain for mineralization after 21 days in osteogenic media .\nwe present a simple and efficient method for removal of mouse hind long bones and subsequent bone marrow isolation .\nthis method maintains the high structural and cellular integrity of the bones and bone marrow and has low handling time , minimizing the likelihood of user - induced fracture or bone scoring that may influence downstream analyses .\nin addition , the centrifugation method for isolating bone marrow does not require cutting the bone to expose the bone marrow space or fluid to flush the bone marrow , reducing potential points of contamination .\nmoreover , the centrifuge technique is relatively high - throughput with lower hands - on time than other methods , thus reducing processing time .\nhigh variation is inherent to in vivo mouse studies due to high mouse - to - mouse phenotypic variation . in order to maximize the research impact of expensive and labor - intensive mouse studies , it is critical to minimize technical experimental error .\ntime from animal sacrifice to downstream analysis or tissue fixation introduces experimental variation that may overcome subtle changes and reduce large differences between groups .\nthe long bone dissection and bone marrow isolation techniques described here are optimized for rapid processing of animals and samples to reduce technical variation .\nthis protocol can be widely applied to many research fields , including investigation of the bone tissue itself or interrogation of the cells of the bone marrow .\nin addition , this straightforward approach to long bone dissection will enable researchers in related fields to directly interrogate bone contributions in order to expand our knowledge of bone marrow dysfunction in otherwise understudied pathologies ."}
{"lay_summary": " tuberculosis ( tb ) is a major health issue in both developing and developed countries such as the uk . \n healthy individuals who contract the infection have only 5 - 10% chance of converting to the active disease over their lifetime . \n we present the clinical history of a 76 year old female who attended the emergency department complaining of wrist pain , and was only diagnosed with tb after three years . \n this case report emphasises the importance of including tb in the differential diagnosis when treating patients with an infection resistant to conventional antibiotics , even though risk factors for tb may not be evident or special stains for tb are negative . ", "article": "tuberculosis ( tb ) is a major health issue in developing countries with over two billion people being infected with tuberculosis bacilli world wide ( 1 ) . although tb was recently regarded primarily as a disease of the developing countries it is now also on the increase in developed countries such as the united kingdom , mainly as a result of globalisation as well as an increase in immunosuppressed patients .\nfigures by the health protection agency ( hpa ) show that the cases of tb in the uk increased by 5.5% in 2009 when compared to those in 2008 ( 2 ) .\nthis caucasian patient presented to the emergency department with sudden pain localised to the ulnar aspect of her wrist .\nx - ray of the forearm was normal and she was treated conservatively but was lost to follow up .\nshe presented again at the orthopaedic clinic 26 months later with continuing swelling and pain .\nultrasound showed a synovial tumour on the dorso - medial aspect of the wrist ( figure 1 ) .\nultrasound showing a synovial tumour on the dorsal medial aspect of the wrist however , special stains for fungi and acid fast bacilli were negative .\nsubsequently the patient developed a sinus and continued to have a chronic discharge from her left wrist .\nx ray this time showed destruction of the ulnar styloid consistent with a bony infection ( figure 2 ) .\nmri showed destruction localised around the ulnar head with oedematous changes extending up the shaft of the ulna ( figure 3 ) .\nap xray of the wrist showing destruction of the ulnar styloid consistent with a bony infection .\nsoft tissue swelling can also be noted over the dorsum of the wrist mri showing localised destruction around the ulnar head .\nthe mri also shows thickening around the extensor carpi ulnaris tendon in keeping with marked tenosynovitis at this site .\nthe patient agreed to a repeat biopsy and excision of the necrotic bone ( figure 4 ) .\nmicroscopy of the specimen again showed a florid granulomatous inflammatory process with areas of fibrinoid necrosis .\npost - operative xray of the wrist showing excision of the ulnar styloid further enquiry revealed that our patient had been experiencing lethargy but no other features to suggest tuberculosis .\nfollowing the diagnosis of tb , the patient recalled that in her former post as a nursing assistant , when she was much younger , she was exposed to patients with tb .\nalthough improvements in its management and treatment are continuously occurring an estimated 1.8 million people died of tb in 2008 ( 1 ) .\nextra - spinal tuberculous osteomyelitis is rare and comprises about 2 - 3% of all cases of osteoarticular tuberculosis , with the hip and knee joints being the most common following spinal involvement ( 3 ) .\ntuberculous involvement of the ulna is uncommon and tends to be more common in the diaphysis .\na high index of suspicion of tb is important to obtain the correct diagnosis . in chronic soft tissue and bony infection\nthe diagnosis of tb may not be evident from the history and examination and indeed no obvious risk factors may be present as in our case . in our patient\nthe infection could have been contracted at a much younger age , when she was caring for patients infected with tuberculosis , and remained latent .\nhowever no other risk factors were evident that could explain why the disease was activated after such a long period of latency .\nit is also interesting to note that the actual distal radio - ulnar joint was not involved , most of the destruction being situated around the ulnar process .\nalthough localisation of the tuberculous infection in the bone without joint involvement can occur , this is rare ( 3 ) ."}
{"lay_summary": " although the ketogenic diet ( kd ) has been widely accepted as a legitimate and successful therapy for epilepsy and other neurological disorders , its mechanism of action remains an enigma . \n the use of the kd causes major metabolic changes . \n the most significant of them seems to be the situation of chronic ketosis , but there are others as well , for instance , high level of polyunsaturated fatty acids ( pufas ) . \n these  primary  influences lead to  secondary  , in part adaptive , effects , for instance changes in mitochondrial density and gene expression . \n clinically , the influences of the diet are considered as anticonvulsive and neuroprotective , although neuroprotection can also lead to prevention of seizures . \n potential clinical implications of these mechanisms are discussed . ", "article": "the value of the ketogenic diet ( kd ) has been recognized in the treatment of epilepsy , although the exact mechanisms by which it exerts its effect remain an enigma .\nthey seem to be different from those of regular antiepileptic medications ( aeds ) , and discovering what they are may lead to its use in clinical situations other than epilepsy as well .\nthe kd is comprised of four elements , the changes of any of them can potentially lead to losing its anticonvulsant effect : ( 1 ) increased amount of fat , usually in a ratio of 3 to 4 grams of fat for each gram of protein and carbohydrates , ( 2 ) as low a consumption of glucose as possible , ( 3 ) caloric restriction , and ( 4 ) fluid restriction .\nalthough there is some debate about the last component , clinical practice has shown that stopping fluid restriction can lead to seizure recurrence much in the same way as when stopping glucose restriction .  \nthe most important result of observing the diet is the increased blood level of free fatty acids ( ffas ) .\nthe ffas are transferred into the mitochondria , a process which requires the presence of an appropriate amount of carnitine , where they are degraded into ketone bodies through  oxidation .\nthese ketone bodies include  hydroxybutyrate , acetoacetate , and acetone   ( figure 1 ) .  \nthe effect of the increased amount of ketone bodies seems to be the most prominent of all other suggested antiepileptic mechanisms of the kd .\nthe degradation of the ketone bodies delivers acetyl - coa directly to the tricarboxylic acid cycle , thus increasing its turnover while bypassing the need to depend on acetyl - coa coming from glycolysis to produce atp . unlike glucose , which requires a transporter to cross the blood brain barrier ,\nthe ketone bodies penetrate it easily . when this transporter is deficient , as in glut 1 deficiency , the kd is the preferred way of antiepileptic treatment , since it allows for bypassing the need for glucose .\nchildren in whom the conversion of pyruvate to acetyl - coa is blocked , for instance , in pyruvate dehydrogenase ( pdh ) deficiency , will also benefit from bypassing this route .\n hydroxybutyrate is the predominant ketone body measured in the blood , and it is used to monitor the degree of ketosis during therapy .\nthe breath of a patient who is ketotic while on the diet will often even smell of acetone .\nacetone is one of the ketone bodies that have an anticonvulsant effect in several types of mouse seizure models .\nthe mechanism of this effect is unknown , although an effect on k2p channels has been proposed .   by means of the tca cycle ,\nacetyl - coa increases the level of the neurotransmitters glutamate and -aminobutyric acid ( gaba ) and the major excitatory and inhibitory neurotransmitters in brain , respectively .\nanother product of an elevated level of free fatty acids is polyunsaturated fatty acids ( pufas ) .\nthe potential ability of pufas to block seizure activity in the brain is speculated to be associated with some rather more complicated mechanisms , including ( 1 ) directly inhibiting voltage - gated sodium and calcium channels , ( 2 ) activating a lipid - sensitive potassium channel , ( 3 ) enhancing the activity of the sodium pump to limit neuronal excitability , ( 4 ) activating peroxisome proliferator - activated receptor- ( ppar ) , and ( 5 ) inducing the expression and activity of brain - specific uncoupling proteins in the mitochondria , thereby inducing a neuroprotective effect .\nneuroprotection can contribute to the anticonvulsant effect , but it may have other effects as well , which can lead to other clinical uses of the kd .\nappleton and de vivo   reported that the kd increased the total quantity of bioenergetic substrates ( adenosine triphosphate ( atp ) ) and elevated the energy charge in rat brain .\nacetoacetate , a product of  hydroxybutyrate dehydrogenation , is transferred into acetyl - coa which enters the tricarboxylic acid ( tca ) cycle .\nthe increased turnover of the tca cycle generates protons and electrons that are channeled to the electron transport chain .\nthis , in turn , drives the formation of atp from adenosine phosphate ( adp ) by atp synthase .\nenhanced atp can either be converted to phosphocreatine for energy storage or broken into adenosine .\nenhanced atp levels provide energy reserves for a neuron to continue functioning under stress . increased extracellular adenosine offers a neuroprotective buffer against insults , reduces excitation , and averts excessive atp demands , thus providing local seizure control and neuroprotection .  \nit was also suggested that the kd influences toward an upregulation of transcripts encoding energy metabolism enzymes and increase in the density of mitochondria in neuronal process , leading to heightened energy reserves .\nan improved energetic status can support seizure prevention , for instance , by supporting gabaergic inhibition .\nit is suggested that adaptive processes to the metabolic changes induced by the diet lead to changes in gene expression which in turn result in some of the above - noted changes .\nother path of neuroprotection is modulated through decreased generation of ros which is considered to be related to pufas effect on uncoupling proteins .\nthe fact that the kd is considered a proven therapy with relatively few adverse affects and wide clinical experience , particularly in children , led to recent studies investigating new potential uses for other neurological disorders .\none of the most intriguing and active fields of research is the effect of a high - fat caloric - restricted diet on the survival of brain tumors cells .\nit is hypothesized that mitochondrial abnormalities impair the ability of brain tumors to generate energy from ketone bodies . unlike normal cells ,\nmalignant tumor cells have impaired genetic adaptability due to their genetic abnormalities and , therefore , increased susceptibility to environmental stress , such as fasting or caloric restriction .\nthe same genomic defects that are involved in the creation of brain tumors can be exploited for their destruction [ 3 , 10 , 11 ] .   in 1995 , nebeling et al\n.   reported two young girls with unresectable advanced stage brain tumors who had poor response to radiation and chemotherapy .\nthey were treated with a kd and their response was remarkable , both clinically and according to positron emission tomography follow - up scans .\ndescribed a patient with glioblastoma multiforme whose tumor , which is very malignant , improved on the kd . surprisingly , despite the appealing efficacy of this treatment , no further human studies or clinical trials on the kd as a therapy for brain tumors have been conducted .\nseveral laboratory studies in mouse and rat models have recently confirmed that inhibition of brain tumor growth is directly related with reduced levels of glucose and elevated levels of ketone bodies .\nmoreover , the kd was shown to reduce reactive oxygen species ( ros ) in the brain .\ncancer cells need high levels of ros for the induction of angiogenesis and the production of tumor growth factors , thus , through this mechanism the kd can be protective .\nthe clinical manifestations were mainly intractable seizures that necessitated repeated admissions to the intensive care unit , as well as severe cognitive and alertness decline .\nafter the oncologists decided that antitumor treatment would be ineffective , she was started on the kd .\nafter four weeks of trial , it did not have any effect on the tumor progression .\nhowever , it did have a notable improving effect on cognition , alertness , and mood of the girl , in spite of her devastating condition .\nthe beneficial effect of the kd on cognition , alertness , and mood is well recognized , and clinical experience shows that in many times it is not less important than the anticonvulsant effect .\nthe potential neuroprotective effect of the kd was what motivated investigations into its potential as a treatment option in other neurologic disorders .\nthere are increasing numbers of reports that ketosis achieved by starvation or administration of a kd has a consistent neuroprotective effect after various brain injuries in animal models .\none human pilot study and several animal model studies have shown improvement in autistic behavior parameters with kd treatment .\nit remains to be further clarified whether this improvement is related to reduced epileptic activity found in up to 30% of these patients or to a primary effect of the kd .  \na factor that can be crucial for the application of the kd in medical conditions other than intractable epilepsy is the inherent difficulties in its use .\ndietary restriction can pose a significant problem in a child with a progressive tumor that undergoes massive chemotherapy , who may already be cachectic .\nthe kd may not be an option in a grown - up hyperactive autistic child .\nthus , the neurologist must evaluate the appropriate clinical , familial , and environmental situations very cautiously prior to the recommendation of the kd . in conclusion ,\nthe major metabolic effect of the kd is in supplying the brain with an increased amount of free fatty acids .\ntheir degradation into ketone bodies , together with the load of pufas , leads to major changes in the metabolic , bioenergetic , mitochondrial , and even genetic constellation .\nwhether it may also be effective in other pathologies , especially in treating malignancies , awaits future research ."}
{"lay_summary": " abstractendotracheal tube ( ett ) should be placed at the optimal level to avoid single lung ventilation or accidental extubation . \n this study was performed to estimate the mid - tracheal level by using surface anatomical landmarks in adult patients.neck computed tomography images of 329 adult patients between the ages of 16 and 79 years were reviewed . in the midline sagittal plane , the levels corresponding to the vocal cords , cricoid cartilage , suprasternal notch , manubriosternal junction , and carina were identified . \n the surface distances from the cricoid cartilage to the suprasternal notch ( extcc - ssn ) and that from the suprasternal notch to the manubriosternal junction ( extssn - msj ) were measured . \n the relationship between mid - tracheal level and the surface distances was analyzed using bland  \n altman plot.the difference between the extcc - ssn and the mid - tracheal level was 6.6 ( 12.5 ) mm , and the difference between the extssn - msj and the mid - tracheal level was 19.2 ( 6.1 ) mm . \n the difference between the extcc - ssn and the mid - tracheal level was smaller in females compared with males [ 1.7 ( 11.7 ) mm vs 12.8 ( 10.7 ) mm ; p  <  0.001].the mid - tracheal level , which is helpful in planning the insertion depth of an ett , can be predicted by the surface distance between the cricoid cartilage and suprasternal notch in adults , especially in females . ", "article": "the endotracheal tube ( ett ) should be placed at the optimal level to avoid inadvertent complication .\nif the ett is too deep , it increases the risk of unintended single lung ventilation .\non the other hand , if the ett is too shallow , it may cause vocal cord injury by the ett balloon or accidental extubation .\nthere are many methods for determining the appropriate depth of ett in adults ; fixed insertion depth according to sex ( 23 and 21  cm from the upper incisors in adult males and females , respectively ) , the use of depth marks on the ett , suprasternal palpation of the ett tip or cuff , and bilateral auscultation .\nalthough chest radiography and bronchoscopy are considered an accurate method , they are not always feasible and the costs are considerable . considering the individual variation in the length of the trachea , using fixed depths or marks on the ett may result in inadequate placement of the ett . to reduce the risk of single lung ventilation or vocal cord injury , the segment between the proximal edge of the cuff and the ett tip should be placed at the mid - trachea level . if the length of the trachea can be predicted at bedside before intubation , the ett can be placed at a safe depth for each patient .\nthe purpose of this study was to determine whether surface anatomical landmarks can be used to predict the mid - tracheal level in adult patients .\nneck computed tomography ( ct ) images of adults obtained between 2009 and 2014 were reviewed by a single reviewer after obtaining approval form seoul national university hospital institutional review board ( july 17 , 2015/no .\npatients with laryngeal , tracheal , or thoracic abnormalities , tracheostomy or significant tracheal deviation caused by mass lesions were excluded .\nin addition , poor ct image quality , absent sagittal ct images , ct images that did not cover the entire trachea , or ct images taken in neck hyperextension ( boidin angle > 130 on scout view ) or hyperflexion ( boidin angle < 110 on scout view ) position were also excluded .\nlevels of subglottic and tracheal airway segments that include the vocal cords ( vc ) , the cricoid cartilage ( cc ) , and the carina were identified using the method described by sirisopana et al .\nthe vocal cords were identified as the most cranial level of the upper airway , with a teardrop shape below the laryngeal ventricle . anatomic level of suprasternal notch ( ssn )\nthe level of manubriosternal junction ( msj ) was defined as the middle level between the manubrium and the body of the sternum where the second rib attaches to the sternum .\nthe level of carina was defined as the bifurcation of right and left main bronchus and identified by the figure 8 shaped lumen .\nthe external locations of the cc , ssn , and msj were defined on the skin surface .\nthe distances between the external points of the cc and the ssn ( extcc - ssn ) , and those of the ssn and the msj ( extssn - msj ) were measured .\nthe distances between the subglottic structures at the levels of the vc , the cc , ssn , and carina were measured .\ntracheal length was calculated as the summation of the distances measured from the vc to the carina .\nthe mid - trachea level was calculated from tracheal length and the ideal position of ett is shown in fig .\n2 . identification of subglottic segments on axial view ( right ) , and defining the distances between subglottic segments on sagittal view ( left ) in a 45-year - old male patient .\ncc  =  cricoid cartilage , extcc - ssn  =  the surface distances from the cricoid cartilage to the suprasternal notch , extssn - msj  =  the surface distances from the suprasternal notch to the manubriosternal junction , msj  =  manubriosternal juction , ssn  =  suprasternal notch , vc  =  vocal cord , tracheal length  =  a  +  b  +  c  +  d. the ideal position of endotracheal tube ( ett ) to minimize the risk of endobronchial intubation and vocal cord injury .\nthe mid - point between the proximal edge of the cuff and the ett tip was matched to the level of the middle of the trachea ( mtl ) , which was calculated from the tracheal length .\ncc  =  cricoid cartilage , ett  =  endotracheal tube , msj  =  manubriosternal juction , mtl  =  the level of the middle of the trachea , ssn  =  suprasternal notch , vc  =  vocal cord .\nthe correlations between age , height , weight , and tracheal length were analyzed using linear regression .\nthe relationships between surface measurements and the mid - tracheal level were analyzed with bland \nthe distance between the cc and the ssn was longer in females ( p  <  0.001 ) , whereas distances between the vc and the cc , the ssn and the carina , and the tracheal length were longer in males ( p  <  0.001 ) .\nthe extcc - ssn was longer in females ( p  <  0.001 ) , whereas extssn - msj was longer in males ( p  <  0.001 ) .\ndemographic data and measured distances between subglottic structures of trachea , external landmarks , and calculated tracheal length .\nthe calculated tracheal length was 131.9 ( 10.3 ) mm and ranged from 106.0 to 169.8  mm .\ntracheal length showed weak correlation with height ( r  =  0.2188 ) and weaker correlation with age ( r  =  0.0004 ) and weight ( r  =  0.0466 ) ( fig .\nthe calculated mid - tracheal level was 66.0    5.1  mm from the vc .\naltman plots showing the difference between the mid - tracheal level and the surface measurements are shown in fig .\nthe bias was calculated by subtracting the mid - tracheal level from the surface measurements .\nthe difference between the extcc - ssn and the mid - tracheal level was 6.6 ( 12.5 ) mm , and the difference between the extssn - msj and the mid - tracheal level was 19.2 ( 6.1 ) mm .\naltman plots showing the agreement between the mid - tracheal level ( mtl ) and the surface measurements of surface anatomical landmarks .\n( left ) the bias ( subtraction of the mid - tracheal level from the surface distance from the cricoid cartilage to the suprasternal notch ) and 95% limit of agreement as the mean difference were 6.6 [ 31.1 to 17.9 ] ( mm ) .\n( right ) the bias ( subtraction of the mid - tracheal level from the surface distance from the suprasternal notch to the manubriosternal junction ) and 95% limit of agreement as the mean difference were 19.2 [ 31.1 to 7.2 ] ( mm ) .\nextcc - ssn  =  the surface distances from the cricoid cartilage to the suprasternal notch , extssn - msj  =  the surface distances from the suprasternal notch to the manubriosternal junction , mtl  =  the level of the middle of the trachea .\naltman plots of the difference between the extcc - ssn and the mid - tracheal level in female and male patients .\nthe calculated mid - tracheal level was 64.5 ( 4.6 ) mm in females and 67.9 ( 5.0 ) mm in males .\nthe difference between the extcc - ssn and the mid - tracheal level was 1.7 ( 11.7 ) mm in females and 12.8 ( 10.7 ) mm in males ( p  <  0.001 ) .\naltman plots of female ( left ) and male ( right ) patients showing the agreement between the mid - tracheal level ( mtl ) and the surface the surface distance from the cricoid cartilage from the suprasternal notch .\n( left ) the bias ( subtraction of the mid - tracheal level from the surface distance from the cricoid cartilage to the suprasternal notch ) and 95% limit of agreement as the mean difference were 1.7 [ 24.6 to 21.2 ] ( mm ) in females .\n( right ) the bias ( subtraction of the mid - tracheal level from the surface distance from the cricoid cartilage to the suprasternal notch ) and 95% limit of agreement as the mean difference were 12.8 [ 33.8 to 8.2 ] ( mm ) in males .\nextcc - ssn  =  the surface distances from the cricoid cartilage to the suprasternal notch , mtl  =  the level of the middle of the trachea .\nthis study showed that mid - tracheal level could be estimated by the surface distance between the cc and the ssn ( extcc - ssn ) . compared with males , extcc - ssn more\naccurately predicts the mid - tracheal level in females . in clinical practice , physicians can use extcc - ssn to determine the depth of ett so that the segment between the proximal edge of the cuff and the ett tip lies at the mid - tracheal level .\nthere are several studies that used the distance between the surface anatomical landmarks to estimate the airway length and the optimal insertion depth of endotracheal tube .\nlee et al showed that the distance between the upper incisor and the manubriosternal angle in the neck extension position correlates with the distance between the upper incisor and the carina in the neutral neck position .\nevron et al used the sum of the 2 distances from the mouth angle to the jaw angle and from the jaw angle to the sternal manubrium to determine the depth of ett\n. however , these methods are complicated than single measurement of extcc - ssn due to the difficulty in locating the sternal manubrium , more than 1 measurement , and the need for full neck extension .\nthe physicians can easily apply our method with a simple measurement of the extcc - ssn to estimate the mid - tracheal level , and apply this depth during endotracheal intubation .\nhowever , according to previous studies in adults , flexion and extension of the neck from neutral position are associated with the inward and outward movements of the ett .\nconrardy et al showed that the orally intubated ett can move 1.5 ( range 0.52.0 ) cm toward the carina during flexion and 2.4 ( range 1.34.3 ) cm away from the carina during extension .\nkim et al showed that the ett can migrate 1.3 ( sd 0.6 ; range 0.52.5 ) cm toward the carina during flexion and 1.7 ( sd 0.8 ; range 0.43.1 ) cm during extension .\ntherefore , the position of the neck should be considered when determining the optimal depth of the ett .\nfirst , this study was a retrospective analysis of ct images and the distances were measured in the neutral position .\nsecond , since the vc is used as a baseline of the depth of intubation in our method , it can be difficult to apply our method to patients with high cormack grades .\nlastly , the efficacy of this method is yet to be demonstrated in clinical practice . in conclusion ,\nthe mid - tracheal level , which is considered the optimal depth of ett , can be predicted by the surface distance between the cc and ssn in adults , especially in females ."}
{"lay_summary": " this paper is based on linked qualitative studies of the donation of human embryos to stem cell research carried out in the united kingdom , switzerland , and china . \n all three studies used semi - structured interview protocols to allow an in - depth examination of donors and non - donors rationales for their donation decisions , with the aim of gaining information on contextual and other factors that play a role in donor decisions and identifying how these relate to factors that are more usually included in evaluations made by theoretical ethics . \n our findings have implications for one factor that has previously been suggested as being of ethical concern : the role of gratitude . \n our empirical work shows no evidence that interpersonal gratitude is an important factor , but it does support the existence of a solidarity - based desire to  give something back  to medical research . \n thus , we use empirical data to expand and refine the conceptual basis of bioethically theorizing the ivf  stem cell interface . ", "article": "embryos generated through assisted reproductive technologies ( art ) are deemed surplus when , for some reason , they are not used for reproductive purposes ( svendsen and koch 2008 ; haimes and taylor 2011 ) ; instead , they are then disposed of or , where this is allowed by a country s art regulation , may be donated for a variety of research purposes .\nthus , the generation and subsequent fate of embryos that are designated surplus are determined as much by legislation as by embryo biology or technological constraints .\nfor example , legislatures differ in whether cryopreservation of embryos is permitted , meaning that in some countries any ivf embryos not immediately transferred for pregnancy are surplus , while in others they may be frozen for later transfer . in some countries , the law considers surplus embryos as the primary source of material for human embryonic stem cell ( hesc ) research , while in others this use of embryos is expressly forbidden .\nalthough hesc research has been subjected to exhaustive ethical scrutiny , the lack of consensus on the ontological or ethical status of surplus embryos means that the uses to which they may then be put remain contested ( deckers 2007 ; guenin 2008 ; moller 2009 ) .\neven if using human embryos for stem cell research is deemed permissible , ethical issues continue to emerge as new social practices and roles develop around the act of embryo donation .\nthe relative novelty of these practices and roles , complicated by the pace of change in technical possibility and regulation , mean that there is still uncertainty about how to conceptualise embryo donation , not just in terms of systematic ethics but as a sociomoral practice in everyday social life and morality ( banks , scully , and shakespeare 2006 ) . from a sociological perspective , and also to understand more generally how everyday morality deals with unprecedented ethical dilemmas , it is important to examine which conceptualisations emerge as salient and how they are stabilised and used .\nfor example , one way of thinking about the donation of embryos to research is as a bodily gift relationship , one of the many established by modern biomedicine such as the donation of eggs and sperm for reproductive purposes , organs or tissues for transplantation , blood for transfusion , and other biological tissues for research .\ndrawing analogies to existing practices in this way has proved helpful in other instances of bioethical novelty ( hofmann , solbakk , and holm 2006 ) .\nhowever , analogies can equally well be misleading , if there are morally relevant but unacknowledged differences between situations .\nthe contexts in which different organs and tissues are donated vary significantly , and these differences influence the sociomoral understanding of donation in each case and make them noncomparable in ethical terms\n. reproductive tissue , for example , is generally distinguished from other types of donated tissue because eggs , sperm , and embryos have the potential to give rise to new individuals , not just to prolong the lives of existing individuals , or to be used for research . because embryos are generally considered to have a different moral status from other tissues , the use of surplus embryos in research raises moral unease about the instrumentalization of human life that is not raised in quite the same way by the donation of either ova or sperm .\nit is therefore unclear whether an embryo can meaningfully be treated as a  gift  (  donation  ) without blurring the morally relevant differences between embryos and other tissues .\nsimilarly ,  hesc research ,  to which the embryo may be given , is a domain of biomedical practices and not an entity . as such\n, hesc research is not a subject with which a gift relationship can be established ( unlike , for instance , an organ recipient ) .\nunderstanding the social and ethical meanings that are emerging for the practices associated with embryo donation calls for a detailed empirical examination of people s reasoning behind donation decisions .\nhowever , most empirical studies of embryo donation have not focused on people s donation rationales in depth ( with some exceptions ; for example , haimes et al . 2008 ; de lacey 2003 ) .\nthe scarcity of data on donor rationales means there is a corresponding lack of information on contextual and other factors that influence donor decisions and how these can be related to the evaluations of theoretical ethics .\nthe authors of this paper have been involved in a series of linked qualitative studies of practices of embryo donation , first in the united kingdom ( researcher haimes and colleagues ) , then switzerland ( scully , rehmann - sutter , and porz ) , and in a smaller pilot project in china ( mitzkat , rehmann - sutter , and haimes ) .\nall three studies shared an interest in understanding reasons for the donation or non - donation of embryos . while the studies in switzerland and china drew upon the original u.k .\ndesign , each study was conducted independently , and the details of each project , including interview design , differed in light of the varying regulatory , clinical , and cultural contexts . however , by looking across the three data sets , we hope to gain cross - cultural insights into donation and non - donation rationales and the moral understandings on which they are based .\nthe three studies all used open - ended , semi - structured , one - off interviews between the researcher and people who had been in the position of deciding whether to donate their surplus embryos to research .\ninterviews were designed to explore in depth not just the interviewees decision about donation but also the background to that decision , such as their ivf story , their family and other relationships , their relationship with the clinic and its staff , and so on .\nthe interviews were transcribed , coded , and initially analysed to identify the reasons for donation decisions given by participants in each study , using an interpretative approach that all of us have previously found useful for identifying key themes around decision - making and implicit or explicit ethical judgements ( charmaz 2006 ; smith , flowers , and larkin 2009 ) .\nstudy ran for more than three years ; after some familiarisation and observation in the collaborating clinic , 44 in - depth interviews were conducted with couples who had been asked to donate their surplus fresh embryos , generated through ongoing ivf treatment , to hesc research ( haimes and taylor 2009 ) . in the united kingdom , it has been possible for some years to donate unused embryos to stem cell and other kinds of research and also to other couples .\nthe swiss study was carried out shortly after a change in the law that permitted fresh or cryopreserved surplus ivf embryos , under strictly defined conditions , to be donated to stem cell research only . in this study , 17 individuals who had variously chosen to donate or not to donate were interviewed ; thus , the decision concerned the fate of cryopreserved embryos some time after the ivf treatment that had produced them ( scully , rehmann - sutter , and porz 2010 ) . the chinese work involved a much smaller three - month pilot study carried out in a large art hospital .\nit was designed as a pilot to provide a comparison with the u.k . and swiss material and is , therefore , included here despite the low number of participants , but with no attempt to draw general conclusions from it .\nlegislation in china does not allow the donation of embryos to other couples , but consent can be given for a surplus embryo to be used in stem cell research or for it to be discarded .\nthe study included participant observation of the information and consent procedures and qualitative interviews with five ivf patients , three choosing to donate to stem cell research and two refusing ( mitzkat , haimes , and rehmann - sutter 2010 ) .\nfor the purposes of this paper , the authors involved in the studies jointly compared the rationales for donation decisions given by their participants .\nwe also independently reexamined interview transcripts for material relevant to the discussion of gratitude . in the rest of this paper , we first identify and compare the main reasons given by participants in these three studies for their decisions to donate or to refuse to donate their surplus embryos to research .\nwe then look in more detail at the implications of our findings for one area of potential ethical concern : the possible role of gratitude in making embryo disposition decisions . in this way\n, we not only collect empirical data to help understand the emerging moral meaning of a new practice , but also give an example to show how empirical data can be used to question and then refine the conceptual basis of bioethical theory .\nparticipants who chose to donate their surplus embryos to research had a background premise that donation is fundamentally permissible because embryos do not have the sort of ontological or moral status that would forbid it .\nthe swiss study discovered people stating this explicitly :  [ embryos ] are not , they are not yet people ; they are nt beings with souls as far as i m concerned ,  as one swiss participant said.1 but this did not mean that the surplus embryos were considered as morally equivalent to any other tissue , and participants in both the swiss and u.k .\ninterviewees stopped themselves midway through sentences referring to the  left over embryos ,  which they clearly felt , on reflection , was an inappropriate phrase .\nso the embryos did not have the sort of moral status that would have made it wrong to donate them , but neither were they completely disposable .\nto some of our participants , embryos had a value ; they were a precious resource ( haimes et al .\n2008 ) that made simply throwing them out an unjustifiable waste . as another u.k .\n[ i]t just really seemed a waste , really , not to have them used .\n it was not always clear , however , quite how interviewees were using this notion of  precious  : whether with reference to economic  bio - value  ( waldby 2000 ; waldby and mitchell 2006 ) or because they had been obtained at intense personal and emotional cost , or because they had high moral value , or possibly a combination of all these aspects\n. particularly in the swiss study , which involved cryopreserved embryos stored for some time , participants referred to embryos moral status in a nuanced way that was highly sensitive to the developmental stage of the embryo , its physical location ( whether inside or outside the body ) , and its state ( whether cryopreserved or not ) ( see scully , rehmann - sutter , and porz 2010 ) .\nstudies seemed less interested in explicitly defining  the  moral status of an abstract embryo than working out what their own particular embryos meant for them at defined points in their own story , and what this meaning then indicated it was morally permissible for them to do with that embryo .\nacross all three studies the commonest rationale for opting to donate was a willingness to contribute to potentially curative medical research .\nsuch research was seen as a valuable endeavour by those like the swiss participant who said ,  i feel that , fundamentally , research has to go on , and i support that .\n donation of their spare embryos to research was therefore seen as a morally good act , based on a kind of ethical arithmetic in which simple disposal produced zero good from the surplus embryo , while donation had the potential to do good by supporting research . as one u.k .\ninterviewee said ,  it was quite simply that  we ve been helped by the system , we should help the system back.  not because of some sort of martyrdom or heroics or anything like that , just quite simply that without such efforts things do nt progress .  in the u.k .\nstudy there was an added imperative to donate surplus embryos to research as there had been a lot of press coverage about the hoped - for curative outcomes of stem cell science : \ni think the research is very important , like it was in the news a while ago to say that [ the senior clinician ] was successful in stem cell research and that s what you need in order to provide medical assistance in the future , so i m all for it .\n this observation raises a separate ethical concern about the patients understanding of the information they were given about the research goals . here\nin the swiss study , the notification from the clinic storing the frozen embryos stated clearly that donation was to stem cell research , yet the majority of donors we interviewed who referred to research did so in terms that were directly relevant to infertility .\na lot of preparatory work , research work , went on before medicine was advanced enough that it was possible for us to have children .\n [ t]his is now maybe a tiny tiny contribution , that we can give back , if we now donate a , er , fertilised egg , perhaps for further research .\n note that in the chinese pilot study none of the participants spoke in precise terms about the research involved ; however , they described it broadly as \n one chinese interviewee said she did not really know what the research was about , but trusted the doctors and hoped it would help other infertile women . in switzerland ,\nthe donors were former ivf patients donating cryopreserved embryos ; in china , they were current ivf patients donating either fresh or cryopreserved embryos . in neither of these studies\nwere participants asked outright if they thought their donated embryo was being used in infertility research .\nhowever , the fact that they used phrases such as  helping others as we have been helped  ( italics added ) indicates a potential misunderstanding .\nit raises the possibility that if they had been fully aware that the research undertaken with their embryos did not concern infertility , participants might have chosen against donation . the u.k .\nparticipants had much clearer ideas about the research to which they were being asked to donate ; they knew that it was not for research on fertility issues .\nthese participants , as in the chinese study , were current patients donating fresh embryos .\nthe differences in comprehension are therefore unlikely to be due to the request context ( former vs. current patients or fresh vs. frozen embryos ) in itself . however , in the u.k .\nstudy participants were asked to decide whether or not to donate to a number of specific projects , for each of which the goal and methodology was explained in detail , orally and in writing .\nit is possible that this level of engagement with the detail of the research underlies the difference .\nit will be important to clarify this , and to identify best practices for maximising patient comprehension of the research goals , because if ( as our material indicates ) the type of research to which people donate is a relevant factor in their moral evaluation , then the question of whether they fully understand its nature is ethically crucial . as we have seen , some of our participants reasoned that if their embryo was not going to be used for pregnancy , then donating it to a good endeavour ( research ) would be more meaningful than simply discarding it .\nfor example , one interviewee said :  if we ve created life that we , or i , do nt want any more , then maybe it s least sinful , or however you want to put it , if something meaningful happens to it .\n i feel a little bit guilty sometimes , not very much , but a little bit like  if we can at least give these embryos for a good reason , then it was nt completely in vain .  using similar wording , another said ,  if i ve already gone a bit astray , and in a sense we ve produced life , erm , then at the very least something meaningful should come out of it .\n our interpretation of their statements is that they felt they had ( inadvertently ) done something wrong in  creating life  but then not using that life as intended in pregnancy , and that donation to a good endeavour would in some way make up for this wrong .\n( we want to be quite clear here that we are not arguing that failure to use an ivf embryo in pregnancy actually is a moral wrong , only that some of our participants said that in their case they felt so . )\nthey did not indicate that they felt their use of ivf in itself had been wrong , but articulated the sense that in ending up with surplus embryos they had done something less than ideal .\nfor these swiss participants , then , their donation decision appears to have been driven in part by what we could call a reparative urge .\nno indication of any similar reparative urge was observed in either the u.k . or the chinese interviews : we discuss this difference further below .\nacross all three studies the commonest rationale for opting to donate was a willingness to contribute to potentially curative medical research .\nsuch research was seen as a valuable endeavour by those like the swiss participant who said ,  i feel that , fundamentally , research has to go on , and i support that .\n donation of their spare embryos to research was therefore seen as a morally good act , based on a kind of ethical arithmetic in which simple disposal produced zero good from the surplus embryo , while donation had the potential to do good by supporting research . as one u.k .\nwe ve been helped by the system , we should help the system back.  not because of some sort of martyrdom or heroics or anything like that , just quite simply that without such efforts things do nt progress .  in the u.k .\nstudy there was an added imperative to donate surplus embryos to research as there had been a lot of press coverage about the hoped - for curative outcomes of stem cell science : \ni think the research is very important , like it was in the news a while ago to say that [ the senior clinician ] was successful in stem cell research and that s what you need in order to provide medical assistance in the future , so i m all for it .\n this observation raises a separate ethical concern about the patients understanding of the information they were given about the research goals . here\nin the swiss study , the notification from the clinic storing the frozen embryos stated clearly that donation was to stem cell research , yet the majority of donors we interviewed who referred to research did so in terms that were directly relevant to infertility . for instance , one participant said , \na lot of preparatory work , research work , went on before medicine was advanced enough that it was possible for us to have children .\n [ t]his is now maybe a tiny tiny contribution , that we can give back , if we now donate a , er , fertilised egg , perhaps for further research .\n note that in the chinese pilot study none of the participants spoke in precise terms about the research involved ; however , they described it broadly as  scientific research  for the ivf treatment . \none chinese interviewee said she did not really know what the research was about , but trusted the doctors and hoped it would help other infertile women . in switzerland ,\nthe donors were former ivf patients donating cryopreserved embryos ; in china , they were current ivf patients donating either fresh or cryopreserved embryos . in neither of these studies\nwere participants asked outright if they thought their donated embryo was being used in infertility research .\nhowever , the fact that they used phrases such as  helping others as we have been helped  ( italics added ) indicates a potential misunderstanding .\nit raises the possibility that if they had been fully aware that the research undertaken with their embryos did not concern infertility , participants might have chosen against donation .\nparticipants had much clearer ideas about the research to which they were being asked to donate ; they knew that it was not for research on fertility issues .\nthese participants , as in the chinese study , were current patients donating fresh embryos .\nthe differences in comprehension are therefore unlikely to be due to the request context ( former vs. current patients or fresh vs. frozen embryos ) in itself . however , in the u.k .\nstudy participants were asked to decide whether or not to donate to a number of specific projects , for each of which the goal and methodology was explained in detail , orally and in writing .\nit is possible that this level of engagement with the detail of the research underlies the difference\n. it will be important to clarify this , and to identify best practices for maximising patient comprehension of the research goals , because if ( as our material indicates ) the type of research to which people donate is a relevant factor in their moral evaluation , then the question of whether they fully understand its nature is ethically crucial .\nas we have seen , some of our participants reasoned that if their embryo was not going to be used for pregnancy , then donating it to a good endeavour ( research ) would be more meaningful than simply discarding it .\nfor example , one interviewee said :  if we ve created life that we , or i , do nt want any more , then maybe it s least sinful , or however you want to put it , if something meaningful happens to it .\n i feel a little bit guilty sometimes , not very much , but a little bit like  if we can at least give these embryos for a good reason , then it was nt completely in vain .  using similar wording , another said , \nif i ve already gone a bit astray , and in a sense we ve produced life , erm , then at the very least something meaningful should come out of it .\n our interpretation of their statements is that they felt they had ( inadvertently ) done something wrong in  creating life  but then not using that life as intended in pregnancy , and that donation to a good endeavour would in some way make up for this wrong .\n( we want to be quite clear here that we are not arguing that failure to use an ivf embryo in pregnancy actually is a moral wrong , only that some of our participants said that in their case they felt so . )\nthey did not indicate that they felt their use of ivf in itself had been wrong , but articulated the sense that in ending up with surplus embryos they had done something less than ideal . for these swiss participants ,\nthen , their donation decision appears to have been driven in part by what we could call a reparative urge .\nno indication of any similar reparative urge was observed in either the u.k . or the chinese interviews : we discuss this difference further below .\napproximately half of the swiss participants who were interviewed turned out to have decided against donation and instead have their surplus cryopreserved embryo(s ) destroyed .\nnone of these explicitly used the moral status of the embryo as the fundamental basis for rejecting donation to research .\nthe scientists  would do with their embryo , which was articulated either as disapproval of specific types of research ( e.g. ,  not if it s for cloning  ) or as a more general unwillingness to relinquish responsibility of the embryo to unknown others . in both sets of reasoning , therefore , participants were expressing unease about the loss of control over what would happen to their embryo .\nthe two chinese interviewees who had opted against donation also did so because of reservations about lack of knowledge of exactly what the embryos would be used for , explicitly mentioning the fear that they would be donated to ( i.e. , used to generate pregnancy in ) other women .\nin addition , two of the swiss participants gave financial reasons , that is , they expressed anger that they would not be compensated for giving up their embryo and that through donation researchers were  getting something for nothing .\nstudy , speculation about why some people might refuse to donate raised concerns about what might be done with the embryos and whether a baby would be developed through experimentation ; others wondered if  refusers  were worried that another infertile couple would receive their embryos and have a baby when they , the embryo providers , failed to do so .\nsample contained only two actual refusers , who objected on the grounds of possible use in animal research ( haimes and taylor 2009 ; hug 2008 ) .\nthese observations provide material for an empirically grounded bioethics of the ivf  stem cell interface ( franklin 2006 ) . in the rest of this paper , we consider a single aspect in detail : the potential  problem  of gratitude influencing informed consent .\nempirically , the main reasons given by our participants for donation were : ( 1 ) to avoid the waste of a precious resource , ( 2 ) to give something back to research , and ( 3 ) to compensate for a perceived moral wrong . in none of the three countries\ndid our participants indicate that their decision arose out of any sense of gratitude to the physician who had given them ivf treatment .\nthis is an important observation , because the possible impact of gratitude on informed consent in embryo donation has previously been raised by bioethical commentators .\nit has been suggested that if there is any institutional or procedural link between ivf treatment and hesc research , the potential donors gratitude toward the clinicians who have helped them to conceive may steer them toward opting for donation ( haimes and luce 2006 ; parry 2006 ; mcleod and baylis 2007 ; also discussed in roberts and throsby 2008 ) .\nthe bioethical concern is that parents who receive the  gift of a baby  will feel a sense of gratitude ; feeling grateful might then cause parents to feel that they should respond with a gift in return ; and if a request for donation of surplus embryos is made in that context , potential donors might inadvertently be encouraged to see donation as an appropriate form of return gift . in this way\nthe moral emotion of gratitude could compromise the potential donor s freedom to weigh the pros and cons of the request , which in turn means compromising the capacity to give fully voluntary consent .\neven where the clinicians and researchers themselves are scrupulous about not using persuasion , gratitude might be persuading potential donors to do something they would not otherwise choose to do . to avoid this possibility , countries that allow embryo donation for research may attempt a strict separation of ivf treatment and the stem cell research domain .\n( not all legislatures do this , however : china is one country that does not . ) in the united kingdom , for example , it is accepted good practice that requests for donation of spare embryos should not be made by the physician(s ) who delivered the original ivf treatment . in switzerland ,\na predominant interpretation of the current law on embryo donation is that a couple undergoing ivf treatment should not be told even of the theoretical possibility that a surplus embryo might be generated unless it actually is ( porz et al .\nregulators hope to rule out any conflict of interest on the part of the treating physician as well as the possibility of gratitude on the part of the patient .\nthere are several theoretical questions that can be asked about a claim that the  risk  of gratitude affects potential donors decisions .\nfor example , moral psychologists might want to examine the emotional exceptionalism in which gratitude is seen as potentially compromising , while other emotions , or even the absence of emotion , is not .\nthere is also an obvious empirical question which does not seem to have been closely examined : whether potential embryo donors actually do experience a sense of personal gratitude to the physician  or one strong enough to sway their donation decision .\nhowever , they do indicate that participants rationales for donation indicate a desire to  give back  in a more complex way .\nfirst , our empirical results show the importance of distinguishing between the three moral emotions of gratitude , indebtedness , and solidarity .\nwhat we normally mean by gratitude is an emotion primarily associated with gifts or with help that is undeserved .\ngratitude has been defined as  a feeling of thankful appreciation for favours received  ( guralnik 1971 , 327 ) and is experienced as a positive emotion .\n( 2006 ) provide a basis from experimental psychology for distinguishing between indebtedness and gratitude .\none important distinction is that  indebtedness is an emotion of exchange , whereas gratitude is not  ( watkins et al .\neven if a debt of gratitude is felt ,  it does not appear to be analogous to an economic debt \nindebtedness , however , is , literally , a debt : a  state of obligation to repay another  ( mauss 2001 , 2 ) .\na further feature associated with indebtedness but not with gratitude is the inherent imbalance of power , so that a hierarchy is created in which those who are indebted are rendered more vulnerable . the empirical social psychological work of watkins et al .\nindicates that , in experimental settings at least , a person s feelings of gratitude diminish as the expectation of return ( indebtedness ) increases . the more reciprocity is expected or demanded ,\nimportantly for considering the effects of these social emotions on donation decisions , watkins et al . found that the greater the expectation that something will be given back in return , the less motivated the participants were actually to comply with the norm of reciprocity ( watkins et al .\nthese results suggest that if patients were to sense any expectation of return by an individual physician or researcher , it would if anything lessen any gratitude they might have felt . in the ivf context , what people have received ( the thing for which they might feel grateful ) is their baby or pregnancy , or at the very least , treatment . donors who achieve this have not received a gift , but a medical service , which will have been paid for in one way or another . in switzerland , where ivf is not covered by the mandatory health insurance\n, this will often be direct payment from the patients to the clinic , as it will also often be in china . in the united kingdom ,\npatients who do not already have children commonly receive two  free  cycles of nhs treatment ( paid for through taxes on the population ) , and then they pay for future cycles directly through fees to the clinics . whatever the system of payment , however , the point is that the ivf physician or clinic has already been paid , directly or indirectly , for the treatment which produced the outcome .\nso in the case of embryo donation , it could be argued that neither gratitude nor indebtedness should be anticipated .\ngratitude would not be expected , because what patients have received was not a favour or unexpected gift ; and indebtedness would not be expected , because there is no debt if payment has already been made . in our three studies , although we found appreciation and high esteem were expressed for the work of the treating hospital or team , we found no evidence of gratitude being expressed toward an individual physician .\nthis is despite the fact that in both the united kingdom and china mention was made of the well - known head physicians who led each clinic ; the mentions were in appreciation of their reputations , not as a debt of gratitude .\nparticipants wanted to do something with the surplus embryo that would be of benefit to research and medical treatment for infertility , but this was not directly associated with the physician who provided it originally . indeed , some of our interviewees were critical of aspects of their own ivf treatment , while still wanting to support the infertility research enterprise overall . in this context , it should be remembered that about half the swiss participants interviewed in fact chose not to donate , primarily out of anxiety about losing control over the fate of their embryos , but also in some cases because it meant researchers were  getting something for nothing .\nstudy , a few patients were suspicious that research was being prioritised over treatment and that embryos might have been kept back for the research rather than frozen .\nalthough only a small number of participants expressed this view , it has particular relevance here as it indicates clearly the absence of either gratitude or indebtedness : indeed , it suggests that these participants felt that , if anything , donation would mean the researchers were receiving something beyond their entitlement or were indebted to the patients rather than the reverse .\nsocial exchanges may entail giving back not to an individual , because the individual may be unknowable or because the benefit may not have come from a single identifiable person , but to  the pattern of social life \n( becker 1986)for example , giving back to the institutional biomedical research that had helped the participants . in serial reciprocity , person a receives something from person b , but pays back not to person b but to some other third party ( moody 2008 ) . serial reciprocity accounts for the way that altruistic blood donors often do describe their action in terms of reciprocity , even though they have not received anything from the person to whom their blood eventually goes .\nwhat drives serial reciprocity is not gratitude or indebtedness to an individual or an organisation but a sense of solidarity with unknown others in the community . in the case of embryo donation , what appears to be a directly reciprocal act of gratitude  a surplus embryo in return for treatment  may thus be understood as something quite different .\nparticipants in our studies used a rationale for donation based not on reciprocal exchange between individuals , but on  giving back to  a research enterprise from which they had benefited and which they hoped would benefit unknown others in the future . for the swiss and chinese donors who choose to donate because they think they are supporting infertility research , these unknown others are not completely anonymous : they are  known  because of imaginatively shared experience .  giving something back  to the research that had helped them ( as they think they are doing )\nwas not considered an obligation but , rather , a form of return that was meaningful and seemed especially fitting to them because of the experiences they had gone through . in the u.k .\nstudy , although there was greater clarity about the purpose of the research being contributed to , there was still a sense among embryo providers that they were benefiting from the fact that others had participated in research in the past which had improved ivf ; they were clear in expressing solidarity with this imagined community of previous ivf research contributors by making their own contributions to research , albeit research in another domain .\nat least some of our participants , then , also see their donation to research as an indirect way of passing on the benefit they have received from research to someone else , whose situation in some way resembles their own .\nthe social meaning of this indirect reciprocity is neither gratitude nor indebtedness , but solidarity with other present and future patients .\nto summarise : our interpretation of the material suggests that donors reasons for donating were not connected in any straightforward way to either gratitude or indebtedness . for some people\nthe desire not to waste a valuable ( in more than one sense ) resource is foremost .\na generally positive stance toward biomedical science means that donation is a good use of a valuable resource . with some of the swiss participants\n, we also identified a reparative urge coming from a sense of moral unease , and here donation seems to offer a route through which the urge to make reparation can be satisfied .\nall of this suggests that neither gratitude nor indebtedness per se are present in decision - making at the ivf  stem cell interface , at least not in terms of undue inducement or of compromising the capacity for informed consent .\nthe reparative urge foregrounds a different set of ethical questions about the sociomoral meaning of the generation of spare embryos and the act of donation .\nfor example , the perceived need for reparation that appears to drive some of the swiss participants donation choices arises because people felt some sense of wrongdoing at creating embryos that are not used for pregnancy .\nthe spirit of the swiss legal framework strongly reinforces the sense that the occurrence of embryos not used for pregnancy is to be considered as wrong . from this point of view\n, one possible conclusion could be that the felt desire for reparation is in fact an ethically appropriate response : if the act of deliberately creating an embryo is a morally significant one , which needs to be justified by the good of its intended outcome ( pregnancy ) , then not using it for the purpose that justifies it does indeed present a genuine ethical difficulty .\non the other hand , the novelty of surplus embryos in the swiss legal and social context ( scully and rehmann - sutter 2006 ) meant that many patients would have been unaware at the time of their ivf of the possibility of generating a surplus embryo .\nmoreover , in most cases there were perfectly valid clinical or legal reasons why the embryos could not be transferred , which fully justified the failure to use them as originally intended . that these factors were not in the participants control\nthe swiss participants were quite aware of the valid reasons why their embryos could not be transferred , and yet some of them still said that they had fallen short of some moral standard .\nwe suggest that this persistent unease ( which does not appear so prevalent in the u.k .\nthese are captured in swiss legislation s highly defensive attitude toward embryos in general and the generation of surplus embryos in particular .\nswiss law operates from the presumption that a surplus embryo is an exceptional event that will happen only through the failure of regulation and practice specifically set up to prevent it ( porz et al .\nin addition , as we discussed earlier , the generation of surplus embryos is still an unfamiliar social practice and the role of the embryo donor is one that lacks widespread cultural recognition . in the swiss context of legal exceptionalism , then , producing one of these culturally unfamiliar entities may more readily be understood as something \nwrong  for which reparation is in order . in the more permissive cultural and legislative context of the united kingdom , although some interviewees expressed guilt about other aspects of the process ( for example , inappropriate styles of speech about embryos ) , there was no sense that not using the embryos as intended in itself constituted a moral failing .\nif our interpretation is correct , as the creation of surplus embryos becomes normalised in swiss society and the role of embryo donor becomes normalised in both the u.k . and\nswiss ( and other ) societies , there will be a shift in ideas about the moral meaning of surplus embryos , and this should be empirically testable . for the majority of the participants in switzerland and the united kingdom who chose to donate their surplus embryos , donation decisions were not driven by a reparative urge but by the feeling that donation expressed solidarity with research and/or other patients .\nwhat our empirical work shows is that gratitude to an individual must be distinguished from a solidarity - based desire to  give something back  to medical research .\nhowever , this does not necessarily mean that solidarity - based reciprocity has no relevant impact on the capacity for voluntary consent .\none possible consequence , for example , is that if potential donors feel solidarity with the research enterprise , or with present and future patients , then they might also experience an obligation to support it .\nhowever , in all three studies there were people who chose not to donate ( about half of the swiss interviewees did not donate , while in the united kingdom approximately 46 percent of those asked have been shown to opt against donation [ choudhary et al .\n2004 ] ) , which suggests either that there is no sense of obligation , or that it is neither universal nor irresistible .\nthere is a second problem if solidarity - based reciprocity is taken as something to be prevented .\nif there is a risk that gratitude felt by an individual could influence donation decisions , then the risk can be minimised by separating ivf and stem cell research physically and procedurally , as bioethicists have suggested and some clinics and guidelines have implemented .\nbut if instead there is a desire to benefit research or to show solidarity with collective  others  rather than an individual , then what sort of physical or procedural barriers could be set up to prevent it having an influence\n? there are further theoretical questions to be explored here about the assumption that contextual emotions such as gratitude or solidarity compromise the decision to donate .\nthe situation in which donation of a surplus embryo is a possibility comes about as a result of a variety of social , cultural , political , legal , and emotional features that combine to make the situation what it is .\nit will be important to identify carefully the features that are constitutive of the situation of having a surplus embryo ( including a sense of solidarity to similar others , emotional bonds with the embryo that change over time , regret over the failure to use all embryos for pregnancy , and so on ) and to consider whether these constitutive features can or should also be treated as factors that compromise the responsible , autonomous decision - making capacity of the people involved .\nthis introduces the question of the extent to which any decision to donate can be detached from its context and the contextual factors that shape how people respond to donation requests .\nfinally , we should not forget that the possibility that some donors misunderstand the kind of research they are donating to raises some ethical difficulty .\nit means that donors may be deciding for donation out of a misplaced sense of solidarity  a different ethical problem .\nthe deliberative processes of the donor participants in our three studies incorporated their appreciation of the particular moral value of their own embryos and of the value of biomedical research .\nthese deliberations are complex , and the participants own dependency on pre - existing medical research and their affiliation with others in similar situations must be recognised , we suggest , in order to understand how they might configure donation as a means to cope with the moral ambivalence of the situation in which they find themselves .\ntheir decisions are not driven by some unacknowledged sense of debt , but rather are responsive to the emerging social and moral reality of embryo donation in the first decade of the 21st century ."}
{"lay_summary": " medullary thyroid carcinoma ( mtc ) , which originates from thyroid parafollicular c cells , accounts for 3 to 5% of thyroid malignancies . \n mtc occurs either sporadically or in an inherited autosomal dominant manner . \n hereditary mtc occurs as a familial mtc or as a part of multiple endocrine neoplasia ( men ) type 2a and b syndromes . \n a strong genotype - phenotype correlation has been observed between hereditary mtc and germ - line  gain of function  mutations of the ret proto - oncogene . \n most cases of pediatric mtc are hereditary whereas sporadic mtc is rare in children and is usually diagnosed in adults . \n therefore , mtc in children is most often diagnosed in the course of a familial genetic investigation . \n the standard treatment of mtc mainly requires surgery involving total thyroidectomy and central neck node dissection before extrathyroidal extension occurs . to prevent mtc development in hereditary syndromes , \n prophylactic thyroidectomy is performed in presymptomatic patients . \n an appropriate age at which the surgery should take place is determined based upon the data from genotyping , serum calcitonin measurements , and ultrasonography . for the treatment of advanced mtc cases , the broad spectrum receptor tyrosine kinase inhibitors vandetanib and cabozantinib , which also inhibit ret , \n are used although they are not always effective . ", "article": "thyroid cancer is the most common endocrine neoplasia which accounts for about 1% of human cancers .\nmtc originates from calcitonin - producing cells ( c - cells ) of the thyroid gland and accounts for 35% of thyroid cancers .\nmtc is relatively slow - growing tumor but , if metastasized or relapsed , it becomes very aggressive causing more than 13% of all thyroid cancer - related mortality . in the united states ,\nmtc has an incidence in children of 0.03 per 100 000 population per year with a fairly equal female to male ratio [ 4 , 5 ] .\nmtc occurs either sporadically or in an inherited autosomal dominant manner . in adults , sporadic mtc accounts for 6575% of mtc , but in children ,\nsporadic mtc is very rare ; the vast majority of mtc diagnosed in the childhood is hereditary .\nhereditary mtc occurs as a familial mtc ( fmtc ) or as a part of multiple endocrine neoplasia ( men ) type 2a and b syndromes , wherein other endocrine glands are also affected .\nmtc diagnosed during childhood almost always results from a dominantly inherited or de novo activating mutations in the ret proto - oncogene , which encodes the ret receptor tyrosine kinase [ 69 ] .\nadvances in predictive genetic testing for ret mutations have enabled early diagnosis of hereditary men syndromes and prophylactic thyroidectomy in presymptomatic patients to prevent mtc .\nthe early onset of mtc in hereditary syndromes makes it an important endocrine disease that is increasingly managed by pediatric providers [ 1012 ] . in this review\n, we discuss the etiology of pediatric mtc and currently available therapeutic modality for the cancer .\nret encodes a receptor tyrosine - kinase which is expressed in the neural crest - derived cell types , including thyroid parafollicular cells , neuronal cells , and adrenal medullary chromaffin cells . in these cell types\n, ret plays a central role in regulating cell proliferation , growth , differentiation , migration and survival . in humans\nafter alternative splicing at the 3 end , ret transcripts encode three protein isoforms with distinct c - terminal ends that contain either 9 ( ret9 ) , 51 ( ret51 ) , or 43 ( ret43 ) amino acids .\nret exon 19 is present in all transcripts and its differential splicing at the 3 end produces distinct transcripts wherein exon 19 is either unspliced , spliced to exon 20 , or spliced to exon 21 .\nall three resulting ret isoforms commonly contain a tyrosine ( tyr1062 ) whose phosphorylation is critical for their activation .\nthe major ret isoforms in vivo are ret9 and ret51 , which consist of 1072 and 1114 amino acids , respectively , and are usually co - expressed .\nret consists of an extracellular ligand binding domain , a trans - membrane domain , and an intracellular kinase domain ( figure 1 ) .\nthe extracellular domain includes four cadherin - like repeats and a highly conserved cysteine - rich region , which is located near the cell membrane .\nthe intracellular domain consists of two tyrosine - kinase subdomains , tk1 and tk2 , which contain multiple tyrosine residues that are phosphorylated during receptor activation and are required for the activation of different downstream signaling pathways of ret [ 19 , 20 ] .\nthe ligands for ret are the glial cell line - derived neurotrophic factor ( gdnf ) family proteins , including gdnf , neurturin , artemin , and perseptin .\nactivation of ret also requires the formation of a heterodimeric complex recruiting a gdnf - family receptor alpha ( gfr ) . when unbound by a ligand , ret is monomeric , unphosphorylated , and inactive .\nwhen a ligand and the gfr co - receptor bind to the extracellular domain of ret , ret undergoes dimerization and autophosphorylation of the tyrosine residues in their kinase domains .\nthis generates the docking sites for their downstream effectors that contain the src homology 2 domain .\nfor example , gdnf - mediated stimulation of ret results in activation of the pathways regulated by phosphatidylinositol 3-kinase ( pi3k ) and different mitogen - activated protein kinases ( mapks ) , including the extracellular regulated kinases ( erks ) , c - jun amino - terminal protein kinases ( jnks ) , the p38 mapk and the big map kinase ( bmk1 ) erk5 [ 22 , 23 ] .\nret is one of the first receptor tyrosine - kinases ( rtks ) that have been found to play a role in neoplasia , being most well - known as a key etiological factor for thyroid cancer [ 6 , 24 ] . activating mutations of ret\nabnormally enhance ret activity and can trigger tumorigenesis in certain organs although the exact underlying mechanisms are as of yet unclear .\nfirst , mutations of the six cysteine residues ( cys609 , 611 , 618 , 620 , 630 , and 634 ) in the extracellular domains can promote ret dimerization via disulfide bonds and result in constitutive ligand - independent activation of ret .\nsecond , mutations affecting the tyrosine kinase domains can also confer ligand - independent catalytic activity to monomeric ret .\nthese ret mutants exhibit different patterns of autophosphorylation and altered substrate specificity [ 2628 ] . indeed ,\nactivation of different downstream signaling pathways is associated with different clinical features of ret mutant thyroid cancers , as observed in men2 syndromes discussed below .\nfor example , the hirschprung disease , a congenital disorder of neural crest development is caused by a loss - of - function ret mutation .\nof note , the hirschprung disease is closely associated with men2a , demanding a genetic screening for men2a for children with familial hirschsprung 's disease .\na strict correlation exists between specific ret mutations and the onset of hereditary mtc ( table 1 ) [ 31 , 32 ] .\nthe detailed and up - to - date information of ret sequence variations can be obtained from the men2 ret database ( www.arup.utah.edu/database/men2/men2_welcome.php ) , which also contains links to selected men2 literature reviews , gene and protein information , and ret reference sequences .\nthe men2a subtype , accounting for 9095% of the men type 2 cases , is a highly penetrant , autosomal dominant endocrine tumor syndrome characterized by the development of mtc in > 90% of ret mutation carriers . in association with mtc\nin addition , rare variants of men2a are also associated with cutaneous lichen amyloidosis and hirschsprung disease [ 35 , 36 ] .\npatients with men2a usually have mutations in the extracellular cysteine - rich region of the ret tyrosine kinase receptor , usually in exon 10 ( codons 609 , 611 , 618 or 620 ) or exon 11 ( codon 634 ) ( table 1 , figure 1 ) [ 31 , 37 ] .\nmore than 80% of men2a patients exhibit a specific substitution , i.e. , cys634arg , on exon 11 .\nmtc is generally the first manifestation of men2a syndrome and develops during early childhood , usually before age six and sometimes before age two . the men2b subtype accounts for approximately 510% of the men type 2 cases .\nmen2b patients typically feature early coincident onsets of mtc , pheochromocytoma , and gastrointestinal mucosal ganglioneuromas .\nvisible physical symptoms include mucosal neuromas of lips ( bumpy lips ) and tongue , and asthenic marfanoid body habitus [ 36 , 40 ] .\nmen2b patients usually have mutations in the tyrosine kinase domain 2 ( tk2 ) in the intracellular region of ret , which almost always ( > 95% ) lead to a single substitution , i.e. , met918thr , in exon 16 ( figure 1 ) [ 31 , 37 ] . de novo mutations , which usually occur on the paternal allele , are also common in men2b .\nmen2b is characterized by the early development of an aggressive form of mtc in all affected individuals , typically during the first year of life .\nthus , apart from the genetic testing of ret mutations in children born to a parent with men2b , early diagnosis of men2b remains challenging .\nindividuals with men2b are likely to develop metastatic mtc at an early age if they do not undergo prophylactic thyroidectomy before age one . without this intervention ,\nfmtc is considered as the least aggressive clinical variant of men2a with decreased penetrance and/or delayed onset of the other endocrine pathologic manifestations [ 39 , 43 ] . similarly to sporadic cases , familial mtcs are isolated and are not associated with other endocrine tumors .\npatients with fmtc harbor mutations similar to men2a in either the extracellular or intracellular region of the ret tyrosine kinase receptor [ 6 , 44 ] .\nthe onset of fmtc is relatively late , not appearing until the second or the third decade of life , and its penetrance is lower than the mtc caused by men2a and men2b [ 31 , 39 , 45 , 46 ] .\ntherefore , it is often difficult to determine fmtc based upon a family history and only careful genetic screening can distinguish between inherited and sporadic forms of mtc .\nmtc cells secrete the polypeptide hormone , calcitonin , and the glycoprotein carcinoembryonic antigen ( cea ) , and these are used as diagnostic biomarkers for mtc .\nmtc is most commonly diagnosed by immunohistochemical staining of fine - needle aspiration of a new thyroid nodule for calcitonin , chromogranin a , or cea .\nserum calcitonin is the primary biochemical marker used for detection , staging , postoperative management , and prognosis for mtc patients .\nhowever , in very rare cases , certain mtc cells do not secrete calcitonin , which makes diagnosis and patient follow - up difficult .\nsymptoms of mtc include neck pain , a palpable neck mass , and/or diarrhea resulting from hypercalcitoninemia .\nthe clinical course of mtc in men2 patients is variable and is determined by the codon specific mutations . in hereditary form , an age - related progression of malignant disease is observed , with lymph - node and distant metastases being typically detected years after the onset of tumorigenesis .\nmetastatic spread to cervical and regional lymph nodes ( i.e. , parathyroid , paratracheal , jugular chain , and upper mediastinum ) or to distant sites including the liver , lungs , or bone is common and is frequently present in individuals with a palpable thyroid mass or diarrhea .\npositive lymph - node status and higher stage at diagnosis predict lower disease - free survival and higher mortality [ 5 , 5456 ] .\nmen2 is one of few hereditary cancer syndromes for which predictive genetic testing is recommended at childhood .\ngenetic testing for hereditary mtc syndromes has had an enormous impact on reducing the incidence of mtc in the families affected by these hereditary syndromes [ 57 , 58 ] .\ngenetic counseling is indicated for all children diagnosed with mtc and others who either carry or are at risk of inheriting a ret mutation .\nchildren of patients with men2b should undergo ret analysis at birth , and children of patients with men2a or fmtc should undergo ret analysis before age six [ 59 , 60 ] .\neven 610% of apparently sporadic cases of mtc demonstrate de novo germ - line ret mutations , thus making genetic testing worthwhile in all patients with mtc .\nthus , all children with an affected parent in this setting retain a 50% risk of mtc , and surgical decisions must rely solely on clinical testing .\nthe standard treatment for mtc is surgical removal of all thyroid tissue including the posterior capsule [ 39 , 62 ] .\nearly thyroidectomy in all men2 patients can change the course of disease , either in a preventive or a curative fashion .\nthe american thyroid association guidelines task force has classified mutations based upon a model that uses the genotypephenotype correlations to rank the mutations into risk levels for the development of aggressive mtc from the lowest  a  to the highest  d  ( table 1 ) .\nthis classification may be used to predict phenotype , to recommend the timing of prophylactic thyroidectomy and the extent of surgical intervention , and to begin biochemical screening for pheochromocytoma and hyperparathyroidism .\nthe ages at which the prophylactic thyroidectomy is recommended for the children tested positive for the ret gene mutation are as follows : ages 01 for ret mutations that carry the highest risk for aggressive metastatic mtc at young ages , i.e. , classified as  ata - d  ; before age 5 for ret mutations that carry a lower , yet still high risk of aggressive mtc at any age , i.e. , classified as  ata - c  ; after age 5 for ret mutations that carry a lower risk of aggressive mtc , i.e. , classified as  ata - b  or  ata - a ,  so long as the affected children have no other clinical signs of mtc development .\nthere is ongoing debate on what age the thyroidectomy should be recommended for fmtc patients .\nsome clinical institutes suggest the prophylactic surgery at age 1015 , depending upon the exact mutation and family history , while recommending yearly test of calcitonin levels prior to deciding the surgery .\nindeed , the ata management guideline for mtc has been very recently revised . in the setting of a prophylactic thyroidectomy ,\nthe lymph - nodes are not routinely removed since metastases are not expected to occur at this stage . in the case of clinically apparent mtc , whether sporadic or hereditary , thyroidectomy and concomitant central and compartment - oriented lateral neck dissection should be performed to increase clinical outcomes .\nprimary hyperthyroidism is rare during childhood ; therefore , parathyroidectomy is usually avoided , particularly during a prophylactic procedure .\ndissection and autotransplantation of parathyroid tissue is not typically performed at the time of thyroidectomy unless there is enough biochemical evidence for hyperparathyroidism .\nthyroidectomy in children is usually associated with a higher rate of complications , such as recurrent laryngeal nerve injury and hypoparathyroidism , as compared to the surgery in adults .\ntherefore , pediatric thyroidectomy must be performed by highly experienced thyroid surgeons . for individuals with a ret mutation who have not had a thyroidectomy , annual biochemical screening of calcitonin levels is recommended and , if the results are abnormal , immediate thyroidectomy is required .\nannual serum calcitonin screening should begin at age six months for children with men2b and at age 35 for children with men2a or fmtc .\nbiochemical evidence of disease recurrence includes elevation of calcitonin and cea levels . all individuals who have undergone thyroidectomy\nneed thyroid hormone replacement therapy along with annual screening for pheochromocytoma and hyperparathyroidism depending upon the ret mutation present in the patients .\nmtc does not respond well to radiation therapy or the standard cytotoxic chemotherapeutic agents , including doxorubicin , dacarbazine , capacitabine , and 5-fluorouracil [ 43 , 71 ] . of note ,\nthe mechanism - based targeted therapies that inhibit ret and other receptor tyrosine kinases have become available for the treatment of surgically inoperable progressive mtc .\nthese include the multi - kinase inhibitors , vandetanib ( zd6474 , caprelsa ) and cabozantinib ( xl-184 , cometriq ) , which have been recently approved by the us food and drug administration [ 72 , 73 ] . a recent phase i / ii trial of vandetanib in children with mtc reported partial responses in 47% patients .\nin general , the drug efficiency and the primary side effects , i.e. , diarrhea , rash , headache , hypertension , and nausea , were similar between children and adults .\nphase iii trial of cabozantinib demonstrated a 28% response rate in adults with significant adverse effects .\ntherefore , there is a critical need for more effective therapies for patients with advanced mtc .\ncharacterization of additional molecular pathways responsible for mtc development may allow the discovery of therapeutic targets that can be exploited to induce reduction of tumor size , disease stabilization , and symptomatic improvement [ 7782 ] .\nmtc and the men type 2 syndromes are rare but significant endocrine diseases that are increasingly encountered by pediatricians .\nour understanding of mtc has been greatly increased by the discovery of ret and the genotype \ngenetic tests according to the established guidelines should be performed whenever diagnosis of mtc is made .\ndue to limited adjuvant treatment options , adequate surgical treatment is critical for initial control of the disease and prophylactic thyroidectomy is recommended for children with men2a and men2b at an early age , sometimes during infancy .\nemerging newer treatments are expected to better treat this rare but life - threatening malignancy ."}
{"lay_summary": " current neuronavigation systems can not adapt to changing intraoperative conditions over time . to overcome this limitation \n , we present an experimental end - to - end system capable of updating 3d preoperative images in the presence of brain shift and successive resections . the heart of our system is a nonrigid registration technique using a biomechanical model , driven by the deformations of key surfaces tracked in successive intraoperative images . \n the biomechanical model is deformed using fem or xfem , depending on the type of deformation under consideration , namely , brain shift or resection . \n we describe the operation of our system on two patient cases , each comprising five intraoperative mr images , and we demonstrate that our approach significantly improves the alignment of nonrigidly registered images . ", "article": "neurosurgery is characterized by the delicate balance between surgical success and potential for devastating side effects . thanks to multiple technological improvements\n, the morbidity of neurosurgical interventions has substantially decreased over the last decades , allowing for the resection of previously inoperable lesions . in particular , image - guided neurosurgery ( igns ) devices allow the use of coregistered and fused multimodality 3d images to guide the surgeon 's hand and help define preoperatively the boundaries of pathological and predefined functional structures . meanwhile\n, new modes of medical imaging have also improved the localization of pathological lesions and their characterization .\nmedical imaging nowadays includes a wealth of different techniques , such as computed tomography ( ct ) , structural and functional magnetic resonance imaging ( smri and fmri ) , diffusion tensor imaging ( dti ) , and positron emission tomography ( pet ) .\nalthough the overall accuracy of igns is estimated to be 12  mm , current neuronavigation systems can not , however , adapt to changing conditions over time .\nskull - opening brain shift , brain retraction , cerebrospinal fluid suction , lesion resection , perfusion , and pharmacological manipulation during surgery indeed all alter the 3d morphology of the structures [ 25 ] .\nthese changes can lead to localization errors that are one order of magnitude larger that igns accuracy [ 1 , 2 , 6 ] and may result in incomplete resections or unexpected damage to normal brain .\nsuch inaccuracies could be reduced if one could acquire , throughout surgery , fresh images of the same modalities and quality as the preoperative ones\nintraoperative images such as intraoperative mr ( imr ) images are  with the exception of a handful surgical facilities  usually acquired using low - field mri scanners that provide lower resolution and contrast than their preoperative counterparts , and , to this date , several useful imaging modalities , such as pet and possibly meg , can not be acquired intraoperatively .\none solution is to  bring over  the high - quality preoperative multimodality images into the intraoperative configuration of the brain using a nonrigid registration technique [ 710 ] .\none category of nonrigid registration techniques uses physics - based models , where landmarks are tracked in successive reduced - quality intraoperative images , and their displacement fields drive the deformation of a biomechanical model .\nso far , most of the mechanical conditions of the brain can not be estimated in the operating room , such as the volume of cerebrospinal fluid flowing out of the skull cavity , intercellular fluid volume changes that result from mannitol injection , or changes in blood volume and vessel permeability .\nthe fact that an intraoperative image can provide the knowledge of the current state of the brain after some deformation partly eliminates the need for a complete evaluation of these mechanical conditions .\nthe nonrigid registration technique replaces them with the landmark displacements evaluated from successive intraoperative images . using a nonrigid registration technique based on a biomechanical model , three types of brain deformations\nhave been identified that require specific modeling , although they depend on common parameters , such as csf suction , perfusion , or pharmacological manipulation .\nthe first deformation is the brain shift , which appears at the beginning of surgery with the opening of the skull and dura .\nthe suction or leakage of csf , as well as the release of intracranial pressure caused by tumor growth , generally cause such shift of the brain ( note that in this work , we name  brain shift  the specific shift of the brain that occurs after the opening of the skull and dura , before any other surgical act has happened ) .\nhowever , for these deformations , we will consider that the shift is a part of these two deformations .\nthe second deformation is the retraction ; when target tissues are located deep inside the brain , the surgeon incises brain tissues and inserts a retractor to spread out the tissues , and to create a path towards the target .\nthe third deformation is the resection , that is , the removal , of lesion tissues .\nthree deformations can thus be defined in terms of the two elemental actions that change the topology of the brain : the introduction of a discontinuity and the removal of some tissues .\nmost studies of brain deformation based on biomechanical models have focused on shifts ( the topology of the brain is not modified ) , that occurs just after the opening of the skull and dura [ 1125 ] .\na good review of these different studies can be found in [ 24 , 2628 ] .\nresection and retraction are more complex to model than ( brain ) shift . until recently ,\ntheir modeling for the specific application of preoperative image update has received much less attention .\none of the difficulty for modeling resection and retraction is that both induce a topological change of the brain because some tissue are cut .\na method of mesh adaptation [ 2931 ] or remeshing [ 3235 ] must be used in conjunction with fem if an accurate representation of the location of the cut , for example , the resection cavity or retraction path , is needed to deform the model . indeed , fem can not directly handle discontinuities that go through the fes , and requires to realign the discontinuity with fe boundaries . in the field of fracture mechanics , which studies the growth and propagation of cracks in mechanical parts\n, some methods were developed to avoid using fem in conjunction with mesh adaptation or remeshing .\nthe extended finite element method ( xfem or x - fem ) appeared in 1999   and has been the object of considerable research since then .\nxfem works by allowing the displacement field to be discontinuous within some fes of the mesh .\nthe mesh does not have to conform to the discontinuities , so that these can be arbitrarily located with respect to the underlying fe mesh . because xfem allows an accurate representation of the discontinuities\nwhile avoiding mesh adaption or remeshing , and because of the similarity between cracks in mechanical parts and cuts in tissue , we proposed the use of xfem for handling cut , resection , and retraction in the updating of preoperative images .\nthis paper presents a complete 3d framework for updating multimodal preoperative images with respect to surgical brain deformations , due to brain shift and successive resections , followed and quantified using imr images .\nour approach is modular , and is applied iteratively each time a new intraoperative image is acquired .\nwe take into account successive deformations based on a linear elastic biomechanical model which is deformed using fem or xfem , depending on the type of deformation occurring between the pair of imr images under consideration , namely , brain shift or resection .\nwhile some 3d results have already been presented for brain shift , and initial 3d results for resection   modelings , this paper is the first complete and detailed account of the generalization to 3d of our 2d previous work .\nwe present the state - of - the - art of resection modeling for preoperative image update . in section 3\n, we describe our basic strategy for updating preoperative images based on successive intraoperative images . in section 4 , we give detail about our methods and algorithms . in section 5 ,\nwe consider two patient cases that illustrate our approach for handling brain shift followed by successive resections .\namong studies that take into account resection for preoperative image update , one should distinguish two categories .\nthe first category of studies models brain deformation using two time - point images , the first image being acquired before surgery has started , the second image being acquired after resection . in this category ,\nthe methods that existed for a second image showing some brain shift are adapted for a second image showing some resection .\nthe second category of studies models brain deformation using more than two time - point images , and models at least two successive resections . among the first category of studies ,\nhagemann et al .   developed a 2d method for modeling brain deformation between a preoperative mr image and a postoperative mr image , the postoperative image showing a complete resection .\nthe 2d mesh of the biomechanical model corresponded to the underlying pixel grid of the 2d image .\nthe biomechanical model included four different linear elastic laws for the skull / skin region , the whole - brain region , the csf region , and the image background .\nthey computed the correspondence of the skull boundary , the whole - brain region boundary in the neighborhood of the tumor , and the posterior midline between the two images .\nthey also computed the correspondence between the internal tumor region boundary visible in the preoperative image , and the resection cavity boundary visible in the postoperative image , both boundaries corresponding under the assumption that the resection is complete .\nthe displacements fields of these landmarks drove the deformation of the biomechanical model . as a result , the biomechanical model presented high deformation in the tumor region , which is not physically plausible .\nhowever , the resection was complete , and , thus , they were not interested by the displacement field of the biomechanical model in the tumor region itself .\nclatz et al .   developed a 3d method for modeling the brain deformation between a preoperative mr image and an imr image , the latter showing partial or complete resection .\nthe biomechanical model was deformed based on a sparse volume displacement field evaluated from the two images , using a block matching algorithm . in their algorithm , blocks of voxels that presented discriminant structures were selected in the preoperative image .\nthe blocks were then matched to blocks in the imr image using a similarity criterion , for example , a coefficient of correlation .\nthe value of the similarity criterion was used as a value of confidence in the displacement measured by the block matching algorithm .\nthe biomechanical model was then deformed iteratively , driven by the sparse displacement field of the matched blocks , where a block rejection step was included for measured block displacements initially selected but considered as outliers . in the imr image , a part , or the totality , of the tumor tissues\nthe blocks were thus selected and matched in only the healthy - brain region of the two images .\nthey tested their algorithm on six patient cases , and used for validation nine landmarks picked up manually in each image .\nthey found a mean and maximum error on displacements of 0.75  mm and 2.5  mm , respectively .\nthey explained this phenomenon by the fact that a substantial number of block matchings were rejected in the tumor neighborhood .\nthe deformation of the biomechanical model in the tumor neighborhood was thus essentially governed by the linear elastic law , and the result might show the limitation of this model .\narchip et al .   also tested the nonrigid registration method presented in   on eleven patient cases , and used the 95% hausdorff distance   for evaluating the alignment of the nonrigidly registered images . as a result\n, they obtained a mean error of 1.82  mm . among the second category of studies , miga et al .  \nthey built a linear poroelastic biomechanical model and preoperatively tagged the tetrahedron fes that were going to be removed to simulate the brain deformation due to successive resections .\nsecond , a boundary condition was applied to the new boundary of the resection cavity , in order to model the relaxation of strain energy , induced by preoperative tumor growth or surgery acts , stored in the resected tissues , and released after their removal . in this approach ,\nthe tissue discontinuity was represented as best as possible with a jagged topology defined by the fe facets defining the boundary of the resection cavity .\n[ 45 , 46 ] also modeled the removal of tetrahedra in order to model the action of an ultrasonic aspirator in the context of real - time surgery simulation .\n[ 13 , 47 , 48 ] modeled successive resections based on several time - point imr images . between two successive images\n, they deformed the biomechanical model , in its current state of update , to take into account the ( partial ) resections(s ) that took place between these two images .\nfirst , the biomechanical model , in its current state of update , was deformed in accordance with the displacement field of the healthy - brain boundary between the pair of images under consideration .\nsecond , the fes that fell into the resection cavity in the second image of the pair were removed , while the fes that laid across the resection - cavity boundary were cut . to ensure the link between the successive deformed configuration of the biomechanical model , their algorithm kept track of the topology modification between fes and nodes of the mesh before and after the removal of fes .\nthey tested their algorithm on one patient case including five imr images ( the first two imr images being used for brain shift modeling ) , and used for validation thirty - two landmarks picked up manually in each image .\nthey found a mean and maximum error on the displacements of 0.9  0.7  mm ( mean  standard deviation ) and 3.7  mm , respectively .\nthey explained this phenomenon by the limited accuracy in the process of picking landmarks in that region , and because the retraction occurring between the second and third images was modeled as a resection , that is , a removal of tissues , even though the tissues were not removed but simply spread out .\nthe methods described above have been all developed using an fem - based biomechanical model for intraoperative image registration .\nthe objective of a surgical simulator is to provide an interactive manipulation with force feedback of the anatomical part to be operated using various surgical instruments . in order to model a large range surgical procedures ,\njebkov and kuhlen   have applied nonlinear xfem for simulating cut , and have shown that xfem is successfully efficient for such purpose .\nthe block diagram of figure 1 shows our global approach for updating preoperative images using successive imr images acquired at different critical points during surgery .\nalthough the principles of the approach are quite general , they are tailored for use based on images acquired with a 0.5  tesla intraoperative ge signa scanner , which guarantees that the full volume of brain tissues is included in the image field of view . in our present strategy ,\nthe preoperative images are updated incrementally . at the end of each update , the preoperative images should be in the best possible alignment with the last imr image acquired .\nprior to surgery , a patient - specific biomechanical model is built from the set of preoperative images . because the patient does not necessarily lie in the same position during the acquisition of each of the preoperative images\n, one may need to perform a rigid registration ( involving translations , rotations , and scales ) to bring these images into correspondence , assuming , in first approximation , there is no local , that is , nonuniform , brain deformation between preoperative images .\nonce the 1st imr image has been acquired prior to the opening of the skull , the set of registered preoperative images and the biomechanical model are registered to the 1st imr image via a rigid transformation . in the present situation , it is assumed that the patient 's brain imaged in the 1st imr image has the same physical shape as the brain imaged in the preoperative images ( note that in the following , when an imr image is defined by a number , this number is the index of the imr image in the series for a specific patient case .\nthe 1st imr image thus corresponds to the very first imr image of the series ) . as each imr image\nis acquired , this new image and the preceding imr image are used to estimate the deformation of the brain .\nthe update of the preoperative images is done incrementally with each new pair of successive imr images . for each pair , we proceed as follows . a set of common anatomical landmarks\nthe use of surface structures rather than volume structures   seems more appropriate given the reduced - quality of typical intraoperative images , and would be more easily adapted to intraoperative modalities other than imr , such as ius .\nthe landmark surface displacement fields resulting from the matching are then applied to the biomechanical model , which is deformed using fem or xfem , depending on the type of deformation occurring between the acquisition times of the imr images in the pair under consideration , namely , brain shift , or resection .\nthe resulting displacement field of the biomechanical model is finally used to warp the set of preoperative images in their current state of updating .\nnote that , for each deformation modeling , the biomechanical model is deformed in accordance with the landmark displacements tracked between the pair of successive imr images under consideration . because intraoperative deformation can follow a reverse direction , it is important to track the landmarks between the next - to - last and the last acquired imr images , rather than track the landmarks between the first and the last acquired imr images . for the patient cases treated in section 5 , we assume that the brain undergoes relatively small deformations ( small strains and small displacements ) , and we use a linear finite - element formulation in the biomechanical model .\na consequence of using this linear formulation ( linear elasticity ) is that the equations of solid mechanics can be solved based on the initial configuration of the solid .\nactually , knowing the displacement field increment un = u  u at the anatomical landmarks between configuration n and increment n + 1 , one can apply this constrained displacement field increment un to the initial configuration , and the finite element analysis will lead to the deformation tensor increment n between the configuration n and n + 1 .\nthe final deformation tensor or the body is thus simply obtained from  = k=0k .\nremark that rigorously , the increment of constrained displacement field at the landmark should be applied to the balanced solution of the solid reached after increment n , but as we are using a linear elasticity model , this step can be skipped owing to the superposition principle : if  = c , then  = k=0k = ck=0k = c , where c is the hooke tensor . as a summary , with this approach ,\nthe process of deformations is modeled as a succession of deformations k , for example , brain deformation composed of shift followed by successive resections and the current configuration of the brain biomechanical model , after a specific deformation can then be recovered by adding the computed volume displacements for all successive incremental deformations . remark\nthat this is not a limitation of the method as we could easily extend it to nonlinear model by simply keeping in memory the previous deformed configuration n and adding the constrained displacement field increment un to compute the new deformed configuration at increment n + 1 , simply this would be less computationally efficient . because we use a linear formulation ( and , thus , the incremental volume displacement fields can be added to recover the current configuration of the biomechanical model ) , we could theoretically obtain an identical deformed configuration of the biomechanical model using the two following approaches .\nthe first one would consist of computing and adding the successive incremental deformations of the biomechanical model based on the landmarks tracked between the next - to - last and the last acquired imr images .\nthe second approach would consist in computing directly the deformed configuration of the biomechanical model based on the landmarks tracked between the first and the last acquired imr images .\nhowever , the landmarks selected to drive the deformation of the biomechanical model vary depending on the type of deformation , namely , brain shift or resection .\nin addition , part of the biomechanical model is  cut ,  using xfem , to model resection .\nconsequently , we would not get an identical deformed configuration of the biomechanical model by these two approaches .\nin order to use a maximum of information from the imr images , we track , as explained for the first approach , the landmarks between the next - to - last and the last acquired imr images .\nthe problem of updating preoperative images between more than two critical points during surgery , that is , based on more than two imr images , is addressed in only a small number of studies . in our previous work [ 39 , 41 ] , and in\n, the biomechanical model was successively deformed , and this was done using a linear formulation .\nthe framework proposed here , where the initial biomechanical model is always used , instead of using it in its successive states of deformation , has the important advantage of using a good quality mesh for each deformation modeling rather than using a mesh whose quality progressively deteriorates with each successive deformation modeling , and which would require remeshing or mesh adaptation for getting back good fe quality . to summarize ,\nfor each deformation , the landmarks are tracked between the two successive imr images under consideration . because we use a linear formulation ,\nthe displacement fields of these landmarks are applied to the initial , rather than current , configuration of the biomechanical model .\nthe resulting volume displacement field corresponds to the deformation that the brain undergoes between the two imr images .\nthis volume displacement field is used to deform the preoperative images in their current state of update , that is , registered ( at the previous step , if any ) to the first imr image of the pair .\nafter the deformation , the preoperative images are thus in as good as possible registration to the second imr image of the pair . in all the rest of this work ,\nwe make a simplification of the approach just presented , by using the 1st imr image as a substitute for the preoperative images .\nthe biomechanical model is thus built based on structures visible in the 1st imr image , instead of in the preoperative images , and the structures used in the model are limited to the ones visible in the intraoperative image . except for the rigid registration between the preoperative images , the biomechanical model , and the 1st imr image , this simplified approach allows us to discuss , illustrate , and test all key aspects of the system .\nthe above strategy allows us to focus on the main issue of this paper , that is , the estimation and handling of 3d deformations .\neven though the issues involved in the update of preoperative images will need to be addressed in a operational image update system , the present strategy of deforming the imr images remains useful for calibration purpose , even in the operating room .\nthis section details the different methods that are commonly used for updating preoperative images in presence of brain shift and resection .\nmore specifically , the block diagram of figure 2(a ) shows the building of the biomechanical model from the preoperative images .\nspecific regions from the preoperative images are segmented , meshed , and assigned appropriate constitutive laws .\nthe block diagram of figure 2(b ) shows , for any pair of successive imr images , a detailed view of the calculation of the volume displacement field of the initial biomechanical model that corresponds to the deformation that has occurred between the acquisition time of these images . all along surgery , the patient is lying inside the 0.5 tesla intraoperative ge signa scanner .\nalthough the patient 's head is fixed , one can not totally rule out the possibility of slight head motion .\nimr images thus have to be rigidly coregistered to take into account this potential rigid motion .\nthe rigid registration that we use is the point - based landmark transform available in vtk ( http://www.vtk.org/ ) .\nthe segmentation of imr images into specific regions , for example , healthy - brain and tumor regions , is first performed manually using 3d slicer ( http://www.slicer.org/ ) and then smoothed to minimize the dependance of the results on segmentation roughness .\nit is clear that performing a manual segmentation in the operating room is not acceptable , and that this process needs to be automated as completely as possible to test the feasibility of our framework online .\nhowever , while there exist sophisticated segmentation algorithms that could be used [ 5052 ] , in particular for extracting the whole - brain region ( skull and external cerebrospinal fluid masked out ) , the segmentation of the tumor region is still challenging . as mentioned above , the biomechanical model is built , in the present context , from the 1st imr image rather than from the preoperative images . thanks to the use of xfem instead of fem for modeling discontinuities , this biomechanical model can be built offline before the operation starts and does not need to be repeated ( through remeshing ) during the surgery . with respect to fem - based approaches ,\nthe execution time thus ceases to be a limiting parameter , which is a remarkable advantage of our approach .\nit thus requires specific techniques , and we use the meshing software tool isosurf ( http://svr-www.eng.cam.ac.uk/~gmt11/software/isosurf/isosurf.html ) . our goal is to model the boundaries of healthy - brain and tumor regions as two connected surfaces meshes .\nhowever , isosurf can only mesh the boundaries of one or several separate regions , and , thus , does not allow one to mesh connected region boundaries with common nodes at their intersections .\nwe thus start by building two separate surfaces meshes that we connect using our own routines based on vtk .\nthe two connected triangle surfaces are then jointly meshed into a single volume mesh of tetrahedra that conform to the two surface meshes using gmsh ( http://www.geuz.org/gmsh/ ) .\nfurther details on the building of the biomechanical model , in particular the building of the connected surface meshes , can be found in .\na linear elastic law is assigned to the biomechanical model , with young modulus e = 3000  pa and poisson ratio  = 0.45 . because displacements , rather than forces , are applied to the model using a linear formulation , the fem or xfem solution is independent of young modulus e .\nwe choose as surface landmarks the whole - brain and internal tumor region boundaries . to evaluate the surface deformations of these region boundaries between two imr images , we use an active surface algorithm [ 55 , 56 ] .\nbecause these region boundaries to match must be closed surfaces , we thus use as surface landmarks the whole - brain and healthy - brain region boundaries .\nthe surface deformation of the internal tumor region boundary will be derived from the active surface algorithm of the healthy - brain region boundary . in our active surface algorithm coming from [ 13 , 47 , 48 ] , the external forces f(x ) are computed using a gradient descent on a distance map of the region boundary . with such external forces , the active surface algorithm is not able to take correctly into account local rigid motion due , as an example , to lateral or tangential movement depending on the head orientation . for the whole - brain region , any rigid transformation that could have occurred\nhas already been taken into account by the rigid registration of the imr images ( section 4.1 ) . however , for the healthy - brain region , it can happen that the internal tumor region boundary moves partly in a rigid way .\ntherefore , the active surface , initialized from the healthy - brain region boundary in the first imr image , is first locally transformed in a rigid way along the internal tumor region boundary using the iterative closest point transform available in vtk .\nthen , this resulting surface is deformed using the active surface algorithm as explained above .\nfurther details on the local rigid registration of the healthy - brain region boundary can be found in . before applying the displacements whole - brain and internal tumor region boundaries to the biomechanical model nodes ,\nthe two surface displacement fields are smoothed based on a weighted - distance average , that is , the displacement of each node is averaged with the displacements of its n closest neighbor nodes .\nthis smoothing will make them consistent with each other , and compatible with the volume mesh in order to avoid element flipping , in particular at the intersections between whole - brain and internal tumor region boundaries .\nthe displacement fields of the surface landmarks are applied to the biomechanical model , which deforms according to the laws of solid mechanics .\nthe equations of solid mechanics are solved using fem or xfem , depending upon the type of circumstances , namely , brain shift or resection .\nwe use the fem - software tool metafor ( http://metafor.ltas.ulg.ac.be/ )   developed in our mechanical - engineering department , to which we have added an xfem module .\nthe initial stress state of the brain is unknown and is thus set to zero for each fem or xfem computation , as in [ 10 , 13 ] .\nfem discretizes the solid of interest into a mesh , that is , into a set of fes interconnected by nodes , and approximates the displacement field u(x ) by the fem displacement field u(x ) defined as \n ( 1)ufem(x)=iii(x)ui , \n\t\t\t\t\t\t\t where i is the set of nodes , the i(x ) 's are the nodal shape functions ( nsfs ) , and the ui 's are the nodal degrees of freedom ( dofs ) .\neach i(x ) is defined as being continuous on its compact support i , which corresponds to the union of the domains of the fes connected to node i . in our approach , we use linear nsfs .\nin contrast , xfem handles a discontinuity by allowing the displacement field to be discontinuous within fes [ 37 , 5860 ] .\nthe xfem displacement field generalises the fem displacement field ( 1 ) with \n ( 2)uxfem(x)=iii(x)ui+iji(x)j=1neigj(x)aji . \n\t\t\t\t\t\t\t\nthe first term corresponds to the fem displacement field ( 1 ) , where i is the set of nodes , the i(x ) 's are the fem nsfs , and the ui 's are the nodal fem dofs . the heart of xfem is the  enrichment  that adds a number , n , of dofs aji to each node i of the set j , which is the subset of nodes of i whose support is intersected by the discontinuity of interest .\nthese dofs are multiplied by the nsfs i(x ) and the discontinuous functions gj(x ) .\nthe use of specific xfem enrichment functions gj(x ) for a node i  j depends on the type of discontinuity , for example , crack , hole , material interface , and so forth , to be modeled .\nsuppose that our goal is to model a crack , characterized by a discontinuity in the displacement field ( as opposed to a material interface for instance , characterized by a discontinuity in the derivative of the displacement field ) .\nwhen the crack fully intersects the support of the node , a simple choice is a piecewise - constant unit function that changes sign at the boundary across the crack , that is , the heaviside function \n ( 3)h(x)={1for  ( xx)en>0,1for  ( xx)en<0 , \n\t\t\t\t\t\t\t where x is again the position of a point of the solid , x * is the position of the point on the crack that is the closest to x , and en is the outward normal to the crack at x * . in case of resection deformation , the goal is to model a discontinuity such that the part of tissues corresponding to tissue removed by the resection has no influence on the deformation of the remaining part of the tissues .\none is actually interested in the deformation of the remaining part of the tissues only . in that sense ,\nthe hole function    as the following equation :  \n ( 4)v(x)={1for  ( xx)en>0,0for  ( xx)en<0 , \n\t\t\t\t\t\t\t could be used as xfem enrichment function , instead of the heaviside function , and would be totally sufficient .\nthe results that we would obtain on the remaining part of the tissues would be identical .\nhowever , because the heaviside function is necessary for retraction modeling , we have used the same function for the resection modeling even if it was not strictly necessary . when minimizing the total deformation energy , the resulting xfem equations remain sparse and symmetric as for fem .\nwhereas fem requires a remeshing and the duplication of the nodes along the crack to take into account any discontinuity , xfem requires the identification of the nodes whose support is intersected by the crack and the addition of dofs : ( 1 ) any node whose support is not intersected by the discontinuity remains unaffected and thus possesses three dofs ; ( 2 ) any node whose support is fully intersected by the discontinuity is enriched with three heaviside dofs and thus possesses six dofs . to qualitatively estimate the similarity between two images , we compare the edges extracted from these images using the canny edge detector available in itk ( http://www.itk.org/ ) .  \nindeed , although potentially useful for the sake of comparing methods on a mathematical basis and defining unique correspondences , landmark - based target analysis presents several relevant limitations in the present setting . having experts picking landmarks introduces significant intra- and interobserver variability . picking landmark points , as ferrant et al .  \ndid , is rather difficult when it comes to define enough visible landmarks  especially in the tumor region  on the 5 different images ( and not 2 images only , as majority of studies focusing on brain shift are using ) . rather than point targets , linear tumor contours , and limits between structures and potential eloquent structures matter most in the practical case of tumor ablation neurosurgery . \n\t\t\t\t\t\nthese are the reason why we chose to use the canny edges in order to evaluate the registration . besides\n, while it is true that these edges do not necessarily physically correspond between the successive imr images , these images have been acquired with the same image protocol ( mr sequence , voxel size , grayscale value range ) , which should limit this problem .\nto quantitatively estimate the similarity of the two edge maps , we compute the modified hausdorff distance between the sets of edge points , that is , voxels representing the edges , in these two images .\nthe modified hausdorff distance (a , b )   between two sets of points a and b is defined as \n ( 5)(a , b)=max(h(a , b),h(b , a ) )  with  h(a , b)=1naaad(a , b ) , \n\t\t\t\t\t\t\t where the directed hausdorff distance h(a , b ) is a measure of the distance of the point set a to the point set b , na is the number of points in set a , and d(a , b ) is the distance of point a  a to the closest point in b , that is , d(a , b ) = minbb||a  b|| , where ||a  b|| is the euclidean distance .\nthe directed hausdorff distance h(a , b ) thus computes the average distance of points of a to points of b. the averaging minimizes the effects of outlier points , for example , due to image noise .\nthe value of the modified hausdorff distance (a , b ) increases with the amount of difference between the two sets of edges points . in the following ,\nwe denote by (ia , ib ) the modified hausdorff distance of the edges extracted from the whole - brain region of the images ia and ib , that is , with the skull and external cerebrospinal fluid masked out from them .\nin this section , we apply our methods , respectively , of brain shift and resection ( imr images are acquired with the 0.5  tesla intraoperative ge signa scanner of the brigham and women 's hospital , boston , usa .\nimr image size is 256  256  60 voxels , and voxel size is 0.9375  0.9375  2.5  mm ) .\ntwo patient cases , each including five imr images , are treated to illustrate our modeling and brain shift followed by successive resections . in both cases , the 1st imr image was acquired prior to the opening of the skull ; the 2nd imr image was acquired after the opening of the skull and dura , and shows some brain shift ; the 3rd , 4th , and 5th imr images were acquired after successive resections .\nthe modelings of brain shift , 1st , 2nd , and 3rd resection are performed using different techniques , as detailed below . except where otherwise noted\n, the following discussion applies to both patient cases ( the result of each deformation modeling is shown for the two patient cases at the end of section 5.2.3 ) . to model brain shift based on the 1st and 2nd imr images\n, we estimate the surface displacement fields of the whole - brain region boundary and the internal tumor region boundary from the two imr images .\nno tissue discontinuity is involved in the brain shift deformation , so the biomechanical model is deformed using fem .\nthis results in the volume displacement field of the biomechanical model , which is illustrated in figure 3 for the first patient case .\nthis volume displacement field is used to warp the part of the 1st imr image corresponding to the whole - brain region . in the following sections ,\nthe three successive resections are modeled separately , because they require different types of processing .\nmatching two region boundaries to get a displacement field makes sense only if they correspond to the same physical entity .\nonce the resection has started , we can no longer rely on the entirety of the whole - brain region boundary , since a part of it is now missing . for modeling the successive resections , we thus evaluate the displacement field for the boundary of the healthy - brain region only .\nthe 1st resection occurs between the times the 2nd and 3rd imr images are acquired .\nhowever , since the corresponding removal of tissues is most likely accompanied by deformation , one can not exactly determine what tissue is removed based just on the two imr images .\nwe thus decided to model the 1st resection by still relying on the displacement fields of key surfaces , here the healthy - brain region boundary , to deform the biomechanical model .\nthis indeed appears to be the only reliable information concerning the deformation due to resection that we can extract from the 2nd and 3rd imr images .\nconsequently , we do not model explicitly the removal of tissue , but we model directly the deformation resulting from it , without introducing any tissue discontinuity . using the surface displacement field of the healthy - brain region boundary , we compute the deformation of the biomechanical model via fem . then , using the resulting volume displacement field , we warp the part of the 2nd imr image corresponding to the whole - brain region , in the same way as we did in the case of for brain shift .\nthe image resulting from the 1st resection modeling is now registered to the 3rd imr image , except outside of the healthy - brain region boundary , that is , for the tumor region . finally , we alter the resulting image to reflect the effect of resection . for this\n, we assign the background color to the voxels corresponding to the resected tissue volume \nthe significant feature of the 2nd resection is that some tissue has already been removed by the 1st resection , which means that this tissue can not have any physical influence on subsequent brain deformations because it does not \nrecall that the biomechanical model has been deformed to model the brain shift and the 1st resection and is thus registered to the 3rd imr image .\nso , using the 3rd imr image , we can define the boundary of the 1st resection , that is , the tissue discontinuity to include in the deformed biomechanical model ( figures 4(a ) and 4(b ) ) .\nwe then enrich the nodes whose supports are intersected by the discontinuity with heaviside dofs .\nconsequently , when the xfem - based biomechanical model deforms , the part corresponding to tissue removed by the 1st resection has no influence on the deformation of the remaining part of the brain .\nfor the first patient case illustrated in figure 4 , the tetrahedron mesh consists of 3,317 nodes , which corresponds to 9,951 fem dofs .\nthe biomechanical model is deformed in accordance with the displacement field of the healthy - brain region boundary evaluated from the 3rd and 4th imr images .  \nthe bottom part of the mesh , representing the tissue remaining after the 1st resection , has been deformed according to the displacement field of the healthy - brain region boundary , while the top part , representing the tissue removed by the 1st resection , has been subjected to a translation , but only for visualization purposes . even though the mesh is displayed as two separate parts , it is , in fact , a single entity .\nindeed , a main feature of xfem is its ability to handle the effect of a discontinuity without modifying the underlying mesh , that is , without remeshing . for modeling the 2nd resection , the edges of fes straddling the discontinuity\nhave been made discontinuous and their nodes moved apart . using the xfem volume displacement field , we warp the part of the 3rd imr image corresponding to the whole - brain region .\nthe resulting image is then masked out with the whole - brain region segmented out from the 4th imr image .\none significant feature of the procedure described for modeling the 2nd resection is that it can be applied repetitively for each subsequent resection visible on successive imr images , no matter how many there are .\nthe modeling of the 3rd resection is thus identical to the modeling of the 2nd resection .\nthe tissue discontinuity due to the 2nd resection is defined from the 4th imr image , and used to appropriately enrich the nodes of the biomechanical model .\nthen , this biomechanical model is deformed using xfem , in accordance with the displacement field of the healthy - brain region boundary evaluated from the 4th and 5th imr images . for the first patient case ,\na simplification for the modeling of the 3rd resection can be made because , by the time the 5th imr image is acquired , the resection is complete .\nthis means that we only need to compute the volume displacement field of the healthy - brain region .\nsince we apply displacements exactly to the boundary of the healthy - brain region , the results obtained with fem and xfem will be identical .\nusing the fem ( for the first patient case ) or xfem ( for the second patient case ) volume displacement field , we warp the part of the 4th imr image corresponding to the whole - brain region . the resulting image is then masked out with the whole - brain region segmented out from the 5th imr image .\nfigures 5 and 6 show the results of warping the imr images , as well as the edges extracted from them , after brain shift and each successive resection modeling for the two patient cases . as explained in section 5.2.3 , since we apply displacements exactly to the boundary of the healthy - brain region , the results obtained with fem and xfem are identical in the healthy - brain region .\none can deduce that using xfem for modeling resection is interesting when the neurosurgeon needs to have an accurate displacement field of the remaining tumor tissues . in this case\n, it is interesting to evaluate the impact of using fem , instead of xfem , to model the resection as if no resection was performed before .\nusing fem for modeling resection is equivalent to ignoring the presence of resection on intraoperative images . to illustrate the comparison between fem and xfem results , we choose the 3rd resection modeling of the second patient case\nindeed , it is the deformation with remaining tumor tissues that shows the largest magnitude , and , thus , that is likely to give a maximum difference between the two computations .  \nthe healthy - brain and tumor regions segmented out from the 4th and 5th imr images are respectively shown in figures 7(a ) and 7(b ) .\nthe volume displacement fields of the biomechanical model using xfem and fem are respectively shown in figures 7(c ) and 7(d ) .\nthe part of the 4th imr image corresponding to the whole - brain region is warped , first with the volume displacement field obtained via fem , and then with that obtained via xfem .\nthe difference between the two warped images is shown in figure 7(e ) . as expected\nhowever , the difference between the two volume displacement fields is smaller than the image resolution ( although the difference between the two volume displacement fields is smaller than the image resolution , the difference between the images resulting of the warping using these two volume displacement fields is nonzero .\nthis is explained by the fact that the ( gray ) value of each voxel of the warped image is defined as a weighted - value of voxels of the original image .\nthe weights are defined based on the overlapping ratio of the voxel of the warped image , with voxels ( determined using the volume displacement field ) of the original image ) .\nin addition , the deformed 4th imr images , using the xfem- and the fem - based deformations of the biomechanical model , show the same similarity , computed based on the modified hausdorff distance , with the 5th imr .\ntwo reasons explain that the differences between the fem and xfem results are so small .\nfirst , the brain deformation itself due to the 3rd resection is small , and , thus , it is expected to obtain small differences between the two resulting brain deformations .\nsecond , in the case the remaining tumor tissues are close to the healthy - brain region boundary , it implies that they are close to the boundary where surface displacement fields are applied to drive the deformation of the biomechanical model .\nalthough this comparison between fem and xfem should be done on more patient cases , we suggest that , in first approximation , fem could be used for modeling resection cases with small brain deformations .\nnevertheless , the presentation of the successive resections using xfem shows the generality of our framework , and details how xfem is implemented .\nnote that in section 6 devoted to validation , the warped images are the ones deformed with xfem .\nfor each deformation modeling based on a pair ( ik , ik+1 ) of two successive imr images that are already rigidly registered , we compare the similarity between these ik and ik+1 images , as well as the similarity between the ik and ik+1 images , where ik is the result of warping ik .\nthis gives us an estimate of how well we are able to capture , and compensate for , the local deformations between ik and ik+1 .\nthe goal of the nonrigid registration is , however , to deform the preoperative images . by warping ik for each deformation modeling\n, we do not take into account the fact that an error of alignment after each deformation modeling could propagate and amplify through the successive deformation modelings . to evaluate the effect of this error amplification on the results\n, we also perform the required succession of warpings on i1 , and we denote the resulting image by i1,k .\nwe then compare , for each deformation modeling , the similarity between i1 and ik+1 , together with the similarity between i1,k and ik+1 .\nthis allows one to evaluate the propagation , that is , the amplification , of alignment error on the results .\nthe modified hausdorff distance computed for each pair of imr images are given in tables 1 and 2 . \n\ntable 1 shows , for each deformation modeling based on a pair ( ik , ik+1 ) of two successive imr images , the values of the modified hausdorff distances (ik , ik+1 ) and (ik , ik+1 ) .\nthese values are computed using the canny edges extracted from the pair of images ( ik , ik+1 ) ( figures 5 ( d ) and 6 ( d ) ) and ( ik , ik+1 ) ( figures 5 ( e ) and 6 ( e ) ) .\nwe observe that the values for the images nonrigidly registered are relatively constant , that is , 1  mm , for each deformation modeling .\nsix out of eight deformation modelings give smaller modified hausdorff distances when the imr images are ( rigidly and subsequently ) nonrigidly registered .\nhowever , the modified hausdorff distance increases for the 3rd resection modeling of the first patient case , as well as for the brain shift modeling of the second patient case . to understand\nif the nonrigid registration is responsible for the increase of the misalignment of the two imr images everywhere in the whole - brain region , or if this effect is localized , we compute the modified hausdorff distance in the region and neighborhood of the tumor only ( volume region that extents by 25  mm the tumor region segmented in i1 for both patient cases ) .\nthe modified hausdorff distance decreases from (i4 , i5 ) = 1.70  mm to (i4 , i5 ) = 1.37  mm for the first patient case , while it decreases from (i1 , i2 ) = 1.36  mm to (i1 , i2 ) = 1.28  mm for the second patient case .\nthis indicates that the nonrigid registration enhances the alignment of the two imr images within the tumor region and its neighborhood , which is in fact the location requiring the best modeling accuracy .\nthis behavior could be explained by the fact that a maximum of information from the imr images is used in this region , that is , one or two ( in case of brain shift modeling ) surface displacement fields are applied around it .\nthe increase of misalignment elsewhere in the brain volume could be explained by two reasons .\nfirst , the landmarks tracked from the imr images are surfaces . as a consequence , the nonrigid registration is expected to give better results near the tracked surfaces than far from them in the volume .\nthe volume misalignment could point out the need for better parameters values and/or other constitutive laws . \n\ntable 2 shows , for each deformation modeling based on a pair ( ik , ik+1 ) of two successive imr images , the values of the modified hausdorff distances (i1 , ik+1 ) and (i1,k , ik+1 ) .\nso far , igns systems allow one to rigidly register preoperative and successive imr images .\n(i1 , ik+1 ) thus represents the navigation accuracy that we can obtain with an igns system at the present time .\nthe comparison of (i1 , ik+1 ) with (i1,k , ik+1 ) gives the improvement that could be practically achieved in the alignment with our approach .\nas expected , table 2 shows that the igns accuracy decreases through the successive deformations .\nindeed , the modified hausdorff distance increases from (i1 , i2 ) = 1.24  mm to (i1 , i5 ) = 1.78  mm for the first patient case , and from (i1 , i2 ) = 1.01  mm to (i1 , i5 ) = 1.68  mm for the second patient case .\nsix out of eight deformation modelings give smaller modified hausdorff distances when the imr images are nonrigidly registered .\nto understand if the modified hausdorff distance increases everywhere in the whole - brain region for the brain shift and 1st resection modeling of the second patient case , we compute the modified hausdorff distance in the neighborhood of the tumor region ( in the same way as explained for table 1 ) , and observe the improvement of the alignment within the tumor region and its neighborhood . as opposed to the values of the modified hausdorff distances in table 1 , the values for the images nonrigidly registered in table 2 increase through the successive resection modeling .\nthis amplification error is due to the fact that , after having modeled brain deformation between a pair of imr images , the deformed biomechanical model is not in perfect alignment with the second image of the pair .\nsince , for the subsequent deformation modeling , the surface landmarks are initialized based on the deformed biomechanical model , this can thus ampliy a misregistration error .\nwe developed a complete 3d framework for serial preoperative image update in the presence of brain shift followed by successive resections .\nthe nonrigid registration technique used an homogeneous linear elastic biomechanical model , driven by the deformations of whole - brain and internal tumor region boundaries for brain shift modeling , and healthy - brain region boundary for resection modelings , tracked between successive imr images .\nthe biomechanical model was deformed using fem for brain shift modeling , and fem or xfem for resection modeling , depending upon whether some brain tissues were previously resected or not .\nwe showed that our approach was modular , and could be applied each time a new imr image is acquired .\nwe used a linear formulation to characterize the deformation of the brains of both patients because the brains underwent relatively small deformations and displacements .\nwhile nonlinear biomechanical models have proven effective to decrease  yet do not abolish  the inaccuracies of fem - based modeling methods of large brain deformations , the deformations observed in our patients during surgery remained moderate ( 47  mm ) , thus reducing the theoretical benefit of using nonlinear models .\nthis allowed us to use simpler linear models and focus on the added value of xfem to simultaneously account for surgical deformations , namely , shift and resection . using a linear formulation\nimplied that , for each new deformation modeling , one could use the initial configuration rather than the last - deformed configuration of the biomechanical model .\nthis had the important advantage of using a good quality mesh for each deformation modeling rather than using a mesh whose quality progressively degraded with each successive deformation modeling .\nthis also had the advantage that we did no longer need to reconnect the deformed mesh for each new xfem calculation , which was one drawback of our previous method , presented in [ 39 , 41 ] , where the biomechanical model was successively deformed .\nwe also showed how xfem could handle a discontinuity for modeling resection without any remeshing or mesh adaptation while the representation of the discontinuity remained accurate , that is , the representation of the discontinuity was not based on a jagged topology using fe facets .\nxfem thus also avoided making the mesh resolution richer in the neighborhood of the resection - cavity boundary for improving the accuracy of the representation of the discontinuity for that purpose only .\nwe showed that our nonrigid registration technique improved the alignment of the successive imr images for most of the deformation modeling of both patient cases . when our nonrigid registration failed , it still improved the alignment locally , that is , within the tumor region and its neighborhood .\nwe tested the explicit modeling of the lateral ventricles ' region with a soft , compressible law in addition to the whole - brain region law used in the homogeneous biomechanical model .\nin addition to the validation that is usually performed for successive deformation modelings , that is , validation between pairs of successive intraoperative images , shown in table 1 of section 6 or in the work of ferrant et al .\n[ 13 , 47 , 48 ] , we also evaluated the fact that an error of alignment after each deformation modeling could propagate and amplify through the successive deformation modelings . as a result , shown in table 2 of section 6\n, we showed that our approach suffered from the propagation of misregistration through the successive deformation modelings .\nwe expected that this was due , at least partly , to the algorithms used to evaluate intraoperative surface displacements fields from the whole - brain and healthy - brain region boundaries .\nthe surface displacement fields were computed using active surface algorithms , and smoothed to make them compatible with the biomechanical model .\nbecause of these two smoothings , the deformed biomechanical model was likely to not be in a perfect alignment with the imr image to which it was registered .\nbecause the surface displacement fields evaluated for the next deformation modeling were initialized based on the deformed biomechanical model , we expected to observe an amplification of the misregistration , which was confirmed by our quantitative evaluation . at the present time\nthough , commercial igns systems allow one to register preoperative images and successive imr images , but in a rigid way only .\nconsequently , although the effect of error amplification exists , our technique still enhances the current capabilities of commercial igns systems .\nfuture work on modeling of brain shift followed by successive resection is required in five main areas .\nfirst , the effect of error amplification through the successive brain deformation modelings calls for further research .\nconsequently , the segmentation , and the subsequent smoothing , as well as the evaluation of surface displacement fields , should be improved to minimize the effect of error amplification .\nsecond , further research is required to include additional structures in the biomechanical model in general , and to study the best way to include the lateral ventricles in particular .\nthe use of a poroelastic model in order to model the cerebrospinal fluid filling the ventricles could be considered [ 17 , 18 ] .\nindeed , these images provide volume information ( rather than surface information only ) , are of good quality in comparison to other intraoperative modalities , and possess a field of view that includes the full volume of brain tissues ( for the 0.5 tesla ge signa scanner ) .\nthese images thus allow one to evaluate what , and how , new structures of the brain could be used , to enhance the modeling of brain shift .\nsome regions , for example , the lateral ventricles ' region , could be extracted from the two imr images , and used as surface landmarks to drive the deformation of the biomechanical model [ 13 , 62 ] . indeed , the workflow presented in this paper has the advantage of being easily adaptable . in case\nthe tumor region would not be visible ( enough ) on the imr images , these new structures , easier to segment , could also adequately replace the tumor for driving the deformation .\nfourth , our global approach should no longer be based on the 1st imr image used as a substitute for preoperative images , but on the preoperative images themselves .\nfifth , we should implement , for the surgery cases involving large deformations of the brain , a nonlinear formulation of fem [ 63 , 64 ] , and , particularly , a nonlinear formulation of xfem , which is the subject of recent research [ 65 , 66 ] ."}
{"lay_summary": " omega-3 polyunsaturated fatty acids ( n-3 pufas ) , particularly eicosapentanoic acid ( epa ) and docosahexanoic acid ( dha ) , has been acknowledged as essential very long - chain fatty acids contributing to either achieving optimal health or protection against diseases , and even longevity . \n recent high impact studies dealing with epa and dha have sparked a renewed interest in using n-3 pufas for cancer prevention and cancer treatment , for which n-3 pufas may exert their anticancer actions by influencing multiple targets implicated in various stages of cancer development , including cell proliferation , cell survival , angiogenesis , inflammation , and metastasis against various cancers . \n however , gastrointestinal cancers develop implicated with the close connection between inflammation and cancer and n-3 pufas especially imposed excellent actions of antiinflammation and antioxidation as well as their restorative actions . in detail , these beneficial lipids can restore or modify inflammation - associated lipid distorsion and alteration of lipid rafts . although the chemopreventive effect of n-3 pufas has been studied in various experimental models , our understanding regarding the underlying mechanisms of n-3 pufas against gi cancer is still limited . in this review article \n , we described the in - detailed perspective and underlying mechanism of n-3 pufas application for gi cancers and added in vivo efficacy of n-3 pufas with fat-1 transgenic mice experience . \n we suggest that future work should consider the n-6/n-3 fa ratio , combination treatment of other nutritions and alteration of lipid rafts to be a key element in experimental design and analysis . ", "article": "the contribution to human health of the specific fatty acid ( fa ) composition of the diet has received considerable attention in the literature .\nfatty acids are key nutrients that affect early growth and development as well as the prevention of chronic disease in later life.1 among the fas , omega-3 polyunsaturated fatty acids ( n-3 pufa ) and omega-6 polyunsaturated fatty acids ( n-6 pufa ) have been suggested to decrease and increase several human diseases , respectively .\npufa that contains more than one carbon double bond consists of two major classes such as n-6 and n-3 ( fig .\nlinoleic acid ( la ) is a representative n-6 pufa , serving as a substrate to be converted into an arachidonic acid ( aa ) affecting the prevalence and severity of inflammation .\nn-6 pufa can induce cardiovascular disease , diabetes , cancer , and age - related disease.1 \n -linolenic acid ( ala ) , eicosapentaenoic acid ( epa 20:5 ) and docosahexaenoic acid ( dha 22:6 ) are important n-3 pufa involved in human .\nthey are essential fatty acids that can not be synthesized by mammals , by which must be obtained from dietary sources such as cold - water fish , certain seeds ( flax ) and nuts ( walnuts ) .\na lot of studies suggest that n-3 pufa , as diet - dependent factors , may be critical to preventing disease backed up with authentic antioxidative and anti - inflammatory actions . especially , n-3\npufa has been shown to exert beneficial effects on some chronic degenerative diseases such as cardiovascular disease,2,3 rheumatoid arthritis,4 diabetes,5 other autoimmune diseases,6,7 and cancer.8,9 increased fat consumption by western diet has been associated with the development of cancer such as breast , colon , pancreatic , and prostate cancers with the notable exception of n-3 pufa , which show to have multiple beneficial anti - tumor actions that affect the essential alterations that dictate malignant growth in a number of studies.10 a diet rich in n-3 pufa may protect from cancer , at least at certain sites .\nstudies on the fatty acid status of patients with several cancer types including bladder , pancreatic , lung and esophageal cancer show low concentrations of plasma phospholipid n-3 pufa , ranging from 55 to 88% of amounts in healthy individuals.1113 recent studies have found a positive association between n-6 pufa and cancer risk , whereas in the same model , n-3 pufa were shown to reduce the development of cancer .\nepidemiological studies suggest that a high n-3 pufa to n-6 pufa ratio may be the optimal strategy to decrease breast cancer risk.14 solid epidemiological study shows that consumption of n-3 pufa appears to protect against the development of hepatocellular carcinoma , even among patients with hepatitis b virus ( hbv ) and/or hepatitis c virus ( hcv ) infection.15 recently , zhennan et al .\nhas reviewed prospective studies investigating the possible protective effects of the dietary intake of n-3 pufa on prostate cancer development.16 fasano et al also has reviewed a lot of in vivo and in vitro experimental studies providing strong indications of the anti - tumor action of n-3 pufa against lung cancer.17 the purpose of this review is to discuss the potential role of n-3 pufa in gastrointestinal ( gi ) cancer development .\nwe believe that increased consumption of n-3 pufa may lower the risk of gi cancer development via various chemopreventive activities .\nfuture studies should include combination treatment of n-3 pufa and nutrients with different and complementary mechanisms of chemopreventive action .\namong various cancers , most of the gi cancers including esophageal cancer , stomach cancer , and colon cancer , have a natural history of multi - step transition from precursor lesions to malignant lesions , inflammation , adenoma formation , dysplastic changes.18 therefore , gi cancers usually have premalignant lesions before developing invasive cancers , for instances , barrett s esophagus for esophageal cancer , chronic atrophic gastritis accompanied with intestinal metaplasia for gastric cancer , and adenoma or dysplasia originating from chronic ulcerative colitis for colon cancer .\nbecause the western diet contains disproportionally high amounts of n-6 pufa and low amounts of n-3 pufa , denoted as a high n-6 to n-3 pufa ratio , n-3 pufa may feasibly play a role in several stages of gi cancers management .\nesophageal cancer is ranked as the sixth leading cause of cancer death worldwide . according to the increasing incidence of gastroesophageal reflux disease ( gerd ) ,\nesophageal cancer is a tumor that has increased in incidence more than 7-fold over the past several decades .\nsuggests that negative associations between n-3 pufa intake and the risk of esophageal adenocarcinoma.19 higher in - takes of n-3 pufa [ cases vs. population controls ; or=0.46 , 95% ci=0.220.97 , 4th vs. 1st quartiles of intake ] was associated with a lower risk of barrett s esophagus .\nin contrast , higher trans - fat intakes were associated with increased risk ( or=1.11 ; 95% ci=1.031.21 per g / day ) .\nmoreover , it is reported that n-3 pufa supplemented parenteral nutrition can reduce inflammation and improve immune function in patients following esophageal cancer surgery20 and n-3 pufa - containing diet may be beneficial to patients with esophageal cancers who receive chemoradiation therapy ( crt ) by reducing crt toxicity.21 in contrast to other gi cancer , little work has so far been performed on the influence of n-3 pufa in oesophageal adenocarcinogenesis and neoplastic progression.22 there is a need for appropriately powered randomized - controlled studies to assess the long - term benefit of n-3 pufa . gastric cancer ( gc ) is the fourth most common cancer worldwide , and almost two thirds of affected individuals will die of their disease .\nsome studies about the association of n-3 pufa and gastric disease suggests a protective effect of n-3 pufa on gastric cancer .\nrecently , correa et al . suggests that docosahexanoic acid ( dha ) inhibits helicobacter pylori ( h. pylori ) growth in vitro and mice gastric mucosa colonization.23 \n h. pylori are recognized as a major etiological factor in chronic active gastritis , gastric duodenal ulcers and gastric cancer .\nit has been proposed that pufa hold an inhibitory effect on bacterial growth via disruption of cell membrane leading to bacteria lysis.24 mohamed also shows that n-3 pufa reduced iodoacetamide - induced gastritis in rats through decrease of malondialdehyde ( mda ) , gastrin , and nitric oxide ( no ) and normalization of mucosal glutathione.25 especially , it is reported that the erythrocyte composition of dha was found to be negatively linked to risk of gastric cancer , of well - differentiated adenocarcinoma.26 application of a diet enriched with n-3 pufa delayed tumor growth in a mouse xenograft model.27 \n in vitro studies have shown that n-3 pufa inhibited macrophage - enhanced gastric cancer cell migration and attenuated matrix metalloproteinase ( mmp)-10 expression through erk and stat3 phosphorylation28 and inhibited the growth of human gastric carcinoma cell via apoptosis and combination with 5-fluorouracil has synergetic effect in inhibiting the proliferation of gastric cancer cells.29 moreover , n-3 pufa are beneficial for preventing oxidative stress - induced apoptosis by inhibiting apoptotic gene expression and dna fragmentation of gastric epithelial cells.30 on the other hand , dha induced apoptosis of gastric cancer cells by inducing the expression of apoptotic genes in gastric cancer cells.31 although a large body of literature spanning numerous cohorts from many countries and with different demographic characteristics does not provide evidence to suggest a significant association between n-3 pufa and stomach cancer incidence,32 further studies are needed to investigate action of n-3 pufa relevant to antitumor effects in the stomach .\ncolorectal cancer ( crc ) is the second leading cause of cancer - related death in men after lung cancer and third in women behind lung and breast cancers in the united states . among the gi tract cancer\n, crc cancer has raised the most attention over the past decades , as they share a long precancerous stage ( the adenoma in crc ) which provides a window of opportunity to intervene and prevent development of cancer . recently\nthere is also evidence suggesting improved efficacy and/or tolerability of conventional colon cancer chemotherapy when administered with n-3 pufa.9 epidemiological studies about the association of dietary fat and cancer suggests a protective effect of n-3 pufa and a promoting effect of n-6 pufa on cancer .\nalthough epidemiological studies of the association between fish intake , n-3 pufa intake or blood n-3 pufa levels and crc risk have not consistently suggested beneficial effects of n-3 pufa on crc and other gi cancer risk .\ndietary administration of one or both of the main n-3 pufa in rodent models of colorectal carcinogenesis has been demonstrated to reduce colorectal tumor size and multiplicity , compatible with crc chemopreventive activity.33 in meta - analyses of prospective cohort studies that evaluated the association between fish consumption or n-3 fatty acids and colorectal cancer incidence or mortality , the pooled relative risks for colorectal cancer incidence were 0.960.97 ( 95% confidence interval : 0.92 , 1.00 ) for each extra occurrence of fish consumption per week.34 in a population - based prospective study on the association of n-3 pufa and cancer , there was an inverse relationship between marine n-3 pufa intake and the risk of colorectal cancer , but this association was only statistically significant in the proximal site of the large bowel.35 cockbain et al.9 has reviewed a lot of in vitro and in vivo experimental studies and epidemiological observations providing strong indications of the cancer treatment and prevention of n-3 pufa against colorectal cancer .\nkim et al.36 provided a significant dose - dependent reduction in crc risk for total n-3 pufa intake ( or=0.61 for the highest vs lowest quartile ) , as well as for epa and dha intake individually in a case - control study of 1,872 patients ( 929 cases of distal crc and 943 controls ) . pot measured and compared serum n-3 pufa levels in 861 patients ( 363 cases of colorectal adenoma and 498 controls ) .\nthere was a significant reduction in colorectal adenoma risk ( or=0.67 ) between low level of n-3 pufa ( < 1.8% ) and high level of n-3 pufa ( > 2.3%).37 recently , sorensen et al.38 reported that n-3 pufa is incorporated rapidly into colonic mucosa and colonic muscular layer in patients given 3 g of n-3 pufa daily for 7 days before surgery for colorectal cancer .\nthe preventive effect of n-3 pufa has been demonstrated in a number of carcinogen - induced models like aom and dimethylhydrazine ( dmh)-induced rat model and apc mouse models relevant to prevention of crc including ours .\nstudies of rodents fed an n-3 pufa - supplemented diet versus a control diet have consistently reported a 20 - 50% reduction in chemically induced tumor incidence , together with a 3070% reduction in tumor multiplicity , in both carcinogen and apc mouse studies .\nsimilar findings have been reported for studies of growth of human crc cell lines such as hct26 , ht-29 , hct116 , and dld-1 grown as xenograft tumors in immunecompromised mice.9 n-3 pufas are likely to have multifaceted roles in both prevention and treatment of crc .\nthe excellent tolerability and safety profile of n-3 pufas combined with other health benefits , particularly cardiovascular , make n-3 pufas an attractive candidate for prevention and treatment of crc.9\nesophageal cancer is ranked as the sixth leading cause of cancer death worldwide . according to the increasing incidence of gastroesophageal reflux disease ( gerd ) ,\nesophageal cancer is a tumor that has increased in incidence more than 7-fold over the past several decades .\nsuggests that negative associations between n-3 pufa intake and the risk of esophageal adenocarcinoma.19 higher in - takes of n-3 pufa [ cases vs. population controls ; or=0.46 , 95% ci=0.220.97 , 4th vs. 1st quartiles of intake ] was associated with a lower risk of barrett s esophagus .\nin contrast , higher trans - fat intakes were associated with increased risk ( or=1.11 ; 95% ci=1.031.21 per g / day ) .\nmoreover , it is reported that n-3 pufa supplemented parenteral nutrition can reduce inflammation and improve immune function in patients following esophageal cancer surgery20 and n-3 pufa - containing diet may be beneficial to patients with esophageal cancers who receive chemoradiation therapy ( crt ) by reducing crt toxicity.21 in contrast to other gi cancer , little work has so far been performed on the influence of n-3 pufa in oesophageal adenocarcinogenesis and neoplastic progression.22 there is a need for appropriately powered randomized - controlled studies to assess the long - term benefit of n-3 pufa .\ngastric cancer ( gc ) is the fourth most common cancer worldwide , and almost two thirds of affected individuals will die of their disease . some studies about the association of n-3 pufa and gastric disease suggests a protective effect of n-3 pufa on gastric cancer .\nrecently , correa et al . suggests that docosahexanoic acid ( dha ) inhibits helicobacter pylori ( h. pylori ) growth in vitro and mice gastric mucosa colonization.23 \n h. pylori are recognized as a major etiological factor in chronic active gastritis , gastric duodenal ulcers and gastric cancer .\nit has been proposed that pufa hold an inhibitory effect on bacterial growth via disruption of cell membrane leading to bacteria lysis.24 mohamed also shows that n-3 pufa reduced iodoacetamide - induced gastritis in rats through decrease of malondialdehyde ( mda ) , gastrin , and nitric oxide ( no ) and normalization of mucosal glutathione.25 especially , it is reported that the erythrocyte composition of dha was found to be negatively linked to risk of gastric cancer , of well - differentiated adenocarcinoma.26 application of a diet enriched with n-3 pufa delayed tumor growth in a mouse xenograft model.27 \n in vitro studies have shown that n-3 pufa inhibited macrophage - enhanced gastric cancer cell migration and attenuated matrix metalloproteinase ( mmp)-10 expression through erk and stat3 phosphorylation28 and inhibited the growth of human gastric carcinoma cell via apoptosis and combination with 5-fluorouracil has synergetic effect in inhibiting the proliferation of gastric cancer cells.29 moreover , n-3 pufa are beneficial for preventing oxidative stress - induced apoptosis by inhibiting apoptotic gene expression and dna fragmentation of gastric epithelial cells.30 on the other hand , dha induced apoptosis of gastric cancer cells by inducing the expression of apoptotic genes in gastric cancer cells.31 although a large body of literature spanning numerous cohorts from many countries and with different demographic characteristics does not provide evidence to suggest a significant association between n-3 pufa and stomach cancer incidence,32 further studies are needed to investigate action of n-3 pufa relevant to antitumor effects in the stomach .\ncolorectal cancer ( crc ) is the second leading cause of cancer - related death in men after lung cancer and third in women behind lung and breast cancers in the united states . among the gi tract cancer ,\ncrc cancer has raised the most attention over the past decades , as they share a long precancerous stage ( the adenoma in crc ) which provides a window of opportunity to intervene and prevent development of cancer .\nthere is also evidence suggesting improved efficacy and/or tolerability of conventional colon cancer chemotherapy when administered with n-3 pufa.9 epidemiological studies about the association of dietary fat and cancer suggests a protective effect of n-3 pufa and a promoting effect of n-6 pufa on cancer .\nalthough epidemiological studies of the association between fish intake , n-3 pufa intake or blood n-3 pufa levels and crc risk have not consistently suggested beneficial effects of n-3 pufa on crc and other gi cancer risk .\ndietary administration of one or both of the main n-3 pufa in rodent models of colorectal carcinogenesis has been demonstrated to reduce colorectal tumor size and multiplicity , compatible with crc chemopreventive activity.33 in meta - analyses of prospective cohort studies that evaluated the association between fish consumption or n-3 fatty acids and colorectal cancer incidence or mortality , the pooled relative risks for colorectal cancer incidence were 0.960.97 ( 95% confidence interval : 0.92 , 1.00 ) for each extra occurrence of fish consumption per week.34 in a population - based prospective study on the association of n-3 pufa and cancer , there was an inverse relationship between marine n-3 pufa intake and the risk of colorectal cancer , but this association was only statistically significant in the proximal site of the large bowel.35 cockbain et al.9 has reviewed a lot of in vitro and in vivo experimental studies and epidemiological observations providing strong indications of the cancer treatment and prevention of n-3 pufa against colorectal cancer .\nkim et al.36 provided a significant dose - dependent reduction in crc risk for total n-3 pufa intake ( or=0.61 for the highest vs lowest quartile ) , as well as for epa and dha intake individually in a case - control study of 1,872 patients ( 929 cases of distal crc and 943 controls ) . pot measured and compared serum n-3 pufa levels in 861 patients ( 363 cases of colorectal adenoma and 498 controls ) .\nthere was a significant reduction in colorectal adenoma risk ( or=0.67 ) between low level of n-3 pufa ( < 1.8% ) and high level of n-3 pufa ( > 2.3%).37 recently , sorensen et al.38 reported that n-3 pufa is incorporated rapidly into colonic mucosa and colonic muscular layer in patients given 3 g of n-3 pufa daily for 7 days before surgery for colorectal cancer .\nthe preventive effect of n-3 pufa has been demonstrated in a number of carcinogen - induced models like aom and dimethylhydrazine ( dmh)-induced rat model and apc mouse models relevant to prevention of crc including ours .\nstudies of rodents fed an n-3 pufa - supplemented diet versus a control diet have consistently reported a 20 - 50% reduction in chemically induced tumor incidence , together with a 3070% reduction in tumor multiplicity , in both carcinogen and apc mouse studies .\nsimilar findings have been reported for studies of growth of human crc cell lines such as hct26 , ht-29 , hct116 , and dld-1 grown as xenograft tumors in immunecompromised mice.9 n-3 pufas are likely to have multifaceted roles in both prevention and treatment of crc .\nthe excellent tolerability and safety profile of n-3 pufas combined with other health benefits , particularly cardiovascular , make n-3 pufas an attractive candidate for prevention and treatment of crc.9\nn-3 pufa , especially , epa and dha , have been shown to have multiple anti - tumor actions .\ncurrent knowledge of the anti - tumor activity of n-3 pufa has been comprehensively reviewed elsewhere.9,16,39 recently , stephenson et al.10 has reviewed more recent underlying mechanisms providing strong indications of the anti - tumor actions of n-3 pufa on the hallmarks of cancer .\nn-3 pufa appear to down - regulate epidermal growth factor receptor ( egfr ) , protein kinase c ( pkc ) , ras , and nf-b , insulin like growth factor ( igf ) , which are important cell signaling mediators often found to be elevated in carcinogenesis .\nsecondly , n-3 pufa induces cancer cell apoptosis via modulation of peroxisome proliferator - activated receptors ( ppars ) , the bcl-2 family , and nf-b cell signaling .\nthirdly , n-3 pufa decreases sprouting angiogenesis by suppressing vascular endothelial growth factor ( vegf)- and platelet derived growth factor ( pdgf)-stimulated endothelial cell proliferation , migration , and tube formation and by inhibition of mmps via no production and nf-b and -catenin cell signaling .\nfourthly , n-3 pufa also decreases cell - cell adhesion via down regulation of rho - gtpase , which inhibits cytoskeleton reorganisation , and reduction in intercellular adhesion molecule ( icam)-1 and vascular cell adhesion molecule ( vcam)-1 expression .\ncockbain et al.9 has also proposed the four main anti - tumor actions of n-3 pufa ( i ) modulation of cox activity ; ( ii ) alteration of membrane dynamics and cell surface receptor function ; ( iii ) increased cellular oxidative stress and ( iiii ) derived anti - inflammatory lipid mediators .\nfirstly , n-3 pufa can act as an alternative substrate for cox-2 , instead of aa , leading to a reduction in formation of pro - tumorigenic \nsecondly , incorporation of n-3 pufa into cell membranes alters the fluidity , structure and/or function of lipid rafts or calveolae .\nespecially , the localization of cell surface receptors , such as g protein - coupled receptors ( gpcrs ) , toll - like receptors ( tlrs ) , and epidermal growth factor receptor ( egfr ) , in lipid rafts is believed to be crucial for downstream receptor signaling , controlling proliferation and apoptosis .\nthirdly , n-3 pufa may have an anti - tumor effect through alteration in the cellular redox state .\nn-3 pufa can increase reactive oxygen species ( ros ) because it is highly peroxidisable .\ntherefore , n-3 pufa can induce cancer cell apoptosis via elevation of intracellular ros levels .\nfourthly , n-3 pufa can be metabolized novel anti - inflammatory lipid mediators including resolvins , protectins and maresins .\nit is known that resolvins exhibit antineoplastic activity via anti - inflammatory and inflammation resolution activity in animal models of acute inflammation . besides these multiple anti - tumor actions\n, it is also reported recently that n-3 pufa can activate nrf2 and induced nrf2-directed gene expression40,41 and can suppress lipopolysaccharide - induced inflammation through induction of nrf2 expression.42 nuclear factor erythroid 2-related factor 2 ( nrf2 ) is a redox - sensitive master regulatory transcriptional factor that plays an important protective role in cells by regulating cellular redox balance.43 moreover , n-3 pufa significantly reduces oxidative stress - induced endothelial cell ca influx .\nthis effect might be associated , at least in part , with altered lipid composition in membrane lipid rafts.44 recently , the engineered n-3 pufa desaturase transgenic mice ( fat-1 mice ) , which can endogenously synthesize n-3 pufa in their tissues , allows carefully controlled studies to be performed in the absence of potential confounding dietary factors.45 the synthesis of n-3 pufa is achieved through the expression of the fat-1 transgene encoding for an n-3 desaturase , which utilizes n-6 pufa as substrate .\nthis allows production of high n-3/n-6 ratios in the animals , thus eliminating the potential diet variations .\nhence , the fat-1 transgenic mouse is a valuable in vivo system for elucidating the role of n-3 pufa in carcinogenesis .\nsince fat-1 mice were generated , xia et al.46 showed that melanoma formation and growth are reduced in fat-1 transgenic mice .\nnowak and jia47,48 reported that lower incidence and growth rate of colon tumors induced by dss ( dextrane sodium sulfate ) plus aom ( azoxymethane ) in the fat-1 transgenic mice via its anti - inflammatory properties .\nsong et al.49 also reported that the growth of pancreatic cancer in vivo was significantly reduced when mouse pancreatic cancer cells , panc02 cells , were inoculated into the fat-1 transgenic mice .\nrecently , mohammed et al.50 suggested the beneficial effects of n-3 pufa for chemoprevention of pancreatic cancer using fat-1 mice .\nthey generated compound fat-1-kras transgenic mice and showed a dramatic reduction in incidence of pancreatic ductal adenocarcinoma ( 84% ; p<0.02 ) in fat-1-kras mice compared to kras mice . besides of gi cancers ,\nthe growth of hepatocellular carcinoma ( hcc ) in vivo was significantly reduced in the fat-1 transgenic mice.5153 mice expressing mmtv - neu(ndl)-yd5 and fat-1 , which were bred with mouse mammary tumor virus ( mmtv)-neu(ndl)-yd5 mice ( an aggressive breast cancer model ) , displayed significant ( p<0.05 ) reductions in tumor volume ( 30% ) and multiplicity ( 33%).54 recently , in our laboratory an in vivo study has shown a suppressive effect of fat-1 mice in gi cancer development ( unpublished data ) .\nfat-1 mice were bred with the apc mouse colon cancer transgenic mice to generate compound fat-1-apc transgenic mice .\na dramatic reduction in incidence of aom - dss induced colon adenocarcinoma in fat-1-apc mice compared to apc mice was shown . moreover , in the case of stomach cancer development , h. pylori initiated- , salt diet - promoted - gastric tumor was also reduced in fat-1 mice . in conclusion , several studies using fat-1 mice model indicate that balancing the tissue n-6/n-3 ratio could exert a significant effect on gi cancer development .\nthe fat-1 mouse model allows carefully controlled studies to be performed in the absence of restricted diets , which can create confounding factors that limit studies of this nature.55\nrecently , the engineered n-3 pufa desaturase transgenic mice ( fat-1 mice ) , which can endogenously synthesize n-3 pufa in their tissues , allows carefully controlled studies to be performed in the absence of potential confounding dietary factors.45 the synthesis of n-3 pufa is achieved through the expression of the fat-1 transgene encoding for an n-3 desaturase , which utilizes n-6 pufa as substrate .\nthis allows production of high n-3/n-6 ratios in the animals , thus eliminating the potential diet variations .\nhence , the fat-1 transgenic mouse is a valuable in vivo system for elucidating the role of n-3 pufa in carcinogenesis .\nsince fat-1 mice were generated , xia et al.46 showed that melanoma formation and growth are reduced in fat-1 transgenic mice .\nnowak and jia47,48 reported that lower incidence and growth rate of colon tumors induced by dss ( dextrane sodium sulfate ) plus aom ( azoxymethane ) in the fat-1 transgenic mice via its anti - inflammatory properties .\nsong et al.49 also reported that the growth of pancreatic cancer in vivo was significantly reduced when mouse pancreatic cancer cells , panc02 cells , were inoculated into the fat-1 transgenic mice .\nrecently , mohammed et al.50 suggested the beneficial effects of n-3 pufa for chemoprevention of pancreatic cancer using fat-1 mice .\nthey generated compound fat-1-kras transgenic mice and showed a dramatic reduction in incidence of pancreatic ductal adenocarcinoma ( 84% ; p<0.02 ) in fat-1-kras mice compared to kras mice . besides of gi cancers , the growth of hepatocellular carcinoma ( hcc ) in vivo was significantly reduced in the fat-1 transgenic mice.5153 mice expressing mmtv - neu(ndl)-yd5 and fat-1 , which were bred with mouse mammary tumor virus ( mmtv)-neu(ndl)-yd5 mice ( an aggressive breast cancer model ) , displayed significant ( p<0.05 ) reductions in tumor volume ( 30% ) and multiplicity ( 33%).54 recently , in our laboratory an in vivo study has shown a suppressive effect of fat-1 mice in gi cancer development ( unpublished data ) .\nfat-1 mice were bred with the apc mouse colon cancer transgenic mice to generate compound fat-1-apc transgenic mice .\na dramatic reduction in incidence of aom - dss induced colon adenocarcinoma in fat-1-apc mice compared to apc mice was shown .\nmoreover , in the case of stomach cancer development , h. pylori initiated- , salt diet - promoted - gastric tumor was also reduced in fat-1 mice . in conclusion ,\nseveral studies using fat-1 mice model indicate that balancing the tissue n-6/n-3 ratio could exert a significant effect on gi cancer development .\nthe fat-1 mouse model allows carefully controlled studies to be performed in the absence of restricted diets , which can create confounding factors that limit studies of this nature.55\ngi cancer incidence and mortality are increasing in the eastern world and a high n-6 to n-3 pufa ratio in the western style diet may be a contributing factor .\nthere is much evidence to suggest that higher consumption of dietary n-3 pufa is associated with a lower risk of gi cancer in animal models and humans .\nespecially , recent studies suggest that endogenous n-3 pufa delay the progression of colon and stomach cancer and elevating n-3 pufa may be an important strategy to delay / prevent gastrointestinal cancer in high - risk patients via various mechanisms mediating cancer prevention by n-3 pufa ( fig .\n2 ) . in addition , using n-3 pufa in combination with other agents with complementary antitumor action may improve their efficacy in gi cancer prevention . recently ,\nmanson et al . has started the vitamin d and omega-3 trial ( vital ) , a large randomized , double - blind , placebo - controlled , 22 factorial trial of vitamin d and n-3 pufa supplements in the primary prevention of cancer among a multi - ethnic population of 20,000 u.s .\nmen aged 50 and women aged 55.56 we expect that new findings in combination consumption of n-3 pufa with other nutrients will provide new approaches to public health implications with regard to prevention of gi cancer through dietary and lifestyle interventions ."}
{"lay_summary": " background and objectives:46 xy disorders of sexual development ( dsd ) cover a wide spectrum of phenotypes ranging from unambiguous female genitalia to ambiguous male genitalia with hypospadias or dysgenetic gonads . \n management of these patients depends on the cause of dsd , degree of feminization , age at presentation , and gender orientation . \n the aim of this study was to evaluate the presentation and management of patients with 46xy dsd at our center.patients and methods : all new and old patients of 46xy dsd attending the endocrine opd in a period of 16 months were included in this study . clinical , cytogenetic , hormonal , and radiological evaluation \n were done to identify the cause of dsd.results:among 19 patients , eight were diagnosed with disorders of gonadal development ( one with complete gonadal dysgenesis , four with partial gonadal dysgenesis , two with congenital bilateral anorchia , and one with ovotesticular dsd ) and eight with disorders of androgen synthesis and action ( one with complete androgen insensitivity syndrome [ ais ] , three with partial ais and four with 5 reductase deficiency ) . in three patients , a definitive diagnosis could not be made.conclusions:management of patients with dsd depends on etiology , gender assignment , gender orientation , hormonal treatment , genital surgery , and consequent psychosocial implications . \n due to the overlapping clinical and biochemical parameters in different subsets of dsd , only a preliminary etiological diagnosis can be made in some cases . \n genetic studies with long - term follow - up are required for an accurate diagnosis . ", "article": "sexual development in males is a multistep process , implying a delicate network of molecular events that directs the bipotential gonad to differentiate into testis ( sex determination ) and consequent differentiation of internal and external genitalia in the presence of testicular hormones ( sex differentiation ) .\nalteration of any genetic or endocrine factors involved in testicular development may lead to 46 xy disorders of sexual development ( dsd ) .\ngenital ambiguity in patients with 46 xy dsd may either occur due to the disorders in gonadal development or due to the disruption in androgen synthesis or action .\npatients with disorders of gonadal development may present with either complete or partial forms of gonadal dysgenesis .\nswyer 's syndrome or complete gonadal dysgenesis ( cgd ) is characterized by unambiguous female genitalia , bilateral streak gonads , and elevated gonadotropins .\npartial gonadal dysgenesis ( pgd ) may have a wide spectrum of phenotypes associated with ambiguous genitalia , varying degree of hypospadias and testis of variable size and echotexture present along the path of decent .\novotesticular dsd ( ot - dsd ) is a rare condition marked by the presence of both ovarian and testicular tissue in an individual while congenital bilateral anorchia ( cba ) is characterized by the complete absence of testicular tissue in genotypic males .\ndisorders of androgen synthesis may occur due to deficiency of various enzymes involved in the steroidogenesis .\ncongenital adrenal hyperplasia ( cah ) due to 17-hydroxysteroid dehydrogenase 3 ( 17-hsd3 ) is caused by the mutations in hsd17b3 gene which is required for the conversion of androstenedione to testosterone .\ndeficiency of this enzyme results in feminized genitalia in newborns due to the low testosterone levels .\nmutations in srd5a2 gene impairs the activity of enzyme 5-reductase and hence the conversion of testosterone to its more potent form dihydrotestosterone ( dht ) .\nindividuals with 5-reductase deficiency ( 5-rd ) are often raised as females due to undermasculinized genitalia but the gender role changes soon after attaining puberty .\nmutations in androgen receptor gene may lead to the androgen insensitivity syndrome ( ais ) which can be partial androgen insensitivity syndrome ( pais ) or complete androgen insensitivity syndrome ( cais ) and is the most common cause of 46xy dsd .\nthe spectrum of phenotypes associated with ais may range from completely female through mixed male / female to completely male type . in 1995 ,\ncharmian quigley and frank french proposed new grading system for the phenotypic features in ais based on prader classification for cah .\nindividuals diagnosed with 46xy dsd show an overlap in clinical and biochemical parameters which emphasizes the need for comprehensive evaluation with a multidisciplinary approach .\nthis is an ambispective study where all new and old follow - up patients diagnosed with 46xy dsd , being managed at endocrine opd in a period of 16 months ( june 2014october 2015 ) were included .\nexternal masculinization score ( ems ) were calculated based on the external genitalia of patients .\nabdominopelvic ultrasound was done for the localization of gonads ( magnetic resonance imaging ( mri ) also , when required ) . for patients on follow - up , previous records were reviewed to establish a diagnosis as they were on medication while in new patients , samples were collected and hormonal measurements included serum luteinizing hormone , follicle - stimulating hormone , testosterone , androstenedione ( a ) , cortisol , dehydroepiandrostenedione , and plasma adrenocorticotropic hormone levels by electrochemiluminescence immunoassay using commercial kits ( roche , germany ) .\nradioimmunoassay kit - based method was used for evaluating 17-hydroxyprogesterone ( 17-ohp ) levels ( diagnostic systems laboratories , inc . , webster , tx , usa ) .\n5dht was measured using radioimmunoassay ( immunotech ; prague , czech republic ) after extraction from other hormones with diethyl ether and celite chromatography .\nthe short - term human chorionic gonadotropin ( hcg ) stimulation test was carried out to check the functioning of testicular tissue .\ntestosterone levels were measured before and 2448 h after the last injection of a series of three intramuscular injections of hcg on alternate days ( < 1-year - old , 500 units ; 110 years , 1000 units ; > 10 years , 2000 units ) .\ntestosterone : androstenedione ( t : a ) and testosterone : 5 dht ( t:5dht ) ratios were calculated as and when required to rule out 17 beta hsd deficiency and 5 alpha reductase deficiency respectively .\non first evaluation , 11 patients had presented with the primary complaint of ambiguous genitalia , three ( who were being reared as female ) with primary amenorrhea , three with undescended gonads and one with fever and vomiting .\nthe presenting complaints , clinical , hormonal , and radiological findings are summarized in table 1 .\nfive ( 26% ) of them were reared females and 14 ( 74% ) as males .\nten patients ( s.5 , s.7 , s.8 , s.9 , s.10 , s.14 , s.15 , s.16 , s.17 , and s.18 ) had undergone corrective surgeries for ambiguous genitalia .\nclinical profile of patients patient s.1 reared as female presented with primary amenorrhea , delayed development of secondary sexual characteristics and unambiguous female genitalia .\npatients s.2 , s.3 , and s.5 had ambiguous genitalia , undescended gonads , raised fsh and low testosterone levels while patient s.4 had unilateral undescended testis with raised fsh and low testosterone levels , all three were suspected to be cases of pgd .\nabdominopelvic ultrasonography ( usg ) and mri could not locate gonads in s.7 while in patient s.6 , a nubbin was seen in the scrotal area .\ninguinal exploration was done to locate testis but it revealed the absence of any testicular tissue .\nfsh was raised in both [ table 2 ] and there was no testosterone response to hcg stimulation .\nhormonal profile of patients patient s.8 being reared as female had presented with ambiguous genitalia and raised gonadotropins .\nshe had undergone bilateral gonadectomy and on histological evaluation ot tissue was found , she was diagnosed with ot - dsd .\npatient s.9 being reared as female presented with primary amenorrhea , genital ambiguity and delayed development of secondary sexual characteristics .\nshe underwent bilateral gonadectomy , histopathological examination revealed testicular tissue and was diagnosed with cais .\nhormonal profile showed normal testosterone levels with t : dht ratio of 9.7 and t : a ratio of 5.8 .\npatient s.11 being reared as female came with a complaint of hirsutism and delayed development of secondary sexual characteristics .\nbilateral gonadectomy was done and histological studies showed the presence of testicular tissue which confirmed the diagnosis of pais as t : dht and t : a ratios were also normal .\ntestosterone levels were undetectable , but showed a good response to hcg stimulation with t : dht ratio of 7.25 , t : a ratio of 5.8 and was diagnosed with pais .\npatients s.13 , s.14 , s.15 , and s.16 came with ambiguous genitalia and low baseline testosterone levels .\ntestosterone to dht ratio in s.13 , s.14 , and s.15 were 31.4 , 18 , and 13.9 , respectively .\ndue to high t : dht ratio post - hcg stimulation , all three were diagnosed with 5rd while in s.16 , t : dht ratio was not calculated as b / l gonadectomy was done at 2 years of age .\nmolecular analysis of srd5a2 gene in this patient revealed r246q mutation commonly seen in 5-rd .\nrecords show that his post hcg serum t : a ratio was 0.06 , he was thought to be a case of 17hsd deficiency . at 2 years of age he had fever , vomiting and loose stools with hyponatremia , hyperkalemia and hypoglycemia .\npatient s.18 was admitted in pediatrics with a complaint of poor feeding and poor activity since day one of life . on evaluation\n, he was found to have hypernatremia , hypokalemia , and genital ambiguity with bifid scrotum and hypospadias . in view of electrolyte imbalance\n, incomplete masculinization , low cortisol , and elevated 17-ohp , he was suspected to be a case of cah and treatment was started .\nan accurate diagnosis could not be established when he came to us as he was already on steroids and had a history of salt wasting , so steroids could not be stopped for evaluation of the cause of cah .\nhe had undergone three genital surgeries for hypospadias correction but still had difficulty in urination .\nthe patient is kept on antihypertensives , but no definitive diagnosis could be made as the baseline hormonal reports are missing . with the help of clinical , biochemical and radiological evaluation ,\naccurate diagnosis was made in 16 patients while rest 2 are on follow - up and managed in our clinic .\ndiscordance between genetic ( xx or xy ) , gonadal ( testis or ovaries ) , external genital ( vulva or penis ) , and internal sex ( wolffian or mullerian ducts ) results in dsd . in humans ,\nthe bipotential gonad differentiates into testis in the presence of sry gene present on y - chromosome .\ntesticular differentiation is followed by the development of internal sex ducts and external genitalia in the presence of fetal hormones produced by the testis .\nsertoli cells secrete anti - mullerian hormone , which causes irreversible regression of paramesonephric or mullerian ducts around the sixth week of gestational age .\ntestosterone produced by leydig cells of fetal testis promotes the development of mesonephric or wolffian ducts and hence male internal genitalia ; epididymis , vas deferens , and vesicular seminalis .\nthe development of external male genitalia depends on the conversion of testosterone to a more potent steroid dht in the presence of 5-reductase enzyme . in 2006 , the term  intersex  or  hermaphrodite  was replaced by  dsd  and\n46xy dsd was subcategorized as disorders of testicular development and disorders of androgen synthesis or action .\nfirst - line testing in newborns includes karyotyping , imaging ( usg / mri pelvis ) , serum electrolytes , and serum gonadotropins .\nmolecular diagnosis has been made in approximately 20% of cases with 46xy dsd , although confirmatory , but is limited by cost and accessibility .\nthe inability of bipotential gonad to differentiate into testis results in testicular dysgenesis or agenesis which occurs due to the disruption of various genetic factors involved in the process of sex determination . in our study , four patients were diagnosed with pgd , one with cgd , one with ot - dsd , and two with testicular agenesis or cba . in the absence of gonadal development ,\npatients with cgd usually present with unambiguous female genitalia due to the absence of gonadal steroid production while in pgd , the external phenotype depends upon the degree of testicular tissue present . in our study , out of four patients with pgd , three ( s.2 , s.3 , and s.5 ) presented with ambiguous genitalia and one with undescended gonad ( s.4 ) . in such cases , corrective surgeries are done if required , and testosterone supplementations are given at pubertal age .\npatient s.5 being reared as female had presented with ambiguous genitalia at 4 years of age . with parents consent clitorovaginoplasty and bilateral orchidectomy\norchidopexy and biopsy are usually recommended for undescended gonads as the risk of malignancy ranges from 8.3% to 54% in patients with xy pgd . in 46xy\ncba is a rare condition and is marked by the absence of testis since birth .\nprevious studies have shown the occurrence of pure or partial forms of 46xy gonadal dysgenesis in families of patients with cba , but the genetic cause is still not known . in our study ,\ntwo patients ( s.6 and s.7 ) with cba were born out of nonconsanguineous marriage and had no family history of genital ambiguity but the father of patient s.7 gave history of oligospermia and assisted reproduction .\n46xy ot - dsd is a very rare condition marked by the presence of ot tissue and is confirmed by histopathological examination .\nparents of patient s.8 had sought medical attention for ambiguous genitalia at the age of 13 years .\nbilateral gonadectomy was done , and the corrective surgeries for hypospadias and phallus are awaited .\nthe complete or partial resistance to the action of androgens may result in cais or pais in xy individuals .\npatients with cais may present with primary amenorrhea in adolescence or inguinal swellings in infants .\npatient s.9 was being reared as female , parents sought medical attention at the age of 18 years for primary amenorrhea and delayed development of secondary sexual characteristics .\nbilateral gonadectomy was recommended after confirming the gender identity of the patient to be female .\na recent study done on 102 phenotypic women with y - chromosome showed an incidence of 17.6% malignancy .\nof these 9 out of 30 patients ( 30% ) of cais with a mean age of 20.7 years were found to have gonadoblastoma on histological analysis .\ntherefore , adult cais patients who receive late intervention are recommended to undergo immediate gonadectomy in order to avoid the risk of malignancy .\nthe phenotype of patients presenting with pais depends on the responsiveness of genital tissues to androgens .\ninfants with pais present with the genital ambiguity of varying degrees while adults may present with gynecomastia .\nhowever , the risk of malignancy in individuals with pais is 15% if the testis is not scrotal in position .\nhormonal profile showed normal testosterone levels with t : dht ratio of 9.7 and t : a ratio of 5.8 .\npatient s.11 being reared as female sought medical attention for hirsutism at the age of 19 years .\nbiochemical examination showed normal t : dht and t : a ratios with testosterone levels in male range .\ngonadectomy was done and histopathological examination showed the presence of testicular tissue , she was then diagnosed with pais .\nshe had female gender orientation and is now on estrogen replacement therapy for breast development .\nhis t : dht ratio was 7.25 and t : a ratio was 5.8 post - hcg stimulation , which excluded the diagnosis of 5rd and 17hsd .\nthough the presumptive diagnosis of patients s.10 , s.11 , and s.12 was pais , as t : dht ratio and t : a ratio were normal , [ figure 1 ] diagnosis with needs further confirmation by molecular studies . flow chart for\ndiagnosis of 46xy disorders of sexual development the interrupted conversion of testosterone to dht due to the mutations in gene encoding 5-reductase enzyme may lead to 5rd .\nthe differentiation of internal and external male genitalia occurs in the presence of testosterone ( t ) and dht .\nthe t : dht ratio is used to diagnose this condition but interpreting these results is not always straightforward .\nthe diagnosis of 5rd is suspected in newborns with undermasculinized genitalia ( depending upon the activity of enzyme 5-reductase ) , low serum testosterone levels , good response to hcg stimulation and high testosterone to dht ratio ( > 1012 ) . a good response to hcg stimulation ( rise by more than twice the baseline value ) is observed in these patients .\nthe patients may present with microphallus , inguinal gonads or gonads in labioscrotal folds and varying degree of hypospadias .\ntreatment with percutaneous dht increases the size of the phallus in infants and children with 5-reductase 2 deficiency .\nmost of them are reared as males and gender reassignment is required in those who are reared as females due to the spontaneous virilization at puberty .\nthe decisions regarding management of masculinizing puberty need to be taken before puberty with a multidisciplinary approach .\nfemale gender assignment in these patients by surgery should be undertaken postpuberty with full caution and counseling with parents . in our study ,\npatient s.16 had severely undervirilized genitalia , bilateral gonadectomy had been done at 2 years of age and female gender had been assigned . at the age of 17 years , he sought medical attention for gender dysphoria . at this time , the presence of common r246q mutation on molecular analysis of srd5a2 gene confirmed the diagnosis of 5rd .\n46xy patients with deficiency of 17-hsd enzyme usually present with female - like genitalia at birth with clitoromegaly and blind - ending vagina or male type genitalia with micropenis and hypospadias . at puberty , these patients experience significant virilization due to the abnormally elevated levels of androstenedione or extragonadal synthesis of testosterone , the exact cause of which is unknown .\nthe diagnosis of 17-hsd3 can be suspected if testosterone to androstenedione ratio is < 0.8 .\nthe overlapping phenotype of individuals with 17-hsd and pais can be differentiated by molecular analysis or on the basis of hcg stimulated t : a ratio , which is < 0.8 in cases of 17-hsd .\npatient s.17 initially predicted to have 17 hsd deficiency , but later presented with features of mineralocorticoid and glucocorticoid deficiency at 2 years of age .\npatient s.19 is presently 49 years of age and gave a history of ambiguous genitalia .\nhe was on dexamethasone , sustanon and had undergone three corrective surgeries for hypospadias but still has a problem in urination . routine examination revealed raised blood pressure for which he is on hypertensives .\nlimitations of this study are that , being an ambispective study , all tests were not done in all patients and baseline records / tests to make a diagnosis could not be obtained in two patients .\nnonetheless , this gives an insight into how to diagnose and manage 46xy dsd , who may present at different ages , with different etiologies and different gender of rearing in our set up .\nthere is overlap in the clinical , hormonal and anatomic profile of different subsets of 46xy dsd .\nthe diagnosis of 46xy dsd needs to be confirmed by cytogenetic , hormonal , radiological , and genetic tests .\nphenotype varies depending on the degree of genetic , hormonal and anatomic defect . at times , in spite of all the tests a definitive diagnosis may not be possible .\nthe pediatrician , endocrinologist , surgeon , psychologist , and clinical geneticist need to work as a team for multifaceted management of these patients .\nthis study was supported by department of biotechnology , ministry of science and technology ( bt / pr7681/med/12/597/2013 ) and indian council of medical research ( dhr / gia/1/2014 ) , new delhi , india .\nthis study was supported by department of biotechnology , ministry of science and technology ( bt / pr7681/med/12/597/2013 ) and indian council of medical research ( dhr / gia/1/2014 ) , new delhi , india ."}
{"lay_summary": " abstracturinary tract infections are one of the most common infectious diseases diagnosed in the community and in the hospital setting . \n their treatment is complicated by drug - resistant pathogens and the colonization by microbes of indwelling urinary catheters . \n this study assessed the occurrence and antimicrobial susceptibility of methicillin - resistant staphylococcus aureus ( mrsa ) uropathogens isolated for 5 consecutive years at university hospital waterford between 2010 and 2014 . \n we created 4 clinically relevant subdivisions , based on urine source : hospital inpatients , patients from the emergency department , patients referred from their general practitioner , and nursing home patients . \n we performed a retrospective review from the hospital 's electronic microbiological system and calculated resistance rates for each of the standard antimicrobial agents . during the 5-year study period \n , we studied 151 urine isolates obtained from 128 patients who had an mrsa cultured in their urine sample . \n there was 100% resistance of all mrsa isolates to flucloxacillin and coamoxiclav . \n ninety - eight percent of isolates were resistant to ciprofloxacin . \n the resistance rate for trimethoprim was 7.4% and there was only 2.7% resistance for nitrofurantoin . for a clinical subset of patients \n , we also demonstrated 100% sensitivity for samples tested against teicoplanin and vancomycin . \n urinary mrsa is an infrequently studied phenomenon , but with the rising trend of hospital superbugs nationally , its management is of critical importance . \n suitable agents to address this within our population include nitrofurantoin in the well patient requiring urinary mrsa eradication or vancomycin / teicoplanin in the unwell patient requiring intravenous therapy . in all groups , fluoroquinolones should be avoided due to significant resistance rates . ", "article": "urinary tract infection ( uti ) is a frequent cause of morbidity both in the community and in the hospital setting .\nthe causative pathogen can vary greatly geographically , and so it is prudent to identify those with resistant strains and have current data on the appropriate empirical therapy within a region .\nthe most frequently encountered organisms associated with utis include enteric gram - negative bacteria ( with escherichia coli being the most predominant ) , coagulase negative staphylococcus saprophyticus along with proteus mirabilis , klebsiella , and enterococcus , which account for less than 5% . however , recent studies have reported the increasing prevalence of staphylococcus aureus ( sa ) in utis .\nsa is an opportunistic pathogen affecting both immune competent and immunocompromised individuals , frequently resulting in significant morbidity\n. many strains of sa carry a wide variety of multidrug - resistant genes on plasmids , which aid the spread of resistance among species .\nmethicillin - resistant sa ( mrsa ) is widespread in many irish hospitals and is increasingly seen in community health care units such as nursing homes .\nglobally , it is considered that there has been an epidemic of mrsa within health care institutions . bacteriuria with sa is hypothesized to occur through a number of mechanisms that includes catheterization , urologic procedures , or seeding of the genitourinary tract  including nephrologically excreted bacteria in overt bacteremia .\nbacteremia itself is associated with bacteriuria in patients infected with sa , which suggests that bacteremia is an important precursor for bacteriuria in some patient groups .\nherein , we chronologically assessed the source , patient demographics , and antimicrobial susceptibilities of mrsa - positive isolates from the hospital and community setting over a 5-year period in university hospital waterford  a tertiary referral hospital with the primary microbiology laboratory for 4 acute hospitals , serving a total catchment area of almost 500,000 people .\nthe microbiology laboratory in university hospital waterford processes all inpatient urines in the catchment area of almost 500,000 , excluding 2 small private elective inpatient institutions .\nit also processes all urine samples sent from the community ( i.e. , all samples from general practice and nursing homes ) and all specimens from the catchments emergency departments .\nlaboratory diagnosis of mrsa bacteriuria was performed using accredited microbiological microscopy analysis with culture identification criteria and standardized susceptibility testing protocols .\nour laboratory utilized clinical and laboratory standards institute ( clsi ; 20102014 ) and european committee on antimicrobial susceptibility testing ( eucast ; 2014 ) methodologies .\na retrospective data extraction was performed , from the hospital 's electronic microbiological system  cognos  and de - duplication was executed .\nwe considered a  separate episode  as a urine specimen culturing mrsa at least 6 months following a previous positive culture .\nfurther urine specimens sent within a 6-month period following an initial laboratory diagnosis mrsa bacteriuria were excluded .\nresistance rates were then calculated for the pathogen 's susceptibility to 5 commonly used antimicrobial agents  ciprofloxacin , coamoxiclav , flucloxacillin , nitrofurantoin , and trimethoprim . for unwell patients ,\nthat is , those in whom there was clinical suspicion of sepsis or invasive infection , teicoplanin and vancomycin were also tested for sensitivity profiling . in order to obtain further clinical information from our patient group , we also assessed those patients who had an mrsa - positive swab ( usually from groin , nose , or perineum ) , those who had documented mrsa bacteremia , and we analyzed their demographic details .\nethical approval was waived for this retrospective observational study in light of its non - interventional nature .\nover a consecutive 5-year period , the laboratory cultured 425,013 urine samples from all sources , with a mean number of 85,003 specimens per year received ( table 1 ) .\na total of 542 unique urine isolates cultured sa and 151 of species ( 27.9% ) were methicillin resistant , meaning that 0.04% of all urine samples tested cultured mrsa .\nnumber of urine cultures by year . of these 151 samples that tested positive for mrsa , 92 ( 61% ) were from mid - stream urine ( msu ) samples , 50 ( 33% ) from catheter specimen urine ( csu ) samples , and 9 ( 6% ) were from an unspecified source ( fig .\ncsu  =  catheter specimen urine , mrsa  =  methicillin resistant staphylococcus aureus , msu  =  mid - stream urine .\nmrsa was slightly more common in msu samples ; however , the findings were not statistically significant ( 18.2% vs 13.9% , p  =  0.388 ) .\nforty - nine ( 32.5% ) specimens were from an inpatient cohort , 9 ( 6% ) were from the emergency department , 79 ( 52.3% ) from general practitioners , 12 ( 7.9% ) were from nursing homes , with 2 ( 1.3% ) from an unrecorded source ( fig .\nmrsa was seen in a similar proportion of inpatient and outpatient samples indicating that this is not solely a hospital - acquired phenomenon ( 29.1% vs 26.9% , p  =  0.587 ) .\nmrsa  =  methicillin resistant staphylococcus aureus . the mean age of our patients who cultured mrsa within their urine was 72.7 years ( range 10.9790.2 ) and most patients were aged between 70 and 90 years ( table 2 ) .\npatients who cultured an mrsa bacterium were older than patients with mssa , and this was statistically significant ( 53 vs 73 years , p    0.001 ) .\nthe number of sa isolates grown over the 5-year study period doubled from 77 in 2010 to 161 in 2014 .\nthe number of mrsa isolates had also increased ; however , the percentage of sa isolates that were methicillin resistant has decreased ( p  =  0.145 ) .\nthis is true for both inpatient and outpatient samples ( p  =  0.313 , p  =  0.254 , figs .\nmrsa  =  methicillin resistant staphylococcus aureus , mssa  =  methicillin sensitive staphylococcus aureus , sa  =  staphylococcus aureus . inpatient trends in sa\nmrsa  =  methicillin resistant staphylococcus aureus , mssa  =  methicillin sensitive staphylococcus aureus , sa  =  staphylococcus aureus .\nmrsa  =  methicillin resistant staphylococcus aureus , mssa  =  methicillin sensitive staphylococcus aureus , sa  =  staphylococcus aureus .\nregarding the clinical stance of patients within the cohort , 9 patients ( 7% ) with mrsa - positive urine cultures had a documented history of mrsa bacteremia at that time .\neach of these patients cultured mrsa isolates that were sensitive to nitrofurantoin , and 8 of the 9 patients ( 88.9% ) were sensitive to trimethoprim .\nit was noted that all 9 patients in this cohort were aged 70 years or above ( p  =  0.079 ) , although this did not reach statistical significance .\nfurther antimicrobials agents were introduced to the testing panel in 59 ( 39% ) samples , where there was a clinical concern regarding invasive infection or sepsis  including the 9 patients with mrsa bacteremia . all 59 samples ( 100% ) were sensitive to both vancomycin and teicoplanin .\neighty - eight ( 66.8% ) of our 128 patients cultured mrsa - positive isolates on routine swabs from either mucosal or skin sites .\nall 3 patients with resistance to nitrofurantoin in their urine had a positive swab from either groin or nose .\neight of the 10 patients ( 80% ) who had trimethoprim - resistant mrsa bacteriuria and 87 of the 125 ( 69.6% ) of the ciprofloxacin - resistant mrsa bacteriuria also had mrsa - positive mucosal or skin swabs .\nthere was no association between age and having an mrsa - positive swab in our cohort . throughout the study period\n, there was 100% resistance of all mrsa isolates to flucloxacillin and coamoxiclav , as expected .\nninety - eight percent of isolates were resistant to ciprofloxacin , but of these samples , there was 97.2% sensitivity for nitrofurantoin and 92.4% sensitivity for trimethoprim ( fig .\noverall , there was only 2.7% resistance for nitrofurantoin , but all of these samples were sensitive to trimethoprim .\ntrimethoprim itself had a 7.4% resistance level , but all of these samples were sensitive to nitrofurantoin , meaning that no sample was resistant to both oral agents , that is , nitrofurantoin and trimethoprim .\nthere was a statistically significant association between nitrofurantoin resistance and younger patients , in that 75% of patients with nitrofurantoin resistance were younger than 70 years ( p  =  0.025 ) .\nthere was no statistically significant association between age and resistance profile in any other of the antimicrobial panel .\nthe impact of mrsa is considerable ; in ireland , approximately 40% to 50% of isolates sa recovered from bloodstream infections are methicillin resistant . despite available publications and guidelines on the management of mrsa skin - colonized patients ,\nlittle has been published on the colonization of urine from patients with indwelling urinary catheters .\nthe identification of an mrsa isolate in a urine culture has important ramifications for patients , both in the community and in the hospital setting .\na recent study demonstrated that 22% of patients with mrsa bacteriuria went on to develop invasive mrsa infection within 12 months .\nmrsa in urine clearly warrants treatment in symptomatic patients , but even in asymptomatic patients , it may require eradication before certain elective procedures  such as endourological surgery .\nit also has consequences for patients and health care providers when it comes to providing isolation and other barrier precautions that should be administered in a nosocomial setting .\nthe european association of urology guidelines outlines that colonization with microorganisms is a special risk factor for urological procedures ( http://uroweb.org/guideline/urological-infections/ ) , and furthermore , that an indwelling catheter is one of the most important risk factors for complications .\npatients with asymptomatic bacteriuria who undergo traumatic genitourinary procedures associated with mucosal bleeding have a high rate of post - procedure bacteremia and sepsis .\nbacteremia occurs in up to 60% of bacteriuric patients who undergo transurethral prostatic resection , and sepsis is clinically confirmed in 6% to 10% of these patients .\nretrospective analysis and prospective , randomized clinical trials support the effectiveness of antimicrobial treatment in preventing these complications in bacteriuric men undergoing transurethral resection of the prostate .\nthere is little information relevant to other genitourinary procedures , but any intervention with a high probability of mucosal bleeding should be considered as a risk for post - procedure sepsis  and treatment of mrsa bacteriuria should be considered .\nsome studies have documented that eradication of asymptomatic bacteriuria is not required before nonurologic procedures , such as arthroplasty  but s. aureus is the most pathogenic of all staphylococci and this study did not include patients with mrsa bacteriuria .\nour study would suggest that when it comes to urine - colonizing mrsa eradication , or for treating a patient who is not critically unwell , oral therapy with nitrofurantoin or trimethoprim would be a suitable first - line agent , as none of the patients in our cohort were resistant to both trimethoprim and nitrofurantoin . in the unwell or septic patient , vancomycin or teicoplanin\ninterestingly , less than one - third ( 32.5% ) of our mrsa urine samples came from hospital inpatient sources , implying that mrsa bacteriuria diagnosis is more frequently a community - based phenomenon .\nnational recommendations dictate that hospital patients colonized with mrsa should be isolated in single rooms  and expert opinion would surmise that there is an increased risk of spread from mrsa - colonized catheterized patients  due to increased interventions and manipulations required from staff ( e.g. changing catheter drainage devices ) .\nhowever , within the community , these patients are not recommended to be isolated as would happen within the nosocomial environment and this could contribute to further bacterial spread\n. the limitations of our study include its retrospective nature  which meant that causation was not addressed , and not all key information was available to our research group .\nalso , acting as a potential confounder is the fact that mrsa bacteriuria is not a common pathology \nmeaning we had only small number of urine isolates ( 167 from 106 patients ) despite the large sample size ( 425,013 ) . to this author 's knowledge\n, there are no prospective mrsa bacteriuria studies underway  and a supra - regional or national study of this type could provide further relevant data in this field ."}
{"lay_summary": " introductionacquired angioedema ( aae ) , an acquired deficiency of c1esterase inhibitor , is a medically treatable condition which can cause severe abdominal pain mimicking an acute surgical abdomen . \n this disorder is strongly associated with chronic lymphocytic leukemia ( cll ) and other indolent lymphoplasmacytic disorders.discussionwe describe a patient with known cll who developed incapacitating , recurrent severe abdominal pains , culminating in partial bowel resection . \n signs , symptoms , laboratory and pathologic findings demonstrated aae.conclusionwider appreciation of the possibility of aae , particularly in patients with lymphoproliferative disorders , could lead to preventive therapy and spare unnecessary surgery . \n this is more important now that more effective medical therapies are available . ", "article": "acquired angioedema ( aae ) , an acquired deficiency of c1esterase inhibitor , is a medically treatable condition which can cause severe abdominal pain mimicking an acute surgical abdomen .\nthis disorder is strongly associated with chronic lymphocytic leukemia ( cll ) and other indolent lymphoplasmacytic disorders .\nwe describe a patient with known cll who developed incapacitating , recurrent severe abdominal pains , culminating in partial bowel resection .\nwider appreciation of the possibility of aae , particularly in patients with lymphoproliferative disorders , could lead to preventive therapy and spare unnecessary surgery .\nacquired angioedema ( aae ) is due to acquired deficiency of c1 inhibitor ( c1inh ) , resulting in excessive complement and bradykinin activities .\nblood vessel permeability is increased ; thus , angioedema occurs . just as with hereditary angioedema ( hereditary c1inh deficiency ; hae ) , common clinical manifestations are skin swelling , laryngeal edema , and/or abdominal pain.1,2 aae often occurs in the context of lymphoplasmacytic disorders , such as monoclonal gammopathy of unknown significance ( mgus ) , non - hodgkin s lymphoma , or chronic lymphocytic leukemia ( cll).1,3 among 32 patients with aae , castelli found that 13 ( 40% ) had mgus and 9 ( 28% ) had lymphoproliferative disease.3 therefore , all cases of aae should be evaluated for the possibility of underlying lymphoplasmacytic disorder .\nconversely , when patients with known lymphoproliferative disease manifest compatible symptoms , aae should be expeditiously considered .\nthis is important because aae can be effectively treated medically , but delayed diagnosis can lead to unnecessary diagnostic procedures , therapeutic interventions , or life - threatening complications , well - illustrated by our case .\na 78-year - old woman with atherosclerotic vascular disease was transferred to our hospital with abdominal pain and underwent emergent laparotomy .\none year earlier , she had been diagnosed with rai stage i cll which had been observed without treatment .\ntwo months earlier , she presented with severe abdominal pain , nausea , and vomiting . over the next 8  weeks , she had six emergency room and/or hospital admissions for identical symptoms .\npains would begin at rest in the lower abdomen , spread to the upper abdomen , described as  gas - like  , non - radiating , constant .\nextensive evaluation included colonoscopy , endoscopic retrograde cholangiopancreatography , magnetic resonance angiography , and abdominal aortography .\nbenign colon polyps and small gallstones were removed , mesenteric stenoses ruled out , yet pains recurred unabated .\nthere was no dysphagia , change in bowel habits , gi bleeding , fever , or sweats .\nphysical examination on transfer revealed blood pressure 130/88  mmhg , pulse 88 beats per minute , respiratory rate 20  cycles per minute , pulse oximetry of 95% on ambient air , and temperature 97.0f .\nhemoglobin was 18.1  g / dl , hematocrit 55% , platelets 146    10/l , and leukocytes elevated to 34,500 cells/l with 47% neutrophils and 48% lymphocytes .\nct scan of abdomen and pelvis with iv contrast showed multiple abnormal loops of small bowel with contrast - enhanced bowel wall edema ( fig . \n. 1a ct scan of abdomen and pelvis with intravenous contrast shows several abnormal loops of small bowel with a target appearance indicating bowel wall edema .\nb a section of small bowel shows massive submucosal edema . there is no infiltration of the wall by lymphocytes a ct scan of abdomen and pelvis with intravenous contrast shows several abnormal loops of small bowel with a target appearance indicating bowel wall edema .\nb a section of small bowel shows massive submucosal edema . there is no infiltration of the wall by lymphocytes at laparotomy , massively swollen small bowel was encountered and resected .\nc4 was 3  mg / dl ( normal 1746 ) , c3 66  mg / dl ( 85200 ) , and c1inh activity reportedly 83% ( 68200% ) .\nserum protein electrophoresis revealed two faint bands immunofixing as monoclonal igm kappa and igg kappa .\nlymphocytosis and lymphadenopathy improved and c1inh activity increased to 110% . over 3  years of follow - up , abdominal symptoms never recurred .\napproximately 145 cases have been reported of aae,3 and this is one of four cases that we have diagnosed in the last decade with abdominal pains from aae with associated cll .\ntable  1 shows characteristics of patients with cll and aae we have seen ( some briefly mentioned in a prior report).4 this is our only case to undergo surgery , allowing unique and dramatic demonstration of massive bowel edema visible radiographically , on surgical inspection and on histopathology .\nan initial c1inh activity was reported low normal , but there can be no doubt about the diagnosis based on radiologic / surgical / histologic findings , further laboratory results , and the clinical course .\ncharacteristic are very low c4 level and low c3 ; diagnostic recommendations currently add c1q and anti - c1inh antibody levels .\nautoantibody is demonstrable in up to 70% with aae.1 our patient had monoclonal gammopathy , which frequently corresponds to the c1inh autoantibody .\npatients with the hereditary form ( hae ) usually manifest before age 20 and give a family history of symptoms . in all our patients with cll and aae , chemotherapy and androgens increased c1inh and produced durable remission.table 1characteristics of patients with aaepatientunderlying diagnosismanifestations of acquired angioedemamonths before diagnosislaboratory valuesinterventions prior to diagnosistreatmentangioeedema episodes post - treatment ( years of follow - up)pretreatmentpost - treatment78  years old / fcllrecurrent abdominal pain2c1 inh activity : 83% ( 68200)c1 inh activity : 110% ( 68200)exploratory laparotomy with small bowel resectionchemotherapydanazolnone ( 3  years)c4 : 3  mg / dl ( 1746)ct scanc3 : 66  mg / dl ( 85200)colonoscopysmall monoclonal gammopathyercpmraabdominal aortography74  years old / fsll / cllrecurrent abdominal pain24c1 inh activity : 1% ( 68200%)c1 inh activity : 117% ( 68200%)ct scanchemotherapynone ( 6  years)episodic oropharyngeal swellingc1 inh quantitative : 6.7  mg / dl ( > 11  mg / dl)c1 inh quantitative : 21  mg / dl ( 1025)colonoscopydanazolc4 : 13  mg / dl ( 1647)c3 : 70  mg / dl ( 75161)small monoclonal gammopathy61  years old / mcllrecurrent abdominal pain5c1 inh activity : 4% ( 68200%)not availablect scanchemotherapynone ( 10  years)small monoclonal gammopathycolonoscopydanazol67  years\nold / mcllrecurrent abdominal pain3c1 inh activity : 6%(68200)c1 inh quantitative : 38  mg / dl ( 2139)colonoscopychemotherapynone ( 3  months)oropharyngeal swellingc1 inh quantitative : 3  mg / dl ( 2139)laryngoscopydanazolc1q : 3.6  mg / dl ( 58.6)c4 : < 2  mg / dl ( 1746)small monoclonal gammopathy characteristics of patients with aae angioedema should be borne in mind among  medical  illnesses that can mimic acute surgical abdomen , along with such other disorders as porphyria , familial mediterranean fever and sickle cell disease ( fig .  2 ) .\none may need to discern whether a true surgical emergency might supervene even when one of these disorders is present .\nour patient had typical symptoms of acute bowel edema , including diffuse abdominal pain , occasionally rebound tenderness and vomiting , with spontaneous resolution within 15  days.1,2 some patients with aae have cutaneous or upper respiratory edema in addition , or instead of , bowel symptoms .\nbecause of cardiovascular comorbidities , there was a high suspicion for ischemic bowel in our patient , but radiography and endoscopy did not support this . in the differential diagnosis ,\nangiotensin - converting enzyme inhibitors rarely precipitate angioedema , but our patient had taken benazepril many years and continued it without incident after aae therapy.fig .\n2algorithm for diagnosis and treatment for suspected aae algorithm for diagnosis and treatment for suspected aae in 2009 , the us fda approved the c1inh concentrate berinert p and the kallikrein inhibitor ecallantide ( kalbitor ) for treatment of acute attacks , and the c1inh concentrate cinryze for prophylaxis in severely affected patients.5 fresh frozen plasma can be given when these are unavailable .\nc1inh concentrates are highly safe and effective ; the standard of care for decades in other countries , but us approval was delayed by concerns of virus transmissibility.1,59 doses used in the clinical hae trials may need to be higher for aae because of increased enzyme clearance .\na bradykinin b2 receptor antagonist icatibant ( firazyr ) is under investigation . for long - term control ,\ncommonly used for prophylaxis are anti - fibrinolytic drugs or the attenuated androgen danazol , which increases c1inh synthesis at low cost.10 in conclusion , earlier suspicion for aae in our known cll patient could have spared her the morbidities of recurrent abdominal pains , hospitalizations , morbid interventions , and bowel resection .\nwider appreciation of this disorder takes on added importance as our ability to effectively treat the problem has grown ."}
{"lay_summary": " purpose : distal clavicle fracture associated with complete coracoclavicular ligament disruption represents an unstable injury , and osteosynthesis is recommended . \n this study was performed ( 1 ) to retrospectively analyse the clinico - radiological outcomes of two internal fixation techniques , and ( 2 ) to identify and analyse radiographic fracture patterns of fracture that are associated with this injury.materials and methods : a total of 15 patients underwent osteosynthesis with either ( 1 ) acromioclavicular joint - spanning implants ( group 1 , hook plate device , n = 10 ) or ( 2 ) joint - sparing implants ( group 2 , distal radius plate , n = 5 ) ; these were reviewed at a mean period of 26.1 months ( 12 to 40 months ) . \n clinical outcomes were measured using constant score ( cs ) , simple shoulder test ( sst ) , and walch acj score ( ws ) . \n radiographs and ultrasonography were used to assess the glenohumeral and acromioclavicular joints , and the subacromial space . \n preoperative radiographs were analyzed for assessment of fracture lines to identify radiographic patterns . \n statistical analysis of the data was performed to determine any significant differences between the two groups.results:the overall clinical outcome was satisfactory ( cs 80.8 , sst 11.3 , ws 17.6 ) and a high union rate ( 93.3% ) was observed . \n radiographic complications ( acromioclavicular degeneration and subluxation , hook migration , abnormal ossification ) did not negatively influence the final clinical outcomes . \n four distinct radiographic fracture patterns were observed . \n a statistically significant difference ( p < 0.05 ) was observed in the reoperation rates between the two groups.conclusions:internal fixation of this fracture pattern is associated with a high union rate and favorable clinical outcomes with both techniques . \n a combination of distal radius plate and ligament reconstruction device resulted in stable fixation and significantly lower reoperation rates , and should be used when fracture geometry permits ( types 1 and 2).design : retrospective review of a consecutive clinical case series.setting:level 1 academic trauma service , public hospital . ", "article": "distal clavicle fractures associated with partial and complete coracoclavicular ligament disruption are potentially unstable , and non - operative treatment of these fractures is associated with a high non - union rate.[13 ] partial ligament disruptions ( conoid or trapezoid ) retain some inherent stability , and should be distinguished from complete dual ligament disruptions that result in an uncommon and highly unstable subgroup\n. internal fixation of these fractures necessitates the use of acromioclavicular joint spanning implants ( clavicle hook plate , synthes , usa ) that overcome distraction forces by subacromial leverage ; however , subacromial / acromioclavicular joint encroachment with these implants is associated with subacromial pathology , and this may negatively influence the final outcomes . to overcome the shortcomings of the joint - spanning implants , acromioclavicular joint - sparing implants ( 2.4 mm lcp distal radius plates , synthes , usa ) have been suggested .\nadditionally , a combination of this implant with some form of coracoclavicular fixation using sutures / anchors / endobutton devices ( tightrope , arthrex , fl , usa ) has been recently described for use in the highly unstable fracture subgroup .\nhowever , comparative clinico - radiological outcomes of the two techniques are lacking in literature .\nthe purpose of this study was ( 1 ) to analyze the overall and comparative clinico - radiological outcomes ( radiographic and ultrasonographic ) of surgical treatment of distal clavicle fractures associated with complete coracoclavicular ligament disruption , and ( 2 ) to identify and analyze radiographic patterns of fracture and comminution that are associated with this injury .\nthe hospital records of all patients who were surgically treated for lateral clavicle fractures between 2005 and 2008 at three hospitals were retrospectively evaluated to identify the study group .\ninclusion criteria for this study was defined as : ( i ) acute , isolated , non - comminuted and comminuted fractures of the lateral clavicle , ( ii ) complete disruption of both coracoclavicular ligaments , confirmed on radiographs and at surgery , ( iii ) absence of concomitant or pre - existing subacromial pathology ( rotator cuff tears , acromial undersurface degeneration ) , ( iv ) surgical treatment with either a joint - spanning implant alone ( group 1 ) , or combination of a joint - sparing implant and coracoclavicular fixation with either endobutton device , suture anchor , or coracoid cerclage ( group 2 ) [ figures 1a and b ] , and ( v ) follow - up period of at least 6 months for radiographic evidence of union .\nexclusion criteria was defined as : ( i ) partial disruption of the coracoclavicular ligaments at surgery , ( ii ) subacromial pathology ( iii ) concomitant injuries to the ipsilateral shoulder girdle , ( iv ) surgical treatment with any technique other than those described in the inclusion criteria , and ( v ) follow - up period inadequate for complete union .\nsurgical treatment of an unstable distal clavicle fracture with a joint - spanning implant ( group 1 ) .\n( hk : hook plate , cl : clavicle , m : medial fragment , l : lateral fragment , arrow : fracture line , ac : acromion , h : humeral head , co : coracoid process ) surgical treatment of an unstable distal clavicle fracture with a joint - sparing implant and coracoclavicular ligament reconstruction using endobutton device ( group 2 ) .\n( rp : locking distal radius plate , arrow : acromioclavicular joint , ac : acromion , cl : clavicle , en : endobutton , h : humeral head ) the clinical records and operative notes were analyzed to identify patients that satisfied the criteria described above , and all other lateral clavicle fracture patients were excluded .\npre - operative radiographs of the study group were obtained and analyzed with a graphic analysis software ; fracture lines were traced to identify involvement of the acromioclavicular joint , lateral fragment integrity , and presence / absence of comminution .\nthe follow - up clinical protocol included a subjective evaluation of pain and functional status by interview , evaluation of active and passive range of motion by clinical examination , and evaluation of muscle strength in elevation and external rotation using a portable dynamometer .\nclinical acromioclavicular joint tests ( tenderness and paxinos sign ) and rotator cuff tests ( lag signs , bear - hug test , impingement signs ) were used to evaluate these structures.[811 ] clinical outcome measures included ( i ) simple shoulder test , ( ii ) constant and murley shoulder score , and ( iii ) walch acromioclavicular joint score . the follow - up radiographic protocol consisted of standardized radiographs that included a true glenohumeral anteroposterior view ( neutral rotation , elbow by the side ) , and a weight bearing comparative cephalic - tilt view ; these were analyzed for implant migration , acromioclavicular joint pathology ( degeneration , instability ) , subacromial changes ( degeneration , osteolysis ) , acromiohumeral interval measurement ( normal interval = 7 mm or more ) , peri - coracoid changes ( abnormal bone formation ) , and glenohumeral changes .\nin addition , in those cases where implant had been previously removed , past radiographs were obtained from the records and individually analyzed as described above .\nthe follow - up ultrasonographic protocol included evaluation of the acromioclavicular joint , subacromial space , glenohumeral joint , bicipital groove and biceps long tendon , and suprascapular and spinoglenoid notches ; ultrasound assessment was performed by a senior radiologist experienced in shoulder ultrasound .\nstatistical analysis was performed using a statistical software ( spss inc , chicago , usa ) to determine mean values and range of measured parameters of the overall and implant specific groups .\nsignificant differences between clinical and radiological parameters were determined using the non - parametric mann - whitney / wilcoxon rank - sum test for numerical data , and the fisher 's exact test for categorical data .\nthe average age of the patients in the study group was 34.5 years ( range , 20 to 57 years ) .\nthe mechanism of injury was a direct impact to the ipsilateral shoulder sustained during a fall ; in 8 patients , the fracture was sustained during a cycling - related sporting activity ( competitive or recreational ) .\nten patients were operated using a joint - spanning implant ( group 1 ) and 5 were operated using a joint - sparing implant technique ( group 2 ) .\nthe mean follow - up period was 26.1 months ( range , 12 to 40 months ) .\nthe overall and group - specific clinico - radiological outcomes and the types and distribution of fracture patterns are summarized in table 1 .\noverall and group.specific clinico.radiological outcomes and fracture patterns clinical outcomes : the mean cs was marginally higher in group 2 , while the mean sst score was marginally higher in group 1 ; none of these differences were statistically significant .\nacromioclavicular joint signs were positive in half of the group 1 patients , and in none in group 2 ; however , the walch scores for the acromioclavicular joint were not significantly different for the two groups .\nreturn to pre - operative level of recreational and competitive sports was seen in approximately two - thirds of the patients of group 1 , and all patients of group 2 ; this difference was not found to be statistically significant .\nreoperation rates related to implant removal were significantly higher ( p < 0.05 ) in group 1 patients ( 90 % ) as compared to group 2 ( 0% ) .\nradiographic outcomes [ figure 2a - d ] : radiographic union was observed in 93.3% of fractures ( 9 in group 1 , 5 in group 2 ) with only one non - union with subsequent fragment resorption ( group 1 ) .\nradiographic acromioclavicular joint degeneration was present in 3 patients ( group 1 ) ; all 3 patients had a clinically symptomatic ac joint .\nradiographic acromioclavicular joint superior subluxation was present in 4 patients ( group 1 = 1 patient , 10% ; group 2 = 3 patients , 60% ) ; none of these were clinically symptomatic .\nsubacromial osteolysis and hook migration were seen in 5 patients ( group 1 ) ; implant removal was necessary in 4 of these 5 patients , and at final follow - up , resolution of the radiographic subacromial osteolytic lesions was observed .\nsigns of progressive implant loosening ( screws and/or plate disengagement ) were seen in 3 patients ( group 1 ) .\nabnormal bone formation was present in 7 patients ( group 1 = 6 , group 2 = 1 ) .\n( b ) acromioclavicular joint subluxation ( arrows ) , ( c ) hook migration and osteolysis of acromial undersurface ( arrow ) , ( d ) peri - coracoid ossification ( arrows ) .\n( ac : acromion , cl : clavicle , co : coracoid , p : plate , an : suture anchor , g : glenoid , h : humeral head , hk : hook plate , ahi : acromiohumeral interval ) ultrasonographic outcomes [ figure 3a and b ] : supraspinatus lesions were seen in 3 patients ; these included partial articular - side tears ( group 1 = 1 patient , 10% ; group 2 = 1 patient , 20% ) , and supraspinatus bursal - side degenerative changes ( group 1 = 1 patient , 10% ) .\nacromioclavicular joint screw penetration was observed in 1 patient ( group 2 ) ; this penetration was not apparent on plain radiographs and the patient was asymptomatic at the final follow - up .\nno abnormalities were detected in the subacromial bursa on static ultrasound evaluation ; dynamic testing revealed abnormal subacromial bursal \" bunching \" with arm abduction in 2 patients ( group 1 = 1 , group 2 = 1 ) .\n( a ) partial articular - surface supraspinatus tendon avulsion ( black arrows ) ( b ) screw penetration into the acromioclavicular joint ( arrows ) .\n( gt : greater tuberosity , h : humeral head , ss : supraspinatus , ac : acromion , cl : clavicle , asterix : acromioclavicular joint ) radiographic evaluation of fracture comminution revealed 5 non - comminuted fractures ( group 1 = 2 , group 2 = 3 ) , and 10 comminuted fractures ( group 1 = 8 , group 2 = 2 ) .\nanalysis of the fracture lines and fragment cortices revealed repetitive patterns in the fracture geometry , and four types could be identified : ( i ) type 1 pattern ( n = 5 , 33% ) involved a clean vertical or a short oblique type bicortical fracture line without any comminution [ figure 4a ] , ( ii ) type 2 pattern ( n = 4 , 27% ) involved a zone of segmental comminution , between intact bicortical lateral and medial fragments [ figure 4b ] , ( iii ) type 3 pattern ( n = 5 , 33% ) involved propogation of at least one fracture line into the juxta - articular cortex of the ac joint [ figure 4c ] and ( iv ) type 4 pattern ( n = 1 , 7% ) consisted of fracture line propogation into the acromioclavicular joint [ figure 4d ] .\nradiographic fracture patterns : ( a ) type 1 , ( b ) type 2 , ( c ) type 3 , and ( d ) type 4 .\n( ac : acromion , cl : clavicle , co : coracoid , g : glenoid , h : humeral head , arrows : fracture lines )\nthe present study is the first study that describes overall and comparative outcomes ( clinical , radiographic , and ultrasonographic ) of surgical treatment of an uncommon lateral clavicular bony - ligamentous injury with joint - spanning and joint - sparing implants .\nin addition , four radiographic patterns of bone injury were identified to develop guidelines for choice of implants in these injuries . clinical outcomes and union rates after operative treatment of this injury\nare satisfactory , and this has been shown in other studies in literature . in the present study , both types of implants resulted in satisfactory and comparable clinical outcome scores , irrespective of the radiographic outcomes .\nhowever , a significant difference in the reoperation rate for implant removal ( p < 0.05 ) in patients treated with a joint - spanning implant probably implies that a joint - sparing implant could be preferentially used whenever fracture geometry permits .\nradiological outcomes , especially those associated with joint sparing techniques , have not been well documented in other studies .\nsubluxation of the acromioclavicular joint , ( present in 60% of group 2 patients ) may be related to either concomitant injury to the acromioclavicular ligaments , or to a partial failure of the coracoclavicular ligament reconstruction ; transfer of distraction forces to ac ligaments after fracture union may then induce gradual subluxation of this joint .\nthis complication was rare in the other group , probably due to the joint spanning implant design ; however , other radiological abnormalities like hook migration , subacromial osteolysis , implant loosening , and new bone formation were frequent .\nthe acromioclavicular joint spanning hook plate is a commonly used implant , and most studies have utilized this as the sole implant of choice .\nalthough clinical outcomes in these studies have been satisfactory , the effect of the subacromial hook on bursal tissues has been debated and use of the distal clavicle plate suggested . by using ultrasonographic evaluation , this study demonstrated the safety of the joint - spanning hook plate in relation to rotator cuff and subacromial bursa .\npersistent pain in the post - operative period probably resulted from acromial undersurface irritation ; early plate removal after fracture union is recommended , and long - term clinical outcomes seem to be satisfactory after implant removal .\nan important finding of this study is the grouping of the radiographic fracture patterns into four surgically relevant types .\ntypes 1 and 2 are ideal indications for use of a joint - sparing implant ; adequate bone stock in the distal fragment in these types will theoretically permit secure fixation across the fracture site . in types 3 and 4\n, inadequate distal fragment size may not permit secure bicortical fixation , thereby necessitating use of joint - spanning implants .\n. the retrospective nature and small sample size does not permit identification of all possible fracture configurations , and statistical analysis may differ with larger numbers .\nhowever , the clinical results are similar to other literature studies that have analyzed joint - spanning implants . also , the current radiographic patterns described provide guidelines for implant choice , and are not intended to be used as a prognostic classification .\nwe attribute the small size of the study group to the stringent inclusion and exclusion criteria that eliminated several other patients with lateral clavicle fractures , and this was necessary to obtain meaningful conclusions\n. lateral clavicle fractures with complete disruption of the coracoclavicular ligaments should be regarded as a distinct entity that is perhaps biomechanically and prognostically different from similar fractures with partial ligament disruption .\na combination of a locking distal radius plate with coracoclavicular ligament reconstruction resulted in stable fixation and significantly lower reoperation rates , and should be used preferentially in lesser comminuted fractures ( types 1 and 2 ) ."}
{"lay_summary": " a 68-year - old woman who suffered from polycythemia vera presented at our clinic with the chief complaints of pain , swelling , and a warm sensation in her left thigh . \n she had undergone a left bipolar hemiarthroplasty following a hip fracture 24 days prior to this presentation . \n her erythrocyte sedimentation rate and c - reactive protein ( crp ) levels were elevated . \n in addition , a postoperative infection was suspected in the 3-phase bone scan ; therefore , she received intravenous antibiotic therapy . \n this approach proved to be ineffective and she was subsequently diagnosed with a deep vein thrombosis via color doppler ultrasonography . \n it is interesting to note that a deep vein thrombosis can present with symptoms similar to those of a postoperative infection . \n furthermore , an elevated crp level is frequently observed in patients suffering from polycythemia vera . \n therefore , the two conditions , which require completely different treatments , can be confused . \n we report on this case with a review of the relevant literature . ", "article": "a 68-year - old woman visited the clinic with the chief complaints of pain , swelling , and a warm sensation in her left thigh for over 2 days prior to her visit .\nthe patient also complained about a warm sensation during the nighttime but body temperature was normal when measured in the clinic .\nshe had undergone a left bipolar hemiarthroplasty following a hip fracture 24 days prior to the current visit and was wearing compression stockings to prevent the occurrence of a deep vein thrombosis .\nshe had been taking aspirin 100 mg daily , fexonadine 180 mg daily , and hydrea 500 mg twice a day for a diagnosis of polycythemia vera for 1 year and was phlebotomized in a hemato - oncology setting on an irregular basis . in advance of the operation , her erythrocyte sedimentation rate ( esr ) , and c - reactive protein ( crp ) levels were 30 mm / hr and 4.99 mg / dl , respectively .\nthree days after her hip surgery , her esr and crp levels were 23 mm / hr and 6.35 mg / dl , respectively .\nmedical care was administered in close cooperation with the hemato - oncology department and the level of hemoglobin was maintained at < 12 g / dl to prevent a thrombosis prior to her operation .\nthe patient did not have a fever and her skin color seemed normal despite swelling and a slight warm sensation in the left hip and proximal femur .\nresults of a blood test showed that her complete blood count , electrolyte levels , and liver function were all within normal ranges ( white blood cell count [ wbc ] : 4,700/l , hemoglobin : 10.6 g / dl , hematocrit : 32.3% , platelet : 213,000/l , neutrophil count 67.2% , lymphocyte 24.1% , monocyte 6.8% ) whereas the esr and crp level were 38 mm / hr and 8.25 mg / dl , respectively . when compared to tests performed previously , no further observations of additional fractures , signs of infection , or loosening of inserts after the surgery\nacute or sub - acute inflammation was diagnosed given the perfusion image of soft tissue in the left hip area as well as the blood pool image ( fig .\nthe patient was injected intravenously with antibiotics for 1 week while staying in the hospital , however , symptoms were not alleviated . in order to prevent a deep vein thrombosis , the patient started to move with the aid of a wheelchair and exercised her knee joints 3 days after the operation .\ng / dl , a color doppler ultrasonography was performed due to her history of polycythemia vera .\nresults revealed a deep vein thrombosis in the common femoral vein as well as in the superficial femoral vein ( fig .\nsymptoms were alleviated following the administration of low - molecular - weight heparin ( enoxaparin , 40 mg ) and warfarin ( 5 mg ) for 5 days .\nadditional warfarin was prescribed ( 2.5 mg daily ) for maintenance at discharge . during her first follow - up visit 2 weeks later , no symptoms were noted and all blood test parameters were within normal ranges .\nit has been reported that patients with polycythemia vera present with various complications related to thrombosis due to excessive blood viscosity1 ) .\nseveral putative reasons have been postulated to explain such complications including hypervolemia , an increase in the volume of red blood cells , telangiectasia due to decreased blood flow velocity as well as vascular elasticity , thrombocytosis , and complex hemostatic disorders attributable to inefficient blood clotting processes2 ) .\nthrombosis is the leading cause of death in those with polycythemia vera and has been associated with high morbidity as well .\napproximately 12 - 49% of patients with polycythemia vera experience thrombosis and 20 - 40% will die as a result2 ) .\nthromboembolism is one of the major complications of hip surgery and contributes to its poor prognosis .\nwarwick et al.3 ) reported that the incidence rate for a deep vein thrombosis was about 1.89% if proper medication was not provided after total hip arthroplasty .\ntherefore , in the case of the patient described in the current case report , it was reasonable to expect that she would be susceptible to the high incidence rate of thrombosis as she underwent the hip surgery based on her history of polycythemia vera . for prophylactic purposes ,\naspirin was administrated ( 100 mg daily ) and early exercise and active movements were recommended for the patient in order to lower the risk of venous thromboembolism . in the current case report , a patient with polycythemia vera exhibited clinical symptoms and signs of a postoperative infection following bipolar hemiarthroplasty due to femoral neck fractures .\nthere was , however , a deep vein thrombosis which rendered the intravenous administration of antibiotics ineffective in the alleviation of symptoms .\nearly symptoms of a deep vein thrombosis , including swelling , pain , oppressive pain , and a warm sensation , can mimic those of a postoperative infection .\nfurthermore , features of systematic inflammatory responses such as increased levels of interleukin-6 , interleukin-8 , and crp may be observed in patients with a deep vein thrombosis .\ncollectively , these findings suggest that appropriate clinical examinations are warranted at an early stage in order to avoid making an inaccurate diagnosis4,5 ) . on the first visit after the operation ,\nthe patient was suspected to have had a postoperative infection due to the simultaneous increase in esr and crp levels\n. however , the specificity of esr and cpr levels pertaining to the diagnosis of infections is questionable , as most patients display elevated levels of esr and crp following a hip surgery6 ) .\nthese inflammatory responses stimulate the production of cytokines due to the fractures and operation per se , thus biochemical parameters for inflammation are known to be elevated in a non - specific manner . in cases without postoperative infections , elevated crp levels recover to the normal range within 3 weeks of the operation6,7 ) . in the current case report , the elevated crp level that was maintained for up to 24 days after the operation led us to suspect a postoperative infection .\nhowever , the abnormally increased level of acute phase reactants ( e.g. , crp ) may be observed in patients with chronic myeloproliferative diseases ( e.g. , polycythemia vera ) and therefore further specific clinical examinations are required for an infectious diagnosis8 ) . regarding the diagnosis of a postoperative infection ,\nelevated level of serum procalcitonin may be more valuable than wbcs and crp levels7 ) .\nregrettably , the level of serum procalcitonin was not measured in the current case but could have been informative in distinguishing between postoperative infection and a deep vein thrombosis . despite the presentation of similar clinical symptoms between a postoperative infection and a deep vein thrombosis , their etiological mechanisms are completely distinct . therefore ,\ndifferent treatments are warranted , as patients receiving inappropriate medical treatments may experience exacerbated symptoms and conditions .\nthe potential for a deep vein thrombosis requires continuous thought and attention regarding relevant examinations for patients at high risk for thrombosis as well as for embolism ( e.g. , polycythemia vera ) ."}
